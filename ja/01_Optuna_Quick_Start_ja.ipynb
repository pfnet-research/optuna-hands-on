{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"01_Optuna_Quick_Start_ja.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"id":"33Z9NHT6_Eva"},"source":["<img src=\"files/logo.jpg\"/>\n","\n","## はじめに\n","\n","このOptunaの基本的な使い方に関するハンズオンは、Google Colaboratry で書かれたノートブックに沿って進めます。Google Colaboratry ではブラウザ上で Python プログラムを実行することができます。\n","\n","試しに以下のコードを実行してみましょう。"]},{"cell_type":"code","metadata":{"id":"1HEtAqHm_EFP"},"source":["print('Hello Notebook!')  # shift + enter で実行できます"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AEomu83y6MCG"},"source":["このノートブックで使うモジュールをインポートしておきましょう。\n","\n"]},{"cell_type":"code","metadata":{"id":"Ow12BEEu6MRQ"},"source":["!pip install optuna\n","\n","import optuna\n","import sklearn\n","import sklearn.datasets\n","import sklearn.linear_model\n","import sklearn.metrics"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ISBJderOrqAc"},"source":["## 機械学習の復習\n","\n","このハンズオンでは機械学習の基礎的な知識が必要となります。\n","少なくとも次のキーワードを復習した上で読むようにしてください。\n","\n","*   ***モデル (model)***\n","*   ***パラメタ (parameter)***\n","*   ***ハイパーパラメータ (hyperparameter)***\n","*   ***線形回帰 (regression)***\n","*   ***正則化 (regularization)***\n","*   ***精度 (accuracy)***\n","*   ***訓練集合 (training set)***\n","*   ***評価集合 (validation set)***\n","*   ***scikit-learn***\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JZbrgJyM1cv1"},"source":["例題として、住宅価格を予測する機械学習モデルを学習・評価してみましょう。\n","Boston データセットにはボストン市内における 150 地域のデータが含まれており、各地域について不動産税率や平均住宅価格など 14 項目の数値が記録されています。そこで、13 個の入力変数から地域の平均住宅価格を予測する線形回帰モデルを学習させます。\n","\n","scikit-learn を使うと、上記の処理を簡潔に書くことができます。"]},{"cell_type":"code","metadata":{"id":"sr8kKOZL_8gI"},"source":["# ボストン物件価格のデータセットをロードする\n","#     X: 各行が地域に、各列がそれぞれの入力変数に対応 (506 * 13 の行列)\n","#     y: 各個体のラベル (506 要素のベクトル)\n","X, y = sklearn.datasets.load_boston(return_X_y=True)\n","\n","# データセットを訓練用と評価用に分割する\n","#     X_train, y_train: 訓練用データセット\n","#     X_val, y_val: 評価用データセット\n","X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, random_state=0)\n","\n","# 線形回帰オブジェクトの初期化\n","#     L1 正則化 (Lasso) を適用\n","#     alpha は正則化の強さに対応するハイパーパラメータ\n","alpha = 1.0\n","model = sklearn.linear_model.Lasso(alpha=alpha)\n","\n","# 訓練用データセットで学習する\n","model.fit(X_train, y_train)\n","\n","# 評価用データセットの出力を予測する\n","y_pred = model.predict(X_val)\n","\n","# モデルの性能を評価する\n","error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n","\n","print(error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"598EfjY8A050"},"source":["## 目的関数を書く\n","\n","まずは簡単な二次関数の最小化問題を考えてみましょう。\n","$(x - 2) ^ 2$ が最小となる $x$ を求める問題です。\n","$(x - 2) ^ 2$ のような最小化対象の関数を**目的関数** ***(objective function)*** と呼びます。\n","以下のコードを実行して目的関数を定義してみましょう。"]},{"cell_type":"code","metadata":{"id":"OCe84eX7AGl-"},"source":["def objective(x):\n","    return (x - 2) ** 2"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZrLZnBZcDokz"},"source":["人間は $x = 2$ が答えであると解りますが、Optuna はこの問題の解き方を知りません。\n","そこで実際に複数の $x$ を代入して出力を計算し、出力が最小となった $x$ が最も良い解であると判断します。\n","以下のような計算をするイメージです。"]},{"cell_type":"code","metadata":{"id":"DeSfeuf2BWir"},"source":["import random\n","\n","outputs = []  # 計算結果を保存しておくリスト\n","\n","# 区間　[-100, 100]　から適当な x を 20 パターン試す\n","for _ in range(20):\n","    x = random.uniform(-100, 100)\n","    objective_value = objective(x)\n","    outputs.append(objective_value)\n","\n","minimum_output = min(outputs)\n","print('目的関数の最小値: ' + str(minimum_output))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yacEhXwso9v1"},"source":["上記の例ではランダムな $x$ を 20 個試していますが、Optuna はこれまでに試した入力 $x$ と出力 $(x - 2) ^ 2$ からヒントを得ることで、より良い結果が得られそうな $x$ に当たりをつけていきます。"]},{"cell_type":"markdown","metadata":{"id":"TNnNem86SkkF"},"source":["## Optuna を使って目的関数を最小化する\n","\n","Optuna を使って $(x - 2) ^ 2$ を最小化する $x$ を求めてみましょう。\n","以下の 4 つのステップが必要となります。\n","\n","1.   目的関数を定義する\n","2.   目的関数の内部で適当な変数を決める ***(suggest)***\n","3.   実験 ***study*** オブジェクトを作成する。\n","4.   施行 ***(trial)*** の回数を設定して最適化を開始する ***(optimize)***"]},{"cell_type":"markdown","metadata":{"id":"mHRgmkUYXNqe"},"source":["目的関数を定義します。\n","先ほど定義した目的関数とは少し違っており、$x$ の代わりに ***trial*** オブジェクトを引数としています。\n","これは Optuna で目的関数を書くときの決まりごとです。\n","***trial*** オブジェクトの ***suggest_float*** メソッド実行したタイミングで、次に試すべき $x$ の値が提案 ***(suggest)*** されます。\n","提案された $x$ を使って関数からの出力 $(x - 2) ^ 2$ を計算します。"]},{"cell_type":"code","metadata":{"id":"tBtw9bx2HC-k"},"source":["def objective(trial):                                           # 目的関数の定義\n","    x = trial.suggest_float(\"x\", -100, 100)  # 区間　[-100, 100]　から適当な x を決める\n","    return (x - 2) ** 2                                          # 目的関数の計算結果を返す"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VGyHDrAihhSU"},"source":["この目的関数を最小化する $x$ を求めることが Optuna の役目です。\n","以下のコードを実行してみましょう。\n","実験 ***(study)*** のオブジェクトを作成し、***optimize*** メソッドに目的関数と施行の回数を与えることで最小化実験が始まります。"]},{"cell_type":"code","metadata":{"id":"vKA1L19zhg4C"},"source":["study = optuna.create_study()\n","study.optimize(objective, n_trials=20)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wFOMcARKm5XP"},"source":["20 行のログが出力されているはずです。\n","Optuna が $(x - 2) ^ 2$ を 20 回実行し、そのつど異なる $x$ を試したことを意味しています。\n","\n","実験結果を見てみましょう。\n","***study.best_value*** で 20 試行中の最小となる出力 $(x - 2) ^ 2$ の値が、***study.best_params*** でその時の入力 $x$ がわかります。"]},{"cell_type":"code","metadata":{"id":"vuvI5UZbTTgb"},"source":["print(\"目的関数の最小値: \" + str(study.best_value))\n","print(\"出力が最小となる入力: \" + str(study.best_params))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2zuF5-nnvqBu"},"source":["## Optuna で機械学習のハイパーパラメータを決める\n","\n","以下のコードでは、Lasso 回帰を使って、ボストンにおける地域毎の平均住宅価格を予測しています。\n","正則化の強さは Lasso 回帰にとって重要なハイパーパラメータですが、この値を人手で適切に決めるには手間がかかります。\n","そこで Optuna を使って自動チューニングするようコードを改変します。\n","Optunaはplatform agnosticなので、もちろんscikit-learnのコードにも適用する事ができます。\n"]},{"cell_type":"code","metadata":{"id":"Spk8G3Y9rxRv"},"source":["# ハイパーパラメータの決定\n","alpha = 1.0\n","\n","# モデルの学習と評価\n","X, y = sklearn.datasets.load_boston(return_X_y=True)\n","X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, random_state=0)\n","model = sklearn.linear_model.Lasso(alpha=alpha)\n","model.fit(X_train, y_train)\n","y_pred = model.predict(X_val)\n","error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n","\n","# 評価性能の出力\n","print(error)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BF6IVv_T-ELA"},"source":["Optuna は目的関数からの出力を最小化 (または最大化) するような入力値を求めるツールでした。\n","一方で、上記の機械学習の学習・評価ロジックは、ハイパーパラメータを入力、評価性能を出力とする目的関数ととらえることができます。\n","したがって学習・評価ロジックをそのまま目的関数としてラップすることで、Optuna の形式に従ったコードになります。"]},{"cell_type":"code","metadata":{"id":"zO0XcBNOzuTR"},"source":["def objective(trial):\n","    # ハイパーパラメータの決定\n","    alpha = trial.suggest_float(\"alpha\", 0.0, 2.0)\n","  \n","    # モデルの学習と評価\n","    X, y = sklearn.datasets.load_boston(return_X_y=True)\n","    X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, random_state=0)\n","    model = sklearn.linear_model.Lasso(alpha=alpha)\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_val)\n","    error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n","  \n","    # 平均二乗誤差を目的関数からの出力とする\n","    return error"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3_C5V0vSHWTV"},"source":["ハイパーパラメータを自動探索してみましょう。\n","20 回の学習・評価が実行されたのち、最も良かった出力と、その時のハイパーパラメータが表示されます。"]},{"cell_type":"code","metadata":{"id":"42EbIIR5HVD7","scrolled":false},"source":["study = optuna.create_study()\n","study.optimize(objective, n_trials=20)\n","\n","print(\"最良の誤差: \" + str(study.best_value))\n","print(\"最良のハイパーパラメータ: \" + str(study.best_params))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"k7IF5WRxTaDt"},"source":["## 条件付きハイパーパラメータを探索する\n","\n","正則化の強さに加えて『どの種類の正則化を使うか (Ridge か Lasso か)』も探索したいとします。\n","探索したいハイパーパラメータは以下の 3 個となります。\n","\n","- `regression_method`: `'ridge'` か `'lasso'` のいずれか\n","- `ridge_alpha`: `ridge` における正則化の強さ\n","- `lasso_alpha`: `lasso` における正則化の強さ\n","\n","`ridge` を使う場合には `ridge_alpha` のみを、`lasso` を使う場合には `lasso_alpha` のみを探索したいことに注意してください。\n","つまり、探索対象のハイパーパラメータが `regression_method` の値によって変化します。\n","Optuna では、このような条件つきの探索空間を通常のPythonのコードを書くようにして扱うことができます。\n","このように通常のPythonコードを書くように探索空間が記述できることから、\n","Optunaの探索空間は\"Pythonic search spaces\"であると言われます。"]},{"cell_type":"code","metadata":{"id":"6aqC4CZt-ELI"},"source":["def objective(trial):\n","    #  データのロードと分割\n","    X, y = sklearn.datasets.load_boston(return_X_y=True)\n","    X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(X, y, random_state=0)\n","\n","    #  ハイパーパラメータの決定とモデルオブジェクトの初期化\n","    regression_method = trial.suggest_categorical(\"regression_method\", ('ridge', 'lasso'))\n","    if regression_method == 'ridge':\n","        ridge_alpha = trial.suggest_float(\"ridge_alpha\", 0.0, 2.0)\n","        model = sklearn.linear_model.Ridge(alpha=ridge_alpha)\n","    else:\n","        lasso_alpha = trial.suggest_float(\"lasso_alpha\", 0.0, 2.0)\n","        model = sklearn.linear_model.Lasso(alpha=lasso_alpha)\n","        \n","    # モデルの学習と評価\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_val)\n","    error = sklearn.metrics.mean_squared_error(y_val, y_pred)\n","  \n","    # 平均二乗誤差を目的関数からの出力とする\n","    return error\n","\n","study = optuna.create_study()\n","study.optimize(objective, n_trials=20)\n","\n","print(\"最良の誤差: \" + str(study.best_value))\n","print(\"最良のハイパーパラメータ: \" + str(study.best_params))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NROoj1y4T8C9"},"source":["## おわりに\n","\n","以上でOptunaの基本的な使い方に関するハンズオンは終わりです。\n","今回はscikit-learnを題材にOptunaの使い方を説明しましたが、Optunaはplatform agnosticなライブラリなため、他のどんなライブラリとも組み合わせる事ができます！\n","皆さんが普段使っている機械学習ライブラリでもOptunaが使えるかもしれませんので、ぜひ検討してみましょう。\n","今回はOptunaの以下の特徴について学びました。\n","- Lightweight, versatile, and platform agnostic architecture\n","- Pythonic search spaces\n","\n","次のチュートリアルでは、Optunaの一歩進んだ使い方に関して学んでみましょう。\n","- Efficient optimization algorithms\n","- Easy parallelization\n","- Quick visualization\n","\n","どうぞお楽しみに！"]}]}