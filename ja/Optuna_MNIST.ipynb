{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"33Z9NHT6_Eva"},"source":["<img src=\"files/logo.jpg\"/>\n","\n","## はじめに\n","\n","このOptunaのチュートリアルは、Google Colaboratry で書かれたノートブックに沿って進めます。Google Colaboratry ではブラウザ上で Python プログラムを実行することができます。\n","\n","試しに以下のコードを実行してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1HEtAqHm_EFP"},"outputs":[],"source":["print('Hello Notebook!')  # shift + enter で実行できます"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["**このチュートリアルは、GPUを利用することで早く進めることができます。**\n","\n","**メニューの ランタイム > ランタイムのタイプを変更 > ハードウェアアクセラレータ をGPUにしてください。**"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optunaは、次のようにインストールしてimportできます。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -U setuptools\n","!pip install optuna\n","\n","import optuna"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"598EfjY8A050"},"source":["## 1. Optuna を使って目的関数を最小化する"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TNnNem86SkkF"},"source":["まずは簡単な問題として、Optuna を使って $(x - 2) ^ 2$ を最小化する $x$ を求めてみましょう。 \n","以下の 4 つのステップが必要となります。\n","\n","1.   目的関数 (objective function) を定義する\n","2.   目的関数の内部で適当な変数を決める ***(suggest)***\n","3.   ***Study*** (実験) オブジェクトを作成する。\n","4.   ***Trial*** (試行) の回数を設定して最適化を開始する ***(optimize)***"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"mHRgmkUYXNqe"},"source":["目的関数を定義します。\n","`scipy.optimize`などの一般的な最適化ライブラリとは違い、$x$ の代わりに ***trial*** オブジェクトを引数にします。\n","これは Optuna で目的関数を書くときの決まりごとです。\n","***trial*** オブジェクトの ***suggest_float*** メソッド実行したタイミングで、次に試すべき $x$ の値が提案 ***(suggest)*** されます。\n","提案された $x$ を使って関数からの出力 $(x - 2) ^ 2$ を計算します。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tBtw9bx2HC-k"},"outputs":[],"source":["def objective(trial):\n","    x = trial.suggest_float(\"x\", -100, 100)  # 区間　[-100, 100]　から適当な x を決める\n","    return (x - 2) ** 2"]},{"cell_type":"markdown","metadata":{"id":"VGyHDrAihhSU"},"source":["この目的関数を最小化する $x$ を求めることが Optuna の役目です。\n","以下のコードを実行してみましょう。\n","実験 ***(study)*** のオブジェクトを作成し、***optimize*** メソッドに目的関数と施行の回数を与えることで最小化実験が始まります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vKA1L19zhg4C"},"outputs":[],"source":["study = optuna.create_study()\n","study.optimize(objective, n_trials=100)"]},{"cell_type":"markdown","metadata":{"id":"wFOMcARKm5XP"},"source":["100 行のログが出力されているはずです。\n","Optuna が $(x - 2) ^ 2$ を 100 回実行し、そのつど異なる $x$ を試したことを意味しています。\n","\n","実験結果を見てみましょう。\n","***study.best_value*** で 100 試行中の最小となる出力 $(x - 2) ^ 2$ の値が、***study.best_params*** でその時の入力 $x$ がわかります。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vuvI5UZbTTgb"},"outputs":[],"source":["print(f\"目的関数の最小値: {study.best_value}\")\n","print(f\"出力が最小となる入力: {study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ISBJderOrqAc"},"source":["## 2. MNIST (手書き文字認識)\n","\n","このチュートリアルでは例として、MNISTというデータセットと簡単なニューラルネットワークを使って手書き文字認識を行います。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JZbrgJyM1cv1"},"source":["MNISTには、次のような手書き文字が28x28の画像として訓練用60000枚 + 評価用10000枚収められています。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"500\"/>\n","\n","(画像: https://ja.wikipedia.org/wiki/MNIST%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9#/media/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:MnistExamples.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["以下のプログラムを実行すると、自動的にデータセットがダウンロードされます。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision.datasets import MNIST\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # あればGPUを使う\n","\n","# データを読み込む (今回はデータが少ないので、全てメモリ上に入れる)\n","# 訓練用データセット\n","train = MNIST(root='./data', download=True, train=True)\n","train_X = train.data.to(device).to(torch.float32) # 60000x28x28\n","train_y = train.targets.to(device) # 60000\n","\n","# 評価用データセット\n","validation = MNIST(root='./data', download=True, train=False)\n","validation_X = validation.data.to(device).to(torch.float32) # 10000x28x28\n","validation_y = validation.targets.to(device) # 10000"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これらの画像を認識するために、今回は非常に単純な2層ニューラルネットワークを使って学習を行います。\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png\" width=\"400\">\n","\n","(画像: https://simple.wikipedia.org/wiki/Deep_learning#/media/File:MultiLayerNeuralNetworkBigger_english.png)\n","\n","今回は入力層(input layer)のサイズは画像サイズ28×28=784, 出力層(output layer)のサイズは0～9の文字に対応する10個です。中間層(hidden layer)のサイズと、中間層でかける活性化関数はうまく学習ができるように調整する必要があります。\n","\n","深層学習フレームワークPyTorchを使うと、このモデルは次のように簡単に書けます。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","# モデルの定義\n","hidden_dim = 30            # 中間層の次元数\n","activation = nn.Sigmoid()  # 活性化関数\n","\n","model = nn.Sequential(\n","    nn.Flatten(),                  # 二次元の画像を一次元に変換\n","    nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","    activation,                    # 活性化関数\n","    nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n",").to(device)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["今はとりあえず中間層のサイズは30, 活性化関数はSigmoidを使っておきました。\n","\n","データセットがあってモデルを立てたら、次にどのようにそのモデルのパラメタ(ハイパーパラメータではなく、モデル内の`nn.Linear`の重みなどのことです)を最適化するかを決めなければなりません。\n","今回は最も基本的な最適化アルゴリズムである確率的勾配降下法(Stochastic gradient descent; SGD)を使うことにします。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","\n","# 最適化アルゴリズムの定義\n","lr = 1e-3  # 学習率\n","momentum = 0.9  # モーメンタム\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["モデルだけではなく最適化アルゴリズムにもハイパーパラメータはつきもので、学習率(`lr`)やモーメンタム(`momentum`)などをいい感じに調整する必要があります。\n","\n","さて、今定義したモデルと最適化アルゴリズムを用いてモデルを訓練するコードは次のように書けます。以後何度もこのコードを使うので、モデルと最適化アルゴリズムを渡すとMNISTのデータで訓練と評価を行ってくれる関数を作ります。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fit_mnist_and_evaluate(model, optimizer):\n","\n","    # 損失関数の定義\n","    loss_func = nn.CrossEntropyLoss() \n","\n","    # 学習 (今回はepoch数は20で固定とします。)\n","    epochs = 20\n","    for epoch in range(epochs):\n","        \n","        loss_sum = 0.0\n","        \n","        # batchをシャッフルする (今回はbatch sizeは600で固定とします。)\n","        batch_size = 600\n","        batch_idxs = torch.randperm(len(train_X), device=device).view(-1, batch_size)\n","\n","        for i, batch in enumerate(batch_idxs):\n","            # 各batchについて最適化を回す\n","\n","            optimizer.zero_grad() # 微分係数の初期化\n","            outputs = model(train_X[batch])          # 予測\n","            loss = loss_func(outputs, train_y[batch]) # 損失関数の計算 \n","            loss.backward()  # 微分の計算\n","            optimizer.step() # 最適化の1ステップの計算 \n","\n","            loss_sum += loss.item()\n","\n","        train_loss = loss_sum / (i + 1) # batchごとの損失関数の平均をとる\n","\n","        # 評価\n","        with torch.no_grad():\n","            outputs = model(validation_X)\n","            _, predicted = torch.max(outputs.data, dim=1) # 最も予測値が高かったものをとる\n","            total = len(validation_X)\n","            correct = (predicted == validation_y).sum().item()\n","            validation_accuracy = correct / total\n","\n","        print(f\"Epoch {epoch + 1}: train_loss={train_loss:.3f}, validation_accuracy={validation_accuracy:.4f}\")\n","\n","    return validation_accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["`batch_size`も性能に影響を与えるため、場合によってはハイパーパラメータとして調整する必要があるかもしれません。今回はColabのGPUインスタンスで効率的に学習できる600で固定しておきました。\n","\n","早速この関数を用いて学習してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fit_mnist_and_evaluate(model, optimizer)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["学習がうまくいけば、validation accuracyが0.90～0.91前後になると思います。(実行するたびに変わります。)\n","\n","この学習したモデルを使って認識した結果をいくつか表示してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def visualize_model(model):\n","\n","    fig, axs = plt.subplots(4, 5, figsize=(10, 11))\n","    axs = [ax for ax1 in axs for ax in ax1]\n","    start_idx = 500\n","    show_X = validation_X[start_idx:start_idx+len(axs)]\n","    show_y = validation_y[start_idx:start_idx+len(axs)]\n","    show_outputs = model(show_X)\n","    _, show_predicted = torch.max(show_outputs.data, dim=1)\n","    for i, ax in enumerate(axs):\n","        correct = show_y[i].item() == show_predicted[i].item()\n","        cmap = 'Greens' if correct else 'Reds'\n","        ax.imshow(show_X[i].cpu(), cmap=cmap)\n","        ax.set_title(f\"Ground truth: {show_y[i].item()}\\nPredicted: {show_predicted[i].item()}\")\n","    \n","    return fig\n","\n","fig = visualize_model(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["正しく認識されたものは緑、間違って認識されたものは赤で表示しています。\n","\n","この中にはいくつか誤認識されたものがあるかもしれません。では、次の節でモデルと最適化アルゴリズムのハイパーパラメタをoptunaで最適化して、認識精度を上げてみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2zuF5-nnvqBu"},"source":["## 3. Optuna で機械学習のハイパーパラメータを決める\n","\n","今回調整するハイパーパラメータは、\n","\n","* モデルの中間層のサイズ (`hidden_dim`)\n","* モデルの中間層の活性化関数 (`activation`)\n","* 最適化時の学習率 (`lr`)\n","* 最適化時のmomentum (`momentum`)\n","\n","の4つです。これら全てを手動で調整するのは大変なので、今回はこの4つのハイパーパラメータをoptunaで自動的に調整して、モデルの精度を上げます。\n","\n","(注: 実際に使われるより複雑なモデルでは、今回よりずっと多くのハイパーパラメータが含まれることがあります。)\n","\n","Optunaでハイパーパラメータを調整するために、先ほどと同様に、`model`と`optimizer`を作って`fit_mnist_and_evaluate`を呼ぶプログラム全体を`objective`関数に包みます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Spk8G3Y9rxRv"},"outputs":[],"source":["def objective(trial):\n","        \n","    # モデルの定義\n","    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)  # <-- 10から50までの間で探索\n","    activation_func = trial.suggest_categorical('activation_func', ['Sigmoid', 'Tanh', 'ReLU', 'ELU'])  # <-- この選択肢の中から探索\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","    activation = activation_funcs[activation_func]\n","\n","    model = nn.Sequential(\n","        nn.Flatten(),                  # 二次元の画像を一次元に変換\n","        nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","        activation,                    # 活性化関数\n","        nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n","    ).to(device)\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # <-- 1e-5から1e-2までの間で、対数スケールで探索\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # <-- 0.5から1.0までの間で探索\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate(model, optimizer)\n","    return validation_accuracy\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["コメントで`<--`と書いた4カ所と、最後に`return validation_accuracy`としているところが主な変更点です。\n","\n","では、この目的関数をoptunaを用いて最適化しましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=100)\n","\n","print(f\"最良の精度: {study.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BF6IVv_T-ELA"},"source":["うまくいけば0.94程度の精度が出ると思います。\n","\n","得られたハイパーパラメータをはじめのの学習コードに入れて、もう一度学習を回してみてください。誤認識する画像が少なくなったでしょうか?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4. 高度なサンプリングアルゴリズム・枝刈りアルゴリズムを利用する\n","\n","Optunaでは最先端のサンプリングアルゴリズム・枝刈りアルゴリズムを数多く利用して、最適化を行う事ができます。\n","その方法は非常にシンプルです。まずは、それぞれ**sampler**, **pruner**というオブジェクトを指定して、**study**を作成しましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gzlMnNB9tKH1"},"outputs":[],"source":["sampler = optuna.samplers.TPESampler(multivariate=True)  # 多くの場合、multivariate=Trueを指定することで性能が少し上がる\n","pruner = optuna.pruners.HyperbandPruner()\n","\n","study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")"]},{"cell_type":"markdown","metadata":{"id":"O-ZA4T6i6Wpp"},"source":["**sampler**は、このようにstudyを作成する際に渡すだけで有効化されます。\n","一方で、**pruner**を有効にするためには、目的関数内で中間値を報告し、各ステップで枝刈りをするかどうか判断するコードを追加する必要があります。\n","上の分散並列最適化のセクションで用いた目的関数を、**pruner**が有効になるよう書き換えると以下のようになるでしょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":868,"status":"ok","timestamp":1602747584962,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"bf0EFoaM6Q_Y"},"outputs":[],"source":["def fit_mnist_and_evaluate_with_report(trial, model, optimizer):\n","\n","    # 損失関数の定義\n","    loss_func = nn.CrossEntropyLoss() \n","\n","    # 学習 (今回はepoch数は20で固定とします。)\n","    epochs = 20\n","    for epoch in range(epochs):\n","        \n","        loss_sum = 0.0\n","        \n","        # batchをシャッフルする (今回はbatch sizeは600で固定とします。)\n","        batch_size = 600\n","        batch_idxs = torch.randperm(len(train_X), device=device).view(-1, batch_size)\n","\n","        for i, batch in enumerate(batch_idxs):\n","            # 各batchについて最適化を回す\n","\n","            optimizer.zero_grad() # 微分係数の初期化\n","            outputs = model(train_X[batch])          # 予測\n","            loss = loss_func(outputs, train_y[batch]) # 損失関数の計算 \n","            loss.backward()  # 微分の計算\n","            optimizer.step() # 最適化の1ステップの計算 \n","\n","            loss_sum += loss.item()\n","\n","        train_loss = loss_sum / (i + 1) # batchごとの損失関数の平均をとる\n","\n","        # 評価\n","        with torch.no_grad():\n","            outputs = model(validation_X)\n","            _, predicted = torch.max(outputs.data, dim=1) # 最も予測値が高かったものをとる\n","            total = len(validation_X)\n","            correct = (predicted == validation_y).sum().item()\n","            validation_accuracy = correct / total\n","        \n","        print(f\"Epoch {epoch + 1}: train_loss={train_loss:.3f}, validation_accuracy={validation_accuracy:.4f}\")\n","\n","        # 中間値をOptunaに報告 <-- この3行が追加されている\n","        trial.report(validation_accuracy, epoch)\n","        if trial.should_prune():\n","            raise optuna.TrialPruned()\n","\n","    return validation_accuracy\n","\n","def objective_with_report(trial):\n","    \n","    # モデルの定義\n","    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)  # 中間層の次元数\n","    activation_func = trial.suggest_categorical('activation_func', ['Sigmoid', 'Tanh', 'ReLU', 'ELU'])  # 活性化関数\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","    activation = activation_funcs[activation_func]\n","\n","    model = nn.Sequential(\n","        nn.Flatten(),                  # 二次元の画像を一次元に変換\n","        nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","        activation,                    # 活性化関数\n","        nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n","    ).to(device)\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # <-- 1e-5から1e-2までの間で、対数スケールで探索\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # <-- 0.5から1.0までの間で探索\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate_with_report(trial, model, optimizer)\n","    return validation_accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gludoDzN9K8N"},"source":["主要な変更点は、`# 中間値をOptunaに報告`と書いた部分の3行です。\n","\n","この目的関数を用いて**Study.optimize**を呼ぶと、枝刈りを考慮した最適化を行う事ができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eQv_J-So9Z55"},"outputs":[],"source":["study_with_pruner.optimize(objective_with_report, n_trials=100)\n","\n","print(f\"最良の精度: {study_with_pruner.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_with_pruner.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TiWh6Mr59eoD"},"source":["実行ログを見ると、いくつかのトライアルが最後まで実行されず途中で枝刈りされている事がわかります。\n","枝刈りによる高速化成功です！\n","\n","...ちょっと待ってください。これで我々の最適化はリーズナブルに改善されたでしょうか？\n","いいえ。これだけだと、実行するはずだった100トライアルが早く終わっただけです。\n","枝刈りの目的は、与えられたリソースの元で、見込みの薄いトライアルを枝刈りすることで\n","最大限多くのハイパーパラメータ候補を試すことにあります。\n","したがって、枝刈りによって最適化を改善するためには**Study.optimizeのトライアル数を一定にしてはダメです。**\n","代わりに、**最適化全体で消費されたリソース量を一定にする必要があります。**\n","\n","これを実現するための最も簡単な方法は、トライアル数ではなく時間を一定にすることです。\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t7MqzHws_F_-"},"outputs":[],"source":["study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n","study_with_pruner.optimize(objective_with_report, timeout=60) # 60秒で終了\n","\n","print(f\"最良の精度: {study_with_pruner.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_with_pruner.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QozTRwjY_ok5"},"source":["こうすることで、与えられたリソース（60秒)の元で、見込みのないパラメータが枝刈りされて最大限多くのハイパーパラメータ候補が試されることになります。\n","\n","最適化全体で消費されたリソース量を一定にする方法には、少しトリッキーですが以下のような方法も考えられるでしょう。\n","それは、最適化全体で実行されるステップ数を一定にすることです。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RBtgFZYoAev6"},"outputs":[],"source":["study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n","\n","# 枝刈りせずに学習した場合、100トライアル分のステップ数\n","N_TOTAL_STEPS = 100 * 20\n","\n","def terminate_callback(study, trial):\n","    complete_steps = sum(\n","        len(t.intermediate_values) \n","        for t in study.trials \n","        if t.state == optuna.trial.TrialState.COMPLETE or t.state == optuna.trial.TrialState.PRUNED)\n","    if complete_steps >= N_TOTAL_STEPS:\n","        study.stop()\n","\n","study_with_pruner.optimize(objective_with_report, callbacks=[terminate_callback])\n","\n","print(f\"最良の精度: {study_with_pruner.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_with_pruner.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yUW5GWKlDmxN"},"source":["こうすることで、与えられたリソース（100 * 20ステップ数)の元で、見込みのないパラメータが枝刈りされて最大限多くのハイパーパラメータ候補が試されることになります。\n","\n","さて、それではOptunaで利用可能な**sampler**と**pruner**について簡単に見ていきましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jteDHdTMt80P"},"source":["Optunaでは、v3.1.0時点で以下のような**sampler**を利用する事ができます。\n","詳細は、各々のドキュメントを参照してください。\n","- [`optuna.samplers.TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html)\n","  - ベイズ最適化のアルゴリズムの1つである[TPE (Tree-structured Parzen Estimator)](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)を実装しているsamplerです。\n","  - TPEはOptunaのデフォルトのsamplerです。\n","- [`optuna.samplers.CmaEsSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html)\n","  - 進化計算のアルゴリズムの1つである[CMA-ES (Covariance Matrix Adaptation - Evolution Strategy)](https://arxiv.org/abs/1604.00772) を実装しているsamplerです。\n","  - ハイパーパラメータの次元数が多い(10～20程度以上)場合や、trial数が多い(数百～数万程度)場合に強い手法です。\n","- [`optuna.integration.BoTorchSampler`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.BoTorchSampler.html)\n","  - [GP (ガウス過程)](https://bayesoptbook.com/)を用いてベイズ最適化を行っているsamplerです。\n","  - 次元が少なく(～10程度)、trial数が少ない(～数百)場合に強い手法です。計算量がtrial数の3乗に比例するため、数百～千を超えるtrial数で用いることは現実的ではありません。\n","- [`optuna.samplers.NSGAIISampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.NSGAIISampler.html)\n","  - 多目的最適化用の進化計算アルゴリズムの一つである[NSGA-II](https://ieeexplore.ieee.org/document/996017)を実装したsamplerです。\n","- [`optuna.samplers.GridSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.GridSampler.html)\n","  - グリッドサーチを行うsamplerです。\n","- [`optuna.samplers.BruteForceSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.BruteForceSampler.html)\n","  - 探索空間を全探索するsamplerです。`GridSampler`に似てますが、条件分岐を含むような探索空間にも対応しています。\n","- [`optuna.samplers.RandomSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.RandomSampler.html)\n","  - ランダムサーチを行うsamplerです。\n","- [`optuna.samplers.QMCSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.QMCSampler.html)\n","  - [準モンテカルロ法(quasi-Monte Carlo method)](https://scipy.github.io/devdocs/reference/stats.qmc.html)により、ランダムよりも満遍なく探索空間を埋め尽くすハイパーパラメータの列を用いて探索します。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ChPSK-QfzLJp"},"source":["また、Optunaでは、v3.1.0時点で以下のような**pruner**を利用する事ができます。\n","- [`optuna.pruners.NopPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.NopPruner.html)\n","  - 何も枝刈りしない、というprunerです。\n","- [`optuna.pruners.PercentilePruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.PercentilePruner.html)\n","  - 各epochにおいて、最適化履歴の 下位$\\alpha$%に入っていれば枝刈りする、というprunerです。\n","- [`optuna.pruners.MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html)\n","  - 各epochにおいて、最適化履歴の下位50%に入っていれば枝刈りする、というprunerです。\n","- [`optuna.pruners.SuccessiveHalvingPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.SuccessiveHalvingPruner.html)\n","  - [Successive Halving](https://arxiv.org/abs/1810.05934)という有名な枝刈りアルゴリズムを実装しているprunerです。\n","  なお、Optunaでは実装の都合上、論文とは多少異なるアルゴリズムを実装しています。\n","- [`optuna.pruners.HyperbandPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.HyperbandPruner.html)\n","  - [Hyperband](https://arxiv.org/abs/1603.06560)という最先端の枝刈りアルゴリズムを実装しているprunerです。\n","  なお、Optunaでは実装の都合上、論文とは多少異なるアルゴリズムを実装しています。\n","- [`optuna.pruners.ThresholdPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.ThresholdPruner.html)\n","  - 各epochにおいて、与えられた閾値から外れた値の場合に枝刈りする、というprunerです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qBQJ6DVq2276"},"source":["以上のsampler, prunerをどういった組み合わせで用いれば良いのかは、タスクごとに異なります。\n","\n","タスクごとに、どういった組み合わせでsamplerとprunerを選択すれば良いのかは難しい問題なので、我々Optuna開発者も多くのベンチマーク実験を行いながら知見を貯めています。\n","そういったベンチマーク実験の結果は[OptunaのWiki](https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako)で公開されているので、samplerとprunerを選ぶ際は参考にしてみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"k7IF5WRxTaDt"},"source":["## 5. 可変の個数のハイパーパラメータを探索する\n","\n","上ではかなり単純な二層ニューラルネットワークを使って手書き文字認識を行いましたが、もしかしたらより複雑なモデルを使うともっと精度を上げることができるかもしれません。ここでは中間層の数を可変にして、各層の次元数と活性化関数もOptunaに決めさせることを考えます。\n","\n","調整するパラメタは以下の通りです。\n","- `n_hidden_layers`: 中間層の数。1～5の整数。\n","- 各中間層`i`に関して\n","  - `hidden_dim[i]`: 中間層`i`のサイズ\n","  - `activation_func[i]`: 中間層`i`の活性化関数\n","- 最適化時の学習率 (`lr`)\n","- 最適化時のmomentum (`momentum`)\n","\n","この問題では、`n_hidden_layers`の値によって、必要なハイパーパラメータの数が変化することに注意してください。\n","このような場合でも、Optunaでは通常のPythonのコードを書くようにして扱うことができます。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6aqC4CZt-ELI"},"outputs":[],"source":["def objective_variable_depth(trial):\n","        \n","    # モデルの定義\n","    n_hidden_layers = trial.suggest_int('n_hidden_layers', 1, 5)  # 隠れ層の数\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","\n","    model = nn.Sequential()\n","    model.add_module('flatten', nn.Flatten()) # 二次元の画像を一次元に変換\n","    last_dim = 28 * 28 # 最初の入力層の次元数\n","    for i in range(n_hidden_layers):\n","        hidden_dim = trial.suggest_int(f'hidden_dim[{i}]', 10, 50) # 中間層の次元数\n","        activation_func = trial.suggest_categorical(f'activation_func[{i}]', ['Sigmoid', 'Tanh', 'ReLU', 'ELU']) # 中間層の活性化関数\n","        activation = activation_funcs[activation_func]\n","\n","        model.add_module(f'linear[{i}]', nn.Linear(last_dim, hidden_dim)) # 線形変換\n","        model.add_module(f'activation[{i}]', activation) # 活性化関数\n","        last_dim = hidden_dim\n","    \n","    model.add_module(f'linear[{n_hidden_layers}]', nn.Linear(last_dim, 10)) # 出力層の線形変換\n","\n","    model = model.to(device)\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # 学習率\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # モーメンタム\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate_with_report(trial, model, optimizer)\n","    return validation_accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_variable_depth = optuna.create_study(\n","    direction=\"maximize\", \n","    sampler=sampler, \n","    pruner=pruner,\n",")\n","study_variable_depth.optimize(objective_variable_depth, n_trials=100)\n","\n","print(f\"最良の精度: {study_variable_depth.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_variable_depth.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","恐らく3～4段くらい中間層を挟むことで、0.96～0.97程度まで性能が上がったのではないでしょうか?\n","\n","このように通常のPythonコードを書くように探索空間が記述できることから、\n","Optunaの探索空間は\"Pythonic search spaces\"であると言われます。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 6. `Study`の永続化と分散最適化\n","\n","ここまでの例では、`optuna.create_study`で作られたStudyは実体がメモリ上に存在していたため、一つのプロセスからしかアクセスすることができず、またそのプロセスが終了するとStudyは失われてしまっていました。この節では、Optuna v3.1で新たに追加された`JournalStorage`を用いてStudyの実体をファイルに置く方法を紹介し、さらにそれを用いて複数プロセスで分散最適化を行います。\n","\n","Studyの実体をファイルに置くには、`optuna.create_study`に次のような引数を渡します。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["distributed_study = optuna.create_study(\n","    direction=\"maximize\",\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これまでとは違い、Studyに名前を与える必要があることに気をつけてください。同じファイルには複数のStudyが入ることが許され、それぞれのStudyはこの名前で区別されます。\n","\n","`load_if_exists=True`と指定することで、既存のStudyと同じ名前が指定された場合に、新たにStudyが作られる代わりにそのStudyの実体と結びついたオブジェクトが返されます。例えばもう一度"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["distributed_study2 = optuna.create_study(\n","    direction=\"maximize\",\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["と実行すると、`distributed_study`と`distributed_study2`は同じ実体を指し示すことになります。その証に、例えば"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["distributed_study.optimize(objective_variable_depth, n_trials=1)\n","print(f\"distributed_study.best_value = {distributed_study.best_value}\")\n","print(f\"distributed_study.best_params = {distributed_study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["を実行した後、`distributed_study2`でも"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(f\"distributed_study2.best_value = {distributed_study2.best_value}\")\n","print(f\"distributed_study2.best_params = {distributed_study2.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["とすると、同じ値が表示されます。\n","\n","これを用いて、分散最適化をしてみましょう。次のPythonスクリプトをダウンロードします。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!wget https://raw.githubusercontent.com/pfnet-research/optuna-hands-on/master/ja/optuna_mnist_distributed_example.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["このスクリプトには、これまで書いたものと同じ`objective_variable_depth`の定義と、\n","```python\n","study_variable_depth = optuna.create_study(\n","    direction=\"maximize\", \n","    sampler=optuna.samplers.TPESampler(multivariate=True, constant_liar=True), \n","    pruner=optuna.pruners.HyperbandPruner(),\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)\n","study_variable_depth.optimize(objective_variable_depth, n_trials=int(sys.argv[1]))\n","```\n","の2行が書かれています。`TPESampler`の`constant_liar`は分散最適化をするときに他のプロセスで実行中のハイパーパラメータと似たようなハイパーパラメータを提案してしまうことを防いで探索性能を上げるオプションです。(分散最適化をしないときは全く影響がありません。) `n_trials`はコマンドライン引数で指定できるようにしています。\n","\n","分散最適化をするには、単にこのスクリプトを複数同時に走らせれば良いのです。(途中まで最適化を回した後、もう一度最初から実行させたい時は、`./mnist_study.optuna`を消してからもう一度コマンドを実行してください。)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_jobs = 4\n","\n","# python optuna_mnist_distributed_example.py を並列で n_jobs 回呼ぶ。\n","!seq $n_jobs | xargs -P0 -n1 python optuna_mnist_distributed_example.py 25"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これで4つのworkerで25trialずつ、合計100trialが実行されます。もし計算資源に余裕があれば、1プロセスで100trial実行するよりも早く終わるでしょう。\n","\n","結果を見るのも、同じstudyを読み込むことでできます。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["distributed_study = optuna.load_study(\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),\n","    study_name=\"distributed_study\")\n","# optuna.load_studyは、指定したstudyが存在しなければエラーになる。\n","\n","print(f\"最良の精度: {distributed_study.best_value}\")\n","print(f\"最良のハイパーパラメータ: {distributed_study.best_params}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optunaのこの`Storage`と呼ばれる枠組みは、非常に柔軟な分散最適化を可能にします。例えばこのファイルをNFS(ネットワークファイルシステム)上に置くことで、スパコン等の環境でもノードを超えた分散最適化が可能になります。また、メモリやファイルだけでなくRedis, あるいはMySQLやPostgreSQLなどのリレーショナルデータベース上にStudyの実体を置くこともできます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"acZ6Z8kIcjD6"},"source":["## 7. 豊富な可視化機能を用いて最適化結果を分析する\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rQPPRPUpJl9n"},"source":["高度なアルゴリズムの利用法、特に枝刈りの利用法について学び、最適化プロセスが改善されました。\n","また、必要があれば複数のワーカーで分散して並列処理をする事ができるようになりました。\n","最終的に達成された目的関数の評価値は**Study.best_value**, ハイパーパラメータの組は**Study.best_params**で取得できます。\n","最適化プロセスの改善や結果の分析は、これで十分でしょうか？\n","\n","**いいえ。そんなことはありません。**\n","\n","一度ハイパーパラメータ最適化を行うと、以下のような疑問が溢れてくることでしょう。\n","- トライアル数を決め打って最適化を行ったが、本当にこんなにたくさんのトライアルを実行する必要はあったのだろうか？\n","実はもっと早い段階で収束していたのではないだろうか？\n","逆にトライアル数は不十分だったりしないだろうか？\n","\n","- 自分の目的関数において、最も適切なsamplerとprunerの組み合わせは何なのだろうか？\n","今使ったsamplerとprunerが本当に最適なのだろうか？\n","\n","- 最適化の際に指定したハイパーパラメータの範囲は適切だろうか？\n","また、最終的に得たハイパーパラメータはどの程度信頼できるのだろうか？\n","\n","- 最適化したハイパーパラメータの中で、目的関数に最もよく効いているパラメータは何なのだろうか？\n","逆に、効いていないパラメータは最適化せずとも良かったのではないだろうか？\n","\n","Optunaは豊富な可視化機能を提供しており、ユーザはこれらの機能を利用して、\n","Optunaとインタラクティブに協同して、ハイパーパラメータ最適化のプロセスを改善していくことができます。\n","以下では、第3節(簡単な二層ニューラルネットワーク)で作った`study`を用いて、Optunaが提供する可視化機能の一部を紹介します。"]},{"cell_type":"markdown","metadata":{"id":"mE3vB64eODb6"},"source":["まずは、`optuna.visualization.plot_optimization_history` 関数を紹介します。\n","この関数の利用法はとてもシンプルで、最適化した`study`を関数に渡すだけです。\n","この関数は、与えられたstudyで行われた最適化の様子を、横軸をトライアル数、縦軸を目的関数値として表示します。\n","表示されるのは枝刈りされずに最後まで完了したトライアルだけです。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":2230,"status":"ok","timestamp":1602580423190,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"8IcgXVIkO0_5","outputId":"608d8ba8-1718-409e-dac0-2b17b0f551f4"},"outputs":[],"source":["optuna.visualization.plot_optimization_history(study)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["図が見にくかったら図の右上のボタンからズームしてみてください。\n","\n","この図でもし早くから収束していてBest valueの線がそれ以上更新されてないようだと、実はこんなにtrialをたくさん回す必要がなかったということがわかります。逆に、まだまだ更新されるようでしたら、追加で`Study.optimize`を回すのがいいのかもしれません。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VTQIH2xPRhvy"},"source":["また、今回の目的関数にどのsamplerが適しているのか調べるために、複数のsamplerに対して`study`を作り最適化を行ってみましょう。\n","\n","例えば、`QMCSampler`を使ってみます。`QMCSampler`は準モンテカルロ法(quasi-Monte Carlo method)と呼ばれる手法を用いて、「ランダムよりも一様な」数列を生成して満遍なく探索空間を試す、という手法です。グリッドサーチしたいけれど事前にどのくらい細かく分けるかは決めたくない、といった場合によく使える手法で、ランダムにとる`RandomSampler`よりも満遍なく試している分性能が高いことが多いです。\n","\n","果たしてOptunaのデフォルトである`TPESampler`はこのような単純な手法と比べて性能が高いのか、調べてみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYYGsxQISNhI"},"outputs":[],"source":["# QMCSamplerはscipyが必要です\n","!pip install scipy\n","study_qmc = optuna.create_study(sampler=optuna.samplers.QMCSampler(), direction=\"maximize\")\n","study_qmc.optimize(objective, n_trials=100)\n","\n","print(f\"最良の精度: {study_qmc.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_qmc.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cSl6aiEkTAjZ"},"source":["`TPESampler`での実行結果は第3節で実行してあるので、それと比較します。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1082,"status":"ok","timestamp":1602580507103,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"OSvfSrytTcP_","outputId":"857b0045-26a5-4107-9169-595fd6f47c61"},"outputs":[],"source":["import plotly\n","fig1 = optuna.visualization.plot_optimization_history(study_qmc)\n","fig2 = optuna.visualization.plot_optimization_history(study)\n","\n","fig1['data'][0]['name'] = 'Objective Value (QMC)'\n","fig1['data'][1]['name'] = 'Best Value (QMC)'\n","fig2['data'][0]['name'] = 'Objective Value (TPE)'\n","fig2['data'][1]['name'] = 'Best Value (TPE)'\n","fig = plotly.graph_objs.Figure(\n","    data=fig1['data'] + fig2['data'],\n","    layout=fig1['layout']\n",")\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MleQK3Q7YRzP"},"source":["初めの10回程度の結果は、かなり運に左右されます。それ以降は、おそらく`TPESampler`の方が`QMCSampler`と比べて良い値をたくさんサンプルしており、より高い精度まで伸ばすことができているでしょう。"]},{"cell_type":"markdown","metadata":{"id":"2hKeVIHMZEtM"},"source":["次に、`optuna.visualization.plot_contour`関数を紹介します。\n","この関数も、引数に`study`を与えるだけで動作します。\n","この関数は、全てのハイパーパラメータに対して、それらの任意の2個を縦軸横軸として目的関数値の等高線を表示します。（等高線を表示するハイパーパラメータの組を制限することもできます。詳細は[ドキュメント](https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_contour.html#)を参照してください。）"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1631,"status":"ok","timestamp":1602580517721,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"sj_p2bYzceN_","outputId":"bbfa49ac-5876-4d69-ea34-f1765b88a8a1"},"outputs":[],"source":["fig = optuna.visualization.plot_contour(study)\n","fig.update_layout(autosize=False, width=800, height=800) # 図が小さいのでサイズを調整"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XQIcyRcSfgRI"},"source":["出力された等高線を見ると、`hidden_dim`は大きい方がよくて、`lr`は0.001以上だと非常に悪い結果になっていそう、ということが読み取れると思います。次に最適化するときは、例えば`lr`の探索範囲の上限を`1e-2`ではなく`1e-3`にしたり、`hidden_dim`の探索範囲の上限をより大きくしたりするとより早く良い解にたどり着くかもしれません。"]},{"cell_type":"markdown","metadata":{"id":"i23WOLZYl2Zj"},"source":["最後に、`optuna.visualization.plot_param_importances`関数を紹介します。\n","この関数も最適化結果のstudyを渡すだけで利用することができます。\n","この関数は、最適化したハイパーパラメータに対して、目的関数の値に与えた影響の度合い（重要度）を計算して出力します。\n","\n","上で計算した`study_new`をもとに、パラメータの重要度を計算してみましょう。"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":2570,"status":"ok","timestamp":1602580562198,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"iSrWvfJpmc6o","outputId":"784b244e-2b3d-4ce5-87fc-1e7dddb229fa"},"outputs":[],"source":["optuna.visualization.plot_param_importances(study)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"223KvKfAmoLL"},"source":["今回の目的関数に対しては、`lr`と`hidden_dim`が最も重要であり、`momentum`の寄与はほとんどないことがわかります。次に最適化するときは、例えば`momentum = 0.9`などと決め打ってやって、変数の数を減らすと早く最適化できるかもしれません。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 8. Optuna Dashboard\n","\n","実は、7節で行った可視化を全て自動で行い、Webインターフェイスで表示してくれるOptuna dashboardという便利なものがあります。この節ではOptuna dashboardの使い方を説明します。\n","\n","まず、次のようにOptuna dashboardをインストールします。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install Cython==3.0.0a11\n","!pip install optuna-dashboard\n","!pip install optuna-fast-fanova gunicorn # Optuna dashboardの表示の高速化に役立つが、なくても構わない"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optuna dashboardで表示するためには、Studyが何らかのStorageに永続化されている必要があります。今回は第6節で作った`./mnist_study.optuna`をそのまま使います。\n","\n","次のようなPythonコードを実行することで、Optuna dashboardのサーバーを立ち上げることができます。\n","```python\n","import optuna_dashboard, optuna\n","optuna_dashboard.run_server(optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")))\n","```\n","しかしこれをそのままJupyter notebook内でやってしまうと、notebookをブロックしてしまってサーバーを落とすまで他に何もできなくなるので、Jupyter notebookでは次のようにします。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import time\n","import threading\n","from optuna_dashboard import wsgi\n","import optuna\n","from wsgiref.simple_server import make_server\n","\n","\n","port = 8081\n","storage = optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\"))\n","\n","app = wsgi(storage)\n","httpd = make_server(\"localhost\", port, app)\n","thread = threading.Thread(target=httpd.serve_forever)\n","thread.start()\n","\n","time.sleep(3) # サーバーが立ち上がるのを待つ。\n","\n","try:\n","    from google.colab import output\n","    output.serve_kernel_port_as_window(port, path='/dashboard/')\n","except ModuleNotFoundError:\n","    # Google Colabではない環境\n","    print(f\"https://localhost:{port}/dashboard/\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["最も下に表示されたリンクをクリックしてください。Study名の一覧が表示され、先ほど設定した`distributed_study`を選択すると、様々な可視化を見ることができます。\n","\n","さらに、このOptuna dashboardの画面は一定時間ごとに自動更新されます。試しに"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python optuna_mnist_distributed_example.py 100"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["をもう一度呼んで、optuna dashboardがどう変化するか見てみてください。\n","\n","次のようなコードを実行すると、Optuna dashboardのサーバーを止められます。"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Dashboardの終了\n","httpd.shutdown()\n","httpd.server_close()\n","thread.join()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NROoj1y4T8C9"},"source":["## おわりに\n","\n","以上でOptunaのチュートリアルは終わりです。\n","\n","今回はPyTorchを使った簡単なニューラルネットワークでMNISTを学習することを題材として、Optunaの基本的な使い方から少し高度な機能までざっと紹介しました。\n","\n","今回は紹介できなかった優れたアルゴリズムや便利な可視化機能がまだまだ沢山あるので、ぜひ[ドキュメント](https://optuna.readthedocs.io/en/stable/index.html)を読んでみてくださいね。\n","\n","[Optunaの解説本](https://www.amazon.co.jp/Optuna%E3%81%AB%E3%82%88%E3%82%8B%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%E3%83%9C%E3%83%83%E3%82%AF%E3%82%B9%E6%9C%80%E9%81%A9%E5%8C%96-%E4%BD%90%E9%87%8E-%E6%AD%A3%E5%A4%AA%E9%83%8E/dp/4274230104)も出ました！アルゴリズムの詳細などについても踏み込んで解説しているので、興味ある方はそちらも是非！\n","\n","Optunaが気に入った方は、ぜひ[GitHubページ](https://github.com/optuna/optuna)でスターを押してください！\n","\n","それでは、よいハイパラ最適化ライフを！"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Optuna_MNIST.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10 (main, Feb 16 2023, 02:46:59) [Clang 14.0.0 (clang-1400.0.29.202)]"},"vscode":{"interpreter":{"hash":"6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"}}},"nbformat":4,"nbformat_minor":0}
