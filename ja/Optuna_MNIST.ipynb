{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"33Z9NHT6_Eva"},"source":["<img src=\"files/logo.jpg\"/>\n","\n","## はじめに\n","\n","このOptunaのチュートリアルは、Google Colaboratry で書かれたノートブックに沿って進めます。Google Colaboratry ではブラウザ上で Python プログラムを実行することができます。\n","\n","試しに以下のコードを実行してみましょう。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"1HEtAqHm_EFP"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello Notebook!\n"]}],"source":["print('Hello Notebook!')  # shift + enter で実行できます"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optunaは、次のようにインストールできます。"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: optuna in /opt/homebrew/lib/python3.10/site-packages (3.1.0.dev0)\n","Requirement already satisfied: scipy>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna) (1.8.1)\n","Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna) (23.0)\n","Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from optuna) (1.23.5)\n","Requirement already satisfied: colorlog in /opt/homebrew/lib/python3.10/site-packages (from optuna) (6.7.0)\n","Requirement already satisfied: PyYAML in /opt/homebrew/lib/python3.10/site-packages (from optuna) (6.0)\n","Requirement already satisfied: cmaes>=0.9.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna) (0.9.1)\n","Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from optuna) (4.64.0)\n","Requirement already satisfied: alembic>=1.5.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna) (1.8.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna) (2.0.3)\n","Requirement already satisfied: Mako in /opt/homebrew/lib/python3.10/site-packages (from alembic>=1.5.0->optuna) (1.2.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna) (4.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/homebrew/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n","\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install optuna"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"598EfjY8A050"},"source":["## 1. Optuna を使って目的関数を最小化する\n","\n","まずは簡単な二次関数の最小化問題を考えてみましょう。\n","$(x - 2) ^ 2$ が最小となる $x$ を求める問題です。\n","$(x - 2) ^ 2$ のような最小化対象の関数を**目的関数** ***(objective function)*** と呼びます。\n","以下のコードを実行して目的関数を定義してみましょう。"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":18939,"status":"ok","timestamp":1602747049728,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"OCe84eX7AGl-"},"outputs":[],"source":["def objective(x):\n","    return (x - 2) ** 2"]},{"cell_type":"markdown","metadata":{"id":"ZrLZnBZcDokz"},"source":["人間は $x = 2$ の時に最小値が0であると解りますが、Optuna はこの問題の解き方を知りません。\n","そこで実際に複数の $x$ を代入して出力を計算し、出力が最小となった $x$ が最も良い解であると判断します。\n","以下のような計算をするイメージです。"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"DeSfeuf2BWir"},"outputs":[{"name":"stdout","output_type":"stream","text":["目的関数の最小値: 2.0011392650963353\n"]}],"source":["import random\n","\n","outputs = []  # 計算結果を保存しておくリスト\n","\n","# 区間　[-100, 100]　から適当な x を 100 パターン試す\n","for _ in range(100):\n","    x = random.uniform(-100, 100)\n","    objective_value = objective(x)\n","    outputs.append(objective_value)\n","\n","minimum_output = min(outputs)\n","print(f'目的関数の最小値: {minimum_output}')"]},{"cell_type":"markdown","metadata":{"id":"yacEhXwso9v1"},"source":["上記の例ではランダムな $x$ を 100 個試していますが、Optuna はこれまでに試した入力 $x$ と出力 $(x - 2) ^ 2$ からヒントを得ることで、より良い結果が得られそうな $x$ に当たりをつけていきます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TNnNem86SkkF"},"source":["Optuna を使って $(x - 2) ^ 2$ を最小化する $x$ を求めてみましょう。\n","以下の 4 つのステップが必要となります。\n","\n","1.   目的関数を定義する\n","2.   目的関数の内部で適当な変数を決める ***(suggest)***\n","3.   実験 ***study*** オブジェクトを作成する。\n","4.   施行 ***(trial)*** の回数を設定して最適化を開始する ***(optimize)***"]},{"cell_type":"markdown","metadata":{"id":"mHRgmkUYXNqe"},"source":["目的関数を定義します。\n","先ほど定義した目的関数とは少し違っており、$x$ の代わりに ***trial*** オブジェクトを引数としています。\n","これは Optuna で目的関数を書くときの決まりごとです。\n","***trial*** オブジェクトの ***suggest_float*** メソッド実行したタイミングで、次に試すべき $x$ の値が提案 ***(suggest)*** されます。\n","提案された $x$ を使って関数からの出力 $(x - 2) ^ 2$ を計算します。"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"tBtw9bx2HC-k"},"outputs":[],"source":["import optuna\n","def objective(trial):                                           # 目的関数の定義\n","    x = trial.suggest_float(\"x\", -100, 100)  # 区間　[-100, 100]　から適当な x を決める\n","    return (x - 2) ** 2                                          # 目的関数の計算結果を返す"]},{"cell_type":"markdown","metadata":{"id":"VGyHDrAihhSU"},"source":["この目的関数を最小化する $x$ を求めることが Optuna の役目です。\n","以下のコードを実行してみましょう。\n","実験 ***(study)*** のオブジェクトを作成し、***optimize*** メソッドに目的関数と施行の回数を与えることで最小化実験が始まります。"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"vKA1L19zhg4C"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-06 21:18:16,921] A new study created in memory with name: no-name-53986c6e-9292-4628-b438-2d2a46fa32a4\n","[I 2023-03-06 21:18:16,925] Trial 0 finished with value: 84.728191378443 and parameters: {'x': 11.20479176181857}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,926] Trial 1 finished with value: 9679.77161717759 and parameters: {'x': -96.38583036788168}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,927] Trial 2 finished with value: 1265.0292511346515 and parameters: {'x': -33.567249698769956}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,927] Trial 3 finished with value: 8231.624421576436 and parameters: {'x': -88.72830000378292}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,928] Trial 4 finished with value: 5771.2393803444165 and parameters: {'x': 77.9686736776707}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,929] Trial 5 finished with value: 6622.009835036876 and parameters: {'x': 83.37573247004832}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,929] Trial 6 finished with value: 1651.8587855431585 and parameters: {'x': 42.64306565138952}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,930] Trial 7 finished with value: 635.3183378209067 and parameters: {'x': 27.205521970808434}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,931] Trial 8 finished with value: 2725.630158441947 and parameters: {'x': 54.20756801884136}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,931] Trial 9 finished with value: 4674.331680287936 and parameters: {'x': -66.3690842434498}. Best is trial 0 with value: 84.728191378443.\n","[I 2023-03-06 21:18:16,938] Trial 10 finished with value: 19.368694405600174 and parameters: {'x': -2.4009878897356867}. Best is trial 10 with value: 19.368694405600174.\n","[I 2023-03-06 21:18:16,941] Trial 11 finished with value: 26.596108714106073 and parameters: {'x': -3.1571415255067485}. Best is trial 10 with value: 19.368694405600174.\n","[I 2023-03-06 21:18:16,945] Trial 12 finished with value: 389.08540710970505 and parameters: {'x': -17.725247960664653}. Best is trial 10 with value: 19.368694405600174.\n","[I 2023-03-06 21:18:16,948] Trial 13 finished with value: 0.6272789344544543 and parameters: {'x': 2.7920094282610872}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,951] Trial 14 finished with value: 1356.6978569670903 and parameters: {'x': -34.83337965714102}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,954] Trial 15 finished with value: 53.18360803459814 and parameters: {'x': 9.292709238314533}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,958] Trial 16 finished with value: 230.2451846856081 and parameters: {'x': -13.17383223466004}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,961] Trial 17 finished with value: 629.590015815331 and parameters: {'x': 27.091632386421793}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,964] Trial 18 finished with value: 2444.28126069763 and parameters: {'x': -47.43967294286674}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,967] Trial 19 finished with value: 32.45611108038864 and parameters: {'x': -3.697026512171822}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,970] Trial 20 finished with value: 3304.8417239373002 and parameters: {'x': 59.48775281690266}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,973] Trial 21 finished with value: 5.214966285963935 and parameters: {'x': -0.28363006766944077}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,976] Trial 22 finished with value: 224.95956412342778 and parameters: {'x': 16.99865207688437}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,979] Trial 23 finished with value: 341.77529928105884 and parameters: {'x': -16.487165799036337}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,982] Trial 24 finished with value: 6.605078339679516 and parameters: {'x': 4.570034696201496}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,985] Trial 25 finished with value: 640.769842909853 and parameters: {'x': 27.313432065009536}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,988] Trial 26 finished with value: 136.25971675212153 and parameters: {'x': 13.67303374243909}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,991] Trial 27 finished with value: 1263.795330884507 and parameters: {'x': 37.54989916841547}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,994] Trial 28 finished with value: 3.453476019778021 and parameters: {'x': 3.8583530395966266}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:16,997] Trial 29 finished with value: 9254.990346214037 and parameters: {'x': 98.20286038478294}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:17,001] Trial 30 finished with value: 165.79112681576387 and parameters: {'x': 14.875990323690209}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:17,004] Trial 31 finished with value: 3.1553680583966877 and parameters: {'x': 3.776335570323549}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:17,006] Trial 32 finished with value: 301.3233333213841 and parameters: {'x': -15.358667383223404}. Best is trial 13 with value: 0.6272789344544543.\n","[I 2023-03-06 21:18:17,009] Trial 33 finished with value: 0.6211380229120647 and parameters: {'x': 1.211876898630636}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,012] Trial 34 finished with value: 325.204587485979 and parameters: {'x': 20.033429720548973}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,015] Trial 35 finished with value: 17.883269341591227 and parameters: {'x': 6.228861471080748}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,018] Trial 36 finished with value: 715.8124788689646 and parameters: {'x': -24.754672094214957}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,021] Trial 37 finished with value: 100.26258994235152 and parameters: {'x': -8.013120889230866}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,024] Trial 38 finished with value: 893.8673519128415 and parameters: {'x': -27.89761448532042}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,026] Trial 39 finished with value: 13.164472954361905 and parameters: {'x': 5.628287881957812}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,030] Trial 40 finished with value: 1940.8193732530133 and parameters: {'x': -42.05473156487295}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,034] Trial 41 finished with value: 18.68034513218852 and parameters: {'x': -2.3220764838429826}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,037] Trial 42 finished with value: 7.690502455302925 and parameters: {'x': -0.7731755183008024}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,039] Trial 43 finished with value: 142.5478613376637 and parameters: {'x': -9.939340908846841}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,042] Trial 44 finished with value: 18.86432355257739 and parameters: {'x': 6.343307904417713}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,045] Trial 45 finished with value: 589.735383401689 and parameters: {'x': -22.284467945616782}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,049] Trial 46 finished with value: 377.0338175217707 and parameters: {'x': 21.41735866491039}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,052] Trial 47 finished with value: 201.39619085485074 and parameters: {'x': -12.191412574329968}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,055] Trial 48 finished with value: 89.91349003030663 and parameters: {'x': 11.482272408568878}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,058] Trial 49 finished with value: 1104.0050641508399 and parameters: {'x': 35.226571658099786}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,062] Trial 50 finished with value: 53.258456781090004 and parameters: {'x': -5.297839185751492}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,066] Trial 51 finished with value: 3.6103947568727293 and parameters: {'x': 3.9001038805477792}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,069] Trial 52 finished with value: 0.816634464908188 and parameters: {'x': 1.0963217027569003}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,072] Trial 53 finished with value: 42.34770958194086 and parameters: {'x': 8.507511781160359}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,075] Trial 54 finished with value: 496.58069708590705 and parameters: {'x': 24.284090672179268}. Best is trial 33 with value: 0.6211380229120647.\n","[I 2023-03-06 21:18:17,078] Trial 55 finished with value: 0.03316480765906365 and parameters: {'x': 2.182112074446105}. Best is trial 55 with value: 0.03316480765906365.\n","[I 2023-03-06 21:18:17,082] Trial 56 finished with value: 91.76801219781578 and parameters: {'x': -7.57956221326506}. Best is trial 55 with value: 0.03316480765906365.\n","[I 2023-03-06 21:18:17,085] Trial 57 finished with value: 182.51487721233875 and parameters: {'x': 15.509806705217464}. Best is trial 55 with value: 0.03316480765906365.\n","[I 2023-03-06 21:18:17,088] Trial 58 finished with value: 354.50694415359965 and parameters: {'x': -16.82835479147341}. Best is trial 55 with value: 0.03316480765906365.\n","[I 2023-03-06 21:18:17,092] Trial 59 finished with value: 0.006023015079880227 and parameters: {'x': 2.0776080864335684}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,095] Trial 60 finished with value: 724.1669132913082 and parameters: {'x': 28.910349557211408}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,099] Trial 61 finished with value: 13.1047568333057 and parameters: {'x': -1.6200492860326778}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,102] Trial 62 finished with value: 224.14026298283466 and parameters: {'x': 16.97131467115813}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,105] Trial 63 finished with value: 89.21607953476138 and parameters: {'x': 11.445426381840122}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,108] Trial 64 finished with value: 0.81797904705752 and parameters: {'x': 1.0955780591684432}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,111] Trial 65 finished with value: 104.49900563777899 and parameters: {'x': -8.222475514168718}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,114] Trial 66 finished with value: 456.38470539896684 and parameters: {'x': -19.363162345471395}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,118] Trial 67 finished with value: 2.913538786371408 and parameters: {'x': 0.2930908675704472}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,120] Trial 68 finished with value: 214.3956880428855 and parameters: {'x': -12.64225693132331}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,123] Trial 69 finished with value: 7.363438762113466 and parameters: {'x': -0.7135656915050843}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,126] Trial 70 finished with value: 294.0852988426559 and parameters: {'x': 19.148915383856085}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,129] Trial 71 finished with value: 43.622072055173334 and parameters: {'x': 8.604700754400106}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,133] Trial 72 finished with value: 1.0055907330422746 and parameters: {'x': 0.9972085296322697}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,135] Trial 73 finished with value: 106.63726144591278 and parameters: {'x': -8.326531917633954}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,138] Trial 74 finished with value: 1.7020317942260048 and parameters: {'x': 0.6953805941095292}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,141] Trial 75 finished with value: 109.14545125144899 and parameters: {'x': 12.44727003821807}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,144] Trial 76 finished with value: 58.286461440130665 and parameters: {'x': -5.634557055922149}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,147] Trial 77 finished with value: 243.22261621369162 and parameters: {'x': -13.595596051888867}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,151] Trial 78 finished with value: 557.1776100723242 and parameters: {'x': -21.604609932645026}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,154] Trial 79 finished with value: 0.8211351736142357 and parameters: {'x': 1.093834908190436}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,157] Trial 80 finished with value: 78.89572205144803 and parameters: {'x': 10.88232638735191}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,160] Trial 81 finished with value: 14.671799295267293 and parameters: {'x': -1.8303784793760645}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,163] Trial 82 finished with value: 1.4020612307020457 and parameters: {'x': 3.184086665198982}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,166] Trial 83 finished with value: 46.971687059334634 and parameters: {'x': 8.853589355902105}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,170] Trial 84 finished with value: 1.4441388253202014 and parameters: {'x': 3.2017232731873846}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,175] Trial 85 finished with value: 152.48434609480213 and parameters: {'x': 14.348455210867558}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,178] Trial 86 finished with value: 183.8516931248279 and parameters: {'x': -11.559192200305588}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,181] Trial 87 finished with value: 0.8593465030717509 and parameters: {'x': 2.9270094406594525}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,186] Trial 88 finished with value: 34.504183239269636 and parameters: {'x': -3.8740261524162145}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,192] Trial 89 finished with value: 403.9067352524733 and parameters: {'x': 22.097431061020544}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,196] Trial 90 finished with value: 336.71695670517346 and parameters: {'x': -16.349848955922592}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,202] Trial 91 finished with value: 8.895765473581957 and parameters: {'x': 4.9825769853571185}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,206] Trial 92 finished with value: 71.04726601336148 and parameters: {'x': -6.428954028428526}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,209] Trial 93 finished with value: 0.8391395056768687 and parameters: {'x': 2.916045580567293}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,212] Trial 94 finished with value: 225.96906588584793 and parameters: {'x': 17.032267489831597}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,215] Trial 95 finished with value: 27.279778966000237 and parameters: {'x': 7.223004783264154}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,220] Trial 96 finished with value: 41.763966417037125 and parameters: {'x': -4.462504655088236}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,223] Trial 97 finished with value: 174.9342034036774 and parameters: {'x': -11.226269443939112}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,226] Trial 98 finished with value: 0.026032075897001176 and parameters: {'x': 1.838655412557467}. Best is trial 59 with value: 0.006023015079880227.\n","[I 2023-03-06 21:18:17,230] Trial 99 finished with value: 115.95879934369333 and parameters: {'x': 12.76841675195074}. Best is trial 59 with value: 0.006023015079880227.\n"]}],"source":["study = optuna.create_study()\n","study.optimize(objective, n_trials=100)"]},{"cell_type":"markdown","metadata":{"id":"wFOMcARKm5XP"},"source":["100 行のログが出力されているはずです。\n","Optuna が $(x - 2) ^ 2$ を 100 回実行し、そのつど異なる $x$ を試したことを意味しています。\n","\n","実験結果を見てみましょう。\n","***study.best_value*** で 100 試行中の最小となる出力 $(x - 2) ^ 2$ の値が、***study.best_params*** でその時の入力 $x$ がわかります。"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"vuvI5UZbTTgb"},"outputs":[{"name":"stdout","output_type":"stream","text":["目的関数の最小値: 0.006023015079880227\n","出力が最小となる入力: {'x': 2.0776080864335684}\n"]}],"source":["print(f\"目的関数の最小値: {study.best_value}\")\n","print(f\"出力が最小となる入力: {study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ISBJderOrqAc"},"source":["## 2. MNIST (手書き文字認識)\n","\n","このチュートリアルでは例として、MNISTというデータセットと簡単なニューラルネットワークを使って手書き文字認識を行います。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"JZbrgJyM1cv1"},"source":["MNISTには、次のような手書き文字が28x28の画像として訓練用60000枚 + 評価用10000枚収められています。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/27/MnistExamples.png\" width=\"500\"/>\n","\n","(画像: https://ja.wikipedia.org/wiki/MNIST%E3%83%87%E3%83%BC%E3%82%BF%E3%83%99%E3%83%BC%E3%82%B9#/media/%E3%83%95%E3%82%A1%E3%82%A4%E3%83%AB:MnistExamples.png)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["以下のプログラムを実行すると、自動的にデータセットがダウンロードされます。"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["import torch\n","from torchvision.datasets import MNIST\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # あればGPUを使う\n","\n","# データを読み込む (今回はデータが少ないので、全てメモリ上に入れる)\n","# 訓練用データセット\n","train = MNIST(root='./data', download=True, train=True)\n","train_X = train.data.to(device).to(torch.float32) # 60000x28x28\n","train_y = train.targets.to(device) # 60000\n","\n","# 評価用データセット\n","validation = MNIST(root='./data', download=True, train=False)\n","validation_X = validation.data.to(device).to(torch.float32) # 10000x28x28\n","validation_y = validation.targets.to(device) # 10000"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これらの画像を認識するために、今回は非常に単純な2層ニューラルネットワークを使って学習を行います。\n","\n","<img src=\"https://upload.wikimedia.org/wikipedia/commons/c/c2/MultiLayerNeuralNetworkBigger_english.png\" width=\"400\">\n","\n","(画像: https://simple.wikipedia.org/wiki/Deep_learning#/media/File:MultiLayerNeuralNetworkBigger_english.png)\n","\n","今回は入力層(input layer)のサイズは画像サイズ28×28=768, 出力層(output layer)のサイズは0~9の文字に対応する10個です。中間層(hidden layer)のサイズと、中間層でかける活性化関数はうまく学習ができるように調整する必要があります。\n","\n","深層学習フレームワークPyTorchを使うと、このモデルは次のように簡単に書けます。"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["import torch.nn as nn\n","\n","# モデルの定義\n","hidden_dim = 30            # 中間層の次元数\n","activation = nn.Sigmoid()  # 活性化関数\n","\n","model = nn.Sequential(\n","    nn.Flatten(),                  # 二次元の画像を一次元に変換\n","    nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","    activation,                    # 活性化関数\n","    nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n",").to(device)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["今はとりあえず中間層のサイズは30, 活性化関数はSigmoidを使っておきました。\n","\n","データセットがあってモデルを立てたら、次にどのようにそのモデルのパラメタ(ハイパーパラメータではなく、モデル内の`nn.Linear`の重みなどのことです)を最適化するかを決めなければなりません。\n","今回は最も基本的な最適化アルゴリズムである確率的勾配降下法(Stochastic gradient descent; SGD)を使うことにします。"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import torch.optim as optim\n","\n","# 最適化アルゴリズムの定義\n","lr = 1e-3  # 学習率\n","momentum = 0.9  # モーメンタム\n","optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["モデルだけではなく最適化アルゴリズムにもハイパーパラメータはつきもので、学習率(`lr`)やモーメンタム(`momentum`)などをいい感じに調整する必要があります。\n","\n","さて、今定義したモデルと最適化アルゴリズムを用いてモデルを訓練するコードは次のように書けます。以後何度もこのコードを使うので、モデルと最適化アルゴリズムを渡すとMNISTのデータで訓練と評価を行ってくれる関数を作ります。"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def fit_mnist_and_evaluate(model, optimizer):\n","\n","    # 損失関数の定義\n","    loss_func = nn.CrossEntropyLoss() \n","\n","    # 学習 (今回はepoch数は20で固定とします。)\n","    epochs = 20\n","    for epoch in range(epochs):\n","        \n","        loss_sum = 0.0\n","        \n","        # batchをシャッフルする (今回はbatch sizeは600で固定とします。)\n","        batch_size = 600\n","        batch_idxs = torch.randperm(len(train_X), device=device).view(-1, batch_size)\n","\n","        for i, batch in enumerate(batch_idxs):\n","            # 各batchについて最適化を回す\n","\n","            optimizer.zero_grad() # 微分係数の初期化\n","            outputs = model(train_X[batch])          # 予測\n","            loss = loss_func(outputs, train_y[batch]) # 損失関数の計算 \n","            loss.backward()  # 微分の計算\n","            optimizer.step() # 最適化の1ステップの計算 \n","\n","            loss_sum += loss.item()\n","\n","        train_loss = loss_sum / (i + 1) # batchごとの損失関数の平均をとる\n","\n","        # 評価\n","        with torch.no_grad():\n","            outputs = model(validation_X)\n","            _, predicted = torch.max(outputs.data, dim=1) # 最も予測値が高かったものをとる\n","            total = len(validation_X)\n","            correct = (predicted == validation_y).sum().item()\n","            validation_accuracy = correct / total\n","\n","        print(f\"Epoch {epoch + 1}: train_loss={train_loss:.3f}, validation_accuracy={validation_accuracy:.4f}\")\n","\n","    return validation_accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["場合によっては、`batch_size`などもハイパーパラメータとして調整する必要があるかもしれません。今回はColabのGPUインスタンスで効率的に学習できる600で固定しておきました。\n","\n","早速この関数を用いて学習してみましょう。"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 2: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 3: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 4: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 5: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 6: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 7: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 8: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 9: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 10: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 11: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 12: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 13: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 14: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 15: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 16: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 17: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 18: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 19: train_loss=2.410, validation_accuracy=0.0995\n","Epoch 20: train_loss=2.410, validation_accuracy=0.0995\n"]},{"data":{"text/plain":["0.0995"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["fit_mnist_and_evaluate(model, optimizer)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["学習がうまくいけば、validation accuracyが0.90~0.91前後になると思います。(実行するたびに変わります。)\n","\n","この学習したモデルを使って認識した結果をいくつか表示してみましょう。"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1000x1100 with 20 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","\n","def visualize_model(model):\n","\n","    fig, axs = plt.subplots(4, 5, figsize=(10, 11))\n","    axs = [ax for ax1 in axs for ax in ax1]\n","    show_X = validation_X[:len(axs)]\n","    show_y = validation_y[:len(axs)]\n","    show_outputs = model(show_X)\n","    _, show_predicted = torch.max(show_outputs.data, dim=1)\n","    for i, ax in enumerate(axs):\n","        correct = show_y[i].item() == show_predicted[i].item()\n","        cmap = 'Greens' if correct else 'Reds'\n","        ax.imshow(show_X[i].cpu(), cmap=cmap)\n","        ax.set_title(f\"Ground truth: {show_y[i].item()}\\nPredicted: {show_predicted[i].item()}\")\n","    \n","    return fig\n","\n","fig = visualize_model(model)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["正しく認識されたものは緑、間違って認識されたものは赤で表示しています。\n","\n","この中にはいくつか誤認識されたものがあるかもしれません。では、次の節でモデルと最適化アルゴリズムのハイパーパラメタをoptunaで最適化して、認識精度を上げてみましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"2zuF5-nnvqBu"},"source":["## 3. Optuna で機械学習のハイパーパラメータを決める\n","\n","今回調整するハイパーパラメータは、\n","\n","* モデルの中間層のサイズ (`hidden_dim`)\n","* モデルの中間層の活性化関数 (`activation`)\n","* 最適化時の学習率 (`lr`)\n","* 最適化時のmomentum (`momentum`)\n","\n","の4つです。これら全てを手動で調整するのは大変なので、今回はこの4つのハイパーパラメータをoptunaで自動的に調整して、モデルの精度を上げます。\n","\n","(注: 実際に使われるより複雑なモデルでは、今回よりずっと多くのハイパーパラメータが含まれることがあります。)\n","\n","Optunaでハイパーパラメータを調整するために、先ほどと同様に、`model`と`optimizer`を作って`fit_mnist_and_evaluate`を呼ぶプログラム全体を`objective`関数に包みます。"]},{"cell_type":"code","execution_count":339,"metadata":{"id":"Spk8G3Y9rxRv"},"outputs":[],"source":["def objective(trial):\n","        \n","    # モデルの定義\n","    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)  # <-- 10から50までの間で探索\n","    activation_func = trial.suggest_categorical('activation_func', ['Sigmoid', 'Tanh', 'ReLU', 'ELU'])  # <-- この選択肢の中から探索\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","    activation = activation_funcs[activation_func]\n","\n","    model = nn.Sequential(\n","        nn.Flatten(),                  # 二次元の画像を一次元に変換\n","        nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","        activation,                    # 活性化関数\n","        nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n","    )\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # <-- 1e-5から1e-2までの間で、対数スケールで探索\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # <-- 0.5から1.0までの間で探索\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate(model, optimizer)\n","    return validation_accuracy\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["コメントで`<--`と書いた4カ所と、最後に`return validation_accuracy`としているところが主な変更点です。\n","\n","では、この目的関数をoptunaを用いて最適化しましょう。"]},{"cell_type":"code","execution_count":340,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:05,873] A new study created in memory with name: no-name-f3fd9487-6bbf-4770-8bb0-a33dc3b119bc\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss=2.295, validation_accuracy=0.2052\n","Epoch 2: train_loss=2.120, validation_accuracy=0.2989\n","Epoch 3: train_loss=1.989, validation_accuracy=0.3784\n","Epoch 4: train_loss=1.875, validation_accuracy=0.4430\n","Epoch 5: train_loss=1.783, validation_accuracy=0.5043\n","Epoch 6: train_loss=1.708, validation_accuracy=0.5517\n","Epoch 7: train_loss=1.641, validation_accuracy=0.5970\n","Epoch 8: train_loss=1.580, validation_accuracy=0.6315\n","Epoch 9: train_loss=1.527, validation_accuracy=0.6596\n","Epoch 10: train_loss=1.479, validation_accuracy=0.6841\n","Epoch 11: train_loss=1.437, validation_accuracy=0.7027\n","Epoch 12: train_loss=1.400, validation_accuracy=0.7144\n","Epoch 13: train_loss=1.367, validation_accuracy=0.7291\n","Epoch 14: train_loss=1.336, validation_accuracy=0.7392\n","Epoch 15: train_loss=1.308, validation_accuracy=0.7493\n","Epoch 16: train_loss=1.281, validation_accuracy=0.7580\n","Epoch 17: train_loss=1.257, validation_accuracy=0.7641\n","Epoch 18: train_loss=1.233, validation_accuracy=0.7696\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:07,603] Trial 0 finished with value: 0.7811 and parameters: {'hidden_dim': 48, 'activation_func': 'Tanh', 'lr': 1.7884984611272574e-05, 'momentum': 0.9073629369292808}. Best is trial 0 with value: 0.7811.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=1.211, validation_accuracy=0.7761\n","Epoch 20: train_loss=1.189, validation_accuracy=0.7811\n","Epoch 1: train_loss=11.140, validation_accuracy=0.1135\n","Epoch 2: train_loss=2.303, validation_accuracy=0.1135\n","Epoch 3: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 4: train_loss=2.300, validation_accuracy=0.1147\n","Epoch 5: train_loss=2.283, validation_accuracy=0.1500\n","Epoch 6: train_loss=2.297, validation_accuracy=0.1135\n","Epoch 7: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 8: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 9: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 10: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 11: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 12: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 13: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 14: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 15: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 16: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 17: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 18: train_loss=2.301, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:09,061] Trial 1 finished with value: 0.1135 and parameters: {'hidden_dim': 22, 'activation_func': 'ReLU', 'lr': 0.0018958571671095403, 'momentum': 0.9860071194540374}. Best is trial 0 with value: 0.7811.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 20: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 1: train_loss=2.924, validation_accuracy=0.1979\n","Epoch 2: train_loss=2.074, validation_accuracy=0.2036\n","Epoch 3: train_loss=2.057, validation_accuracy=0.2061\n","Epoch 4: train_loss=2.046, validation_accuracy=0.2065\n","Epoch 5: train_loss=2.037, validation_accuracy=0.2081\n","Epoch 6: train_loss=2.030, validation_accuracy=0.2087\n","Epoch 7: train_loss=2.023, validation_accuracy=0.2095\n","Epoch 8: train_loss=2.016, validation_accuracy=0.2360\n","Epoch 9: train_loss=1.832, validation_accuracy=0.3045\n","Epoch 10: train_loss=1.762, validation_accuracy=0.3111\n","Epoch 11: train_loss=1.717, validation_accuracy=0.3667\n","Epoch 12: train_loss=1.732, validation_accuracy=0.3278\n","Epoch 13: train_loss=1.699, validation_accuracy=0.3965\n","Epoch 14: train_loss=1.586, validation_accuracy=0.3716\n","Epoch 15: train_loss=1.565, validation_accuracy=0.4463\n","Epoch 16: train_loss=1.481, validation_accuracy=0.4817\n","Epoch 17: train_loss=1.653, validation_accuracy=0.3229\n","Epoch 18: train_loss=1.619, validation_accuracy=0.4491\n","Epoch 19: train_loss=1.451, validation_accuracy=0.5357\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:10,523] Trial 2 finished with value: 0.526 and parameters: {'hidden_dim': 31, 'activation_func': 'ReLU', 'lr': 0.0015168786055192328, 'momentum': 0.8792115310408857}. Best is trial 0 with value: 0.7811.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=1.426, validation_accuracy=0.5260\n","Epoch 1: train_loss=5.952, validation_accuracy=0.2371\n","Epoch 2: train_loss=2.359, validation_accuracy=0.2649\n","Epoch 3: train_loss=2.115, validation_accuracy=0.2873\n","Epoch 4: train_loss=1.990, validation_accuracy=0.3087\n","Epoch 5: train_loss=1.892, validation_accuracy=0.3349\n","Epoch 6: train_loss=1.806, validation_accuracy=0.3595\n","Epoch 7: train_loss=1.726, validation_accuracy=0.3865\n","Epoch 8: train_loss=1.650, validation_accuracy=0.4132\n","Epoch 9: train_loss=1.579, validation_accuracy=0.4384\n","Epoch 10: train_loss=1.512, validation_accuracy=0.4675\n","Epoch 11: train_loss=1.451, validation_accuracy=0.4875\n","Epoch 12: train_loss=1.394, validation_accuracy=0.5261\n","Epoch 13: train_loss=1.343, validation_accuracy=0.5487\n","Epoch 14: train_loss=1.298, validation_accuracy=0.5656\n","Epoch 15: train_loss=1.255, validation_accuracy=0.5822\n","Epoch 16: train_loss=1.216, validation_accuracy=0.5967\n","Epoch 17: train_loss=1.178, validation_accuracy=0.6082\n","Epoch 18: train_loss=1.142, validation_accuracy=0.6190\n","Epoch 19: train_loss=1.108, validation_accuracy=0.6302\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:11,952] Trial 3 finished with value: 0.6426 and parameters: {'hidden_dim': 27, 'activation_func': 'ReLU', 'lr': 1.4256516553133118e-05, 'momentum': 0.7407734900285801}. Best is trial 0 with value: 0.7811.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=1.075, validation_accuracy=0.6426\n","Epoch 1: train_loss=1.768, validation_accuracy=0.6643\n","Epoch 2: train_loss=1.341, validation_accuracy=0.7386\n","Epoch 3: train_loss=1.179, validation_accuracy=0.7528\n","Epoch 4: train_loss=1.071, validation_accuracy=0.7692\n","Epoch 5: train_loss=0.985, validation_accuracy=0.8065\n","Epoch 6: train_loss=0.914, validation_accuracy=0.8302\n","Epoch 7: train_loss=0.852, validation_accuracy=0.8420\n","Epoch 8: train_loss=0.800, validation_accuracy=0.8509\n","Epoch 9: train_loss=0.758, validation_accuracy=0.8629\n","Epoch 10: train_loss=0.722, validation_accuracy=0.8620\n","Epoch 11: train_loss=0.691, validation_accuracy=0.8659\n","Epoch 12: train_loss=0.662, validation_accuracy=0.8637\n","Epoch 13: train_loss=0.636, validation_accuracy=0.8715\n","Epoch 14: train_loss=0.615, validation_accuracy=0.8773\n","Epoch 15: train_loss=0.592, validation_accuracy=0.8732\n","Epoch 16: train_loss=0.577, validation_accuracy=0.8686\n","Epoch 17: train_loss=0.562, validation_accuracy=0.8722\n","Epoch 18: train_loss=0.546, validation_accuracy=0.8795\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:13,326] Trial 4 finished with value: 0.8837 and parameters: {'hidden_dim': 14, 'activation_func': 'Tanh', 'lr': 0.0013699932141826698, 'momentum': 0.7181836592480387}. Best is trial 4 with value: 0.8837.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.537, validation_accuracy=0.8815\n","Epoch 20: train_loss=0.524, validation_accuracy=0.8837\n","Epoch 1: train_loss=2.111, validation_accuracy=0.4728\n","Epoch 2: train_loss=1.831, validation_accuracy=0.6120\n","Epoch 3: train_loss=1.707, validation_accuracy=0.6893\n","Epoch 4: train_loss=1.615, validation_accuracy=0.7424\n","Epoch 5: train_loss=1.545, validation_accuracy=0.7729\n","Epoch 6: train_loss=1.488, validation_accuracy=0.7851\n","Epoch 7: train_loss=1.437, validation_accuracy=0.7979\n","Epoch 8: train_loss=1.392, validation_accuracy=0.8098\n","Epoch 9: train_loss=1.350, validation_accuracy=0.8189\n","Epoch 10: train_loss=1.311, validation_accuracy=0.8299\n","Epoch 11: train_loss=1.274, validation_accuracy=0.8357\n","Epoch 12: train_loss=1.238, validation_accuracy=0.8361\n","Epoch 13: train_loss=1.205, validation_accuracy=0.8425\n","Epoch 14: train_loss=1.173, validation_accuracy=0.8466\n","Epoch 15: train_loss=1.143, validation_accuracy=0.8500\n","Epoch 16: train_loss=1.114, validation_accuracy=0.8569\n","Epoch 17: train_loss=1.086, validation_accuracy=0.8602\n","Epoch 18: train_loss=1.060, validation_accuracy=0.8614\n","Epoch 19: train_loss=1.035, validation_accuracy=0.8668\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:14,905] Trial 5 finished with value: 0.8661 and parameters: {'hidden_dim': 22, 'activation_func': 'Sigmoid', 'lr': 0.0008678928057781409, 'momentum': 0.6951331506648264}. Best is trial 4 with value: 0.8837.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=1.011, validation_accuracy=0.8661\n","Epoch 1: train_loss=3.919, validation_accuracy=0.5386\n","Epoch 2: train_loss=1.206, validation_accuracy=0.6972\n","Epoch 3: train_loss=0.916, validation_accuracy=0.7714\n","Epoch 4: train_loss=0.758, validation_accuracy=0.8055\n","Epoch 5: train_loss=0.666, validation_accuracy=0.8291\n","Epoch 6: train_loss=0.606, validation_accuracy=0.8449\n","Epoch 7: train_loss=0.562, validation_accuracy=0.8564\n","Epoch 8: train_loss=0.529, validation_accuracy=0.8660\n","Epoch 9: train_loss=0.502, validation_accuracy=0.8747\n","Epoch 10: train_loss=0.479, validation_accuracy=0.8787\n","Epoch 11: train_loss=0.460, validation_accuracy=0.8833\n","Epoch 12: train_loss=0.444, validation_accuracy=0.8880\n","Epoch 13: train_loss=0.429, validation_accuracy=0.8912\n","Epoch 14: train_loss=0.415, validation_accuracy=0.8949\n","Epoch 15: train_loss=0.403, validation_accuracy=0.8971\n","Epoch 16: train_loss=0.393, validation_accuracy=0.8981\n","Epoch 17: train_loss=0.383, validation_accuracy=0.9023\n","Epoch 18: train_loss=0.373, validation_accuracy=0.9033\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:16,900] Trial 6 finished with value: 0.9067 and parameters: {'hidden_dim': 36, 'activation_func': 'ELU', 'lr': 1.2832545390956608e-05, 'momentum': 0.9784680995982606}. Best is trial 6 with value: 0.9067.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.365, validation_accuracy=0.9043\n","Epoch 20: train_loss=0.358, validation_accuracy=0.9067\n","Epoch 1: train_loss=2.369, validation_accuracy=0.0976\n","Epoch 2: train_loss=2.339, validation_accuracy=0.1091\n","Epoch 3: train_loss=2.314, validation_accuracy=0.1222\n","Epoch 4: train_loss=2.293, validation_accuracy=0.1372\n","Epoch 5: train_loss=2.274, validation_accuracy=0.1517\n","Epoch 6: train_loss=2.257, validation_accuracy=0.1683\n","Epoch 7: train_loss=2.241, validation_accuracy=0.1848\n","Epoch 8: train_loss=2.226, validation_accuracy=0.2038\n","Epoch 9: train_loss=2.211, validation_accuracy=0.2260\n","Epoch 10: train_loss=2.197, validation_accuracy=0.2496\n","Epoch 11: train_loss=2.183, validation_accuracy=0.2715\n","Epoch 12: train_loss=2.170, validation_accuracy=0.2881\n","Epoch 13: train_loss=2.158, validation_accuracy=0.3035\n","Epoch 14: train_loss=2.146, validation_accuracy=0.3163\n","Epoch 15: train_loss=2.134, validation_accuracy=0.3290\n","Epoch 16: train_loss=2.124, validation_accuracy=0.3415\n","Epoch 17: train_loss=2.113, validation_accuracy=0.3534\n","Epoch 18: train_loss=2.103, validation_accuracy=0.3654\n","Epoch 19: train_loss=2.093, validation_accuracy=0.3749\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:18,517] Trial 7 finished with value: 0.384 and parameters: {'hidden_dim': 31, 'activation_func': 'Sigmoid', 'lr': 1.6499386871508213e-05, 'momentum': 0.8252702287052598}. Best is trial 6 with value: 0.9067.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=2.083, validation_accuracy=0.3840\n","Epoch 1: train_loss=4.831, validation_accuracy=0.5662\n","Epoch 2: train_loss=1.769, validation_accuracy=0.6337\n","Epoch 3: train_loss=1.380, validation_accuracy=0.6872\n","Epoch 4: train_loss=1.186, validation_accuracy=0.7211\n","Epoch 5: train_loss=1.063, validation_accuracy=0.7466\n","Epoch 6: train_loss=0.975, validation_accuracy=0.7666\n","Epoch 7: train_loss=0.909, validation_accuracy=0.7804\n","Epoch 8: train_loss=0.855, validation_accuracy=0.7937\n","Epoch 9: train_loss=0.811, validation_accuracy=0.8040\n","Epoch 10: train_loss=0.774, validation_accuracy=0.8129\n","Epoch 11: train_loss=0.742, validation_accuracy=0.8190\n","Epoch 12: train_loss=0.713, validation_accuracy=0.8254\n","Epoch 13: train_loss=0.688, validation_accuracy=0.8335\n","Epoch 14: train_loss=0.666, validation_accuracy=0.8380\n","Epoch 15: train_loss=0.646, validation_accuracy=0.8438\n","Epoch 16: train_loss=0.628, validation_accuracy=0.8469\n","Epoch 17: train_loss=0.611, validation_accuracy=0.8496\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:20,088] Trial 8 finished with value: 0.8591 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 1.8022454658839353e-05, 'momentum': 0.8095968674096524}. Best is trial 6 with value: 0.9067.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.596, validation_accuracy=0.8523\n","Epoch 19: train_loss=0.582, validation_accuracy=0.8545\n","Epoch 20: train_loss=0.569, validation_accuracy=0.8591\n","Epoch 1: train_loss=2.186, validation_accuracy=0.4890\n","Epoch 2: train_loss=1.879, validation_accuracy=0.6423\n","Epoch 3: train_loss=1.695, validation_accuracy=0.7008\n","Epoch 4: train_loss=1.551, validation_accuracy=0.7480\n","Epoch 5: train_loss=1.423, validation_accuracy=0.7794\n","Epoch 6: train_loss=1.312, validation_accuracy=0.8133\n","Epoch 7: train_loss=1.215, validation_accuracy=0.8296\n","Epoch 8: train_loss=1.129, validation_accuracy=0.8481\n","Epoch 9: train_loss=1.055, validation_accuracy=0.8593\n","Epoch 10: train_loss=0.987, validation_accuracy=0.8667\n","Epoch 11: train_loss=0.928, validation_accuracy=0.8704\n","Epoch 12: train_loss=0.875, validation_accuracy=0.8729\n","Epoch 13: train_loss=0.829, validation_accuracy=0.8786\n","Epoch 14: train_loss=0.788, validation_accuracy=0.8791\n","Epoch 15: train_loss=0.752, validation_accuracy=0.8802\n","Epoch 16: train_loss=0.719, validation_accuracy=0.8837\n","Epoch 17: train_loss=0.689, validation_accuracy=0.8864\n","Epoch 18: train_loss=0.663, validation_accuracy=0.8884\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:21,659] Trial 9 finished with value: 0.8928 and parameters: {'hidden_dim': 23, 'activation_func': 'Sigmoid', 'lr': 0.00012116922979219344, 'momentum': 0.9850415521883736}. Best is trial 6 with value: 0.9067.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.639, validation_accuracy=0.8885\n","Epoch 20: train_loss=0.617, validation_accuracy=0.8928\n","Epoch 1: train_loss=165.530, validation_accuracy=0.1032\n","Epoch 2: train_loss=28.210, validation_accuracy=0.1135\n","Epoch 3: train_loss=17.510, validation_accuracy=0.1135\n","Epoch 4: train_loss=10.664, validation_accuracy=0.1135\n","Epoch 5: train_loss=5.710, validation_accuracy=0.1135\n","Epoch 6: train_loss=2.823, validation_accuracy=0.1135\n","Epoch 7: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 8: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 9: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 10: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 11: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 12: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 13: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 14: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 15: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 16: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 17: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 18: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 19: train_loss=2.302, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:23,412] Trial 10 finished with value: 0.1135 and parameters: {'hidden_dim': 39, 'activation_func': 'ELU', 'lr': 0.00879154045336726, 'momentum': 0.5647559528063972}. Best is trial 6 with value: 0.9067.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 1: train_loss=2.479, validation_accuracy=0.6025\n","Epoch 2: train_loss=1.010, validation_accuracy=0.7843\n","Epoch 3: train_loss=0.775, validation_accuracy=0.8290\n","Epoch 4: train_loss=0.635, validation_accuracy=0.8566\n","Epoch 5: train_loss=0.538, validation_accuracy=0.8698\n","Epoch 6: train_loss=0.478, validation_accuracy=0.8847\n","Epoch 7: train_loss=0.433, validation_accuracy=0.8937\n","Epoch 8: train_loss=0.398, validation_accuracy=0.8990\n","Epoch 9: train_loss=0.372, validation_accuracy=0.9065\n","Epoch 10: train_loss=0.354, validation_accuracy=0.9080\n","Epoch 11: train_loss=0.334, validation_accuracy=0.9119\n","Epoch 12: train_loss=0.320, validation_accuracy=0.9179\n","Epoch 13: train_loss=0.309, validation_accuracy=0.9192\n","Epoch 14: train_loss=0.299, validation_accuracy=0.9216\n","Epoch 15: train_loss=0.289, validation_accuracy=0.9237\n","Epoch 16: train_loss=0.282, validation_accuracy=0.9259\n","Epoch 17: train_loss=0.276, validation_accuracy=0.9253\n","Epoch 18: train_loss=0.270, validation_accuracy=0.9276\n","Epoch 19: train_loss=0.264, validation_accuracy=0.9285\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:25,356] Trial 11 finished with value: 0.9281 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 9.035152376488792e-05, 'momentum': 0.9914151175397956}. Best is trial 11 with value: 0.9281.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.260, validation_accuracy=0.9281\n","Epoch 1: train_loss=1.927, validation_accuracy=0.7722\n","Epoch 2: train_loss=0.727, validation_accuracy=0.8319\n","Epoch 3: train_loss=0.559, validation_accuracy=0.8617\n","Epoch 4: train_loss=0.462, validation_accuracy=0.8764\n","Epoch 5: train_loss=0.403, validation_accuracy=0.8940\n","Epoch 6: train_loss=0.362, validation_accuracy=0.9046\n","Epoch 7: train_loss=0.335, validation_accuracy=0.9109\n","Epoch 8: train_loss=0.312, validation_accuracy=0.9137\n","Epoch 9: train_loss=0.294, validation_accuracy=0.9134\n","Epoch 10: train_loss=0.283, validation_accuracy=0.9186\n","Epoch 11: train_loss=0.270, validation_accuracy=0.9212\n","Epoch 12: train_loss=0.260, validation_accuracy=0.9221\n","Epoch 13: train_loss=0.252, validation_accuracy=0.9220\n","Epoch 14: train_loss=0.247, validation_accuracy=0.9253\n","Epoch 15: train_loss=0.241, validation_accuracy=0.9268\n","Epoch 16: train_loss=0.235, validation_accuracy=0.9269\n","Epoch 17: train_loss=0.230, validation_accuracy=0.9283\n","Epoch 18: train_loss=0.228, validation_accuracy=0.9263\n","Epoch 19: train_loss=0.220, validation_accuracy=0.9301\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:27,269] Trial 12 finished with value: 0.9312 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 8.178829839367222e-05, 'momentum': 0.9888853232962571}. Best is trial 12 with value: 0.9312.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.215, validation_accuracy=0.9312\n","Epoch 1: train_loss=2.008, validation_accuracy=0.7945\n","Epoch 2: train_loss=0.648, validation_accuracy=0.8460\n","Epoch 3: train_loss=0.514, validation_accuracy=0.8696\n","Epoch 4: train_loss=0.440, validation_accuracy=0.8846\n","Epoch 5: train_loss=0.390, validation_accuracy=0.8936\n","Epoch 6: train_loss=0.354, validation_accuracy=0.9000\n","Epoch 7: train_loss=0.327, validation_accuracy=0.9044\n","Epoch 8: train_loss=0.305, validation_accuracy=0.9125\n","Epoch 9: train_loss=0.286, validation_accuracy=0.9162\n","Epoch 10: train_loss=0.271, validation_accuracy=0.9181\n","Epoch 11: train_loss=0.259, validation_accuracy=0.9208\n","Epoch 12: train_loss=0.248, validation_accuracy=0.9232\n","Epoch 13: train_loss=0.239, validation_accuracy=0.9239\n","Epoch 14: train_loss=0.231, validation_accuracy=0.9274\n","Epoch 15: train_loss=0.224, validation_accuracy=0.9271\n","Epoch 16: train_loss=0.218, validation_accuracy=0.9284\n","Epoch 17: train_loss=0.213, validation_accuracy=0.9300\n","Epoch 18: train_loss=0.208, validation_accuracy=0.9308\n","Epoch 19: train_loss=0.203, validation_accuracy=0.9318\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:29,608] Trial 13 finished with value: 0.9338 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00010943889377667568, 'momentum': 0.9180707709898601}. Best is trial 13 with value: 0.9338.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.199, validation_accuracy=0.9338\n","Epoch 1: train_loss=2.143, validation_accuracy=0.7033\n","Epoch 2: train_loss=0.838, validation_accuracy=0.8103\n","Epoch 3: train_loss=0.636, validation_accuracy=0.8402\n","Epoch 4: train_loss=0.537, validation_accuracy=0.8623\n","Epoch 5: train_loss=0.475, validation_accuracy=0.8772\n","Epoch 6: train_loss=0.431, validation_accuracy=0.8857\n","Epoch 7: train_loss=0.396, validation_accuracy=0.8914\n","Epoch 8: train_loss=0.370, validation_accuracy=0.8979\n","Epoch 9: train_loss=0.349, validation_accuracy=0.9024\n","Epoch 10: train_loss=0.331, validation_accuracy=0.9048\n","Epoch 11: train_loss=0.316, validation_accuracy=0.9065\n","Epoch 12: train_loss=0.304, validation_accuracy=0.9087\n","Epoch 13: train_loss=0.293, validation_accuracy=0.9120\n","Epoch 14: train_loss=0.283, validation_accuracy=0.9139\n","Epoch 15: train_loss=0.274, validation_accuracy=0.9155\n","Epoch 16: train_loss=0.267, validation_accuracy=0.9178\n","Epoch 17: train_loss=0.259, validation_accuracy=0.9196\n","Epoch 18: train_loss=0.253, validation_accuracy=0.9208\n","Epoch 19: train_loss=0.247, validation_accuracy=0.9221\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:32,038] Trial 14 finished with value: 0.9233 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 7.40538801349256e-05, 'momentum': 0.907808743721846}. Best is trial 13 with value: 0.9338.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.241, validation_accuracy=0.9233\n","Epoch 1: train_loss=1.642, validation_accuracy=0.7930\n","Epoch 2: train_loss=0.592, validation_accuracy=0.8605\n","Epoch 3: train_loss=0.463, validation_accuracy=0.8895\n","Epoch 4: train_loss=0.385, validation_accuracy=0.9039\n","Epoch 5: train_loss=0.337, validation_accuracy=0.9142\n","Epoch 6: train_loss=0.306, validation_accuracy=0.9186\n","Epoch 7: train_loss=0.283, validation_accuracy=0.9229\n","Epoch 8: train_loss=0.266, validation_accuracy=0.9242\n","Epoch 9: train_loss=0.252, validation_accuracy=0.9274\n","Epoch 10: train_loss=0.240, validation_accuracy=0.9276\n","Epoch 11: train_loss=0.230, validation_accuracy=0.9299\n","Epoch 12: train_loss=0.221, validation_accuracy=0.9305\n","Epoch 13: train_loss=0.215, validation_accuracy=0.9319\n","Epoch 14: train_loss=0.207, validation_accuracy=0.9323\n","Epoch 15: train_loss=0.201, validation_accuracy=0.9343\n","Epoch 16: train_loss=0.195, validation_accuracy=0.9371\n","Epoch 17: train_loss=0.189, validation_accuracy=0.9375\n","Epoch 18: train_loss=0.185, validation_accuracy=0.9375\n","Epoch 19: train_loss=0.180, validation_accuracy=0.9399\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:34,316] Trial 15 finished with value: 0.9397 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.00024546678976831987, 'momentum': 0.9163587003857323}. Best is trial 15 with value: 0.9397.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.176, validation_accuracy=0.9397\n","Epoch 1: train_loss=1.882, validation_accuracy=0.7986\n","Epoch 2: train_loss=0.567, validation_accuracy=0.8625\n","Epoch 3: train_loss=0.439, validation_accuracy=0.8877\n","Epoch 4: train_loss=0.376, validation_accuracy=0.8982\n","Epoch 5: train_loss=0.335, validation_accuracy=0.9072\n","Epoch 6: train_loss=0.308, validation_accuracy=0.9116\n","Epoch 7: train_loss=0.286, validation_accuracy=0.9173\n","Epoch 8: train_loss=0.268, validation_accuracy=0.9205\n","Epoch 9: train_loss=0.255, validation_accuracy=0.9256\n","Epoch 10: train_loss=0.242, validation_accuracy=0.9270\n","Epoch 11: train_loss=0.231, validation_accuracy=0.9296\n","Epoch 12: train_loss=0.223, validation_accuracy=0.9319\n","Epoch 13: train_loss=0.215, validation_accuracy=0.9346\n","Epoch 14: train_loss=0.209, validation_accuracy=0.9359\n","Epoch 15: train_loss=0.203, validation_accuracy=0.9372\n","Epoch 16: train_loss=0.198, validation_accuracy=0.9392\n","Epoch 17: train_loss=0.193, validation_accuracy=0.9385\n","Epoch 18: train_loss=0.188, validation_accuracy=0.9380\n","Epoch 19: train_loss=0.184, validation_accuracy=0.9414\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:36,850] Trial 16 finished with value: 0.9419 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.0002660970028436869, 'momentum': 0.8384625783626596}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.180, validation_accuracy=0.9419\n","Epoch 1: train_loss=1.545, validation_accuracy=0.8306\n","Epoch 2: train_loss=0.545, validation_accuracy=0.8703\n","Epoch 3: train_loss=0.435, validation_accuracy=0.8864\n","Epoch 4: train_loss=0.380, validation_accuracy=0.8979\n","Epoch 5: train_loss=0.345, validation_accuracy=0.9032\n","Epoch 6: train_loss=0.319, validation_accuracy=0.9089\n","Epoch 7: train_loss=0.299, validation_accuracy=0.9133\n","Epoch 8: train_loss=0.283, validation_accuracy=0.9141\n","Epoch 9: train_loss=0.270, validation_accuracy=0.9188\n","Epoch 10: train_loss=0.258, validation_accuracy=0.9220\n","Epoch 11: train_loss=0.248, validation_accuracy=0.9245\n","Epoch 12: train_loss=0.239, validation_accuracy=0.9270\n","Epoch 13: train_loss=0.231, validation_accuracy=0.9291\n","Epoch 14: train_loss=0.224, validation_accuracy=0.9303\n","Epoch 15: train_loss=0.217, validation_accuracy=0.9302\n","Epoch 16: train_loss=0.211, validation_accuracy=0.9324\n","Epoch 17: train_loss=0.206, validation_accuracy=0.9335\n","Epoch 18: train_loss=0.200, validation_accuracy=0.9330\n","Epoch 19: train_loss=0.194, validation_accuracy=0.9352\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:39,339] Trial 17 finished with value: 0.9358 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.0004022147930903596, 'momentum': 0.8016712300801881}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.190, validation_accuracy=0.9358\n","Epoch 1: train_loss=1.776, validation_accuracy=0.7787\n","Epoch 2: train_loss=0.628, validation_accuracy=0.8453\n","Epoch 3: train_loss=0.491, validation_accuracy=0.8694\n","Epoch 4: train_loss=0.423, validation_accuracy=0.8833\n","Epoch 5: train_loss=0.382, validation_accuracy=0.8904\n","Epoch 6: train_loss=0.353, validation_accuracy=0.8970\n","Epoch 7: train_loss=0.332, validation_accuracy=0.9020\n","Epoch 8: train_loss=0.315, validation_accuracy=0.9082\n","Epoch 9: train_loss=0.301, validation_accuracy=0.9084\n","Epoch 10: train_loss=0.289, validation_accuracy=0.9104\n","Epoch 11: train_loss=0.280, validation_accuracy=0.9152\n","Epoch 12: train_loss=0.270, validation_accuracy=0.9171\n","Epoch 13: train_loss=0.262, validation_accuracy=0.9184\n","Epoch 14: train_loss=0.255, validation_accuracy=0.9205\n","Epoch 15: train_loss=0.249, validation_accuracy=0.9203\n","Epoch 16: train_loss=0.244, validation_accuracy=0.9224\n","Epoch 17: train_loss=0.238, validation_accuracy=0.9237\n","Epoch 18: train_loss=0.233, validation_accuracy=0.9250\n","Epoch 19: train_loss=0.228, validation_accuracy=0.9265\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:41,512] Trial 18 finished with value: 0.9269 and parameters: {'hidden_dim': 35, 'activation_func': 'ELU', 'lr': 0.0002584902415874618, 'momentum': 0.8585627899580573}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.223, validation_accuracy=0.9269\n","Epoch 1: train_loss=1.869, validation_accuracy=0.6164\n","Epoch 2: train_loss=1.349, validation_accuracy=0.7330\n","Epoch 3: train_loss=1.131, validation_accuracy=0.7856\n","Epoch 4: train_loss=0.996, validation_accuracy=0.8156\n","Epoch 5: train_loss=0.902, validation_accuracy=0.8361\n","Epoch 6: train_loss=0.830, validation_accuracy=0.8500\n","Epoch 7: train_loss=0.774, validation_accuracy=0.8582\n","Epoch 8: train_loss=0.727, validation_accuracy=0.8660\n","Epoch 9: train_loss=0.686, validation_accuracy=0.8694\n","Epoch 10: train_loss=0.652, validation_accuracy=0.8756\n","Epoch 11: train_loss=0.622, validation_accuracy=0.8782\n","Epoch 12: train_loss=0.596, validation_accuracy=0.8845\n","Epoch 13: train_loss=0.573, validation_accuracy=0.8861\n","Epoch 14: train_loss=0.553, validation_accuracy=0.8881\n","Epoch 15: train_loss=0.534, validation_accuracy=0.8915\n","Epoch 16: train_loss=0.518, validation_accuracy=0.8945\n","Epoch 17: train_loss=0.503, validation_accuracy=0.8945\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:43,278] Trial 19 finished with value: 0.9007 and parameters: {'hidden_dim': 45, 'activation_func': 'Tanh', 'lr': 0.00036573633284952775, 'momentum': 0.7769429749807124}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.491, validation_accuracy=0.8969\n","Epoch 19: train_loss=0.478, validation_accuracy=0.8986\n","Epoch 20: train_loss=0.467, validation_accuracy=0.9007\n","Epoch 1: train_loss=1.676, validation_accuracy=0.8226\n","Epoch 2: train_loss=0.583, validation_accuracy=0.8641\n","Epoch 3: train_loss=0.462, validation_accuracy=0.8852\n","Epoch 4: train_loss=0.396, validation_accuracy=0.8963\n","Epoch 5: train_loss=0.352, validation_accuracy=0.9067\n","Epoch 6: train_loss=0.322, validation_accuracy=0.9120\n","Epoch 7: train_loss=0.299, validation_accuracy=0.9168\n","Epoch 8: train_loss=0.280, validation_accuracy=0.9208\n","Epoch 9: train_loss=0.264, validation_accuracy=0.9230\n","Epoch 10: train_loss=0.251, validation_accuracy=0.9254\n","Epoch 11: train_loss=0.240, validation_accuracy=0.9293\n","Epoch 12: train_loss=0.230, validation_accuracy=0.9298\n","Epoch 13: train_loss=0.221, validation_accuracy=0.9312\n","Epoch 14: train_loss=0.214, validation_accuracy=0.9332\n","Epoch 15: train_loss=0.206, validation_accuracy=0.9345\n","Epoch 16: train_loss=0.200, validation_accuracy=0.9337\n","Epoch 17: train_loss=0.194, validation_accuracy=0.9364\n","Epoch 18: train_loss=0.189, validation_accuracy=0.9368\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:45,806] Trial 20 finished with value: 0.9392 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 0.0001983892617479747, 'momentum': 0.8564603723859742}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.184, validation_accuracy=0.9394\n","Epoch 20: train_loss=0.179, validation_accuracy=0.9392\n","Epoch 1: train_loss=1.866, validation_accuracy=0.8098\n","Epoch 2: train_loss=0.621, validation_accuracy=0.8504\n","Epoch 3: train_loss=0.501, validation_accuracy=0.8746\n","Epoch 4: train_loss=0.433, validation_accuracy=0.8859\n","Epoch 5: train_loss=0.387, validation_accuracy=0.8945\n","Epoch 6: train_loss=0.352, validation_accuracy=0.9017\n","Epoch 7: train_loss=0.325, validation_accuracy=0.9074\n","Epoch 8: train_loss=0.304, validation_accuracy=0.9119\n","Epoch 9: train_loss=0.287, validation_accuracy=0.9165\n","Epoch 10: train_loss=0.272, validation_accuracy=0.9190\n","Epoch 11: train_loss=0.260, validation_accuracy=0.9223\n","Epoch 12: train_loss=0.248, validation_accuracy=0.9237\n","Epoch 13: train_loss=0.239, validation_accuracy=0.9246\n","Epoch 14: train_loss=0.231, validation_accuracy=0.9257\n","Epoch 15: train_loss=0.223, validation_accuracy=0.9282\n","Epoch 16: train_loss=0.217, validation_accuracy=0.9285\n","Epoch 17: train_loss=0.211, validation_accuracy=0.9299\n","Epoch 18: train_loss=0.206, validation_accuracy=0.9298\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:48,309] Trial 21 finished with value: 0.932 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.0001788613211710298, 'momentum': 0.8549599999073267}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.200, validation_accuracy=0.9320\n","Epoch 20: train_loss=0.195, validation_accuracy=0.9320\n","Epoch 1: train_loss=2.394, validation_accuracy=0.5607\n","Epoch 2: train_loss=1.033, validation_accuracy=0.6823\n","Epoch 3: train_loss=0.797, validation_accuracy=0.7528\n","Epoch 4: train_loss=0.616, validation_accuracy=0.8282\n","Epoch 5: train_loss=0.516, validation_accuracy=0.8521\n","Epoch 6: train_loss=0.462, validation_accuracy=0.8676\n","Epoch 7: train_loss=0.430, validation_accuracy=0.8763\n","Epoch 8: train_loss=0.410, validation_accuracy=0.8784\n","Epoch 9: train_loss=0.393, validation_accuracy=0.8822\n","Epoch 10: train_loss=0.377, validation_accuracy=0.8913\n","Epoch 11: train_loss=0.359, validation_accuracy=0.8964\n","Epoch 12: train_loss=0.341, validation_accuracy=0.8989\n","Epoch 13: train_loss=0.328, validation_accuracy=0.9045\n","Epoch 14: train_loss=0.316, validation_accuracy=0.9082\n","Epoch 15: train_loss=0.307, validation_accuracy=0.9105\n","Epoch 16: train_loss=0.297, validation_accuracy=0.9137\n","Epoch 17: train_loss=0.287, validation_accuracy=0.9132\n","Epoch 18: train_loss=0.277, validation_accuracy=0.9175\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:50,313] Trial 22 finished with value: 0.9222 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0005599320833020706, 'momentum': 0.9343089492578196}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.269, validation_accuracy=0.9203\n","Epoch 20: train_loss=0.259, validation_accuracy=0.9222\n","Epoch 1: train_loss=1.695, validation_accuracy=0.8077\n","Epoch 2: train_loss=0.577, validation_accuracy=0.8555\n","Epoch 3: train_loss=0.456, validation_accuracy=0.8830\n","Epoch 4: train_loss=0.392, validation_accuracy=0.8959\n","Epoch 5: train_loss=0.351, validation_accuracy=0.9053\n","Epoch 6: train_loss=0.321, validation_accuracy=0.9126\n","Epoch 7: train_loss=0.298, validation_accuracy=0.9161\n","Epoch 8: train_loss=0.280, validation_accuracy=0.9201\n","Epoch 9: train_loss=0.265, validation_accuracy=0.9224\n","Epoch 10: train_loss=0.252, validation_accuracy=0.9252\n","Epoch 11: train_loss=0.242, validation_accuracy=0.9282\n","Epoch 12: train_loss=0.233, validation_accuracy=0.9288\n","Epoch 13: train_loss=0.225, validation_accuracy=0.9299\n","Epoch 14: train_loss=0.218, validation_accuracy=0.9318\n","Epoch 15: train_loss=0.211, validation_accuracy=0.9325\n","Epoch 16: train_loss=0.205, validation_accuracy=0.9341\n","Epoch 17: train_loss=0.201, validation_accuracy=0.9343\n","Epoch 18: train_loss=0.196, validation_accuracy=0.9354\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:52,941] Trial 23 finished with value: 0.9371 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00019150676004093796, 'momentum': 0.8618230492360812}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.192, validation_accuracy=0.9365\n","Epoch 20: train_loss=0.188, validation_accuracy=0.9371\n","Epoch 1: train_loss=3.031, validation_accuracy=0.7913\n","Epoch 2: train_loss=0.708, validation_accuracy=0.8407\n","Epoch 3: train_loss=0.573, validation_accuracy=0.8664\n","Epoch 4: train_loss=0.496, validation_accuracy=0.8798\n","Epoch 5: train_loss=0.444, validation_accuracy=0.8901\n","Epoch 6: train_loss=0.405, validation_accuracy=0.8931\n","Epoch 7: train_loss=0.374, validation_accuracy=0.8994\n","Epoch 8: train_loss=0.350, validation_accuracy=0.9035\n","Epoch 9: train_loss=0.331, validation_accuracy=0.9079\n","Epoch 10: train_loss=0.314, validation_accuracy=0.9145\n","Epoch 11: train_loss=0.300, validation_accuracy=0.9182\n","Epoch 12: train_loss=0.288, validation_accuracy=0.9196\n","Epoch 13: train_loss=0.277, validation_accuracy=0.9208\n","Epoch 14: train_loss=0.268, validation_accuracy=0.9221\n","Epoch 15: train_loss=0.259, validation_accuracy=0.9223\n","Epoch 16: train_loss=0.252, validation_accuracy=0.9254\n","Epoch 17: train_loss=0.245, validation_accuracy=0.9259\n","Epoch 18: train_loss=0.238, validation_accuracy=0.9272\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:55,524] Trial 24 finished with value: 0.9294 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 4.714322045719687e-05, 'momentum': 0.9385067904945825}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.232, validation_accuracy=0.9273\n","Epoch 20: train_loss=0.227, validation_accuracy=0.9294\n","Epoch 1: train_loss=1.899, validation_accuracy=0.8034\n","Epoch 2: train_loss=0.596, validation_accuracy=0.8635\n","Epoch 3: train_loss=0.477, validation_accuracy=0.8855\n","Epoch 4: train_loss=0.419, validation_accuracy=0.8967\n","Epoch 5: train_loss=0.381, validation_accuracy=0.9017\n","Epoch 6: train_loss=0.353, validation_accuracy=0.9076\n","Epoch 7: train_loss=0.332, validation_accuracy=0.9105\n","Epoch 8: train_loss=0.313, validation_accuracy=0.9137\n","Epoch 9: train_loss=0.297, validation_accuracy=0.9163\n","Epoch 10: train_loss=0.285, validation_accuracy=0.9182\n","Epoch 11: train_loss=0.274, validation_accuracy=0.9201\n","Epoch 12: train_loss=0.265, validation_accuracy=0.9208\n","Epoch 13: train_loss=0.257, validation_accuracy=0.9262\n","Epoch 14: train_loss=0.249, validation_accuracy=0.9286\n","Epoch 15: train_loss=0.243, validation_accuracy=0.9282\n","Epoch 16: train_loss=0.237, validation_accuracy=0.9309\n","Epoch 17: train_loss=0.231, validation_accuracy=0.9305\n","Epoch 18: train_loss=0.226, validation_accuracy=0.9312\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:57,721] Trial 25 finished with value: 0.9333 and parameters: {'hidden_dim': 37, 'activation_func': 'ELU', 'lr': 0.00028042894467293866, 'momentum': 0.84190125982011}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.222, validation_accuracy=0.9327\n","Epoch 20: train_loss=0.218, validation_accuracy=0.9333\n","Epoch 1: train_loss=2.820, validation_accuracy=0.2382\n","Epoch 2: train_loss=2.050, validation_accuracy=0.3230\n","Epoch 3: train_loss=1.900, validation_accuracy=0.3513\n","Epoch 4: train_loss=1.825, validation_accuracy=0.3632\n","Epoch 5: train_loss=1.782, validation_accuracy=0.3722\n","Epoch 6: train_loss=1.751, validation_accuracy=0.3770\n","Epoch 7: train_loss=1.722, validation_accuracy=0.3830\n","Epoch 8: train_loss=1.689, validation_accuracy=0.3901\n","Epoch 9: train_loss=1.657, validation_accuracy=0.3928\n","Epoch 10: train_loss=1.631, validation_accuracy=0.3970\n","Epoch 11: train_loss=1.605, validation_accuracy=0.4084\n","Epoch 12: train_loss=1.572, validation_accuracy=0.4250\n","Epoch 13: train_loss=1.516, validation_accuracy=0.4431\n","Epoch 14: train_loss=1.467, validation_accuracy=0.4522\n","Epoch 15: train_loss=1.432, validation_accuracy=0.4671\n","Epoch 16: train_loss=1.410, validation_accuracy=0.4688\n","Epoch 17: train_loss=1.393, validation_accuracy=0.4714\n","Epoch 18: train_loss=1.379, validation_accuracy=0.4758\n","Epoch 19: train_loss=1.367, validation_accuracy=0.4777\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:31:59,185] Trial 26 finished with value: 0.4798 and parameters: {'hidden_dim': 11, 'activation_func': 'ELU', 'lr': 4.0612811500850435e-05, 'momentum': 0.7761555487807899}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=1.354, validation_accuracy=0.4798\n","Epoch 1: train_loss=2.208, validation_accuracy=0.3981\n","Epoch 2: train_loss=1.972, validation_accuracy=0.5167\n","Epoch 3: train_loss=1.818, validation_accuracy=0.5997\n","Epoch 4: train_loss=1.707, validation_accuracy=0.6502\n","Epoch 5: train_loss=1.619, validation_accuracy=0.6842\n","Epoch 6: train_loss=1.546, validation_accuracy=0.7124\n","Epoch 7: train_loss=1.483, validation_accuracy=0.7380\n","Epoch 8: train_loss=1.427, validation_accuracy=0.7568\n","Epoch 9: train_loss=1.377, validation_accuracy=0.7769\n","Epoch 10: train_loss=1.330, validation_accuracy=0.7944\n","Epoch 11: train_loss=1.285, validation_accuracy=0.8078\n","Epoch 12: train_loss=1.245, validation_accuracy=0.8184\n","Epoch 13: train_loss=1.207, validation_accuracy=0.8278\n","Epoch 14: train_loss=1.171, validation_accuracy=0.8360\n","Epoch 15: train_loss=1.137, validation_accuracy=0.8406\n","Epoch 16: train_loss=1.105, validation_accuracy=0.8437\n","Epoch 17: train_loss=1.075, validation_accuracy=0.8494\n","Epoch 18: train_loss=1.046, validation_accuracy=0.8523\n","Epoch 19: train_loss=1.018, validation_accuracy=0.8541\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:01,510] Trial 27 finished with value: 0.8584 and parameters: {'hidden_dim': 47, 'activation_func': 'Sigmoid', 'lr': 0.00016397974121165322, 'momentum': 0.886478309921702}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.992, validation_accuracy=0.8584\n","Epoch 1: train_loss=1.833, validation_accuracy=0.6705\n","Epoch 2: train_loss=1.301, validation_accuracy=0.7765\n","Epoch 3: train_loss=1.094, validation_accuracy=0.8213\n","Epoch 4: train_loss=0.961, validation_accuracy=0.8456\n","Epoch 5: train_loss=0.864, validation_accuracy=0.8577\n","Epoch 6: train_loss=0.791, validation_accuracy=0.8677\n","Epoch 7: train_loss=0.732, validation_accuracy=0.8743\n","Epoch 8: train_loss=0.684, validation_accuracy=0.8782\n","Epoch 9: train_loss=0.642, validation_accuracy=0.8828\n","Epoch 10: train_loss=0.607, validation_accuracy=0.8847\n","Epoch 11: train_loss=0.577, validation_accuracy=0.8889\n","Epoch 12: train_loss=0.551, validation_accuracy=0.8911\n","Epoch 13: train_loss=0.528, validation_accuracy=0.8954\n","Epoch 14: train_loss=0.505, validation_accuracy=0.8961\n","Epoch 15: train_loss=0.488, validation_accuracy=0.8984\n","Epoch 16: train_loss=0.470, validation_accuracy=0.8988\n","Epoch 17: train_loss=0.455, validation_accuracy=0.9019\n","Epoch 18: train_loss=0.440, validation_accuracy=0.9006\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:03,276] Trial 28 finished with value: 0.9032 and parameters: {'hidden_dim': 34, 'activation_func': 'Tanh', 'lr': 0.0005225831119454467, 'momentum': 0.8283476168625541}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.429, validation_accuracy=0.9034\n","Epoch 20: train_loss=0.418, validation_accuracy=0.9032\n","Epoch 1: train_loss=1.791, validation_accuracy=0.6964\n","Epoch 2: train_loss=1.207, validation_accuracy=0.7958\n","Epoch 3: train_loss=0.983, validation_accuracy=0.8261\n","Epoch 4: train_loss=0.850, validation_accuracy=0.8418\n","Epoch 5: train_loss=0.757, validation_accuracy=0.8543\n","Epoch 6: train_loss=0.688, validation_accuracy=0.8660\n","Epoch 7: train_loss=0.636, validation_accuracy=0.8731\n","Epoch 8: train_loss=0.594, validation_accuracy=0.8774\n","Epoch 9: train_loss=0.559, validation_accuracy=0.8812\n","Epoch 10: train_loss=0.531, validation_accuracy=0.8833\n","Epoch 11: train_loss=0.506, validation_accuracy=0.8866\n","Epoch 12: train_loss=0.486, validation_accuracy=0.8911\n","Epoch 13: train_loss=0.467, validation_accuracy=0.8937\n","Epoch 14: train_loss=0.451, validation_accuracy=0.8932\n","Epoch 15: train_loss=0.436, validation_accuracy=0.8971\n","Epoch 16: train_loss=0.423, validation_accuracy=0.8955\n","Epoch 17: train_loss=0.411, validation_accuracy=0.8986\n","Epoch 18: train_loss=0.401, validation_accuracy=0.9012\n","Epoch 19: train_loss=0.391, validation_accuracy=0.9008\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:05,082] Trial 29 finished with value: 0.9045 and parameters: {'hidden_dim': 50, 'activation_func': 'Tanh', 'lr': 0.00024802566310253097, 'momentum': 0.8967900431140616}. Best is trial 16 with value: 0.9419.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.382, validation_accuracy=0.9045\n","Epoch 1: train_loss=1.794, validation_accuracy=0.8372\n","Epoch 2: train_loss=0.504, validation_accuracy=0.8817\n","Epoch 3: train_loss=0.396, validation_accuracy=0.8979\n","Epoch 4: train_loss=0.338, validation_accuracy=0.9090\n","Epoch 5: train_loss=0.302, validation_accuracy=0.9192\n","Epoch 6: train_loss=0.278, validation_accuracy=0.9224\n","Epoch 7: train_loss=0.260, validation_accuracy=0.9271\n","Epoch 8: train_loss=0.245, validation_accuracy=0.9290\n","Epoch 9: train_loss=0.233, validation_accuracy=0.9315\n","Epoch 10: train_loss=0.222, validation_accuracy=0.9327\n","Epoch 11: train_loss=0.214, validation_accuracy=0.9340\n","Epoch 12: train_loss=0.208, validation_accuracy=0.9348\n","Epoch 13: train_loss=0.201, validation_accuracy=0.9374\n","Epoch 14: train_loss=0.196, validation_accuracy=0.9366\n","Epoch 15: train_loss=0.190, validation_accuracy=0.9390\n","Epoch 16: train_loss=0.186, validation_accuracy=0.9396\n","Epoch 17: train_loss=0.182, validation_accuracy=0.9403\n","Epoch 18: train_loss=0.178, validation_accuracy=0.9396\n","Epoch 19: train_loss=0.174, validation_accuracy=0.9429\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:07,350] Trial 30 finished with value: 0.9421 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00014907503625148617, 'momentum': 0.94605407828453}. Best is trial 30 with value: 0.9421.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.171, validation_accuracy=0.9421\n","Epoch 1: train_loss=2.033, validation_accuracy=0.7813\n","Epoch 2: train_loss=0.661, validation_accuracy=0.8639\n","Epoch 3: train_loss=0.476, validation_accuracy=0.8847\n","Epoch 4: train_loss=0.397, validation_accuracy=0.8983\n","Epoch 5: train_loss=0.351, validation_accuracy=0.9078\n","Epoch 6: train_loss=0.319, validation_accuracy=0.9139\n","Epoch 7: train_loss=0.296, validation_accuracy=0.9184\n","Epoch 8: train_loss=0.276, validation_accuracy=0.9197\n","Epoch 9: train_loss=0.261, validation_accuracy=0.9248\n","Epoch 10: train_loss=0.249, validation_accuracy=0.9268\n","Epoch 11: train_loss=0.238, validation_accuracy=0.9287\n","Epoch 12: train_loss=0.229, validation_accuracy=0.9306\n","Epoch 13: train_loss=0.220, validation_accuracy=0.9340\n","Epoch 14: train_loss=0.213, validation_accuracy=0.9333\n","Epoch 15: train_loss=0.208, validation_accuracy=0.9370\n","Epoch 16: train_loss=0.203, validation_accuracy=0.9370\n","Epoch 17: train_loss=0.198, validation_accuracy=0.9388\n","Epoch 18: train_loss=0.194, validation_accuracy=0.9394\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:09,466] Trial 31 finished with value: 0.9399 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00015032060908039475, 'momentum': 0.9447836589030433}. Best is trial 30 with value: 0.9421.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.189, validation_accuracy=0.9405\n","Epoch 20: train_loss=0.186, validation_accuracy=0.9399\n","Epoch 1: train_loss=2.043, validation_accuracy=0.7925\n","Epoch 2: train_loss=0.622, validation_accuracy=0.8561\n","Epoch 3: train_loss=0.475, validation_accuracy=0.8853\n","Epoch 4: train_loss=0.395, validation_accuracy=0.8988\n","Epoch 5: train_loss=0.345, validation_accuracy=0.9091\n","Epoch 6: train_loss=0.311, validation_accuracy=0.9158\n","Epoch 7: train_loss=0.288, validation_accuracy=0.9177\n","Epoch 8: train_loss=0.269, validation_accuracy=0.9238\n","Epoch 9: train_loss=0.253, validation_accuracy=0.9270\n","Epoch 10: train_loss=0.241, validation_accuracy=0.9275\n","Epoch 11: train_loss=0.231, validation_accuracy=0.9299\n","Epoch 12: train_loss=0.223, validation_accuracy=0.9328\n","Epoch 13: train_loss=0.215, validation_accuracy=0.9321\n","Epoch 14: train_loss=0.209, validation_accuracy=0.9349\n","Epoch 15: train_loss=0.202, validation_accuracy=0.9360\n","Epoch 16: train_loss=0.197, validation_accuracy=0.9375\n","Epoch 17: train_loss=0.191, validation_accuracy=0.9385\n","Epoch 18: train_loss=0.186, validation_accuracy=0.9396\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:11,555] Trial 32 finished with value: 0.9408 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.00013388523825287713, 'momentum': 0.9564551924002929}. Best is trial 30 with value: 0.9421.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.181, validation_accuracy=0.9400\n","Epoch 20: train_loss=0.177, validation_accuracy=0.9408\n","Epoch 1: train_loss=1.830, validation_accuracy=0.8311\n","Epoch 2: train_loss=0.508, validation_accuracy=0.8793\n","Epoch 3: train_loss=0.395, validation_accuracy=0.9001\n","Epoch 4: train_loss=0.336, validation_accuracy=0.9100\n","Epoch 5: train_loss=0.298, validation_accuracy=0.9153\n","Epoch 6: train_loss=0.271, validation_accuracy=0.9200\n","Epoch 7: train_loss=0.252, validation_accuracy=0.9250\n","Epoch 8: train_loss=0.236, validation_accuracy=0.9287\n","Epoch 9: train_loss=0.223, validation_accuracy=0.9305\n","Epoch 10: train_loss=0.211, validation_accuracy=0.9325\n","Epoch 11: train_loss=0.202, validation_accuracy=0.9344\n","Epoch 12: train_loss=0.193, validation_accuracy=0.9361\n","Epoch 13: train_loss=0.186, validation_accuracy=0.9373\n","Epoch 14: train_loss=0.179, validation_accuracy=0.9381\n","Epoch 15: train_loss=0.173, validation_accuracy=0.9414\n","Epoch 16: train_loss=0.167, validation_accuracy=0.9412\n","Epoch 17: train_loss=0.163, validation_accuracy=0.9417\n","Epoch 18: train_loss=0.158, validation_accuracy=0.9452\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:13,772] Trial 33 finished with value: 0.9448 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00013517560908049732, 'momentum': 0.9507501082623552}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.154, validation_accuracy=0.9425\n","Epoch 20: train_loss=0.150, validation_accuracy=0.9448\n","Epoch 1: train_loss=2.491, validation_accuracy=0.5793\n","Epoch 2: train_loss=1.120, validation_accuracy=0.7320\n","Epoch 3: train_loss=0.939, validation_accuracy=0.7782\n","Epoch 4: train_loss=0.827, validation_accuracy=0.8025\n","Epoch 5: train_loss=0.749, validation_accuracy=0.8089\n","Epoch 6: train_loss=0.696, validation_accuracy=0.8162\n","Epoch 7: train_loss=0.654, validation_accuracy=0.8252\n","Epoch 8: train_loss=0.605, validation_accuracy=0.8418\n","Epoch 9: train_loss=0.548, validation_accuracy=0.8504\n","Epoch 10: train_loss=0.494, validation_accuracy=0.8603\n","Epoch 11: train_loss=0.451, validation_accuracy=0.8699\n","Epoch 12: train_loss=0.420, validation_accuracy=0.8763\n","Epoch 13: train_loss=0.396, validation_accuracy=0.8808\n","Epoch 14: train_loss=0.378, validation_accuracy=0.8849\n","Epoch 15: train_loss=0.362, validation_accuracy=0.8872\n","Epoch 16: train_loss=0.350, validation_accuracy=0.8899\n","Epoch 17: train_loss=0.339, validation_accuracy=0.8950\n","Epoch 18: train_loss=0.330, validation_accuracy=0.8982\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:15,279] Trial 34 finished with value: 0.9014 and parameters: {'hidden_dim': 38, 'activation_func': 'ReLU', 'lr': 5.4789035619553734e-05, 'momentum': 0.962557567589222}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.320, validation_accuracy=0.8998\n","Epoch 20: train_loss=0.312, validation_accuracy=0.9014\n","Epoch 1: train_loss=2.544, validation_accuracy=0.4747\n","Epoch 2: train_loss=1.164, validation_accuracy=0.7174\n","Epoch 3: train_loss=0.791, validation_accuracy=0.8004\n","Epoch 4: train_loss=0.633, validation_accuracy=0.8358\n","Epoch 5: train_loss=0.547, validation_accuracy=0.8577\n","Epoch 6: train_loss=0.493, validation_accuracy=0.8695\n","Epoch 7: train_loss=0.453, validation_accuracy=0.8789\n","Epoch 8: train_loss=0.424, validation_accuracy=0.8858\n","Epoch 9: train_loss=0.401, validation_accuracy=0.8907\n","Epoch 10: train_loss=0.382, validation_accuracy=0.8945\n","Epoch 11: train_loss=0.367, validation_accuracy=0.8953\n","Epoch 12: train_loss=0.355, validation_accuracy=0.8991\n","Epoch 13: train_loss=0.344, validation_accuracy=0.9001\n","Epoch 14: train_loss=0.336, validation_accuracy=0.9020\n","Epoch 15: train_loss=0.328, validation_accuracy=0.9029\n","Epoch 16: train_loss=0.321, validation_accuracy=0.9051\n","Epoch 17: train_loss=0.314, validation_accuracy=0.9067\n","Epoch 18: train_loss=0.308, validation_accuracy=0.9077\n","Epoch 19: train_loss=0.303, validation_accuracy=0.9082\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:16,992] Trial 35 finished with value: 0.9099 and parameters: {'hidden_dim': 33, 'activation_func': 'ELU', 'lr': 0.00011105108679259807, 'momentum': 0.9578719782106638}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.298, validation_accuracy=0.9099\n","Epoch 1: train_loss=3.282, validation_accuracy=0.4506\n","Epoch 2: train_loss=1.539, validation_accuracy=0.5551\n","Epoch 3: train_loss=1.288, validation_accuracy=0.6397\n","Epoch 4: train_loss=1.112, validation_accuracy=0.6922\n","Epoch 5: train_loss=0.982, validation_accuracy=0.7332\n","Epoch 6: train_loss=0.887, validation_accuracy=0.7609\n","Epoch 7: train_loss=0.819, validation_accuracy=0.7788\n","Epoch 8: train_loss=0.766, validation_accuracy=0.7914\n","Epoch 9: train_loss=0.722, validation_accuracy=0.8034\n","Epoch 10: train_loss=0.685, validation_accuracy=0.8152\n","Epoch 11: train_loss=0.654, validation_accuracy=0.8252\n","Epoch 12: train_loss=0.626, validation_accuracy=0.8320\n","Epoch 13: train_loss=0.601, validation_accuracy=0.8411\n","Epoch 14: train_loss=0.579, validation_accuracy=0.8452\n","Epoch 15: train_loss=0.560, validation_accuracy=0.8503\n","Epoch 16: train_loss=0.543, validation_accuracy=0.8552\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:18,312] Trial 36 finished with value: 0.869 and parameters: {'hidden_dim': 28, 'activation_func': 'ReLU', 'lr': 3.108645847887955e-05, 'momentum': 0.8915268320345964}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.527, validation_accuracy=0.8580\n","Epoch 18: train_loss=0.513, validation_accuracy=0.8643\n","Epoch 19: train_loss=0.499, validation_accuracy=0.8696\n","Epoch 20: train_loss=0.487, validation_accuracy=0.8690\n","Epoch 1: train_loss=2.056, validation_accuracy=0.8383\n","Epoch 2: train_loss=0.548, validation_accuracy=0.8723\n","Epoch 3: train_loss=0.448, validation_accuracy=0.8875\n","Epoch 4: train_loss=0.395, validation_accuracy=0.9002\n","Epoch 5: train_loss=0.360, validation_accuracy=0.9050\n","Epoch 6: train_loss=0.334, validation_accuracy=0.9103\n","Epoch 7: train_loss=0.313, validation_accuracy=0.9149\n","Epoch 8: train_loss=0.295, validation_accuracy=0.9183\n","Epoch 9: train_loss=0.280, validation_accuracy=0.9222\n","Epoch 10: train_loss=0.268, validation_accuracy=0.9245\n","Epoch 11: train_loss=0.256, validation_accuracy=0.9270\n","Epoch 12: train_loss=0.246, validation_accuracy=0.9292\n","Epoch 13: train_loss=0.236, validation_accuracy=0.9295\n","Epoch 14: train_loss=0.228, validation_accuracy=0.9327\n","Epoch 15: train_loss=0.220, validation_accuracy=0.9340\n","Epoch 16: train_loss=0.214, validation_accuracy=0.9344\n","Epoch 17: train_loss=0.207, validation_accuracy=0.9367\n","Epoch 18: train_loss=0.201, validation_accuracy=0.9368\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:20,819] Trial 37 finished with value: 0.939 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 6.439005839207221e-05, 'momentum': 0.9575411957842059}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.196, validation_accuracy=0.9373\n","Epoch 20: train_loss=0.191, validation_accuracy=0.9390\n","Epoch 1: train_loss=2.116, validation_accuracy=0.6341\n","Epoch 2: train_loss=1.679, validation_accuracy=0.7020\n","Epoch 3: train_loss=1.366, validation_accuracy=0.7775\n","Epoch 4: train_loss=1.041, validation_accuracy=0.8129\n","Epoch 5: train_loss=0.781, validation_accuracy=0.8385\n","Epoch 6: train_loss=0.619, validation_accuracy=0.8527\n","Epoch 7: train_loss=0.533, validation_accuracy=0.8654\n","Epoch 8: train_loss=0.479, validation_accuracy=0.8718\n","Epoch 9: train_loss=0.457, validation_accuracy=0.8748\n","Epoch 10: train_loss=0.447, validation_accuracy=0.8769\n","Epoch 11: train_loss=0.443, validation_accuracy=0.8802\n","Epoch 12: train_loss=0.440, validation_accuracy=0.8827\n","Epoch 13: train_loss=0.438, validation_accuracy=0.8853\n","Epoch 14: train_loss=0.438, validation_accuracy=0.8874\n","Epoch 15: train_loss=0.439, validation_accuracy=0.8917\n","Epoch 16: train_loss=0.441, validation_accuracy=0.8938\n","Epoch 17: train_loss=0.444, validation_accuracy=0.8923\n","Epoch 18: train_loss=0.453, validation_accuracy=0.8910\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:22,504] Trial 38 finished with value: 0.8933 and parameters: {'hidden_dim': 38, 'activation_func': 'Sigmoid', 'lr': 0.00011829869526731271, 'momentum': 0.9997746964189058}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.463, validation_accuracy=0.8922\n","Epoch 20: train_loss=0.472, validation_accuracy=0.8933\n","Epoch 1: train_loss=1.877, validation_accuracy=0.6418\n","Epoch 2: train_loss=1.374, validation_accuracy=0.7415\n","Epoch 3: train_loss=1.175, validation_accuracy=0.7887\n","Epoch 4: train_loss=1.046, validation_accuracy=0.8110\n","Epoch 5: train_loss=0.945, validation_accuracy=0.8304\n","Epoch 6: train_loss=0.863, validation_accuracy=0.8421\n","Epoch 7: train_loss=0.798, validation_accuracy=0.8528\n","Epoch 8: train_loss=0.745, validation_accuracy=0.8602\n","Epoch 9: train_loss=0.701, validation_accuracy=0.8630\n","Epoch 10: train_loss=0.665, validation_accuracy=0.8704\n","Epoch 11: train_loss=0.633, validation_accuracy=0.8696\n","Epoch 12: train_loss=0.603, validation_accuracy=0.8743\n","Epoch 13: train_loss=0.579, validation_accuracy=0.8722\n","Epoch 14: train_loss=0.562, validation_accuracy=0.8788\n","Epoch 15: train_loss=0.541, validation_accuracy=0.8825\n","Epoch 16: train_loss=0.527, validation_accuracy=0.8806\n","Epoch 17: train_loss=0.511, validation_accuracy=0.8863\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:23,771] Trial 39 finished with value: 0.8872 and parameters: {'hidden_dim': 16, 'activation_func': 'Tanh', 'lr': 0.00036813287090880446, 'momentum': 0.9287345281334032}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.499, validation_accuracy=0.8826\n","Epoch 19: train_loss=0.488, validation_accuracy=0.8873\n","Epoch 20: train_loss=0.477, validation_accuracy=0.8872\n","Epoch 1: train_loss=2.710, validation_accuracy=0.5456\n","Epoch 2: train_loss=1.189, validation_accuracy=0.6900\n","Epoch 3: train_loss=0.921, validation_accuracy=0.7604\n","Epoch 4: train_loss=0.773, validation_accuracy=0.7940\n","Epoch 5: train_loss=0.691, validation_accuracy=0.8129\n","Epoch 6: train_loss=0.634, validation_accuracy=0.8269\n","Epoch 7: train_loss=0.592, validation_accuracy=0.8374\n","Epoch 8: train_loss=0.559, validation_accuracy=0.8447\n","Epoch 9: train_loss=0.530, validation_accuracy=0.8533\n","Epoch 10: train_loss=0.506, validation_accuracy=0.8591\n","Epoch 11: train_loss=0.485, validation_accuracy=0.8646\n","Epoch 12: train_loss=0.465, validation_accuracy=0.8689\n","Epoch 13: train_loss=0.448, validation_accuracy=0.8730\n","Epoch 14: train_loss=0.432, validation_accuracy=0.8778\n","Epoch 15: train_loss=0.419, validation_accuracy=0.8794\n","Epoch 16: train_loss=0.405, validation_accuracy=0.8847\n","Epoch 17: train_loss=0.394, validation_accuracy=0.8885\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:25,047] Trial 40 finished with value: 0.8937 and parameters: {'hidden_dim': 25, 'activation_func': 'ReLU', 'lr': 7.512707053981215e-05, 'momentum': 0.8791426960813119}. Best is trial 33 with value: 0.9448.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.383, validation_accuracy=0.8904\n","Epoch 19: train_loss=0.374, validation_accuracy=0.8922\n","Epoch 20: train_loss=0.364, validation_accuracy=0.8937\n","Epoch 1: train_loss=1.595, validation_accuracy=0.8367\n","Epoch 2: train_loss=0.509, validation_accuracy=0.8813\n","Epoch 3: train_loss=0.407, validation_accuracy=0.9019\n","Epoch 4: train_loss=0.350, validation_accuracy=0.9088\n","Epoch 5: train_loss=0.317, validation_accuracy=0.9191\n","Epoch 6: train_loss=0.289, validation_accuracy=0.9222\n","Epoch 7: train_loss=0.269, validation_accuracy=0.9280\n","Epoch 8: train_loss=0.252, validation_accuracy=0.9307\n","Epoch 9: train_loss=0.239, validation_accuracy=0.9332\n","Epoch 10: train_loss=0.228, validation_accuracy=0.9354\n","Epoch 11: train_loss=0.218, validation_accuracy=0.9369\n","Epoch 12: train_loss=0.210, validation_accuracy=0.9374\n","Epoch 13: train_loss=0.203, validation_accuracy=0.9389\n","Epoch 14: train_loss=0.196, validation_accuracy=0.9400\n","Epoch 15: train_loss=0.190, validation_accuracy=0.9413\n","Epoch 16: train_loss=0.185, validation_accuracy=0.9423\n","Epoch 17: train_loss=0.181, validation_accuracy=0.9436\n","Epoch 18: train_loss=0.176, validation_accuracy=0.9455\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:27,071] Trial 41 finished with value: 0.9451 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00014813846042473206, 'momentum': 0.952352749284626}. Best is trial 41 with value: 0.9451.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.172, validation_accuracy=0.9442\n","Epoch 20: train_loss=0.169, validation_accuracy=0.9451\n","Epoch 1: train_loss=1.698, validation_accuracy=0.8152\n","Epoch 2: train_loss=0.562, validation_accuracy=0.8772\n","Epoch 3: train_loss=0.414, validation_accuracy=0.9000\n","Epoch 4: train_loss=0.333, validation_accuracy=0.9151\n","Epoch 5: train_loss=0.288, validation_accuracy=0.9205\n","Epoch 6: train_loss=0.261, validation_accuracy=0.9246\n","Epoch 7: train_loss=0.243, validation_accuracy=0.9304\n","Epoch 8: train_loss=0.230, validation_accuracy=0.9312\n","Epoch 9: train_loss=0.220, validation_accuracy=0.9334\n","Epoch 10: train_loss=0.211, validation_accuracy=0.9357\n","Epoch 11: train_loss=0.203, validation_accuracy=0.9379\n","Epoch 12: train_loss=0.198, validation_accuracy=0.9396\n","Epoch 13: train_loss=0.192, validation_accuracy=0.9380\n","Epoch 14: train_loss=0.186, validation_accuracy=0.9421\n","Epoch 15: train_loss=0.181, validation_accuracy=0.9408\n","Epoch 16: train_loss=0.176, validation_accuracy=0.9432\n","Epoch 17: train_loss=0.172, validation_accuracy=0.9437\n","Epoch 18: train_loss=0.168, validation_accuracy=0.9440\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:29,054] Trial 42 finished with value: 0.9462 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.0001438697920405901, 'momentum': 0.9699784024166463}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.164, validation_accuracy=0.9447\n","Epoch 20: train_loss=0.161, validation_accuracy=0.9462\n","Epoch 1: train_loss=2.461, validation_accuracy=0.5575\n","Epoch 2: train_loss=1.131, validation_accuracy=0.6312\n","Epoch 3: train_loss=0.922, validation_accuracy=0.7310\n","Epoch 4: train_loss=0.736, validation_accuracy=0.7888\n","Epoch 5: train_loss=0.599, validation_accuracy=0.8387\n","Epoch 6: train_loss=0.504, validation_accuracy=0.8715\n","Epoch 7: train_loss=0.433, validation_accuracy=0.8835\n","Epoch 8: train_loss=0.391, validation_accuracy=0.8902\n","Epoch 9: train_loss=0.363, validation_accuracy=0.8980\n","Epoch 10: train_loss=0.342, validation_accuracy=0.8981\n","Epoch 11: train_loss=0.326, validation_accuracy=0.9014\n","Epoch 12: train_loss=0.313, validation_accuracy=0.9055\n","Epoch 13: train_loss=0.304, validation_accuracy=0.9061\n","Epoch 14: train_loss=0.296, validation_accuracy=0.9074\n","Epoch 15: train_loss=0.289, validation_accuracy=0.9107\n","Epoch 16: train_loss=0.283, validation_accuracy=0.9116\n","Epoch 17: train_loss=0.277, validation_accuracy=0.9128\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:31,070] Trial 43 finished with value: 0.9199 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00014493078448679544, 'momentum': 0.9714783937288286}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.272, validation_accuracy=0.9150\n","Epoch 19: train_loss=0.266, validation_accuracy=0.9162\n","Epoch 20: train_loss=0.261, validation_accuracy=0.9199\n","Epoch 1: train_loss=2.457, validation_accuracy=0.6554\n","Epoch 2: train_loss=0.886, validation_accuracy=0.7673\n","Epoch 3: train_loss=0.682, validation_accuracy=0.8121\n","Epoch 4: train_loss=0.588, validation_accuracy=0.8330\n","Epoch 5: train_loss=0.532, validation_accuracy=0.8535\n","Epoch 6: train_loss=0.490, validation_accuracy=0.8650\n","Epoch 7: train_loss=0.459, validation_accuracy=0.8742\n","Epoch 8: train_loss=0.432, validation_accuracy=0.8827\n","Epoch 9: train_loss=0.408, validation_accuracy=0.8894\n","Epoch 10: train_loss=0.387, validation_accuracy=0.8939\n","Epoch 11: train_loss=0.367, validation_accuracy=0.8969\n","Epoch 12: train_loss=0.351, validation_accuracy=0.9008\n","Epoch 13: train_loss=0.337, validation_accuracy=0.9027\n","Epoch 14: train_loss=0.326, validation_accuracy=0.9072\n","Epoch 15: train_loss=0.315, validation_accuracy=0.9083\n","Epoch 16: train_loss=0.307, validation_accuracy=0.9109\n","Epoch 17: train_loss=0.298, validation_accuracy=0.9110\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:32,942] Trial 44 finished with value: 0.9159 and parameters: {'hidden_dim': 32, 'activation_func': 'ELU', 'lr': 9.599394510989447e-05, 'momentum': 0.9210586727011874}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.291, validation_accuracy=0.9138\n","Epoch 19: train_loss=0.285, validation_accuracy=0.9155\n","Epoch 20: train_loss=0.279, validation_accuracy=0.9159\n","Epoch 1: train_loss=1.989, validation_accuracy=0.7638\n","Epoch 2: train_loss=0.632, validation_accuracy=0.8591\n","Epoch 3: train_loss=0.471, validation_accuracy=0.8784\n","Epoch 4: train_loss=0.388, validation_accuracy=0.8997\n","Epoch 5: train_loss=0.339, validation_accuracy=0.9084\n","Epoch 6: train_loss=0.314, validation_accuracy=0.9130\n","Epoch 7: train_loss=0.297, validation_accuracy=0.9136\n","Epoch 8: train_loss=0.283, validation_accuracy=0.9204\n","Epoch 9: train_loss=0.274, validation_accuracy=0.9230\n","Epoch 10: train_loss=0.265, validation_accuracy=0.9196\n","Epoch 11: train_loss=0.257, validation_accuracy=0.9253\n","Epoch 12: train_loss=0.250, validation_accuracy=0.9239\n","Epoch 13: train_loss=0.245, validation_accuracy=0.9262\n","Epoch 14: train_loss=0.242, validation_accuracy=0.9268\n","Epoch 15: train_loss=0.237, validation_accuracy=0.9267\n","Epoch 16: train_loss=0.234, validation_accuracy=0.9273\n","Epoch 17: train_loss=0.229, validation_accuracy=0.9287\n","Epoch 18: train_loss=0.227, validation_accuracy=0.9289\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:34,969] Trial 45 finished with value: 0.9293 and parameters: {'hidden_dim': 39, 'activation_func': 'ELU', 'lr': 0.00020046560798051382, 'momentum': 0.9723359929068874}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.225, validation_accuracy=0.9314\n","Epoch 20: train_loss=0.220, validation_accuracy=0.9293\n","Epoch 1: train_loss=2.132, validation_accuracy=0.7463\n","Epoch 2: train_loss=0.854, validation_accuracy=0.8174\n","Epoch 3: train_loss=0.650, validation_accuracy=0.8432\n","Epoch 4: train_loss=0.555, validation_accuracy=0.8616\n","Epoch 5: train_loss=0.486, validation_accuracy=0.8781\n","Epoch 6: train_loss=0.433, validation_accuracy=0.8876\n","Epoch 7: train_loss=0.397, validation_accuracy=0.8907\n","Epoch 8: train_loss=0.378, validation_accuracy=0.8958\n","Epoch 9: train_loss=0.366, validation_accuracy=0.9021\n","Epoch 10: train_loss=0.346, validation_accuracy=0.9006\n","Epoch 11: train_loss=0.334, validation_accuracy=0.9037\n","Epoch 12: train_loss=0.325, validation_accuracy=0.9103\n","Epoch 13: train_loss=0.317, validation_accuracy=0.9115\n","Epoch 14: train_loss=0.307, validation_accuracy=0.9141\n","Epoch 15: train_loss=0.304, validation_accuracy=0.9153\n","Epoch 16: train_loss=0.298, validation_accuracy=0.9147\n","Epoch 17: train_loss=0.291, validation_accuracy=0.9182\n","Epoch 18: train_loss=0.283, validation_accuracy=0.9194\n","Epoch 19: train_loss=0.279, validation_accuracy=0.9196\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:37,102] Trial 46 finished with value: 0.9196 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 9.12388434318063e-05, 'momentum': 0.9949153152070669}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.276, validation_accuracy=0.9196\n","Epoch 1: train_loss=1.912, validation_accuracy=0.7529\n","Epoch 2: train_loss=1.395, validation_accuracy=0.8304\n","Epoch 3: train_loss=1.127, validation_accuracy=0.8615\n","Epoch 4: train_loss=0.942, validation_accuracy=0.8779\n","Epoch 5: train_loss=0.812, validation_accuracy=0.8844\n","Epoch 6: train_loss=0.717, validation_accuracy=0.8914\n","Epoch 7: train_loss=0.645, validation_accuracy=0.8984\n","Epoch 8: train_loss=0.590, validation_accuracy=0.9008\n","Epoch 9: train_loss=0.546, validation_accuracy=0.9059\n","Epoch 10: train_loss=0.509, validation_accuracy=0.9076\n","Epoch 11: train_loss=0.480, validation_accuracy=0.9097\n","Epoch 12: train_loss=0.456, validation_accuracy=0.9123\n","Epoch 13: train_loss=0.435, validation_accuracy=0.9128\n","Epoch 14: train_loss=0.415, validation_accuracy=0.9132\n","Epoch 15: train_loss=0.400, validation_accuracy=0.9141\n","Epoch 16: train_loss=0.388, validation_accuracy=0.9158\n","Epoch 17: train_loss=0.376, validation_accuracy=0.9162\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:39,157] Trial 47 finished with value: 0.9219 and parameters: {'hidden_dim': 36, 'activation_func': 'Sigmoid', 'lr': 0.000720593165991397, 'momentum': 0.9456761247379641}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.366, validation_accuracy=0.9213\n","Epoch 19: train_loss=0.353, validation_accuracy=0.9221\n","Epoch 20: train_loss=0.344, validation_accuracy=0.9219\n","Epoch 1: train_loss=1.743, validation_accuracy=0.7895\n","Epoch 2: train_loss=0.586, validation_accuracy=0.8719\n","Epoch 3: train_loss=0.438, validation_accuracy=0.8913\n","Epoch 4: train_loss=0.374, validation_accuracy=0.9002\n","Epoch 5: train_loss=0.331, validation_accuracy=0.9079\n","Epoch 6: train_loss=0.301, validation_accuracy=0.9152\n","Epoch 7: train_loss=0.280, validation_accuracy=0.9201\n","Epoch 8: train_loss=0.265, validation_accuracy=0.9220\n","Epoch 9: train_loss=0.252, validation_accuracy=0.9254\n","Epoch 10: train_loss=0.242, validation_accuracy=0.9274\n","Epoch 11: train_loss=0.233, validation_accuracy=0.9269\n","Epoch 12: train_loss=0.225, validation_accuracy=0.9294\n","Epoch 13: train_loss=0.218, validation_accuracy=0.9305\n","Epoch 14: train_loss=0.212, validation_accuracy=0.9321\n","Epoch 15: train_loss=0.206, validation_accuracy=0.9347\n","Epoch 16: train_loss=0.201, validation_accuracy=0.9342\n","Epoch 17: train_loss=0.196, validation_accuracy=0.9354\n","Epoch 18: train_loss=0.192, validation_accuracy=0.9370\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:41,364] Trial 48 finished with value: 0.9385 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00029366618206255176, 'momentum': 0.8999861081593569}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.189, validation_accuracy=0.9378\n","Epoch 20: train_loss=0.185, validation_accuracy=0.9385\n","Epoch 1: train_loss=1.826, validation_accuracy=0.7635\n","Epoch 2: train_loss=0.652, validation_accuracy=0.8504\n","Epoch 3: train_loss=0.492, validation_accuracy=0.8793\n","Epoch 4: train_loss=0.411, validation_accuracy=0.8945\n","Epoch 5: train_loss=0.362, validation_accuracy=0.9035\n","Epoch 6: train_loss=0.331, validation_accuracy=0.9084\n","Epoch 7: train_loss=0.308, validation_accuracy=0.9147\n","Epoch 8: train_loss=0.290, validation_accuracy=0.9181\n","Epoch 9: train_loss=0.277, validation_accuracy=0.9199\n","Epoch 10: train_loss=0.265, validation_accuracy=0.9244\n","Epoch 11: train_loss=0.255, validation_accuracy=0.9247\n","Epoch 12: train_loss=0.247, validation_accuracy=0.9261\n","Epoch 13: train_loss=0.239, validation_accuracy=0.9278\n","Epoch 14: train_loss=0.232, validation_accuracy=0.9305\n","Epoch 15: train_loss=0.226, validation_accuracy=0.9304\n","Epoch 16: train_loss=0.221, validation_accuracy=0.9329\n","Epoch 17: train_loss=0.215, validation_accuracy=0.9318\n","Epoch 18: train_loss=0.211, validation_accuracy=0.9331\n","Epoch 19: train_loss=0.206, validation_accuracy=0.9346\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:43,880] Trial 49 finished with value: 0.936 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.0001455198000158879, 'momentum': 0.9201150153745523}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.203, validation_accuracy=0.9360\n","Epoch 1: train_loss=2.705, validation_accuracy=0.3076\n","Epoch 2: train_loss=1.752, validation_accuracy=0.3562\n","Epoch 3: train_loss=1.648, validation_accuracy=0.3928\n","Epoch 4: train_loss=1.565, validation_accuracy=0.4223\n","Epoch 5: train_loss=1.478, validation_accuracy=0.4494\n","Epoch 6: train_loss=1.404, validation_accuracy=0.4633\n","Epoch 7: train_loss=1.354, validation_accuracy=0.4808\n","Epoch 8: train_loss=1.322, validation_accuracy=0.4802\n","Epoch 9: train_loss=1.297, validation_accuracy=0.4910\n","Epoch 10: train_loss=1.275, validation_accuracy=0.5103\n","Epoch 11: train_loss=1.257, validation_accuracy=0.5101\n","Epoch 12: train_loss=1.239, validation_accuracy=0.5116\n","Epoch 13: train_loss=1.224, validation_accuracy=0.5138\n","Epoch 14: train_loss=1.206, validation_accuracy=0.5190\n","Epoch 15: train_loss=1.187, validation_accuracy=0.5270\n","Epoch 16: train_loss=1.170, validation_accuracy=0.5302\n","Epoch 17: train_loss=1.157, validation_accuracy=0.5467\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:45,466] Trial 50 finished with value: 0.5616 and parameters: {'hidden_dim': 19, 'activation_func': 'ELU', 'lr': 6.349900941113971e-05, 'momentum': 0.9749453627595306}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=1.143, validation_accuracy=0.5477\n","Epoch 19: train_loss=1.128, validation_accuracy=0.5579\n","Epoch 20: train_loss=1.113, validation_accuracy=0.5616\n","Epoch 1: train_loss=2.046, validation_accuracy=0.7490\n","Epoch 2: train_loss=0.684, validation_accuracy=0.8397\n","Epoch 3: train_loss=0.518, validation_accuracy=0.8727\n","Epoch 4: train_loss=0.441, validation_accuracy=0.8876\n","Epoch 5: train_loss=0.391, validation_accuracy=0.8954\n","Epoch 6: train_loss=0.355, validation_accuracy=0.9026\n","Epoch 7: train_loss=0.331, validation_accuracy=0.9068\n","Epoch 8: train_loss=0.312, validation_accuracy=0.9119\n","Epoch 9: train_loss=0.298, validation_accuracy=0.9153\n","Epoch 10: train_loss=0.286, validation_accuracy=0.9154\n","Epoch 11: train_loss=0.273, validation_accuracy=0.9185\n","Epoch 12: train_loss=0.264, validation_accuracy=0.9180\n","Epoch 13: train_loss=0.255, validation_accuracy=0.9227\n","Epoch 14: train_loss=0.246, validation_accuracy=0.9252\n","Epoch 15: train_loss=0.237, validation_accuracy=0.9272\n","Epoch 16: train_loss=0.230, validation_accuracy=0.9292\n","Epoch 17: train_loss=0.222, validation_accuracy=0.9275\n","Epoch 18: train_loss=0.216, validation_accuracy=0.9310\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:48,088] Trial 51 finished with value: 0.9349 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00012126771633289403, 'momentum': 0.9505171095242184}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.210, validation_accuracy=0.9333\n","Epoch 20: train_loss=0.205, validation_accuracy=0.9349\n","Epoch 1: train_loss=2.072, validation_accuracy=0.8047\n","Epoch 2: train_loss=0.619, validation_accuracy=0.8652\n","Epoch 3: train_loss=0.461, validation_accuracy=0.8827\n","Epoch 4: train_loss=0.397, validation_accuracy=0.8958\n","Epoch 5: train_loss=0.360, validation_accuracy=0.9037\n","Epoch 6: train_loss=0.335, validation_accuracy=0.9095\n","Epoch 7: train_loss=0.316, validation_accuracy=0.9100\n","Epoch 8: train_loss=0.302, validation_accuracy=0.9130\n","Epoch 9: train_loss=0.291, validation_accuracy=0.9140\n","Epoch 10: train_loss=0.282, validation_accuracy=0.9171\n","Epoch 11: train_loss=0.275, validation_accuracy=0.9198\n","Epoch 12: train_loss=0.267, validation_accuracy=0.9195\n","Epoch 13: train_loss=0.262, validation_accuracy=0.9208\n","Epoch 14: train_loss=0.256, validation_accuracy=0.9239\n","Epoch 15: train_loss=0.252, validation_accuracy=0.9244\n","Epoch 16: train_loss=0.246, validation_accuracy=0.9254\n","Epoch 17: train_loss=0.242, validation_accuracy=0.9263\n","Epoch 18: train_loss=0.237, validation_accuracy=0.9277\n","Epoch 19: train_loss=0.232, validation_accuracy=0.9273\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:50,514] Trial 52 finished with value: 0.9295 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.00013464417654612378, 'momentum': 0.9726533325578182}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.229, validation_accuracy=0.9295\n","Epoch 1: train_loss=1.637, validation_accuracy=0.8574\n","Epoch 2: train_loss=0.497, validation_accuracy=0.8835\n","Epoch 3: train_loss=0.404, validation_accuracy=0.8956\n","Epoch 4: train_loss=0.352, validation_accuracy=0.9048\n","Epoch 5: train_loss=0.316, validation_accuracy=0.9095\n","Epoch 6: train_loss=0.290, validation_accuracy=0.9176\n","Epoch 7: train_loss=0.269, validation_accuracy=0.9209\n","Epoch 8: train_loss=0.252, validation_accuracy=0.9231\n","Epoch 9: train_loss=0.239, validation_accuracy=0.9259\n","Epoch 10: train_loss=0.226, validation_accuracy=0.9286\n","Epoch 11: train_loss=0.217, validation_accuracy=0.9294\n","Epoch 12: train_loss=0.208, validation_accuracy=0.9305\n","Epoch 13: train_loss=0.200, validation_accuracy=0.9328\n","Epoch 14: train_loss=0.193, validation_accuracy=0.9350\n","Epoch 15: train_loss=0.187, validation_accuracy=0.9368\n","Epoch 16: train_loss=0.181, validation_accuracy=0.9372\n","Epoch 17: train_loss=0.176, validation_accuracy=0.9399\n","Epoch 18: train_loss=0.171, validation_accuracy=0.9405\n","Epoch 19: train_loss=0.167, validation_accuracy=0.9406\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:53,084] Trial 53 finished with value: 0.9421 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.00022199504414328018, 'momentum': 0.9084574940888153}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.163, validation_accuracy=0.9421\n","Epoch 1: train_loss=1.610, validation_accuracy=0.7484\n","Epoch 2: train_loss=0.656, validation_accuracy=0.8289\n","Epoch 3: train_loss=0.527, validation_accuracy=0.8622\n","Epoch 4: train_loss=0.454, validation_accuracy=0.8787\n","Epoch 5: train_loss=0.406, validation_accuracy=0.8891\n","Epoch 6: train_loss=0.372, validation_accuracy=0.8968\n","Epoch 7: train_loss=0.347, validation_accuracy=0.9027\n","Epoch 8: train_loss=0.327, validation_accuracy=0.9080\n","Epoch 9: train_loss=0.307, validation_accuracy=0.9147\n","Epoch 10: train_loss=0.290, validation_accuracy=0.9180\n","Epoch 11: train_loss=0.277, validation_accuracy=0.9203\n","Epoch 12: train_loss=0.266, validation_accuracy=0.9227\n","Epoch 13: train_loss=0.256, validation_accuracy=0.9239\n","Epoch 14: train_loss=0.247, validation_accuracy=0.9280\n","Epoch 15: train_loss=0.239, validation_accuracy=0.9289\n","Epoch 16: train_loss=0.232, validation_accuracy=0.9305\n","Epoch 17: train_loss=0.225, validation_accuracy=0.9316\n","Epoch 18: train_loss=0.218, validation_accuracy=0.9322\n","Epoch 19: train_loss=0.213, validation_accuracy=0.9338\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:55,231] Trial 54 finished with value: 0.9353 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 0.0002497551365070088, 'momentum': 0.9114864037947822}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.208, validation_accuracy=0.9353\n","Epoch 1: train_loss=1.542, validation_accuracy=0.8486\n","Epoch 2: train_loss=0.467, validation_accuracy=0.8841\n","Epoch 3: train_loss=0.379, validation_accuracy=0.8986\n","Epoch 4: train_loss=0.333, validation_accuracy=0.9067\n","Epoch 5: train_loss=0.302, validation_accuracy=0.9142\n","Epoch 6: train_loss=0.279, validation_accuracy=0.9193\n","Epoch 7: train_loss=0.262, validation_accuracy=0.9235\n","Epoch 8: train_loss=0.248, validation_accuracy=0.9249\n","Epoch 9: train_loss=0.235, validation_accuracy=0.9294\n","Epoch 10: train_loss=0.225, validation_accuracy=0.9306\n","Epoch 11: train_loss=0.215, validation_accuracy=0.9333\n","Epoch 12: train_loss=0.206, validation_accuracy=0.9368\n","Epoch 13: train_loss=0.198, validation_accuracy=0.9372\n","Epoch 14: train_loss=0.190, validation_accuracy=0.9395\n","Epoch 15: train_loss=0.183, validation_accuracy=0.9403\n","Epoch 16: train_loss=0.177, validation_accuracy=0.9423\n","Epoch 17: train_loss=0.172, validation_accuracy=0.9416\n","Epoch 18: train_loss=0.167, validation_accuracy=0.9438\n","Epoch 19: train_loss=0.162, validation_accuracy=0.9442\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:57,550] Trial 55 finished with value: 0.9439 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.00022143796737477496, 'momentum': 0.933236023285647}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.158, validation_accuracy=0.9439\n","Epoch 1: train_loss=1.980, validation_accuracy=0.8051\n","Epoch 2: train_loss=0.594, validation_accuracy=0.8502\n","Epoch 3: train_loss=0.473, validation_accuracy=0.8777\n","Epoch 4: train_loss=0.408, validation_accuracy=0.8916\n","Epoch 5: train_loss=0.365, validation_accuracy=0.8996\n","Epoch 6: train_loss=0.335, validation_accuracy=0.9054\n","Epoch 7: train_loss=0.311, validation_accuracy=0.9110\n","Epoch 8: train_loss=0.292, validation_accuracy=0.9149\n","Epoch 9: train_loss=0.276, validation_accuracy=0.9179\n","Epoch 10: train_loss=0.264, validation_accuracy=0.9204\n","Epoch 11: train_loss=0.252, validation_accuracy=0.9240\n","Epoch 12: train_loss=0.241, validation_accuracy=0.9274\n","Epoch 13: train_loss=0.233, validation_accuracy=0.9292\n","Epoch 14: train_loss=0.225, validation_accuracy=0.9308\n","Epoch 15: train_loss=0.218, validation_accuracy=0.9317\n","Epoch 16: train_loss=0.211, validation_accuracy=0.9333\n","Epoch 17: train_loss=0.205, validation_accuracy=0.9338\n","Epoch 18: train_loss=0.200, validation_accuracy=0.9357\n","Epoch 19: train_loss=0.194, validation_accuracy=0.9358\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:32:59,331] Trial 56 finished with value: 0.937 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 9.211152310015401e-05, 'momentum': 0.9357296290446812}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.190, validation_accuracy=0.9370\n","Epoch 1: train_loss=2.031, validation_accuracy=0.6275\n","Epoch 2: train_loss=1.239, validation_accuracy=0.6382\n","Epoch 3: train_loss=1.312, validation_accuracy=0.5952\n","Epoch 4: train_loss=1.350, validation_accuracy=0.6400\n","Epoch 5: train_loss=1.444, validation_accuracy=0.5639\n","Epoch 6: train_loss=1.480, validation_accuracy=0.5439\n","Epoch 7: train_loss=1.669, validation_accuracy=0.5242\n","Epoch 8: train_loss=1.983, validation_accuracy=0.4967\n","Epoch 9: train_loss=1.686, validation_accuracy=0.4624\n","Epoch 10: train_loss=1.740, validation_accuracy=0.4328\n","Epoch 11: train_loss=2.537, validation_accuracy=0.4199\n","Epoch 12: train_loss=1.991, validation_accuracy=0.3759\n","Epoch 13: train_loss=1.803, validation_accuracy=0.3681\n","Epoch 14: train_loss=1.803, validation_accuracy=0.3658\n","Epoch 15: train_loss=1.824, validation_accuracy=0.3688\n","Epoch 16: train_loss=1.799, validation_accuracy=0.3696\n","Epoch 17: train_loss=1.746, validation_accuracy=0.3814\n","Epoch 18: train_loss=1.769, validation_accuracy=0.3798\n","Epoch 19: train_loss=2.163, validation_accuracy=0.3813\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:01,460] Trial 57 finished with value: 0.3407 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.0002007620436866521, 'momentum': 0.999982924543581}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=3.089, validation_accuracy=0.3407\n","Epoch 1: train_loss=2.092, validation_accuracy=0.5444\n","Epoch 2: train_loss=1.197, validation_accuracy=0.5910\n","Epoch 3: train_loss=1.072, validation_accuracy=0.6440\n","Epoch 4: train_loss=0.939, validation_accuracy=0.6897\n","Epoch 5: train_loss=0.847, validation_accuracy=0.7162\n","Epoch 6: train_loss=0.789, validation_accuracy=0.7401\n","Epoch 7: train_loss=0.737, validation_accuracy=0.7482\n","Epoch 8: train_loss=0.681, validation_accuracy=0.8052\n","Epoch 9: train_loss=0.616, validation_accuracy=0.8332\n","Epoch 10: train_loss=0.562, validation_accuracy=0.8432\n","Epoch 11: train_loss=0.525, validation_accuracy=0.8496\n","Epoch 12: train_loss=0.495, validation_accuracy=0.8569\n","Epoch 13: train_loss=0.464, validation_accuracy=0.8728\n","Epoch 14: train_loss=0.436, validation_accuracy=0.8827\n","Epoch 15: train_loss=0.417, validation_accuracy=0.8863\n","Epoch 16: train_loss=0.402, validation_accuracy=0.8894\n","Epoch 17: train_loss=0.392, validation_accuracy=0.8891\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:03,138] Trial 58 finished with value: 0.8943 and parameters: {'hidden_dim': 29, 'activation_func': 'ELU', 'lr': 0.0003324697184674038, 'momentum': 0.8750979158269607}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.383, validation_accuracy=0.8937\n","Epoch 19: train_loss=0.375, validation_accuracy=0.8942\n","Epoch 20: train_loss=0.368, validation_accuracy=0.8943\n","Epoch 1: train_loss=2.163, validation_accuracy=0.4378\n","Epoch 2: train_loss=1.862, validation_accuracy=0.6107\n","Epoch 3: train_loss=1.684, validation_accuracy=0.6925\n","Epoch 4: train_loss=1.563, validation_accuracy=0.7479\n","Epoch 5: train_loss=1.469, validation_accuracy=0.7802\n","Epoch 6: train_loss=1.391, validation_accuracy=0.8018\n","Epoch 7: train_loss=1.322, validation_accuracy=0.8170\n","Epoch 8: train_loss=1.260, validation_accuracy=0.8299\n","Epoch 9: train_loss=1.206, validation_accuracy=0.8374\n","Epoch 10: train_loss=1.157, validation_accuracy=0.8430\n","Epoch 11: train_loss=1.113, validation_accuracy=0.8496\n","Epoch 12: train_loss=1.072, validation_accuracy=0.8546\n","Epoch 13: train_loss=1.034, validation_accuracy=0.8585\n","Epoch 14: train_loss=0.999, validation_accuracy=0.8623\n","Epoch 15: train_loss=0.967, validation_accuracy=0.8666\n","Epoch 16: train_loss=0.937, validation_accuracy=0.8692\n","Epoch 17: train_loss=0.909, validation_accuracy=0.8724\n","Epoch 18: train_loss=0.883, validation_accuracy=0.8737\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:05,035] Trial 59 finished with value: 0.8785 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.00018543419733320436, 'momentum': 0.9064735027169302}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.858, validation_accuracy=0.8766\n","Epoch 20: train_loss=0.834, validation_accuracy=0.8785\n","Epoch 1: train_loss=1.699, validation_accuracy=0.7153\n","Epoch 2: train_loss=0.790, validation_accuracy=0.7988\n","Epoch 3: train_loss=0.589, validation_accuracy=0.8587\n","Epoch 4: train_loss=0.463, validation_accuracy=0.8908\n","Epoch 5: train_loss=0.386, validation_accuracy=0.8974\n","Epoch 6: train_loss=0.344, validation_accuracy=0.9061\n","Epoch 7: train_loss=0.324, validation_accuracy=0.9103\n","Epoch 8: train_loss=0.309, validation_accuracy=0.9117\n","Epoch 9: train_loss=0.298, validation_accuracy=0.9146\n","Epoch 10: train_loss=0.288, validation_accuracy=0.9154\n","Epoch 11: train_loss=0.283, validation_accuracy=0.9152\n","Epoch 12: train_loss=0.274, validation_accuracy=0.9187\n","Epoch 13: train_loss=0.270, validation_accuracy=0.9195\n","Epoch 14: train_loss=0.267, validation_accuracy=0.9200\n","Epoch 15: train_loss=0.261, validation_accuracy=0.9204\n","Epoch 16: train_loss=0.261, validation_accuracy=0.9217\n","Epoch 17: train_loss=0.256, validation_accuracy=0.9213\n","Epoch 18: train_loss=0.253, validation_accuracy=0.9259\n","Epoch 19: train_loss=0.248, validation_accuracy=0.9236\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:06,966] Trial 60 finished with value: 0.9236 and parameters: {'hidden_dim': 39, 'activation_func': 'ELU', 'lr': 0.00037667781921846066, 'momentum': 0.9837010803771731}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.242, validation_accuracy=0.9236\n","Epoch 1: train_loss=2.185, validation_accuracy=0.7842\n","Epoch 2: train_loss=0.631, validation_accuracy=0.8453\n","Epoch 3: train_loss=0.488, validation_accuracy=0.8695\n","Epoch 4: train_loss=0.416, validation_accuracy=0.8938\n","Epoch 5: train_loss=0.369, validation_accuracy=0.9036\n","Epoch 6: train_loss=0.335, validation_accuracy=0.9070\n","Epoch 7: train_loss=0.313, validation_accuracy=0.9170\n","Epoch 8: train_loss=0.296, validation_accuracy=0.9196\n","Epoch 9: train_loss=0.283, validation_accuracy=0.9208\n","Epoch 10: train_loss=0.272, validation_accuracy=0.9222\n","Epoch 11: train_loss=0.264, validation_accuracy=0.9249\n","Epoch 12: train_loss=0.257, validation_accuracy=0.9241\n","Epoch 13: train_loss=0.252, validation_accuracy=0.9261\n","Epoch 14: train_loss=0.247, validation_accuracy=0.9260\n","Epoch 15: train_loss=0.241, validation_accuracy=0.9294\n","Epoch 16: train_loss=0.236, validation_accuracy=0.9297\n","Epoch 17: train_loss=0.233, validation_accuracy=0.9296\n","Epoch 18: train_loss=0.229, validation_accuracy=0.9310\n","Epoch 19: train_loss=0.226, validation_accuracy=0.9309\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:09,015] Trial 61 finished with value: 0.9317 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.00025357173922542, 'momentum': 0.9343745146554743}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.222, validation_accuracy=0.9317\n","Epoch 1: train_loss=2.130, validation_accuracy=0.8134\n","Epoch 2: train_loss=0.539, validation_accuracy=0.8764\n","Epoch 3: train_loss=0.411, validation_accuracy=0.8970\n","Epoch 4: train_loss=0.351, validation_accuracy=0.9069\n","Epoch 5: train_loss=0.314, validation_accuracy=0.9132\n","Epoch 6: train_loss=0.288, validation_accuracy=0.9202\n","Epoch 7: train_loss=0.269, validation_accuracy=0.9231\n","Epoch 8: train_loss=0.254, validation_accuracy=0.9263\n","Epoch 9: train_loss=0.240, validation_accuracy=0.9274\n","Epoch 10: train_loss=0.230, validation_accuracy=0.9310\n","Epoch 11: train_loss=0.221, validation_accuracy=0.9323\n","Epoch 12: train_loss=0.213, validation_accuracy=0.9341\n","Epoch 13: train_loss=0.206, validation_accuracy=0.9354\n","Epoch 14: train_loss=0.200, validation_accuracy=0.9371\n","Epoch 15: train_loss=0.195, validation_accuracy=0.9386\n","Epoch 16: train_loss=0.190, validation_accuracy=0.9393\n","Epoch 17: train_loss=0.185, validation_accuracy=0.9402\n","Epoch 18: train_loss=0.181, validation_accuracy=0.9408\n","Epoch 19: train_loss=0.177, validation_accuracy=0.9416\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:11,261] Trial 62 finished with value: 0.9421 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.00022654671442044896, 'momentum': 0.9132819558231389}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.173, validation_accuracy=0.9421\n","Epoch 1: train_loss=2.021, validation_accuracy=0.8239\n","Epoch 2: train_loss=0.523, validation_accuracy=0.8814\n","Epoch 3: train_loss=0.397, validation_accuracy=0.8996\n","Epoch 4: train_loss=0.338, validation_accuracy=0.9113\n","Epoch 5: train_loss=0.301, validation_accuracy=0.9158\n","Epoch 6: train_loss=0.277, validation_accuracy=0.9225\n","Epoch 7: train_loss=0.259, validation_accuracy=0.9266\n","Epoch 8: train_loss=0.246, validation_accuracy=0.9280\n","Epoch 9: train_loss=0.235, validation_accuracy=0.9310\n","Epoch 10: train_loss=0.226, validation_accuracy=0.9310\n","Epoch 11: train_loss=0.217, validation_accuracy=0.9325\n","Epoch 12: train_loss=0.210, validation_accuracy=0.9338\n","Epoch 13: train_loss=0.204, validation_accuracy=0.9363\n","Epoch 14: train_loss=0.198, validation_accuracy=0.9353\n","Epoch 15: train_loss=0.192, validation_accuracy=0.9380\n","Epoch 16: train_loss=0.188, validation_accuracy=0.9390\n","Epoch 17: train_loss=0.183, validation_accuracy=0.9412\n","Epoch 18: train_loss=0.178, validation_accuracy=0.9421\n","Epoch 19: train_loss=0.174, validation_accuracy=0.9414\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:13,735] Trial 63 finished with value: 0.9428 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00019684167938032682, 'momentum': 0.9217494302008884}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.170, validation_accuracy=0.9428\n","Epoch 1: train_loss=1.694, validation_accuracy=0.8360\n","Epoch 2: train_loss=0.501, validation_accuracy=0.8736\n","Epoch 3: train_loss=0.403, validation_accuracy=0.8908\n","Epoch 4: train_loss=0.351, validation_accuracy=0.9023\n","Epoch 5: train_loss=0.318, validation_accuracy=0.9094\n","Epoch 6: train_loss=0.293, validation_accuracy=0.9153\n","Epoch 7: train_loss=0.274, validation_accuracy=0.9204\n","Epoch 8: train_loss=0.258, validation_accuracy=0.9243\n","Epoch 9: train_loss=0.244, validation_accuracy=0.9288\n","Epoch 10: train_loss=0.233, validation_accuracy=0.9316\n","Epoch 11: train_loss=0.223, validation_accuracy=0.9334\n","Epoch 12: train_loss=0.213, validation_accuracy=0.9353\n","Epoch 13: train_loss=0.206, validation_accuracy=0.9341\n","Epoch 14: train_loss=0.198, validation_accuracy=0.9387\n","Epoch 15: train_loss=0.191, validation_accuracy=0.9395\n","Epoch 16: train_loss=0.185, validation_accuracy=0.9395\n","Epoch 17: train_loss=0.179, validation_accuracy=0.9396\n","Epoch 18: train_loss=0.173, validation_accuracy=0.9412\n","Epoch 19: train_loss=0.169, validation_accuracy=0.9418\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:16,187] Trial 64 finished with value: 0.9425 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00016646590291112472, 'momentum': 0.9285945747161642}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.164, validation_accuracy=0.9425\n","Epoch 1: train_loss=1.935, validation_accuracy=0.6629\n","Epoch 2: train_loss=1.242, validation_accuracy=0.7872\n","Epoch 3: train_loss=0.977, validation_accuracy=0.8290\n","Epoch 4: train_loss=0.829, validation_accuracy=0.8533\n","Epoch 5: train_loss=0.729, validation_accuracy=0.8663\n","Epoch 6: train_loss=0.657, validation_accuracy=0.8759\n","Epoch 7: train_loss=0.602, validation_accuracy=0.8826\n","Epoch 8: train_loss=0.559, validation_accuracy=0.8870\n","Epoch 9: train_loss=0.523, validation_accuracy=0.8889\n","Epoch 10: train_loss=0.496, validation_accuracy=0.8940\n","Epoch 11: train_loss=0.472, validation_accuracy=0.8993\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8980\n","Epoch 13: train_loss=0.434, validation_accuracy=0.9005\n","Epoch 14: train_loss=0.418, validation_accuracy=0.9030\n","Epoch 15: train_loss=0.405, validation_accuracy=0.9023\n","Epoch 16: train_loss=0.392, validation_accuracy=0.9047\n","Epoch 17: train_loss=0.380, validation_accuracy=0.9067\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:17,901] Trial 65 finished with value: 0.9112 and parameters: {'hidden_dim': 48, 'activation_func': 'Tanh', 'lr': 0.00016813421141844808, 'momentum': 0.9476697764372144}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.371, validation_accuracy=0.9071\n","Epoch 19: train_loss=0.362, validation_accuracy=0.9108\n","Epoch 20: train_loss=0.353, validation_accuracy=0.9112\n","Epoch 1: train_loss=1.783, validation_accuracy=0.8197\n","Epoch 2: train_loss=0.575, validation_accuracy=0.8609\n","Epoch 3: train_loss=0.456, validation_accuracy=0.8852\n","Epoch 4: train_loss=0.390, validation_accuracy=0.8977\n","Epoch 5: train_loss=0.348, validation_accuracy=0.9077\n","Epoch 6: train_loss=0.318, validation_accuracy=0.9123\n","Epoch 7: train_loss=0.294, validation_accuracy=0.9158\n","Epoch 8: train_loss=0.275, validation_accuracy=0.9196\n","Epoch 9: train_loss=0.260, validation_accuracy=0.9240\n","Epoch 10: train_loss=0.246, validation_accuracy=0.9266\n","Epoch 11: train_loss=0.234, validation_accuracy=0.9290\n","Epoch 12: train_loss=0.225, validation_accuracy=0.9300\n","Epoch 13: train_loss=0.216, validation_accuracy=0.9322\n","Epoch 14: train_loss=0.209, validation_accuracy=0.9328\n","Epoch 15: train_loss=0.202, validation_accuracy=0.9345\n","Epoch 16: train_loss=0.196, validation_accuracy=0.9371\n","Epoch 17: train_loss=0.191, validation_accuracy=0.9381\n","Epoch 18: train_loss=0.185, validation_accuracy=0.9392\n","Epoch 19: train_loss=0.181, validation_accuracy=0.9405\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:20,639] Trial 66 finished with value: 0.9411 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00010530213737177028, 'momentum': 0.9266573963582411}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.177, validation_accuracy=0.9411\n","Epoch 1: train_loss=1.782, validation_accuracy=0.8044\n","Epoch 2: train_loss=0.670, validation_accuracy=0.8638\n","Epoch 3: train_loss=0.494, validation_accuracy=0.8904\n","Epoch 4: train_loss=0.397, validation_accuracy=0.9067\n","Epoch 5: train_loss=0.339, validation_accuracy=0.9147\n","Epoch 6: train_loss=0.302, validation_accuracy=0.9207\n","Epoch 7: train_loss=0.277, validation_accuracy=0.9262\n","Epoch 8: train_loss=0.256, validation_accuracy=0.9281\n","Epoch 9: train_loss=0.241, validation_accuracy=0.9283\n","Epoch 10: train_loss=0.229, validation_accuracy=0.9317\n","Epoch 11: train_loss=0.219, validation_accuracy=0.9323\n","Epoch 12: train_loss=0.209, validation_accuracy=0.9349\n","Epoch 13: train_loss=0.200, validation_accuracy=0.9360\n","Epoch 14: train_loss=0.193, validation_accuracy=0.9370\n","Epoch 15: train_loss=0.188, validation_accuracy=0.9390\n","Epoch 16: train_loss=0.182, validation_accuracy=0.9393\n","Epoch 17: train_loss=0.176, validation_accuracy=0.9395\n","Epoch 18: train_loss=0.172, validation_accuracy=0.9371\n","Epoch 19: train_loss=0.170, validation_accuracy=0.9401\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:22,658] Trial 67 finished with value: 0.9427 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.0001611913572150103, 'momentum': 0.981837950106063}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.164, validation_accuracy=0.9427\n","Epoch 1: train_loss=2.048, validation_accuracy=0.8056\n","Epoch 2: train_loss=0.571, validation_accuracy=0.8634\n","Epoch 3: train_loss=0.432, validation_accuracy=0.8876\n","Epoch 4: train_loss=0.360, validation_accuracy=0.9027\n","Epoch 5: train_loss=0.321, validation_accuracy=0.9109\n","Epoch 6: train_loss=0.295, validation_accuracy=0.9143\n","Epoch 7: train_loss=0.278, validation_accuracy=0.9180\n","Epoch 8: train_loss=0.263, validation_accuracy=0.9209\n","Epoch 9: train_loss=0.250, validation_accuracy=0.9245\n","Epoch 10: train_loss=0.240, validation_accuracy=0.9248\n","Epoch 11: train_loss=0.231, validation_accuracy=0.9312\n","Epoch 12: train_loss=0.224, validation_accuracy=0.9302\n","Epoch 13: train_loss=0.218, validation_accuracy=0.9321\n","Epoch 14: train_loss=0.212, validation_accuracy=0.9343\n","Epoch 15: train_loss=0.207, validation_accuracy=0.9359\n","Epoch 16: train_loss=0.203, validation_accuracy=0.9346\n","Epoch 17: train_loss=0.199, validation_accuracy=0.9383\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:24,656] Trial 68 finished with value: 0.9403 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 8.077605018236301e-05, 'momentum': 0.9816495736652071}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.194, validation_accuracy=0.9381\n","Epoch 19: train_loss=0.191, validation_accuracy=0.9405\n","Epoch 20: train_loss=0.187, validation_accuracy=0.9403\n","Epoch 1: train_loss=1.656, validation_accuracy=0.8401\n","Epoch 2: train_loss=0.485, validation_accuracy=0.8881\n","Epoch 3: train_loss=0.365, validation_accuracy=0.9080\n","Epoch 4: train_loss=0.309, validation_accuracy=0.9211\n","Epoch 5: train_loss=0.278, validation_accuracy=0.9228\n","Epoch 6: train_loss=0.261, validation_accuracy=0.9275\n","Epoch 7: train_loss=0.249, validation_accuracy=0.9299\n","Epoch 8: train_loss=0.239, validation_accuracy=0.9341\n","Epoch 9: train_loss=0.229, validation_accuracy=0.9344\n","Epoch 10: train_loss=0.221, validation_accuracy=0.9364\n","Epoch 11: train_loss=0.215, validation_accuracy=0.9375\n","Epoch 12: train_loss=0.210, validation_accuracy=0.9375\n","Epoch 13: train_loss=0.205, validation_accuracy=0.9381\n","Epoch 14: train_loss=0.201, validation_accuracy=0.9389\n","Epoch 15: train_loss=0.195, validation_accuracy=0.9409\n","Epoch 16: train_loss=0.192, validation_accuracy=0.9413\n","Epoch 17: train_loss=0.187, validation_accuracy=0.9420\n","Epoch 18: train_loss=0.183, validation_accuracy=0.9446\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:26,633] Trial 69 finished with value: 0.9453 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.00030673019946849013, 'momentum': 0.961778614821173}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.180, validation_accuracy=0.9427\n","Epoch 20: train_loss=0.176, validation_accuracy=0.9453\n","Epoch 1: train_loss=1.773, validation_accuracy=0.8201\n","Epoch 2: train_loss=0.528, validation_accuracy=0.8858\n","Epoch 3: train_loss=0.404, validation_accuracy=0.9004\n","Epoch 4: train_loss=0.346, validation_accuracy=0.9112\n","Epoch 5: train_loss=0.317, validation_accuracy=0.9140\n","Epoch 6: train_loss=0.296, validation_accuracy=0.9179\n","Epoch 7: train_loss=0.280, validation_accuracy=0.9208\n","Epoch 8: train_loss=0.269, validation_accuracy=0.9243\n","Epoch 9: train_loss=0.259, validation_accuracy=0.9240\n","Epoch 10: train_loss=0.253, validation_accuracy=0.9258\n","Epoch 11: train_loss=0.249, validation_accuracy=0.9280\n","Epoch 12: train_loss=0.241, validation_accuracy=0.9309\n","Epoch 13: train_loss=0.237, validation_accuracy=0.9313\n","Epoch 14: train_loss=0.232, validation_accuracy=0.9325\n","Epoch 15: train_loss=0.228, validation_accuracy=0.9314\n","Epoch 16: train_loss=0.225, validation_accuracy=0.9342\n","Epoch 17: train_loss=0.221, validation_accuracy=0.9333\n","Epoch 18: train_loss=0.218, validation_accuracy=0.9326\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:28,635] Trial 70 finished with value: 0.9351 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.00046430621989649543, 'momentum': 0.9697558994388211}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.215, validation_accuracy=0.9342\n","Epoch 20: train_loss=0.211, validation_accuracy=0.9351\n","Epoch 1: train_loss=1.730, validation_accuracy=0.8261\n","Epoch 2: train_loss=0.544, validation_accuracy=0.8814\n","Epoch 3: train_loss=0.407, validation_accuracy=0.9003\n","Epoch 4: train_loss=0.347, validation_accuracy=0.9085\n","Epoch 5: train_loss=0.314, validation_accuracy=0.9184\n","Epoch 6: train_loss=0.287, validation_accuracy=0.9222\n","Epoch 7: train_loss=0.269, validation_accuracy=0.9257\n","Epoch 8: train_loss=0.255, validation_accuracy=0.9285\n","Epoch 9: train_loss=0.242, validation_accuracy=0.9298\n","Epoch 10: train_loss=0.233, validation_accuracy=0.9294\n","Epoch 11: train_loss=0.226, validation_accuracy=0.9319\n","Epoch 12: train_loss=0.218, validation_accuracy=0.9330\n","Epoch 13: train_loss=0.214, validation_accuracy=0.9328\n","Epoch 14: train_loss=0.208, validation_accuracy=0.9331\n","Epoch 15: train_loss=0.203, validation_accuracy=0.9359\n","Epoch 16: train_loss=0.199, validation_accuracy=0.9358\n","Epoch 17: train_loss=0.195, validation_accuracy=0.9369\n","Epoch 18: train_loss=0.191, validation_accuracy=0.9371\n","Epoch 19: train_loss=0.188, validation_accuracy=0.9361\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:31,090] Trial 71 finished with value: 0.9393 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.0002998555713583689, 'momentum': 0.9629396729014644}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.185, validation_accuracy=0.9393\n","Epoch 1: train_loss=1.809, validation_accuracy=0.7849\n","Epoch 2: train_loss=0.682, validation_accuracy=0.8434\n","Epoch 3: train_loss=0.510, validation_accuracy=0.8778\n","Epoch 4: train_loss=0.431, validation_accuracy=0.8883\n","Epoch 5: train_loss=0.382, validation_accuracy=0.9016\n","Epoch 6: train_loss=0.353, validation_accuracy=0.9064\n","Epoch 7: train_loss=0.335, validation_accuracy=0.9101\n","Epoch 8: train_loss=0.319, validation_accuracy=0.9135\n","Epoch 9: train_loss=0.311, validation_accuracy=0.9176\n","Epoch 10: train_loss=0.300, validation_accuracy=0.9204\n","Epoch 11: train_loss=0.289, validation_accuracy=0.9226\n","Epoch 12: train_loss=0.283, validation_accuracy=0.9206\n","Epoch 13: train_loss=0.276, validation_accuracy=0.9241\n","Epoch 14: train_loss=0.269, validation_accuracy=0.9243\n","Epoch 15: train_loss=0.265, validation_accuracy=0.9239\n","Epoch 16: train_loss=0.260, validation_accuracy=0.9294\n","Epoch 17: train_loss=0.256, validation_accuracy=0.9310\n","Epoch 18: train_loss=0.250, validation_accuracy=0.9335\n","Epoch 19: train_loss=0.248, validation_accuracy=0.9325\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:33,019] Trial 72 finished with value: 0.931 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00017367531702090097, 'momentum': 0.9880643548860186}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.243, validation_accuracy=0.9310\n","Epoch 1: train_loss=2.460, validation_accuracy=0.7876\n","Epoch 2: train_loss=0.737, validation_accuracy=0.8394\n","Epoch 3: train_loss=0.589, validation_accuracy=0.8630\n","Epoch 4: train_loss=0.490, validation_accuracy=0.8804\n","Epoch 5: train_loss=0.420, validation_accuracy=0.8924\n","Epoch 6: train_loss=0.371, validation_accuracy=0.9012\n","Epoch 7: train_loss=0.338, validation_accuracy=0.9078\n","Epoch 8: train_loss=0.314, validation_accuracy=0.9108\n","Epoch 9: train_loss=0.296, validation_accuracy=0.9145\n","Epoch 10: train_loss=0.281, validation_accuracy=0.9187\n","Epoch 11: train_loss=0.269, validation_accuracy=0.9194\n","Epoch 12: train_loss=0.259, validation_accuracy=0.9222\n","Epoch 13: train_loss=0.250, validation_accuracy=0.9233\n","Epoch 14: train_loss=0.241, validation_accuracy=0.9242\n","Epoch 15: train_loss=0.234, validation_accuracy=0.9270\n","Epoch 16: train_loss=0.228, validation_accuracy=0.9276\n","Epoch 17: train_loss=0.223, validation_accuracy=0.9293\n","Epoch 18: train_loss=0.217, validation_accuracy=0.9302\n","Epoch 19: train_loss=0.212, validation_accuracy=0.9314\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:35,376] Trial 73 finished with value: 0.9321 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 0.00011608655799848767, 'momentum': 0.9345557639538118}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.208, validation_accuracy=0.9321\n","Epoch 1: train_loss=1.608, validation_accuracy=0.8120\n","Epoch 2: train_loss=0.553, validation_accuracy=0.8674\n","Epoch 3: train_loss=0.421, validation_accuracy=0.8925\n","Epoch 4: train_loss=0.343, validation_accuracy=0.9056\n","Epoch 5: train_loss=0.302, validation_accuracy=0.9157\n","Epoch 6: train_loss=0.276, validation_accuracy=0.9217\n","Epoch 7: train_loss=0.258, validation_accuracy=0.9259\n","Epoch 8: train_loss=0.243, validation_accuracy=0.9290\n","Epoch 9: train_loss=0.231, validation_accuracy=0.9329\n","Epoch 10: train_loss=0.222, validation_accuracy=0.9331\n","Epoch 11: train_loss=0.212, validation_accuracy=0.9370\n","Epoch 12: train_loss=0.205, validation_accuracy=0.9370\n","Epoch 13: train_loss=0.198, validation_accuracy=0.9383\n","Epoch 14: train_loss=0.192, validation_accuracy=0.9391\n","Epoch 15: train_loss=0.188, validation_accuracy=0.9380\n","Epoch 16: train_loss=0.183, validation_accuracy=0.9421\n","Epoch 17: train_loss=0.177, validation_accuracy=0.9414\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:37,344] Trial 74 finished with value: 0.9431 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.0003113906508908332, 'momentum': 0.955686980125698}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.173, validation_accuracy=0.9445\n","Epoch 19: train_loss=0.170, validation_accuracy=0.9427\n","Epoch 20: train_loss=0.166, validation_accuracy=0.9431\n","Epoch 1: train_loss=1.948, validation_accuracy=0.7864\n","Epoch 2: train_loss=0.557, validation_accuracy=0.8731\n","Epoch 3: train_loss=0.393, validation_accuracy=0.8989\n","Epoch 4: train_loss=0.328, validation_accuracy=0.9087\n","Epoch 5: train_loss=0.300, validation_accuracy=0.9168\n","Epoch 6: train_loss=0.282, validation_accuracy=0.9218\n","Epoch 7: train_loss=0.271, validation_accuracy=0.9226\n","Epoch 8: train_loss=0.262, validation_accuracy=0.9241\n","Epoch 9: train_loss=0.254, validation_accuracy=0.9257\n","Epoch 10: train_loss=0.248, validation_accuracy=0.9255\n","Epoch 11: train_loss=0.241, validation_accuracy=0.9287\n","Epoch 12: train_loss=0.236, validation_accuracy=0.9303\n","Epoch 13: train_loss=0.233, validation_accuracy=0.9317\n","Epoch 14: train_loss=0.228, validation_accuracy=0.9325\n","Epoch 15: train_loss=0.224, validation_accuracy=0.9324\n","Epoch 16: train_loss=0.221, validation_accuracy=0.9335\n","Epoch 17: train_loss=0.218, validation_accuracy=0.9361\n","Epoch 18: train_loss=0.216, validation_accuracy=0.9339\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:39,194] Trial 75 finished with value: 0.9344 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.0003142579471762771, 'momentum': 0.958578046103839}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.213, validation_accuracy=0.9352\n","Epoch 20: train_loss=0.209, validation_accuracy=0.9344\n","Epoch 1: train_loss=1.485, validation_accuracy=0.8053\n","Epoch 2: train_loss=0.683, validation_accuracy=0.8638\n","Epoch 3: train_loss=0.487, validation_accuracy=0.8932\n","Epoch 4: train_loss=0.412, validation_accuracy=0.8978\n","Epoch 5: train_loss=0.377, validation_accuracy=0.9000\n","Epoch 6: train_loss=0.356, validation_accuracy=0.9059\n","Epoch 7: train_loss=0.340, validation_accuracy=0.9051\n","Epoch 8: train_loss=0.318, validation_accuracy=0.9137\n","Epoch 9: train_loss=0.314, validation_accuracy=0.9131\n","Epoch 10: train_loss=0.299, validation_accuracy=0.9164\n","Epoch 11: train_loss=0.303, validation_accuracy=0.9111\n","Epoch 12: train_loss=0.299, validation_accuracy=0.9163\n","Epoch 13: train_loss=0.289, validation_accuracy=0.9155\n","Epoch 14: train_loss=0.283, validation_accuracy=0.9191\n","Epoch 15: train_loss=0.271, validation_accuracy=0.9195\n","Epoch 16: train_loss=0.268, validation_accuracy=0.9211\n","Epoch 17: train_loss=0.263, validation_accuracy=0.9237\n","Epoch 18: train_loss=0.257, validation_accuracy=0.9215\n","Epoch 19: train_loss=0.255, validation_accuracy=0.9241\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:40,859] Trial 76 finished with value: 0.9275 and parameters: {'hidden_dim': 45, 'activation_func': 'Tanh', 'lr': 0.00047756348559916377, 'momentum': 0.9813754863167118}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.254, validation_accuracy=0.9275\n","Epoch 1: train_loss=1.628, validation_accuracy=0.8473\n","Epoch 2: train_loss=0.467, validation_accuracy=0.8893\n","Epoch 3: train_loss=0.359, validation_accuracy=0.9061\n","Epoch 4: train_loss=0.306, validation_accuracy=0.9148\n","Epoch 5: train_loss=0.274, validation_accuracy=0.9210\n","Epoch 6: train_loss=0.252, validation_accuracy=0.9258\n","Epoch 7: train_loss=0.236, validation_accuracy=0.9291\n","Epoch 8: train_loss=0.224, validation_accuracy=0.9308\n","Epoch 9: train_loss=0.214, validation_accuracy=0.9330\n","Epoch 10: train_loss=0.206, validation_accuracy=0.9344\n","Epoch 11: train_loss=0.199, validation_accuracy=0.9375\n","Epoch 12: train_loss=0.192, validation_accuracy=0.9389\n","Epoch 13: train_loss=0.187, validation_accuracy=0.9405\n","Epoch 14: train_loss=0.182, validation_accuracy=0.9404\n","Epoch 15: train_loss=0.177, validation_accuracy=0.9420\n","Epoch 16: train_loss=0.174, validation_accuracy=0.9412\n","Epoch 17: train_loss=0.170, validation_accuracy=0.9433\n","Epoch 18: train_loss=0.167, validation_accuracy=0.9435\n","Epoch 19: train_loss=0.163, validation_accuracy=0.9438\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:43,109] Trial 77 finished with value: 0.9435 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.00020581765918666636, 'momentum': 0.9496468234340045}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.160, validation_accuracy=0.9435\n","Epoch 1: train_loss=1.649, validation_accuracy=0.7853\n","Epoch 2: train_loss=0.566, validation_accuracy=0.8688\n","Epoch 3: train_loss=0.420, validation_accuracy=0.8943\n","Epoch 4: train_loss=0.348, validation_accuracy=0.9114\n","Epoch 5: train_loss=0.303, validation_accuracy=0.9157\n","Epoch 6: train_loss=0.276, validation_accuracy=0.9228\n","Epoch 7: train_loss=0.257, validation_accuracy=0.9260\n","Epoch 8: train_loss=0.244, validation_accuracy=0.9293\n","Epoch 9: train_loss=0.232, validation_accuracy=0.9326\n","Epoch 10: train_loss=0.223, validation_accuracy=0.9333\n","Epoch 11: train_loss=0.216, validation_accuracy=0.9346\n","Epoch 12: train_loss=0.210, validation_accuracy=0.9366\n","Epoch 13: train_loss=0.205, validation_accuracy=0.9364\n","Epoch 14: train_loss=0.200, validation_accuracy=0.9363\n","Epoch 15: train_loss=0.196, validation_accuracy=0.9384\n","Epoch 16: train_loss=0.192, validation_accuracy=0.9386\n","Epoch 17: train_loss=0.189, validation_accuracy=0.9384\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:44,592] Trial 78 finished with value: 0.9407 and parameters: {'hidden_dim': 44, 'activation_func': 'ReLU', 'lr': 0.00023145475991463547, 'momentum': 0.9525829552161056}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.185, validation_accuracy=0.9397\n","Epoch 19: train_loss=0.182, validation_accuracy=0.9412\n","Epoch 20: train_loss=0.180, validation_accuracy=0.9407\n","Epoch 1: train_loss=2.080, validation_accuracy=0.4648\n","Epoch 2: train_loss=1.755, validation_accuracy=0.6839\n","Epoch 3: train_loss=1.577, validation_accuracy=0.7642\n","Epoch 4: train_loss=1.434, validation_accuracy=0.7961\n","Epoch 5: train_loss=1.325, validation_accuracy=0.8173\n","Epoch 6: train_loss=1.235, validation_accuracy=0.8356\n","Epoch 7: train_loss=1.155, validation_accuracy=0.8456\n","Epoch 8: train_loss=1.084, validation_accuracy=0.8545\n","Epoch 9: train_loss=1.020, validation_accuracy=0.8618\n","Epoch 10: train_loss=0.963, validation_accuracy=0.8682\n","Epoch 11: train_loss=0.914, validation_accuracy=0.8694\n","Epoch 12: train_loss=0.870, validation_accuracy=0.8760\n","Epoch 13: train_loss=0.830, validation_accuracy=0.8778\n","Epoch 14: train_loss=0.794, validation_accuracy=0.8817\n","Epoch 15: train_loss=0.762, validation_accuracy=0.8842\n","Epoch 16: train_loss=0.732, validation_accuracy=0.8837\n","Epoch 17: train_loss=0.704, validation_accuracy=0.8851\n","Epoch 18: train_loss=0.678, validation_accuracy=0.8882\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:46,409] Trial 79 finished with value: 0.8912 and parameters: {'hidden_dim': 40, 'activation_func': 'Sigmoid', 'lr': 0.00043974902897130574, 'momentum': 0.8890597995734997}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.655, validation_accuracy=0.8888\n","Epoch 20: train_loss=0.634, validation_accuracy=0.8912\n","Epoch 1: train_loss=1.743, validation_accuracy=0.7166\n","Epoch 2: train_loss=0.694, validation_accuracy=0.8537\n","Epoch 3: train_loss=0.476, validation_accuracy=0.8847\n","Epoch 4: train_loss=0.393, validation_accuracy=0.8966\n","Epoch 5: train_loss=0.354, validation_accuracy=0.9036\n","Epoch 6: train_loss=0.333, validation_accuracy=0.9078\n","Epoch 7: train_loss=0.314, validation_accuracy=0.9129\n","Epoch 8: train_loss=0.302, validation_accuracy=0.9136\n","Epoch 9: train_loss=0.292, validation_accuracy=0.9173\n","Epoch 10: train_loss=0.281, validation_accuracy=0.9165\n","Epoch 11: train_loss=0.274, validation_accuracy=0.9203\n","Epoch 12: train_loss=0.266, validation_accuracy=0.9218\n","Epoch 13: train_loss=0.258, validation_accuracy=0.9205\n","Epoch 14: train_loss=0.253, validation_accuracy=0.9236\n","Epoch 15: train_loss=0.246, validation_accuracy=0.9256\n","Epoch 16: train_loss=0.240, validation_accuracy=0.9257\n","Epoch 17: train_loss=0.235, validation_accuracy=0.9270\n","Epoch 18: train_loss=0.230, validation_accuracy=0.9287\n","Epoch 19: train_loss=0.224, validation_accuracy=0.9255\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:48,813] Trial 80 finished with value: 0.928 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0003589004039097349, 'momentum': 0.9444361239734625}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.218, validation_accuracy=0.9280\n","Epoch 1: train_loss=2.087, validation_accuracy=0.7817\n","Epoch 2: train_loss=0.606, validation_accuracy=0.8590\n","Epoch 3: train_loss=0.437, validation_accuracy=0.8899\n","Epoch 4: train_loss=0.361, validation_accuracy=0.9044\n","Epoch 5: train_loss=0.323, validation_accuracy=0.9139\n","Epoch 6: train_loss=0.298, validation_accuracy=0.9162\n","Epoch 7: train_loss=0.279, validation_accuracy=0.9221\n","Epoch 8: train_loss=0.264, validation_accuracy=0.9255\n","Epoch 9: train_loss=0.251, validation_accuracy=0.9262\n","Epoch 10: train_loss=0.239, validation_accuracy=0.9284\n","Epoch 11: train_loss=0.232, validation_accuracy=0.9307\n","Epoch 12: train_loss=0.223, validation_accuracy=0.9327\n","Epoch 13: train_loss=0.216, validation_accuracy=0.9326\n","Epoch 14: train_loss=0.209, validation_accuracy=0.9315\n","Epoch 15: train_loss=0.204, validation_accuracy=0.9320\n","Epoch 16: train_loss=0.200, validation_accuracy=0.9366\n","Epoch 17: train_loss=0.195, validation_accuracy=0.9377\n","Epoch 18: train_loss=0.190, validation_accuracy=0.9363\n","Epoch 19: train_loss=0.186, validation_accuracy=0.9384\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:51,017] Trial 81 finished with value: 0.9373 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 0.00020538578825378577, 'momentum': 0.9665665745162416}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.183, validation_accuracy=0.9373\n","Epoch 1: train_loss=1.689, validation_accuracy=0.7690\n","Epoch 2: train_loss=0.679, validation_accuracy=0.8412\n","Epoch 3: train_loss=0.509, validation_accuracy=0.8712\n","Epoch 4: train_loss=0.403, validation_accuracy=0.8961\n","Epoch 5: train_loss=0.342, validation_accuracy=0.9087\n","Epoch 6: train_loss=0.309, validation_accuracy=0.9139\n","Epoch 7: train_loss=0.282, validation_accuracy=0.9189\n","Epoch 8: train_loss=0.269, validation_accuracy=0.9251\n","Epoch 9: train_loss=0.257, validation_accuracy=0.9263\n","Epoch 10: train_loss=0.248, validation_accuracy=0.9263\n","Epoch 11: train_loss=0.239, validation_accuracy=0.9298\n","Epoch 12: train_loss=0.229, validation_accuracy=0.9290\n","Epoch 13: train_loss=0.228, validation_accuracy=0.9319\n","Epoch 14: train_loss=0.218, validation_accuracy=0.9336\n","Epoch 15: train_loss=0.215, validation_accuracy=0.9336\n","Epoch 16: train_loss=0.213, validation_accuracy=0.9329\n","Epoch 17: train_loss=0.207, validation_accuracy=0.9357\n","Epoch 18: train_loss=0.202, validation_accuracy=0.9355\n","Epoch 19: train_loss=0.197, validation_accuracy=0.9345\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:52,993] Trial 82 finished with value: 0.9372 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.00012667455772444905, 'momentum': 0.9898261260920046}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.194, validation_accuracy=0.9372\n","Epoch 1: train_loss=1.873, validation_accuracy=0.7635\n","Epoch 2: train_loss=0.622, validation_accuracy=0.8720\n","Epoch 3: train_loss=0.442, validation_accuracy=0.8976\n","Epoch 4: train_loss=0.367, validation_accuracy=0.9064\n","Epoch 5: train_loss=0.328, validation_accuracy=0.9137\n","Epoch 6: train_loss=0.303, validation_accuracy=0.9172\n","Epoch 7: train_loss=0.286, validation_accuracy=0.9213\n","Epoch 8: train_loss=0.271, validation_accuracy=0.9220\n","Epoch 9: train_loss=0.262, validation_accuracy=0.9232\n","Epoch 10: train_loss=0.256, validation_accuracy=0.9244\n","Epoch 11: train_loss=0.249, validation_accuracy=0.9270\n","Epoch 12: train_loss=0.244, validation_accuracy=0.9265\n","Epoch 13: train_loss=0.238, validation_accuracy=0.9296\n","Epoch 14: train_loss=0.233, validation_accuracy=0.9303\n","Epoch 15: train_loss=0.229, validation_accuracy=0.9302\n","Epoch 16: train_loss=0.226, validation_accuracy=0.9319\n","Epoch 17: train_loss=0.223, validation_accuracy=0.9294\n","Epoch 18: train_loss=0.219, validation_accuracy=0.9326\n","Epoch 19: train_loss=0.216, validation_accuracy=0.9342\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:54,968] Trial 83 finished with value: 0.9347 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.00027956498331487575, 'momentum': 0.9615026412470145}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.212, validation_accuracy=0.9347\n","Epoch 1: train_loss=1.965, validation_accuracy=0.8210\n","Epoch 2: train_loss=0.540, validation_accuracy=0.8707\n","Epoch 3: train_loss=0.424, validation_accuracy=0.8910\n","Epoch 4: train_loss=0.367, validation_accuracy=0.9006\n","Epoch 5: train_loss=0.331, validation_accuracy=0.9051\n","Epoch 6: train_loss=0.305, validation_accuracy=0.9114\n","Epoch 7: train_loss=0.285, validation_accuracy=0.9183\n","Epoch 8: train_loss=0.269, validation_accuracy=0.9191\n","Epoch 9: train_loss=0.255, validation_accuracy=0.9228\n","Epoch 10: train_loss=0.243, validation_accuracy=0.9265\n","Epoch 11: train_loss=0.233, validation_accuracy=0.9267\n","Epoch 12: train_loss=0.224, validation_accuracy=0.9291\n","Epoch 13: train_loss=0.216, validation_accuracy=0.9303\n","Epoch 14: train_loss=0.208, validation_accuracy=0.9314\n","Epoch 15: train_loss=0.202, validation_accuracy=0.9336\n","Epoch 16: train_loss=0.196, validation_accuracy=0.9337\n","Epoch 17: train_loss=0.191, validation_accuracy=0.9342\n","Epoch 18: train_loss=0.186, validation_accuracy=0.9355\n","Epoch 19: train_loss=0.182, validation_accuracy=0.9365\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:57,362] Trial 84 finished with value: 0.9365 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.0001622290504144264, 'momentum': 0.9236420689402576}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.177, validation_accuracy=0.9365\n","Epoch 1: train_loss=1.770, validation_accuracy=0.8250\n","Epoch 2: train_loss=0.593, validation_accuracy=0.8761\n","Epoch 3: train_loss=0.424, validation_accuracy=0.9002\n","Epoch 4: train_loss=0.353, validation_accuracy=0.9130\n","Epoch 5: train_loss=0.311, validation_accuracy=0.9171\n","Epoch 6: train_loss=0.286, validation_accuracy=0.9211\n","Epoch 7: train_loss=0.268, validation_accuracy=0.9255\n","Epoch 8: train_loss=0.250, validation_accuracy=0.9262\n","Epoch 9: train_loss=0.239, validation_accuracy=0.9276\n","Epoch 10: train_loss=0.228, validation_accuracy=0.9295\n","Epoch 11: train_loss=0.219, validation_accuracy=0.9314\n","Epoch 12: train_loss=0.212, validation_accuracy=0.9327\n","Epoch 13: train_loss=0.207, validation_accuracy=0.9336\n","Epoch 14: train_loss=0.201, validation_accuracy=0.9353\n","Epoch 15: train_loss=0.196, validation_accuracy=0.9359\n","Epoch 16: train_loss=0.191, validation_accuracy=0.9382\n","Epoch 17: train_loss=0.186, validation_accuracy=0.9372\n","Epoch 18: train_loss=0.183, validation_accuracy=0.9380\n","Epoch 19: train_loss=0.179, validation_accuracy=0.9379\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:33:59,241] Trial 85 finished with value: 0.9398 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00014068355517863124, 'momentum': 0.975934833391343}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.177, validation_accuracy=0.9398\n","Epoch 1: train_loss=1.683, validation_accuracy=0.7792\n","Epoch 2: train_loss=0.618, validation_accuracy=0.8599\n","Epoch 3: train_loss=0.459, validation_accuracy=0.8846\n","Epoch 4: train_loss=0.386, validation_accuracy=0.9005\n","Epoch 5: train_loss=0.342, validation_accuracy=0.9102\n","Epoch 6: train_loss=0.315, validation_accuracy=0.9133\n","Epoch 7: train_loss=0.296, validation_accuracy=0.9159\n","Epoch 8: train_loss=0.280, validation_accuracy=0.9206\n","Epoch 9: train_loss=0.267, validation_accuracy=0.9219\n","Epoch 10: train_loss=0.256, validation_accuracy=0.9230\n","Epoch 11: train_loss=0.246, validation_accuracy=0.9266\n","Epoch 12: train_loss=0.238, validation_accuracy=0.9272\n","Epoch 13: train_loss=0.231, validation_accuracy=0.9308\n","Epoch 14: train_loss=0.224, validation_accuracy=0.9322\n","Epoch 15: train_loss=0.218, validation_accuracy=0.9347\n","Epoch 16: train_loss=0.214, validation_accuracy=0.9340\n","Epoch 17: train_loss=0.208, validation_accuracy=0.9365\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:01,549] Trial 86 finished with value: 0.9375 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0002075866990140131, 'momentum': 0.9467273750328851}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.204, validation_accuracy=0.9356\n","Epoch 19: train_loss=0.199, validation_accuracy=0.9358\n","Epoch 20: train_loss=0.195, validation_accuracy=0.9375\n","Epoch 1: train_loss=2.548, validation_accuracy=0.5311\n","Epoch 2: train_loss=1.231, validation_accuracy=0.6437\n","Epoch 3: train_loss=0.960, validation_accuracy=0.6972\n","Epoch 4: train_loss=0.809, validation_accuracy=0.7410\n","Epoch 5: train_loss=0.694, validation_accuracy=0.7891\n","Epoch 6: train_loss=0.604, validation_accuracy=0.8203\n","Epoch 7: train_loss=0.534, validation_accuracy=0.8488\n","Epoch 8: train_loss=0.489, validation_accuracy=0.8563\n","Epoch 9: train_loss=0.449, validation_accuracy=0.8715\n","Epoch 10: train_loss=0.420, validation_accuracy=0.8767\n","Epoch 11: train_loss=0.394, validation_accuracy=0.8841\n","Epoch 12: train_loss=0.378, validation_accuracy=0.8874\n","Epoch 13: train_loss=0.366, validation_accuracy=0.8919\n","Epoch 14: train_loss=0.354, validation_accuracy=0.8983\n","Epoch 15: train_loss=0.344, validation_accuracy=0.8992\n","Epoch 16: train_loss=0.334, validation_accuracy=0.9025\n","Epoch 17: train_loss=0.328, validation_accuracy=0.9040\n","Epoch 18: train_loss=0.320, validation_accuracy=0.9032\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:03,236] Trial 87 finished with value: 0.9069 and parameters: {'hidden_dim': 37, 'activation_func': 'ELU', 'lr': 0.00010605002796072514, 'momentum': 0.986913039836939}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.316, validation_accuracy=0.9032\n","Epoch 20: train_loss=0.308, validation_accuracy=0.9069\n","Epoch 1: train_loss=2.147, validation_accuracy=0.7587\n","Epoch 2: train_loss=0.651, validation_accuracy=0.8441\n","Epoch 3: train_loss=0.475, validation_accuracy=0.8793\n","Epoch 4: train_loss=0.394, validation_accuracy=0.8984\n","Epoch 5: train_loss=0.351, validation_accuracy=0.9055\n","Epoch 6: train_loss=0.322, validation_accuracy=0.9111\n","Epoch 7: train_loss=0.300, validation_accuracy=0.9151\n","Epoch 8: train_loss=0.282, validation_accuracy=0.9154\n","Epoch 9: train_loss=0.268, validation_accuracy=0.9213\n","Epoch 10: train_loss=0.256, validation_accuracy=0.9234\n","Epoch 11: train_loss=0.247, validation_accuracy=0.9245\n","Epoch 12: train_loss=0.239, validation_accuracy=0.9296\n","Epoch 13: train_loss=0.233, validation_accuracy=0.9287\n","Epoch 14: train_loss=0.226, validation_accuracy=0.9306\n","Epoch 15: train_loss=0.221, validation_accuracy=0.9319\n","Epoch 16: train_loss=0.216, validation_accuracy=0.9345\n","Epoch 17: train_loss=0.211, validation_accuracy=0.9341\n","Epoch 18: train_loss=0.207, validation_accuracy=0.9348\n","Epoch 19: train_loss=0.202, validation_accuracy=0.9346\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:05,165] Trial 88 finished with value: 0.9362 and parameters: {'hidden_dim': 45, 'activation_func': 'ELU', 'lr': 0.0002701233270194532, 'momentum': 0.9394494853828814}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.200, validation_accuracy=0.9362\n","Epoch 1: train_loss=1.677, validation_accuracy=0.8337\n","Epoch 2: train_loss=0.487, validation_accuracy=0.8826\n","Epoch 3: train_loss=0.381, validation_accuracy=0.9014\n","Epoch 4: train_loss=0.327, validation_accuracy=0.9108\n","Epoch 5: train_loss=0.292, validation_accuracy=0.9161\n","Epoch 6: train_loss=0.269, validation_accuracy=0.9219\n","Epoch 7: train_loss=0.252, validation_accuracy=0.9270\n","Epoch 8: train_loss=0.237, validation_accuracy=0.9290\n","Epoch 9: train_loss=0.227, validation_accuracy=0.9290\n","Epoch 10: train_loss=0.219, validation_accuracy=0.9319\n","Epoch 11: train_loss=0.210, validation_accuracy=0.9330\n","Epoch 12: train_loss=0.203, validation_accuracy=0.9339\n","Epoch 13: train_loss=0.198, validation_accuracy=0.9380\n","Epoch 14: train_loss=0.191, validation_accuracy=0.9385\n","Epoch 15: train_loss=0.186, validation_accuracy=0.9399\n","Epoch 16: train_loss=0.181, validation_accuracy=0.9417\n","Epoch 17: train_loss=0.177, validation_accuracy=0.9428\n","Epoch 18: train_loss=0.172, validation_accuracy=0.9419\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:07,376] Trial 89 finished with value: 0.945 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 0.000568316393730459, 'momentum': 0.8956245703590147}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.168, validation_accuracy=0.9457\n","Epoch 20: train_loss=0.164, validation_accuracy=0.9450\n","Epoch 1: train_loss=2.843, validation_accuracy=0.6643\n","Epoch 2: train_loss=0.855, validation_accuracy=0.7742\n","Epoch 3: train_loss=0.640, validation_accuracy=0.8377\n","Epoch 4: train_loss=0.520, validation_accuracy=0.8742\n","Epoch 5: train_loss=0.438, validation_accuracy=0.8872\n","Epoch 6: train_loss=0.384, validation_accuracy=0.8967\n","Epoch 7: train_loss=0.349, validation_accuracy=0.9068\n","Epoch 8: train_loss=0.326, validation_accuracy=0.9095\n","Epoch 9: train_loss=0.309, validation_accuracy=0.9106\n","Epoch 10: train_loss=0.296, validation_accuracy=0.9147\n","Epoch 11: train_loss=0.285, validation_accuracy=0.9172\n","Epoch 12: train_loss=0.276, validation_accuracy=0.9189\n","Epoch 13: train_loss=0.269, validation_accuracy=0.9211\n","Epoch 14: train_loss=0.263, validation_accuracy=0.9207\n","Epoch 15: train_loss=0.257, validation_accuracy=0.9222\n","Epoch 16: train_loss=0.253, validation_accuracy=0.9223\n","Epoch 17: train_loss=0.248, validation_accuracy=0.9243\n","Epoch 18: train_loss=0.245, validation_accuracy=0.9250\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:09,455] Trial 90 finished with value: 0.9284 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.00041874799451280405, 'momentum': 0.9178521364312877}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.241, validation_accuracy=0.9248\n","Epoch 20: train_loss=0.238, validation_accuracy=0.9284\n","Epoch 1: train_loss=2.226, validation_accuracy=0.7433\n","Epoch 2: train_loss=0.681, validation_accuracy=0.8444\n","Epoch 3: train_loss=0.506, validation_accuracy=0.8721\n","Epoch 4: train_loss=0.419, validation_accuracy=0.8921\n","Epoch 5: train_loss=0.360, validation_accuracy=0.9021\n","Epoch 6: train_loss=0.325, validation_accuracy=0.9106\n","Epoch 7: train_loss=0.301, validation_accuracy=0.9139\n","Epoch 8: train_loss=0.284, validation_accuracy=0.9235\n","Epoch 9: train_loss=0.268, validation_accuracy=0.9269\n","Epoch 10: train_loss=0.256, validation_accuracy=0.9290\n","Epoch 11: train_loss=0.244, validation_accuracy=0.9317\n","Epoch 12: train_loss=0.236, validation_accuracy=0.9312\n","Epoch 13: train_loss=0.228, validation_accuracy=0.9330\n","Epoch 14: train_loss=0.223, validation_accuracy=0.9346\n","Epoch 15: train_loss=0.217, validation_accuracy=0.9349\n","Epoch 16: train_loss=0.212, validation_accuracy=0.9337\n","Epoch 17: train_loss=0.208, validation_accuracy=0.9361\n","Epoch 18: train_loss=0.204, validation_accuracy=0.9388\n","Epoch 19: train_loss=0.200, validation_accuracy=0.9405\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:11,977] Trial 91 finished with value: 0.9411 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 0.0006576322186633757, 'momentum': 0.8957559450080851}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.196, validation_accuracy=0.9411\n","Epoch 1: train_loss=2.364, validation_accuracy=0.7023\n","Epoch 2: train_loss=0.752, validation_accuracy=0.8279\n","Epoch 3: train_loss=0.535, validation_accuracy=0.8688\n","Epoch 4: train_loss=0.438, validation_accuracy=0.8933\n","Epoch 5: train_loss=0.387, validation_accuracy=0.9006\n","Epoch 6: train_loss=0.356, validation_accuracy=0.9059\n","Epoch 7: train_loss=0.334, validation_accuracy=0.9106\n","Epoch 8: train_loss=0.317, validation_accuracy=0.9121\n","Epoch 9: train_loss=0.307, validation_accuracy=0.9165\n","Epoch 10: train_loss=0.298, validation_accuracy=0.9181\n","Epoch 11: train_loss=0.293, validation_accuracy=0.9172\n","Epoch 12: train_loss=0.284, validation_accuracy=0.9178\n","Epoch 13: train_loss=0.279, validation_accuracy=0.9205\n","Epoch 14: train_loss=0.274, validation_accuracy=0.9236\n","Epoch 15: train_loss=0.269, validation_accuracy=0.9225\n","Epoch 16: train_loss=0.265, validation_accuracy=0.9242\n","Epoch 17: train_loss=0.261, validation_accuracy=0.9286\n","Epoch 18: train_loss=0.258, validation_accuracy=0.9271\n","Epoch 19: train_loss=0.255, validation_accuracy=0.9251\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:14,002] Trial 92 finished with value: 0.9268 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 0.0003341497136033777, 'momentum': 0.956067332938486}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.253, validation_accuracy=0.9268\n","Epoch 1: train_loss=2.020, validation_accuracy=0.8135\n","Epoch 2: train_loss=0.519, validation_accuracy=0.8806\n","Epoch 3: train_loss=0.374, validation_accuracy=0.9015\n","Epoch 4: train_loss=0.313, validation_accuracy=0.9132\n","Epoch 5: train_loss=0.276, validation_accuracy=0.9205\n","Epoch 6: train_loss=0.250, validation_accuracy=0.9270\n","Epoch 7: train_loss=0.231, validation_accuracy=0.9288\n","Epoch 8: train_loss=0.218, validation_accuracy=0.9340\n","Epoch 9: train_loss=0.206, validation_accuracy=0.9359\n","Epoch 10: train_loss=0.197, validation_accuracy=0.9389\n","Epoch 11: train_loss=0.189, validation_accuracy=0.9389\n","Epoch 12: train_loss=0.184, validation_accuracy=0.9404\n","Epoch 13: train_loss=0.178, validation_accuracy=0.9424\n","Epoch 14: train_loss=0.174, validation_accuracy=0.9441\n","Epoch 15: train_loss=0.169, validation_accuracy=0.9436\n","Epoch 16: train_loss=0.165, validation_accuracy=0.9432\n","Epoch 17: train_loss=0.161, validation_accuracy=0.9422\n","Epoch 18: train_loss=0.157, validation_accuracy=0.9462\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:15,996] Trial 93 finished with value: 0.9442 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.00017983208235496225, 'momentum': 0.9674551273203138}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.154, validation_accuracy=0.9457\n","Epoch 20: train_loss=0.152, validation_accuracy=0.9442\n","Epoch 1: train_loss=1.918, validation_accuracy=0.8028\n","Epoch 2: train_loss=0.560, validation_accuracy=0.8815\n","Epoch 3: train_loss=0.406, validation_accuracy=0.9018\n","Epoch 4: train_loss=0.343, validation_accuracy=0.9119\n","Epoch 5: train_loss=0.304, validation_accuracy=0.9194\n","Epoch 6: train_loss=0.275, validation_accuracy=0.9235\n","Epoch 7: train_loss=0.255, validation_accuracy=0.9285\n","Epoch 8: train_loss=0.238, validation_accuracy=0.9286\n","Epoch 9: train_loss=0.226, validation_accuracy=0.9318\n","Epoch 10: train_loss=0.216, validation_accuracy=0.9351\n","Epoch 11: train_loss=0.207, validation_accuracy=0.9361\n","Epoch 12: train_loss=0.199, validation_accuracy=0.9350\n","Epoch 13: train_loss=0.192, validation_accuracy=0.9374\n","Epoch 14: train_loss=0.186, validation_accuracy=0.9383\n","Epoch 15: train_loss=0.181, validation_accuracy=0.9397\n","Epoch 16: train_loss=0.175, validation_accuracy=0.9413\n","Epoch 17: train_loss=0.170, validation_accuracy=0.9410\n","Epoch 18: train_loss=0.166, validation_accuracy=0.9423\n","Epoch 19: train_loss=0.163, validation_accuracy=0.9418\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:18,013] Trial 94 finished with value: 0.9447 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.0002372182215457099, 'momentum': 0.9357623597717878}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.160, validation_accuracy=0.9447\n","Epoch 1: train_loss=1.902, validation_accuracy=0.8414\n","Epoch 2: train_loss=0.574, validation_accuracy=0.8879\n","Epoch 3: train_loss=0.440, validation_accuracy=0.9026\n","Epoch 4: train_loss=0.373, validation_accuracy=0.9119\n","Epoch 5: train_loss=0.333, validation_accuracy=0.9183\n","Epoch 6: train_loss=0.307, validation_accuracy=0.9204\n","Epoch 7: train_loss=0.287, validation_accuracy=0.9240\n","Epoch 8: train_loss=0.271, validation_accuracy=0.9273\n","Epoch 9: train_loss=0.259, validation_accuracy=0.9278\n","Epoch 10: train_loss=0.248, validation_accuracy=0.9292\n","Epoch 11: train_loss=0.239, validation_accuracy=0.9306\n","Epoch 12: train_loss=0.231, validation_accuracy=0.9315\n","Epoch 13: train_loss=0.225, validation_accuracy=0.9342\n","Epoch 14: train_loss=0.220, validation_accuracy=0.9328\n","Epoch 15: train_loss=0.214, validation_accuracy=0.9348\n","Epoch 16: train_loss=0.210, validation_accuracy=0.9366\n","Epoch 17: train_loss=0.206, validation_accuracy=0.9365\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:20,084] Trial 95 finished with value: 0.9382 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.00024206491814058313, 'momentum': 0.9358015654344533}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.203, validation_accuracy=0.9362\n","Epoch 19: train_loss=0.200, validation_accuracy=0.9370\n","Epoch 20: train_loss=0.197, validation_accuracy=0.9382\n","Epoch 1: train_loss=1.616, validation_accuracy=0.7914\n","Epoch 2: train_loss=0.526, validation_accuracy=0.8931\n","Epoch 3: train_loss=0.361, validation_accuracy=0.9127\n","Epoch 4: train_loss=0.300, validation_accuracy=0.9237\n","Epoch 5: train_loss=0.266, validation_accuracy=0.9280\n","Epoch 6: train_loss=0.247, validation_accuracy=0.9333\n","Epoch 7: train_loss=0.232, validation_accuracy=0.9344\n","Epoch 8: train_loss=0.220, validation_accuracy=0.9377\n","Epoch 9: train_loss=0.212, validation_accuracy=0.9367\n","Epoch 10: train_loss=0.204, validation_accuracy=0.9385\n","Epoch 11: train_loss=0.197, validation_accuracy=0.9389\n","Epoch 12: train_loss=0.192, validation_accuracy=0.9401\n","Epoch 13: train_loss=0.186, validation_accuracy=0.9394\n","Epoch 14: train_loss=0.182, validation_accuracy=0.9444\n","Epoch 15: train_loss=0.175, validation_accuracy=0.9450\n","Epoch 16: train_loss=0.173, validation_accuracy=0.9438\n","Epoch 17: train_loss=0.169, validation_accuracy=0.9448\n","Epoch 18: train_loss=0.167, validation_accuracy=0.9442\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:21,546] Trial 96 finished with value: 0.945 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.0003983273466350274, 'momentum': 0.9666534609225201}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.164, validation_accuracy=0.9461\n","Epoch 20: train_loss=0.162, validation_accuracy=0.9450\n","Epoch 1: train_loss=4.390, validation_accuracy=0.3653\n","Epoch 2: train_loss=1.724, validation_accuracy=0.3797\n","Epoch 3: train_loss=1.647, validation_accuracy=0.4029\n","Epoch 4: train_loss=1.621, validation_accuracy=0.3771\n","Epoch 5: train_loss=1.595, validation_accuracy=0.4063\n","Epoch 6: train_loss=1.578, validation_accuracy=0.3635\n","Epoch 7: train_loss=1.535, validation_accuracy=0.4118\n","Epoch 8: train_loss=1.471, validation_accuracy=0.4398\n","Epoch 9: train_loss=1.485, validation_accuracy=0.4793\n","Epoch 10: train_loss=1.291, validation_accuracy=0.5310\n","Epoch 11: train_loss=1.114, validation_accuracy=0.6286\n","Epoch 12: train_loss=1.015, validation_accuracy=0.6500\n","Epoch 13: train_loss=0.920, validation_accuracy=0.7297\n","Epoch 14: train_loss=0.767, validation_accuracy=0.7146\n","Epoch 15: train_loss=0.687, validation_accuracy=0.7967\n","Epoch 16: train_loss=0.632, validation_accuracy=0.8099\n","Epoch 17: train_loss=0.609, validation_accuracy=0.8345\n","Epoch 18: train_loss=0.567, validation_accuracy=0.8412\n","Epoch 19: train_loss=0.529, validation_accuracy=0.8579\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:22,977] Trial 97 finished with value: 0.8531 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.0005759902558577823, 'momentum': 0.9656413136716933}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.484, validation_accuracy=0.8531\n","Epoch 1: train_loss=2.266, validation_accuracy=0.5597\n","Epoch 2: train_loss=1.269, validation_accuracy=0.6224\n","Epoch 3: train_loss=1.430, validation_accuracy=0.5647\n","Epoch 4: train_loss=1.688, validation_accuracy=0.4381\n","Epoch 5: train_loss=1.831, validation_accuracy=0.4271\n","Epoch 6: train_loss=1.746, validation_accuracy=0.3795\n","Epoch 7: train_loss=1.679, validation_accuracy=0.3895\n","Epoch 8: train_loss=1.971, validation_accuracy=0.3388\n","Epoch 9: train_loss=2.152, validation_accuracy=0.2669\n","Epoch 10: train_loss=2.181, validation_accuracy=0.2646\n","Epoch 11: train_loss=2.748, validation_accuracy=0.2247\n","Epoch 12: train_loss=2.153, validation_accuracy=0.1988\n","Epoch 13: train_loss=2.112, validation_accuracy=0.1981\n","Epoch 14: train_loss=2.168, validation_accuracy=0.1988\n","Epoch 15: train_loss=2.266, validation_accuracy=0.2005\n","Epoch 16: train_loss=2.412, validation_accuracy=0.1987\n","Epoch 17: train_loss=2.277, validation_accuracy=0.1664\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:24,443] Trial 98 finished with value: 0.1669 and parameters: {'hidden_dim': 47, 'activation_func': 'ReLU', 'lr': 0.00039635235306164865, 'momentum': 0.9999235180268151}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=2.331, validation_accuracy=0.1487\n","Epoch 19: train_loss=2.400, validation_accuracy=0.1472\n","Epoch 20: train_loss=2.401, validation_accuracy=0.1669\n","Epoch 1: train_loss=2.025, validation_accuracy=0.7779\n","Epoch 2: train_loss=0.629, validation_accuracy=0.8483\n","Epoch 3: train_loss=0.495, validation_accuracy=0.8678\n","Epoch 4: train_loss=0.433, validation_accuracy=0.8839\n","Epoch 5: train_loss=0.393, validation_accuracy=0.8907\n","Epoch 6: train_loss=0.366, validation_accuracy=0.8953\n","Epoch 7: train_loss=0.344, validation_accuracy=0.9032\n","Epoch 8: train_loss=0.327, validation_accuracy=0.9048\n","Epoch 9: train_loss=0.312, validation_accuracy=0.9081\n","Epoch 10: train_loss=0.299, validation_accuracy=0.9122\n","Epoch 11: train_loss=0.288, validation_accuracy=0.9143\n","Epoch 12: train_loss=0.279, validation_accuracy=0.9186\n","Epoch 13: train_loss=0.270, validation_accuracy=0.9202\n","Epoch 14: train_loss=0.262, validation_accuracy=0.9226\n","Epoch 15: train_loss=0.255, validation_accuracy=0.9237\n","Epoch 16: train_loss=0.249, validation_accuracy=0.9256\n","Epoch 17: train_loss=0.242, validation_accuracy=0.9254\n","Epoch 18: train_loss=0.237, validation_accuracy=0.9272\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 19:34:26,011] Trial 99 finished with value: 0.9294 and parameters: {'hidden_dim': 42, 'activation_func': 'ReLU', 'lr': 0.0001307324764758524, 'momentum': 0.9086633947210923}. Best is trial 42 with value: 0.9462.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.231, validation_accuracy=0.9277\n","Epoch 20: train_loss=0.226, validation_accuracy=0.9294\n","最良の精度: 0.9462\n","最良のハイパーパラメータ: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.0001438697920405901, 'momentum': 0.9699784024166463}\n"]}],"source":["study = optuna.create_study(direction=\"maximize\")\n","study.optimize(objective, n_trials=100)\n","\n","print(f\"最良の精度: {study.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"BF6IVv_T-ELA"},"source":["うまくいけば0.94程度の精度が出ると思います。\n","\n","得られたハイパーパラメータをはじめのの学習コードに入れて、もう一度学習を回してみてください。誤認識する画像が少なくなったでしょうか?"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 4. 高度なサンプリングアルゴリズム・枝刈りアルゴリズムを利用する\n","\n","Optunaでは最先端のサンプリングアルゴリズム・枝刈りアルゴリズムを数多く利用して、最適化を行う事ができます。\n","その方法は非常にシンプルです。まずは、それぞれ**sampler**, **pruner**というオブジェクトを指定して、**study**を作成しましょう。"]},{"cell_type":"code","execution_count":282,"metadata":{"id":"gzlMnNB9tKH1"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 15:27:29,809] A new study created in memory with name: no-name-29cc8732-19a9-44ce-b3ba-0b8b903a8031\n"]}],"source":["sampler = optuna.samplers.TPESampler(multivariate=True)  # 多くの場合、multivariate=Trueを指定することで性能が少し上がる\n","pruner = optuna.pruners.HyperbandPruner()\n","\n","study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")"]},{"cell_type":"markdown","metadata":{"id":"O-ZA4T6i6Wpp"},"source":["**sampler**は、このようにstudyを作成する際に渡すだけで有効化されます。\n","一方で、**pruner**を有効にするためには、目的関数内で中間値を報告し、各ステップで枝刈りをするかどうか判断するコードを追加する必要があります。\n","上の分散並列最適化のセクションで用いた目的関数を、**pruner**が有効になるよう書き換えると以下のようになるでしょう。"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":868,"status":"ok","timestamp":1602747584962,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"bf0EFoaM6Q_Y"},"outputs":[],"source":["def fit_mnist_and_evaluate_with_report(trial, model, optimizer):\n","\n","    # 損失関数の定義\n","    loss_func = nn.CrossEntropyLoss() \n","\n","    # 学習 (今回はepoch数は20で固定とします。)\n","    epochs = 20\n","    for epoch in range(epochs):\n","        \n","        loss_sum = 0.0\n","        \n","        # batchをシャッフルする (今回はbatch sizeは600で固定とします。)\n","        batch_size = 600\n","        batch_idxs = torch.randperm(len(train_X), device=device).view(-1, batch_size)\n","\n","        for i, batch in enumerate(batch_idxs):\n","            # 各batchについて最適化を回す\n","\n","            optimizer.zero_grad() # 微分係数の初期化\n","            outputs = model(train_X[batch])          # 予測\n","            loss = loss_func(outputs, train_y[batch]) # 損失関数の計算 \n","            loss.backward()  # 微分の計算\n","            optimizer.step() # 最適化の1ステップの計算 \n","\n","            loss_sum += loss.item()\n","\n","        train_loss = loss_sum / (i + 1) # batchごとの損失関数の平均をとる\n","\n","        # 評価\n","        with torch.no_grad():\n","            outputs = model(validation_X)\n","            _, predicted = torch.max(outputs.data, dim=1) # 最も予測値が高かったものをとる\n","            total = len(validation_X)\n","            correct = (predicted == validation_y).sum().item()\n","            validation_accuracy = correct / total\n","        \n","        print(f\"Epoch {epoch + 1}: train_loss={train_loss:.3f}, validation_accuracy={validation_accuracy:.4f}\")\n","\n","        # 中間値をOptunaに報告 <-- この3行が追加されている\n","        trial.report(validation_accuracy, epoch)\n","        if trial.should_prune():\n","            raise optuna.TrialPruned()\n","\n","    return validation_accuracy\n","\n","def objective_with_report(trial):\n","    \n","    # モデルの定義\n","    hidden_dim = trial.suggest_int('hidden_dim', 10, 50)  # 中間層の次元数\n","    activation_func = trial.suggest_categorical('activation_func', ['Sigmoid', 'Tanh', 'ReLU', 'ELU'])  # 活性化関数\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","    activation = activation_funcs[activation_func]\n","\n","    model = nn.Sequential(\n","        nn.Flatten(),                  # 二次元の画像を一次元に変換\n","        nn.Linear(28*28, hidden_dim),  # 入力層から中間層への線形変換\n","        activation,                    # 活性化関数\n","        nn.Linear(hidden_dim, 10),     # 中間層から出力層への線形変換\n","    )\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # <-- 1e-5から1e-2までの間で、対数スケールで探索\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # <-- 0.5から1.0までの間で探索\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate_with_report(trial, model, optimizer)\n","    return validation_accuracy"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"gludoDzN9K8N"},"source":["主要な変更点は、`# 中間値をOptunaに報告`と書いた部分の3行です。\n","\n","この目的関数を用いて**Study.optimize**を呼ぶと、枝刈りを考慮した最適化を行う事ができます。"]},{"cell_type":"code","execution_count":284,"metadata":{"id":"eQv_J-So9Z55"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 15:27:35,272] Trial 0 finished with value: 0.8743 and parameters: {'hidden_dim': 27, 'activation_func': 'Tanh', 'lr': 0.062487778612860014, 'momentum': 0.21267217913032133}. Best is trial 0 with value: 0.8743.\n","[I 2023-03-07 15:27:36,840] Trial 1 finished with value: 0.6087 and parameters: {'hidden_dim': 31, 'activation_func': 'Sigmoid', 'lr': 0.00010417613899852868, 'momentum': 0.4834202351705208}. Best is trial 0 with value: 0.8743.\n","[I 2023-03-07 15:27:38,612] Trial 2 finished with value: 0.9007 and parameters: {'hidden_dim': 40, 'activation_func': 'Sigmoid', 'lr': 0.003345949647816638, 'momentum': 0.3359722385255286}. Best is trial 2 with value: 0.9007.\n","[I 2023-03-07 15:27:40,308] Trial 3 finished with value: 0.9126 and parameters: {'hidden_dim': 38, 'activation_func': 'Sigmoid', 'lr': 0.07345995437347194, 'momentum': 0.6770169324278631}. Best is trial 3 with value: 0.9126.\n","[I 2023-03-07 15:27:40,432] Trial 4 pruned. \n","[I 2023-03-07 15:27:40,572] Trial 5 pruned. \n","[I 2023-03-07 15:27:41,964] Trial 6 finished with value: 0.9278 and parameters: {'hidden_dim': 33, 'activation_func': 'ReLU', 'lr': 0.0008648493110902111, 'momentum': 0.5806424436301846}. Best is trial 6 with value: 0.9278.\n","[I 2023-03-07 15:27:42,226] Trial 7 pruned. \n","[I 2023-03-07 15:27:42,383] Trial 8 pruned. \n","[I 2023-03-07 15:27:44,348] Trial 9 finished with value: 0.9333 and parameters: {'hidden_dim': 40, 'activation_func': 'Sigmoid', 'lr': 0.033929482179144585, 'momentum': 0.46075280892759585}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:27:44,498] Trial 10 pruned. \n","[I 2023-03-07 15:27:44,849] Trial 11 pruned. \n","[I 2023-03-07 15:27:45,134] Trial 12 pruned. \n","[I 2023-03-07 15:27:45,398] Trial 13 pruned. \n","[I 2023-03-07 15:27:45,635] Trial 14 pruned. \n","[I 2023-03-07 15:27:47,024] Trial 15 finished with value: 0.7013 and parameters: {'hidden_dim': 21, 'activation_func': 'ReLU', 'lr': 0.002790972162359176, 'momentum': 0.14938407236992013}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:27:47,336] Trial 16 pruned. \n","[I 2023-03-07 15:27:47,475] Trial 17 pruned. \n","[I 2023-03-07 15:27:47,609] Trial 18 pruned. \n","[I 2023-03-07 15:27:47,995] Trial 19 pruned. \n","[I 2023-03-07 15:27:48,281] Trial 20 pruned. \n","[I 2023-03-07 15:27:48,458] Trial 21 pruned. \n","[I 2023-03-07 15:27:49,773] Trial 22 finished with value: 0.7586 and parameters: {'hidden_dim': 16, 'activation_func': 'Sigmoid', 'lr': 0.00012508507951699044, 'momentum': 0.8864542041678954}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:27:50,021] Trial 23 pruned. \n","[I 2023-03-07 15:27:50,390] Trial 24 pruned. \n","[I 2023-03-07 15:27:50,750] Trial 25 pruned. \n","[I 2023-03-07 15:27:51,642] Trial 26 pruned. \n","[I 2023-03-07 15:27:51,846] Trial 27 pruned. \n","[I 2023-03-07 15:27:53,254] Trial 28 finished with value: 0.8557 and parameters: {'hidden_dim': 17, 'activation_func': 'Sigmoid', 'lr': 0.0013234890158293632, 'momentum': 0.5221820641001232}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:27:54,203] Trial 29 pruned. \n","[I 2023-03-07 15:27:54,483] Trial 30 pruned. \n","[I 2023-03-07 15:27:54,696] Trial 31 pruned. \n","[I 2023-03-07 15:27:55,375] Trial 32 pruned. \n","[I 2023-03-07 15:27:55,570] Trial 33 pruned. \n","[I 2023-03-07 15:27:55,738] Trial 34 pruned. \n","[I 2023-03-07 15:27:55,924] Trial 35 pruned. \n","[I 2023-03-07 15:27:57,899] Trial 36 finished with value: 0.9296 and parameters: {'hidden_dim': 43, 'activation_func': 'Sigmoid', 'lr': 0.014359106515225544, 'momentum': 0.42624184615189986}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:27:58,090] Trial 37 pruned. \n","[I 2023-03-07 15:27:58,880] Trial 38 pruned. \n","[I 2023-03-07 15:28:00,355] Trial 39 finished with value: 0.9307 and parameters: {'hidden_dim': 43, 'activation_func': 'ReLU', 'lr': 0.001015704770191709, 'momentum': 0.37392067975917265}. Best is trial 9 with value: 0.9333.\n","[I 2023-03-07 15:28:02,364] Trial 40 finished with value: 0.9341 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.017603684704398548, 'momentum': 0.42428418660902967}. Best is trial 40 with value: 0.9341.\n","[I 2023-03-07 15:28:03,885] Trial 41 finished with value: 0.935 and parameters: {'hidden_dim': 45, 'activation_func': 'ReLU', 'lr': 0.001292883702694982, 'momentum': 0.43258985021909196}. Best is trial 41 with value: 0.935.\n","[I 2023-03-07 15:28:05,406] Trial 42 finished with value: 0.9349 and parameters: {'hidden_dim': 45, 'activation_func': 'ReLU', 'lr': 0.0009838913799556463, 'momentum': 0.439607013510227}. Best is trial 41 with value: 0.935.\n","[I 2023-03-07 15:28:05,725] Trial 43 pruned. \n","[I 2023-03-07 15:28:06,046] Trial 44 pruned. \n","[I 2023-03-07 15:28:06,832] Trial 45 pruned. \n","[I 2023-03-07 15:28:07,241] Trial 46 pruned. \n","[I 2023-03-07 15:28:07,640] Trial 47 pruned. \n","[I 2023-03-07 15:28:07,811] Trial 48 pruned. \n","[I 2023-03-07 15:28:09,188] Trial 49 finished with value: 0.9173 and parameters: {'hidden_dim': 32, 'activation_func': 'Tanh', 'lr': 0.009854898862567437, 'momentum': 0.42843105995627584}. Best is trial 41 with value: 0.935.\n","[I 2023-03-07 15:28:09,356] Trial 50 pruned. \n","[I 2023-03-07 15:28:09,657] Trial 51 pruned. \n","[I 2023-03-07 15:28:11,312] Trial 52 finished with value: 0.928 and parameters: {'hidden_dim': 50, 'activation_func': 'Tanh', 'lr': 0.02044131359025087, 'momentum': 0.47896206561978943}. Best is trial 41 with value: 0.935.\n","[I 2023-03-07 15:28:11,478] Trial 53 pruned. \n","[I 2023-03-07 15:28:11,638] Trial 54 pruned. \n","[I 2023-03-07 15:28:11,990] Trial 55 pruned. \n","[I 2023-03-07 15:28:12,136] Trial 56 pruned. \n","[I 2023-03-07 15:28:12,301] Trial 57 pruned. \n","[I 2023-03-07 15:28:13,067] Trial 58 pruned. \n","[I 2023-03-07 15:28:13,213] Trial 59 pruned. \n","[I 2023-03-07 15:28:13,383] Trial 60 pruned. \n","[I 2023-03-07 15:28:13,849] Trial 61 pruned. \n","[I 2023-03-07 15:28:14,009] Trial 62 pruned. \n","[I 2023-03-07 15:28:15,506] Trial 63 finished with value: 0.9331 and parameters: {'hidden_dim': 42, 'activation_func': 'ReLU', 'lr': 0.0009328499343405651, 'momentum': 0.46257940322393776}. Best is trial 41 with value: 0.935.\n","[I 2023-03-07 15:28:15,651] Trial 64 pruned. \n","[I 2023-03-07 15:28:16,022] Trial 65 pruned. \n","[I 2023-03-07 15:28:16,190] Trial 66 pruned. \n","[I 2023-03-07 15:28:17,007] Trial 67 pruned. \n","[I 2023-03-07 15:28:17,163] Trial 68 pruned. \n","[I 2023-03-07 15:28:17,479] Trial 69 pruned. \n","[I 2023-03-07 15:28:17,683] Trial 70 pruned. \n","[I 2023-03-07 15:28:17,874] Trial 71 pruned. \n","[I 2023-03-07 15:28:18,034] Trial 72 pruned. \n","[I 2023-03-07 15:28:18,195] Trial 73 pruned. \n","[I 2023-03-07 15:28:18,337] Trial 74 pruned. \n","[I 2023-03-07 15:28:19,316] Trial 75 pruned. \n","[I 2023-03-07 15:28:19,635] Trial 76 pruned. \n","[I 2023-03-07 15:28:20,601] Trial 77 pruned. \n","[I 2023-03-07 15:28:20,779] Trial 78 pruned. \n","[I 2023-03-07 15:28:20,993] Trial 79 pruned. \n","[I 2023-03-07 15:28:21,800] Trial 80 pruned. \n","[I 2023-03-07 15:28:22,729] Trial 81 pruned. \n","[I 2023-03-07 15:28:22,889] Trial 82 pruned. \n","[I 2023-03-07 15:28:23,068] Trial 83 pruned. \n","[I 2023-03-07 15:28:24,612] Trial 84 finished with value: 0.9396 and parameters: {'hidden_dim': 44, 'activation_func': 'ReLU', 'lr': 0.0011076208343969746, 'momentum': 0.3864770357017791}. Best is trial 84 with value: 0.9396.\n","[I 2023-03-07 15:28:25,395] Trial 85 pruned. \n","[I 2023-03-07 15:28:26,353] Trial 86 pruned. \n","[I 2023-03-07 15:28:27,044] Trial 87 pruned. \n","[I 2023-03-07 15:28:27,351] Trial 88 pruned. \n","[I 2023-03-07 15:28:28,367] Trial 89 pruned. \n","[I 2023-03-07 15:28:29,200] Trial 90 pruned. \n","[I 2023-03-07 15:28:30,744] Trial 91 finished with value: 0.9401 and parameters: {'hidden_dim': 44, 'activation_func': 'ReLU', 'lr': 0.001854561527432844, 'momentum': 0.4133402704688983}. Best is trial 91 with value: 0.9401.\n","[I 2023-03-07 15:28:31,068] Trial 92 pruned. \n","[I 2023-03-07 15:28:31,840] Trial 93 pruned. \n","[I 2023-03-07 15:28:32,000] Trial 94 pruned. \n","[I 2023-03-07 15:28:32,166] Trial 95 pruned. \n","[I 2023-03-07 15:28:32,536] Trial 96 pruned. \n","[I 2023-03-07 15:28:33,313] Trial 97 pruned. \n","[I 2023-03-07 15:28:33,453] Trial 98 pruned. \n","[I 2023-03-07 15:28:35,022] Trial 99 finished with value: 0.9273 and parameters: {'hidden_dim': 39, 'activation_func': 'Tanh', 'lr': 0.009517538831307184, 'momentum': 0.34714551721432096}. Best is trial 91 with value: 0.9401.\n"]}],"source":["study_with_pruner.optimize(objective_with_report, n_trials=100)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"TiWh6Mr59eoD"},"source":["実行ログを見ると、いくつかのトライアルが最後まで実行されず途中で枝刈りされている事がわかります。\n","枝刈りによる高速化成功です！\n","\n","...ちょっと待ってください。これで我々の最適化はリーズナブルに改善されたでしょうか？\n","いいえ。これだけだと、実行するはずだった40トライアルが早く終わっただけです。\n","枝刈りの目的は、与えられたリソースの元で、見込みの薄いトライアルを枝刈りすることで\n","最大限多くのハイパーパラメータ候補を試すことにあります。\n","したがって、枝刈りによって最適化を改善するためには**Study.optimizeのトライアル数を一定にしてはダメです。**\n","代わりに、**最適化全体で消費されたリソース量を一定にする必要があります。**\n","\n","これを実現するための最も簡単な方法は、トライアル数ではなく時間を一定にすることです。\n"]},{"cell_type":"code","execution_count":285,"metadata":{"id":"t7MqzHws_F_-"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 15:29:16,182] Trial 100 pruned. \n","[I 2023-03-07 15:29:16,378] Trial 101 pruned. \n","[I 2023-03-07 15:29:16,598] Trial 102 pruned. \n","[I 2023-03-07 15:29:17,345] Trial 103 pruned. \n","[I 2023-03-07 15:29:17,505] Trial 104 pruned. \n","[I 2023-03-07 15:29:18,396] Trial 105 pruned. \n","[I 2023-03-07 15:29:18,566] Trial 106 pruned. \n","[I 2023-03-07 15:29:18,932] Trial 107 pruned. \n","[I 2023-03-07 15:29:19,255] Trial 108 pruned. \n","[I 2023-03-07 15:29:19,458] Trial 109 pruned. \n","[I 2023-03-07 15:29:20,265] Trial 110 pruned. \n","[I 2023-03-07 15:29:20,595] Trial 111 pruned. \n","[I 2023-03-07 15:29:22,234] Trial 112 finished with value: 0.9295 and parameters: {'hidden_dim': 47, 'activation_func': 'Tanh', 'lr': 0.005043990385564181, 'momentum': 0.6106718391276362}. Best is trial 91 with value: 0.9401.\n","[I 2023-03-07 15:29:23,080] Trial 113 pruned. \n","[I 2023-03-07 15:29:23,513] Trial 114 pruned. \n","[I 2023-03-07 15:29:23,905] Trial 115 pruned. \n","[I 2023-03-07 15:29:24,083] Trial 116 pruned. \n","[I 2023-03-07 15:29:24,273] Trial 117 pruned. \n","[I 2023-03-07 15:29:25,050] Trial 118 pruned. \n","[I 2023-03-07 15:29:25,218] Trial 119 pruned. \n","[I 2023-03-07 15:29:26,722] Trial 120 finished with value: 0.9409 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.0016053620479786182, 'momentum': 0.44341478628853687}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:28,375] Trial 121 finished with value: 0.9278 and parameters: {'hidden_dim': 50, 'activation_func': 'Tanh', 'lr': 0.0035979802326507417, 'momentum': 0.6189784955374865}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:28,547] Trial 122 pruned. \n","[I 2023-03-07 15:29:29,365] Trial 123 pruned. \n","[I 2023-03-07 15:29:29,529] Trial 124 pruned. \n","[I 2023-03-07 15:29:29,700] Trial 125 pruned. \n","[I 2023-03-07 15:29:29,906] Trial 126 pruned. \n","[I 2023-03-07 15:29:30,209] Trial 127 pruned. \n","[I 2023-03-07 15:29:30,984] Trial 128 pruned. \n","[I 2023-03-07 15:29:32,528] Trial 129 finished with value: 0.9306 and parameters: {'hidden_dim': 46, 'activation_func': 'ReLU', 'lr': 0.0003544843999287384, 'momentum': 0.6759496018770355}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:32,846] Trial 130 pruned. \n","[I 2023-03-07 15:29:33,032] Trial 131 pruned. \n","[I 2023-03-07 15:29:33,869] Trial 132 pruned. \n","[I 2023-03-07 15:29:34,692] Trial 133 pruned. \n","[I 2023-03-07 15:29:34,863] Trial 134 pruned. \n","[I 2023-03-07 15:29:35,180] Trial 135 pruned. \n","[I 2023-03-07 15:29:35,502] Trial 136 pruned. \n","[I 2023-03-07 15:29:35,829] Trial 137 pruned. \n","[I 2023-03-07 15:29:36,219] Trial 138 pruned. \n","[I 2023-03-07 15:29:36,530] Trial 139 pruned. \n","[I 2023-03-07 15:29:36,678] Trial 140 pruned. \n","[I 2023-03-07 15:29:38,453] Trial 141 finished with value: 0.9241 and parameters: {'hidden_dim': 36, 'activation_func': 'Sigmoid', 'lr': 0.06201602562269211, 'momentum': 0.358211187338937}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:38,626] Trial 142 pruned. \n","[I 2023-03-07 15:29:40,147] Trial 143 finished with value: 0.9287 and parameters: {'hidden_dim': 45, 'activation_func': 'ReLU', 'lr': 0.0007249795051481652, 'momentum': 0.4400962018688655}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:40,940] Trial 144 pruned. \n","[I 2023-03-07 15:29:41,426] Trial 145 pruned. \n","[I 2023-03-07 15:29:41,611] Trial 146 pruned. \n","[I 2023-03-07 15:29:41,776] Trial 147 pruned. \n","[I 2023-03-07 15:29:41,940] Trial 148 pruned. \n","[I 2023-03-07 15:29:42,256] Trial 149 pruned. \n","[I 2023-03-07 15:29:44,283] Trial 150 finished with value: 0.9344 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.02552707198043081, 'momentum': 0.21822009369748346}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:46,320] Trial 151 finished with value: 0.938 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.02241206751482048, 'momentum': 0.19310081138323731}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:48,345] Trial 152 finished with value: 0.9332 and parameters: {'hidden_dim': 45, 'activation_func': 'Sigmoid', 'lr': 0.028721280927322963, 'momentum': 0.2074452498885551}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:50,264] Trial 153 finished with value: 0.9354 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.045248658422657614, 'momentum': 0.18212895144375438}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:51,040] Trial 154 pruned. \n","[I 2023-03-07 15:29:51,210] Trial 155 pruned. \n","[I 2023-03-07 15:29:53,212] Trial 156 finished with value: 0.9333 and parameters: {'hidden_dim': 47, 'activation_func': 'Sigmoid', 'lr': 0.04347013359961821, 'momentum': 0.1522057152515071}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:54,722] Trial 157 finished with value: 0.9358 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.001872093144361404, 'momentum': 0.4490738911134741}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:56,620] Trial 158 finished with value: 0.9374 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.053923388239321246, 'momentum': 0.1434915295048541}. Best is trial 120 with value: 0.9409.\n","[I 2023-03-07 15:29:57,575] Trial 159 pruned. \n","[I 2023-03-07 15:29:58,297] Trial 160 pruned. \n","[I 2023-03-07 15:29:59,846] Trial 161 finished with value: 0.9411 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.0017520403711463787, 'momentum': 0.41306629216797575}. Best is trial 161 with value: 0.9411.\n","[I 2023-03-07 15:30:01,383] Trial 162 finished with value: 0.9438 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.001702729154512423, 'momentum': 0.36225336077343406}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:02,919] Trial 163 finished with value: 0.9378 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.0016252413661639773, 'momentum': 0.3608379379142545}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:04,904] Trial 164 finished with value: 0.9398 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.057826516120119464, 'momentum': 0.24369533564159315}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:05,073] Trial 165 pruned. \n","[I 2023-03-07 15:30:05,364] Trial 166 pruned. \n","[I 2023-03-07 15:30:05,552] Trial 167 pruned. \n","[I 2023-03-07 15:30:07,113] Trial 168 finished with value: 0.9403 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.0011713518177070704, 'momentum': 0.357467341652752}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:07,285] Trial 169 pruned. \n","[I 2023-03-07 15:30:08,018] Trial 170 pruned. \n","[I 2023-03-07 15:30:08,790] Trial 171 pruned. \n","[I 2023-03-07 15:30:09,109] Trial 172 pruned. \n","[I 2023-03-07 15:30:10,630] Trial 173 finished with value: 0.9391 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.001393590907621182, 'momentum': 0.3953375262681068}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:12,135] Trial 174 finished with value: 0.9396 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0015207436250645923, 'momentum': 0.39724289707551325}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:12,508] Trial 175 pruned. \n","[I 2023-03-07 15:30:13,291] Trial 176 pruned. \n","[I 2023-03-07 15:30:15,645] Trial 177 finished with value: 0.9346 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 0.0010023030908451695, 'momentum': 0.6011121061901984}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:30:16,661] Trial 178 pruned. \n"]}],"source":["study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n","study_with_pruner.optimize(objective_with_report, timeout=60) # 60秒で終了"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"QozTRwjY_ok5"},"source":["こうすることで、与えられたリソース（60秒)の元で、見込みのないパラメータが枝刈りされて最大限多くのハイパーパラメータ候補が試されることになります。\n","\n","最適化全体で消費されたリソース量を一定にする方法には、少しトリッキーですが以下のような方法も考えられるでしょう。\n","それは、最適化全体で実行されるステップ数を一定にすることです。"]},{"cell_type":"code","execution_count":286,"metadata":{"id":"RBtgFZYoAev6"},"outputs":[{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 15:31:19,453] Trial 179 pruned. \n","[I 2023-03-07 15:31:21,439] Trial 180 finished with value: 0.9348 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.05112828467102986, 'momentum': 0.2399964197569001}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:22,427] Trial 181 pruned. \n","[I 2023-03-07 15:31:23,973] Trial 182 finished with value: 0.9395 and parameters: {'hidden_dim': 47, 'activation_func': 'ReLU', 'lr': 0.0014896003837425679, 'momentum': 0.35888078687084063}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:25,986] Trial 183 finished with value: 0.9339 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.05184606053411009, 'momentum': 0.23129256591258848}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:27,980] Trial 184 finished with value: 0.9353 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.03741928585482138, 'momentum': 0.1897518300609319}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:28,400] Trial 185 pruned. \n","[I 2023-03-07 15:31:28,571] Trial 186 pruned. \n","[I 2023-03-07 15:31:30,160] Trial 187 finished with value: 0.9373 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0014814511399613129, 'momentum': 0.3558821321754963}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:30,443] Trial 188 pruned. \n","[I 2023-03-07 15:31:30,620] Trial 189 pruned. \n","[I 2023-03-07 15:31:30,795] Trial 190 pruned. \n","[I 2023-03-07 15:31:31,122] Trial 191 pruned. \n","[I 2023-03-07 15:31:32,773] Trial 192 finished with value: 0.9405 and parameters: {'hidden_dim': 47, 'activation_func': 'ReLU', 'lr': 0.002922769832423467, 'momentum': 0.4034474779822839}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:33,810] Trial 193 pruned. \n","[I 2023-03-07 15:31:34,001] Trial 194 pruned. \n","[I 2023-03-07 15:31:35,981] Trial 195 finished with value: 0.9296 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.0010371568214999143, 'momentum': 0.6626577370267006}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:37,995] Trial 196 finished with value: 0.9343 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.0365093738480945, 'momentum': 0.3103946999148622}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:39,980] Trial 197 finished with value: 0.9381 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.04859790717514026, 'momentum': 0.1791479279144983}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:40,387] Trial 198 pruned. \n","[I 2023-03-07 15:31:40,562] Trial 199 pruned. \n","[I 2023-03-07 15:31:41,549] Trial 200 pruned. \n","[I 2023-03-07 15:31:42,620] Trial 201 pruned. \n","[I 2023-03-07 15:31:44,063] Trial 202 finished with value: 0.9352 and parameters: {'hidden_dim': 38, 'activation_func': 'ReLU', 'lr': 0.0003666247499227542, 'momentum': 0.7948835596643637}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:44,389] Trial 203 pruned. \n","[I 2023-03-07 15:31:44,746] Trial 204 pruned. \n","[I 2023-03-07 15:31:46,642] Trial 205 finished with value: 0.9382 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.04964555015272726, 'momentum': 0.24029094812071236}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:48,612] Trial 206 finished with value: 0.935 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.044682802477909116, 'momentum': 0.17564548943276498}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:48,822] Trial 207 pruned. \n","[I 2023-03-07 15:31:49,002] Trial 208 pruned. \n","[I 2023-03-07 15:31:49,191] Trial 209 pruned. \n","[I 2023-03-07 15:31:51,123] Trial 210 finished with value: 0.9337 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.03496631765980724, 'momentum': 0.11137083335665666}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:51,899] Trial 211 pruned. \n","[I 2023-03-07 15:31:52,631] Trial 212 pruned. \n","[I 2023-03-07 15:31:54,510] Trial 213 finished with value: 0.9286 and parameters: {'hidden_dim': 44, 'activation_func': 'Sigmoid', 'lr': 0.09397183159733127, 'momentum': 0.06378637012712879}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:31:54,682] Trial 214 pruned. \n","[I 2023-03-07 15:31:54,862] Trial 215 pruned. \n","[I 2023-03-07 15:31:55,186] Trial 216 pruned. \n","[I 2023-03-07 15:31:56,026] Trial 217 pruned. \n","[I 2023-03-07 15:31:56,202] Trial 218 pruned. \n","[I 2023-03-07 15:31:56,872] Trial 219 pruned. \n","[I 2023-03-07 15:31:57,053] Trial 220 pruned. \n","[I 2023-03-07 15:31:59,296] Trial 221 finished with value: 0.937 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0004197529798477661, 'momentum': 0.7525782442333375}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:00,839] Trial 222 finished with value: 0.9376 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0010098539419530835, 'momentum': 0.39177232171381227}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:03,077] Trial 223 finished with value: 0.9352 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0004971391424187487, 'momentum': 0.7658906578945348}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:03,871] Trial 224 pruned. \n","[I 2023-03-07 15:32:04,654] Trial 225 pruned. \n","[I 2023-03-07 15:32:05,068] Trial 226 pruned. \n","[I 2023-03-07 15:32:05,246] Trial 227 pruned. \n","[I 2023-03-07 15:32:06,225] Trial 228 pruned. \n","[I 2023-03-07 15:32:06,564] Trial 229 pruned. \n","[I 2023-03-07 15:32:08,106] Trial 230 finished with value: 0.9392 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.0014609854042587093, 'momentum': 0.34020025079186167}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:08,437] Trial 231 pruned. \n","[I 2023-03-07 15:32:09,976] Trial 232 finished with value: 0.938 and parameters: {'hidden_dim': 50, 'activation_func': 'ReLU', 'lr': 0.0013809096909395305, 'momentum': 0.3334455095243829}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:12,113] Trial 233 finished with value: 0.934 and parameters: {'hidden_dim': 38, 'activation_func': 'ELU', 'lr': 0.00042097793067814545, 'momentum': 0.7296837118979562}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:12,534] Trial 234 pruned. \n","[I 2023-03-07 15:32:13,328] Trial 235 pruned. \n","[I 2023-03-07 15:32:13,507] Trial 236 pruned. \n","[I 2023-03-07 15:32:13,833] Trial 237 pruned. \n","[I 2023-03-07 15:32:14,984] Trial 238 pruned. \n","[I 2023-03-07 15:32:17,196] Trial 239 finished with value: 0.9408 and parameters: {'hidden_dim': 48, 'activation_func': 'ELU', 'lr': 0.0005320406667705737, 'momentum': 0.7875153141624656}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:19,234] Trial 240 finished with value: 0.9364 and parameters: {'hidden_dim': 47, 'activation_func': 'Sigmoid', 'lr': 0.03348039472826467, 'momentum': 0.17606985414028375}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:20,245] Trial 241 pruned. \n","[I 2023-03-07 15:32:20,564] Trial 242 pruned. \n","[I 2023-03-07 15:32:22,561] Trial 243 finished with value: 0.9323 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.05168349123947648, 'momentum': 0.12873750889690355}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:23,492] Trial 244 pruned. \n","[I 2023-03-07 15:32:24,530] Trial 245 pruned. \n","[I 2023-03-07 15:32:24,871] Trial 246 pruned. \n","[I 2023-03-07 15:32:25,693] Trial 247 pruned. \n","[I 2023-03-07 15:32:25,872] Trial 248 pruned. \n","[I 2023-03-07 15:32:26,660] Trial 249 pruned. \n","[I 2023-03-07 15:32:27,059] Trial 250 pruned. \n","[I 2023-03-07 15:32:27,505] Trial 251 pruned. \n","[I 2023-03-07 15:32:28,273] Trial 252 pruned. \n","[I 2023-03-07 15:32:29,059] Trial 253 pruned. \n","[I 2023-03-07 15:32:31,004] Trial 254 finished with value: 0.9352 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.04362242326201491, 'momentum': 0.23962172813838792}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:31,383] Trial 255 pruned. \n","[I 2023-03-07 15:32:32,395] Trial 256 pruned. \n","[I 2023-03-07 15:32:32,720] Trial 257 pruned. \n","[I 2023-03-07 15:32:33,052] Trial 258 pruned. \n","[I 2023-03-07 15:32:34,072] Trial 259 pruned. \n","[I 2023-03-07 15:32:34,380] Trial 260 pruned. \n","[I 2023-03-07 15:32:34,717] Trial 261 pruned. \n","[I 2023-03-07 15:32:36,729] Trial 262 finished with value: 0.9374 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.047844931221694725, 'momentum': 0.289587863225483}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:37,056] Trial 263 pruned. \n","[I 2023-03-07 15:32:37,235] Trial 264 pruned. \n","[I 2023-03-07 15:32:39,250] Trial 265 finished with value: 0.9374 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.047103820313224534, 'momentum': 0.25085299778098297}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:41,238] Trial 266 finished with value: 0.9375 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.0461276578348161, 'momentum': 0.2866337584493022}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:42,171] Trial 267 pruned. \n","[I 2023-03-07 15:32:42,530] Trial 268 pruned. \n","[I 2023-03-07 15:32:44,808] Trial 269 finished with value: 0.9371 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.05570010097616278, 'momentum': 0.2872223571654197}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:45,867] Trial 270 pruned. \n","[I 2023-03-07 15:32:46,053] Trial 271 pruned. \n","[I 2023-03-07 15:32:46,403] Trial 272 pruned. \n","[I 2023-03-07 15:32:47,387] Trial 273 pruned. \n","[I 2023-03-07 15:32:49,519] Trial 274 finished with value: 0.9437 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.000309218056647452, 'momentum': 0.9324735474422703}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:49,851] Trial 275 pruned. \n","[I 2023-03-07 15:32:50,034] Trial 276 pruned. \n","[I 2023-03-07 15:32:51,037] Trial 277 pruned. \n","[I 2023-03-07 15:32:51,224] Trial 278 pruned. \n","[I 2023-03-07 15:32:52,229] Trial 279 pruned. \n","[I 2023-03-07 15:32:52,558] Trial 280 pruned. \n","[I 2023-03-07 15:32:54,558] Trial 281 finished with value: 0.9325 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.04819916875343511, 'momentum': 0.3241475942621011}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:54,985] Trial 282 pruned. \n","[I 2023-03-07 15:32:55,167] Trial 283 pruned. \n","[I 2023-03-07 15:32:55,538] Trial 284 pruned. \n","[I 2023-03-07 15:32:55,718] Trial 285 pruned. \n","[I 2023-03-07 15:32:57,794] Trial 286 finished with value: 0.9337 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0003148445811587628, 'momentum': 0.8850867978661962}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:32:59,772] Trial 287 finished with value: 0.9341 and parameters: {'hidden_dim': 49, 'activation_func': 'ELU', 'lr': 0.0003810281634213197, 'momentum': 0.9518858777207573}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:33:01,325] Trial 288 finished with value: 0.9387 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0013275655341549214, 'momentum': 0.4622482782099461}. Best is trial 162 with value: 0.9438.\n","[I 2023-03-07 15:33:03,534] Trial 289 finished with value: 0.95 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.00024125728318861143, 'momentum': 0.9285672544771327}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:04,329] Trial 290 pruned. \n","[I 2023-03-07 15:33:04,516] Trial 291 pruned. \n","[I 2023-03-07 15:33:06,506] Trial 292 finished with value: 0.9385 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.03921675674010229, 'momentum': 0.2259844966409564}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:06,659] Trial 293 pruned. \n","[I 2023-03-07 15:33:06,999] Trial 294 pruned. \n","[I 2023-03-07 15:33:08,938] Trial 295 finished with value: 0.9437 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 0.0002528811516974639, 'momentum': 0.9377787933911095}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:10,973] Trial 296 finished with value: 0.9346 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.04020517915258842, 'momentum': 0.22337935831062927}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:12,919] Trial 297 finished with value: 0.9391 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00023017695938816764, 'momentum': 0.9381490587427928}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:13,101] Trial 298 pruned. \n","[I 2023-03-07 15:33:13,888] Trial 299 pruned. \n","[I 2023-03-07 15:33:15,434] Trial 300 finished with value: 0.94 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0019005419604438622, 'momentum': 0.43523690360667905}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:17,586] Trial 301 finished with value: 0.9336 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00010053125694394025, 'momentum': 0.9344963878022605}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:18,612] Trial 302 pruned. \n","[I 2023-03-07 15:33:18,953] Trial 303 pruned. \n","[I 2023-03-07 15:33:19,689] Trial 304 pruned. \n","[I 2023-03-07 15:33:20,377] Trial 305 pruned. \n","[I 2023-03-07 15:33:20,557] Trial 306 pruned. \n","[I 2023-03-07 15:33:21,531] Trial 307 pruned. \n","[I 2023-03-07 15:33:21,726] Trial 308 pruned. \n","[I 2023-03-07 15:33:22,733] Trial 309 pruned. \n","[I 2023-03-07 15:33:23,591] Trial 310 pruned. \n","[I 2023-03-07 15:33:24,021] Trial 311 pruned. \n","[I 2023-03-07 15:33:24,208] Trial 312 pruned. \n","[I 2023-03-07 15:33:24,987] Trial 313 pruned. \n","[I 2023-03-07 15:33:26,009] Trial 314 pruned. \n","[I 2023-03-07 15:33:26,438] Trial 315 pruned. \n","[I 2023-03-07 15:33:28,888] Trial 316 finished with value: 0.9297 and parameters: {'hidden_dim': 44, 'activation_func': 'ELU', 'lr': 0.0007496127766739708, 'momentum': 0.868445703828753}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:29,421] Trial 317 pruned. \n","[I 2023-03-07 15:33:29,795] Trial 318 pruned. \n","[I 2023-03-07 15:33:31,983] Trial 319 finished with value: 0.9428 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00025376988174059155, 'momentum': 0.9074496269787862}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:32,417] Trial 320 pruned. \n","[I 2023-03-07 15:33:32,764] Trial 321 pruned. \n","[I 2023-03-07 15:33:33,216] Trial 322 pruned. \n","[I 2023-03-07 15:33:35,185] Trial 323 finished with value: 0.9367 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 0.030429554294234305, 'momentum': 0.22393820195124767}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:35,729] Trial 324 pruned. \n","[I 2023-03-07 15:33:37,718] Trial 325 finished with value: 0.9361 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 0.000232504769213621, 'momentum': 0.9210155421608217}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:39,919] Trial 326 finished with value: 0.9348 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 0.00015341348517317784, 'momentum': 0.9643701253274449}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:40,877] Trial 327 pruned. \n","[I 2023-03-07 15:33:41,076] Trial 328 pruned. \n","[I 2023-03-07 15:33:41,438] Trial 329 pruned. \n","[I 2023-03-07 15:33:42,502] Trial 330 pruned. \n","[I 2023-03-07 15:33:43,974] Trial 331 finished with value: 0.9408 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.0013479136443596549, 'momentum': 0.38829303374183627}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:45,083] Trial 332 pruned. \n","[I 2023-03-07 15:33:45,588] Trial 333 pruned. \n","[I 2023-03-07 15:33:47,234] Trial 334 finished with value: 0.9379 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0013676378996882318, 'momentum': 0.3861299303397621}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:49,668] Trial 335 finished with value: 0.9302 and parameters: {'hidden_dim': 47, 'activation_func': 'ELU', 'lr': 0.0001240437910432134, 'momentum': 0.9199558548312019}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:51,634] Trial 336 finished with value: 0.931 and parameters: {'hidden_dim': 47, 'activation_func': 'Sigmoid', 'lr': 0.053623102525349485, 'momentum': 0.24701469955107883}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:51,831] Trial 337 pruned. \n","[I 2023-03-07 15:33:52,676] Trial 338 pruned. \n","[I 2023-03-07 15:33:52,862] Trial 339 pruned. \n","[I 2023-03-07 15:33:53,836] Trial 340 pruned. \n","[I 2023-03-07 15:33:54,174] Trial 341 pruned. \n","[I 2023-03-07 15:33:56,237] Trial 342 finished with value: 0.9382 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.038115039510479856, 'momentum': 0.1642973067084968}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:57,882] Trial 343 finished with value: 0.9409 and parameters: {'hidden_dim': 48, 'activation_func': 'ReLU', 'lr': 0.0013901317427196381, 'momentum': 0.3450315079568841}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:33:59,019] Trial 344 pruned. \n","[I 2023-03-07 15:33:59,334] Trial 345 pruned. \n","[I 2023-03-07 15:33:59,511] Trial 346 pruned. \n","[I 2023-03-07 15:34:01,322] Trial 347 finished with value: 0.9331 and parameters: {'hidden_dim': 39, 'activation_func': 'ELU', 'lr': 0.00032499099532322915, 'momentum': 0.9677861721751525}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:02,080] Trial 348 pruned. \n","[I 2023-03-07 15:34:02,258] Trial 349 pruned. \n","[I 2023-03-07 15:34:03,045] Trial 350 pruned. \n","[I 2023-03-07 15:34:03,742] Trial 351 pruned. \n","[I 2023-03-07 15:34:03,922] Trial 352 pruned. \n","[I 2023-03-07 15:34:06,011] Trial 353 finished with value: 0.935 and parameters: {'hidden_dim': 37, 'activation_func': 'ELU', 'lr': 0.00016857984778623298, 'momentum': 0.8939878312118342}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:06,360] Trial 354 pruned. \n","[I 2023-03-07 15:34:06,528] Trial 355 pruned. \n","[I 2023-03-07 15:34:08,545] Trial 356 finished with value: 0.9339 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.0004503818108009094, 'momentum': 0.8320234977646155}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:10,560] Trial 357 finished with value: 0.9385 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.035957313167849975, 'momentum': 0.164423147568772}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:11,512] Trial 358 pruned. \n","[I 2023-03-07 15:34:13,036] Trial 359 finished with value: 0.9435 and parameters: {'hidden_dim': 47, 'activation_func': 'ReLU', 'lr': 0.0018538043506353004, 'momentum': 0.2803562913657287}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:13,459] Trial 360 pruned. \n","[I 2023-03-07 15:34:13,732] Trial 361 pruned. \n","[I 2023-03-07 15:34:14,755] Trial 362 pruned. \n","[I 2023-03-07 15:34:14,937] Trial 363 pruned. \n","[I 2023-03-07 15:34:15,706] Trial 364 pruned. \n","[I 2023-03-07 15:34:16,837] Trial 365 pruned. \n","[I 2023-03-07 15:34:17,262] Trial 366 pruned. \n","[I 2023-03-07 15:34:17,434] Trial 367 pruned. \n","[I 2023-03-07 15:34:17,612] Trial 368 pruned. \n","[I 2023-03-07 15:34:19,640] Trial 369 finished with value: 0.9475 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.000479839593523207, 'momentum': 0.9072510910579278}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:21,159] Trial 370 finished with value: 0.9401 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.001800768775660027, 'momentum': 0.42677912784319416}. Best is trial 289 with value: 0.95.\n","[I 2023-03-07 15:34:23,163] Trial 371 finished with value: 0.9376 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 0.04519349217080829, 'momentum': 0.20062315930454974}. Best is trial 289 with value: 0.95.\n"]}],"source":["study_with_pruner = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n","\n","# 枝刈りせずに学習した場合、100トライアル分のステップ数\n","N_TOTAL_STEPS = 100 * 20\n","\n","def terminate_callback(study, trial):\n","    complete_steps = sum([len(t.intermediate_values) for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE])\n","    if complete_steps >= N_TOTAL_STEPS:\n","        study.stop()\n","\n","study_with_pruner.optimize(objective_with_report, callbacks=[terminate_callback])"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"yUW5GWKlDmxN"},"source":["こうすることで、与えられたリソース（100 * 20ステップ数)の元で、見込みのないパラメータが枝刈りされて最大限多くのハイパーパラメータ候補が試されることになります。\n","\n","さて、それではOptunaで利用可能な**sampler**と**pruner**について簡単に見ていきましょう。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"jteDHdTMt80P"},"source":["Optunaでは、v3.1.0時点で以下のような**sampler**を利用する事ができます。\n","詳細は、各々のドキュメントを参照してください。\n","- [`optuna.samplers.TPESampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.TPESampler.html)\n","  - ベイズ最適化のアルゴリズムの1つである[TPE (Tree-structured Parzen Estimator)](https://papers.nips.cc/paper/4443-algorithms-for-hyper-parameter-optimization.pdf)を実装しているsamplerです。\n","  - TPEはOptunaのデフォルトのsamplerです。\n","- [`optuna.samplers.CmaEsSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.CmaEsSampler.html)\n","  - 進化計算のアルゴリズムの1つである[CMA-ES (Covariance Matrix Adaptation - Evolution Strategy)](https://arxiv.org/abs/1604.00772) を実装しているsamplerです。\n","  - ハイパーパラメータの次元数が多い(10~20程度以上)場合や、trial数が多い(数百~数万程度)場合に強い手法です。\n","- [`optuna.integration.BoTorchSampler`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.integration.BoTorchSampler.html)\n","  - [GP (ガウス過程)](https://bayesoptbook.com/)を用いてベイズ最適化を行っているsamplerです。\n","  - 次元が少なく(~10程度)、trial数が少ない(~数百)場合に強い手法です。計算量がtrial数の3乗に比例するため、数百~千を超えるtrial数で用いることは現実的ではありません。\n","- [`optuna.samplers.NSGAIISampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.NSGAIISampler.html)\n","  - 多目的最適化用の進化計算アルゴリズムの一つである[NSGA-II](https://ieeexplore.ieee.org/document/996017)を実装したsamplerです。\n","- [`optuna.samplers.GridSampler`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.GridSampler.html)\n","  - グリッドサーチを行うsamplerです。\n","- [`optuna.samplers.BruteForceSampler`](https://optuna.readthedocs.io/en/stable/reference/samplers/generated/optuna.samplers.BruteForceSampler.html)\n","  - 探索空間を全探索するsamplerです。`GridSampler`に似てますが、条件分岐を含むような探索空間にも対応しています。\n","- [`optuna.samplers.RandomSampler`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.RandomSampler.html)\n","  - ランダムサーチを行うsamplerです。\n","- [`optuna.samplers.QMCSampler`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.QMCSampler.html)\n","  - [準モンテカルロ法(quasi-Monte Carlo method)](https://scipy.github.io/devdocs/reference/stats.qmc.html)により、ランダムよりも満遍なく探索空間を埋め尽くすハイパーパラメータの列を用いて探索します。\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"ChPSK-QfzLJp"},"source":["また、Optunaでは、v3.1.0時点で以下のような**pruner**を利用する事ができます。\n","- [`optuna.pruners.NopPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.NopPruner.html)\n","  - 何も枝刈りしない、というprunerです。\n","- [`optuna.pruners.PercentilePruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.PercentilePruner.html)\n","  - 各epochにおいて、最適化履歴の 下位$\\alpha$%に入っていれば枝刈りする、というprunerです。\n","- [`optuna.pruners.MedianPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.MedianPruner.html)\n","  - 各epochにおいて、最適化履歴の下位50%に入っていれば枝刈りする、というprunerです。\n","- [`optuna.pruners.SuccessiveHalvingPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.SuccessiveHalvingPruner.html)\n","  - [Successive Halving](https://arxiv.org/abs/1810.05934)という有名な枝刈りアルゴリズムを実装しているprunerです。\n","  なお、Optunaでは実装の都合上、論文とは多少異なるアルゴリズムを実装しています。\n","- [`optuna.pruners.HyperbandPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.HyperbandPruner.html)\n","  - [Hyperband](https://arxiv.org/abs/1603.06560)という最先端の枝刈りアルゴリズムを実装しているprunerです。\n","  なお、Optunaでは実装の都合上、論文とは多少異なるアルゴリズムを実装しています。\n","- [`optuna.pruners.ThresholdPruner`](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.pruners.ThresholdPruner.html)\n","  - 各epochにおいて、与えられた閾値から外れた値の場合に枝刈りする、というprunerです。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"qBQJ6DVq2276"},"source":["以上のsampler, prunerをどういった組み合わせで用いれば良いのかは、タスクごとに異なります。\n","\n","タスクごとに、どういった組み合わせでsamplerとprunerを選択すれば良いのかは難しい問題なので、我々Optuna開発者も多くのベンチマーク実験を行いながら知見を貯めています。\n","そういったベンチマーク実験の結果は[OptunaのWiki](https://github.com/optuna/optuna/wiki/Benchmarks-with-Kurobako)で公開されているので、samplerとprunerを選ぶ際は参考にしてみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"k7IF5WRxTaDt"},"source":["## 5. 可変の個数のハイパーパラメータを探索する\n","\n","上ではかなり単純な二層ニューラルネットワークを使って手書き文字認識を行いましたが、もしかしたらより複雑なモデルを使うともっと精度を上げることができるかもしれません。ここでは中間層の数を可変にして、各層の次元数と活性化関数もOptunaに決めさせることを考えます。\n","\n","調整するパラメタは以下の通りです。\n","- `n_hidden_layers`: 中間層の数。1~3の整数。\n","- 各中間層`i`に関して\n","  - `hidden_dim[i]`: 中間層`i`のサイズ\n","  - `activation_func[i]`: 中間層`i`の活性化関数\n","\n","この問題では、`n_hidden_layers`の値によって、必要なハイパーパラメータの数が変化することに注意してください。\n","このような場合でも、Optunaでは通常のPythonのコードを書くようにして扱うことができます。"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"6aqC4CZt-ELI"},"outputs":[],"source":["def objective_variable_depth(trial):\n","        \n","    # モデルの定義\n","    n_hidden_layers = trial.suggest_int('n_hidden_layers', 1, 5)  # 隠れ層の数\n","    activation_funcs = {\n","        'Sigmoid': nn.Sigmoid(),\n","        'Tanh': nn.Tanh(),\n","        'ReLU': nn.ReLU(),\n","        'ELU': nn.ELU(),\n","    }\n","\n","    model = nn.Sequential()\n","    model.add_module('flatten', nn.Flatten()) # 二次元の画像を一次元に変換\n","    last_dim = 28 * 28 # 最初の入力層の次元数\n","    for i in range(n_hidden_layers):\n","        hidden_dim = trial.suggest_int(f'hidden_dim[{i}]', 10, 50) # 中間層の次元数\n","        activation_func = trial.suggest_categorical(f'activation_func[{i}]', ['Sigmoid', 'Tanh', 'ReLU', 'ELU']) # 中間層の活性化関数\n","        activation = activation_funcs[activation_func]\n","\n","        model.add_module(f'linear[{i}]', nn.Linear(last_dim, hidden_dim)) # 線形変換\n","        model.add_module(f'activation[{i}]', activation) # 活性化関数\n","        last_dim = hidden_dim\n","    \n","    model.add_module(f'linear[{n_hidden_layers}]', nn.Linear(last_dim, 10)) # 出力層の線形変換\n","\n","    # 最適化アルゴリズムの定義\n","    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True) # 学習率\n","    momentum = trial.suggest_float(\"momentum\", 0.5, 1.0) # モーメンタム\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum, nesterov=True)\n","\n","    validation_accuracy = fit_mnist_and_evaluate_with_report(trial, model, optimizer)\n","    return validation_accuracy\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["study_variable_depth = optuna.create_study(\n","    direction=\"maximize\", \n","    sampler=sampler, \n","    pruner=pruner,\n",")\n","study_variable_depth.optimize(objective_variable_depth, n_trials=100)\n","\n","print(f\"最良の精度: {study_variable_depth.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_variable_depth.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["\n","恐らく3~4段くらい中間層を挟むことで、0.96~0.97程度まで性能が上がったのではないでしょうか?\n","\n","このように通常のPythonコードを書くように探索空間が記述できることから、\n","Optunaの探索空間は\"Pythonic search spaces\"であると言われます。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## 6. `Study`の永続化と分散最適化\n","\n","ここまでの例では、`optuna.create_study`で作られたStudyは実体がメモリ上に存在していたため、一つのプロセスからしかアクセスすることができず、またそのプロセスが終了するとStudyは失われてしまっていました。この節では、Optuna v3.1で新たに追加された`JournalStorage`を用いてStudyの実体をファイルに置く方法を紹介し、さらにそれを用いて複数プロセスで分散最適化を行います。\n","\n","Studyの実体をファイルに置くには、`optuna.create_study`に次のような引数を渡します。"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/tt/_c3nrr_56h14ctfrdh94spsh0000gn/T/ipykernel_23884/3279569179.py:3: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","[I 2023-03-07 22:14:06,074] A new study created in Journal with name: distributed_study\n"]}],"source":["distributed_study = optuna.create_study(\n","    direction=\"maximize\",\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これまでとは違い、Studyに名前を与える必要があることに気をつけてください。同じファイルには複数のStudyが入ることが許され、それぞれのStudyはこの名前で区別されます。\n","\n","`load_if_exists=True`と指定することで、既存のStudyと同じ名前が指定された場合に、新たにStudyが作られる代わりにそのStudyの実体と結びついたオブジェクトが返されます。例えばもう一度"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/tt/_c3nrr_56h14ctfrdh94spsh0000gn/T/ipykernel_23884/3431290950.py:3: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","[I 2023-03-07 22:14:09,030] Using an existing study with name 'distributed_study' instead of creating a new one.\n"]}],"source":["distributed_study2 = optuna.create_study(\n","    direction=\"maximize\",\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["と実行すると、`distributed_study`と`distributed_study2`は同じ実体を指し示すことになります。その証に、例えば"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss=1.595, validation_accuracy=0.7567\n","Epoch 2: train_loss=1.023, validation_accuracy=0.8402\n","Epoch 3: train_loss=0.810, validation_accuracy=0.8652\n","Epoch 4: train_loss=0.689, validation_accuracy=0.8786\n","Epoch 5: train_loss=0.606, validation_accuracy=0.8869\n","Epoch 6: train_loss=0.548, validation_accuracy=0.8936\n","Epoch 7: train_loss=0.504, validation_accuracy=0.8961\n","Epoch 8: train_loss=0.471, validation_accuracy=0.9024\n","Epoch 9: train_loss=0.445, validation_accuracy=0.9000\n","Epoch 10: train_loss=0.422, validation_accuracy=0.9028\n","Epoch 11: train_loss=0.403, validation_accuracy=0.9066\n","Epoch 12: train_loss=0.387, validation_accuracy=0.9071\n","Epoch 13: train_loss=0.373, validation_accuracy=0.9098\n","Epoch 14: train_loss=0.360, validation_accuracy=0.9109\n","Epoch 15: train_loss=0.348, validation_accuracy=0.9131\n","Epoch 16: train_loss=0.339, validation_accuracy=0.9159\n","Epoch 17: train_loss=0.332, validation_accuracy=0.9147\n","Epoch 18: train_loss=0.322, validation_accuracy=0.9153\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 22:14:14,150] Trial 0 finished with value: 0.9204 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 41, 'activation_func[0]': 'Tanh', 'lr': 0.0009931286379507753, 'momentum': 0.8042976513825069}. Best is trial 0 with value: 0.9204.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.318, validation_accuracy=0.9163\n","Epoch 20: train_loss=0.310, validation_accuracy=0.9204\n"]},{"ename":"NameError","evalue":"name 'study_variable_depth' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mセル59 を /Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m distributed_study\u001b[39m.\u001b[39moptimize(objective_variable_depth, n_trials\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y112sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m最良の精度: \u001b[39m\u001b[39m{\u001b[39;00mstudy_variable_depth\u001b[39m.\u001b[39mbest_value\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y112sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m最良のハイパーパラメータ: \u001b[39m\u001b[39m{\u001b[39;00mstudy_variable_depth\u001b[39m.\u001b[39mbest_params\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'study_variable_depth' is not defined"]}],"source":["distributed_study.optimize(objective_variable_depth, n_trials=1)\n","print(f\"distributed_study.best_value = {distributed_study.best_value}\")\n","print(f\"distributed_study.best_params = {distributed_study.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["を実行した後、`distributed_study2`でも"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["distributed_study2.best_value = 0.9204\n","distributed_study2.best_params = {'n_hidden_layers': 1, 'hidden_dim[0]': 41, 'activation_func[0]': 'Tanh', 'lr': 0.0009931286379507753, 'momentum': 0.8042976513825069}\n"]}],"source":["print(f\"distributed_study2.best_value = {distributed_study2.best_value}\")\n","print(f\"distributed_study2.best_params = {distributed_study2.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["とすると、同じ値が表示されます。\n","\n","これを用いて、分散最適化をしてみましょう。次のPythonスクリプトをダウンロードします。"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-03-07 22:57:25--  https://raw.githubusercontent.com/pfnet-research/optuna-hands-on/master/ja/optuna_mnist_distributed_example.py\n","raw.githubusercontent.com (raw.githubusercontent.com) をDNSに問いあわせています... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443 に接続しています... 接続しました。\n","HTTP による接続要求を送信しました、応答を待っています... 404 Not Found\n","2023-03-07 22:57:25 エラー 404: Not Found。\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/pfnet-research/optuna-hands-on/master/ja/optuna_mnist_distributed_example.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["このスクリプトには、これまで書いたものと同じ`objective_variable_depth`の定義と、\n","```python\n","study_variable_depth = optuna.create_study(\n","    direction=\"maximize\", \n","    sampler=optuna.samplers.TPESampler(multivariate=True, constant_liar=True), \n","    pruner=optuna.pruners.HyperbandPruner(),\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","    study_name=\"distributed_study\", # Study名を指定。既存のStudy名と同一のものを指定することで、同じStudyを参照できる。\n","    load_if_exists=True)\n","study_variable_depth.optimize(objective_variable_depth, n_trials=25)\n","```\n","の2行が書かれています。`TPESampler`の`constant_liar`は分散最適化をするときに他のプロセスで実行中のハイパーパラメータと似たようなハイパーパラメータを提案してしまうことを防いで探索性能を上げるオプションです。(分散最適化をしないときは全く影響がありません。)\n","\n","分散最適化をするには、単にこのスクリプトを複数同時に走らせれば良いのです。(途中まで最適化を回した後、もう一度最初から実行させたい時は、`./mnist_study.optuna`を消してからもう一度コマンドを実行してください。)"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["/Users/yunzhuowang/local-python-modules/optuna/samplers/_tpe/sampler.py:297: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.\n","  warnings.warn(\n","/Users/yunzhuowang/optuna-hands-on/ja/optuna_mnist_distributed_example.py:103: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","\u001b[32m[I 2023-03-07 23:17:58,186]\u001b[0m A new study created in Journal with name: distributed_study\u001b[0m\n","/Users/yunzhuowang/local-python-modules/optuna/samplers/_tpe/sampler.py:297: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.\n","  warnings.warn(\n","/Users/yunzhuowang/optuna-hands-on/ja/optuna_mnist_distributed_example.py:103: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","/Users/yunzhuowang/local-python-modules/optuna/samplers/_tpe/sampler.py:297: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.\n","  warnings.warn(\n","/Users/yunzhuowang/optuna-hands-on/ja/optuna_mnist_distributed_example.py:103: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","\u001b[32m[I 2023-03-07 23:17:58,332]\u001b[0m Using an existing study with name 'distributed_study' instead of creating a new one.\u001b[0m\n","\u001b[32m[I 2023-03-07 23:17:58,351]\u001b[0m Using an existing study with name 'distributed_study' instead of creating a new one.\u001b[0m\n","/Users/yunzhuowang/local-python-modules/optuna/samplers/_tpe/sampler.py:297: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.\n","  warnings.warn(\n","/Users/yunzhuowang/optuna-hands-on/ja/optuna_mnist_distributed_example.py:103: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),  # 保存するファイルパスを指定\n","\u001b[32m[I 2023-03-07 23:17:58,389]\u001b[0m Using an existing study with name 'distributed_study' instead of creating a new one.\u001b[0m\n","Epoch 1: train_loss=2.544, validation_accuracy=0.2201\n","Epoch 2: train_loss=1.986, validation_accuracy=0.2720\n","Epoch 1: train_loss=2.312, validation_accuracy=0.0893\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1228\n","Epoch 1: train_loss=2.324, validation_accuracy=0.1032\n","Epoch 3: train_loss=1.906, validation_accuracy=0.2840\n","Epoch 4: train_loss=1.873, validation_accuracy=0.2870\n","Epoch 2: train_loss=2.312, validation_accuracy=0.0893\n","Epoch 2: train_loss=2.301, validation_accuracy=0.1339\n","Epoch 5: train_loss=1.856, validation_accuracy=0.2897\n","Epoch 2: train_loss=2.323, validation_accuracy=0.1032\n","Epoch 6: train_loss=1.844, validation_accuracy=0.2926\n","Epoch 3: train_loss=2.311, validation_accuracy=0.0894\n","Epoch 3: train_loss=2.297, validation_accuracy=0.1475\n","Epoch 7: train_loss=1.836, validation_accuracy=0.2918\n","Epoch 3: train_loss=2.323, validation_accuracy=0.1032\n","Epoch 8: train_loss=1.830, validation_accuracy=0.2930\n","Epoch 4: train_loss=2.311, validation_accuracy=0.0895\n","Epoch 9: train_loss=1.823, validation_accuracy=0.2923\n","Epoch 4: train_loss=2.292, validation_accuracy=0.1586\n","Epoch 10: train_loss=1.818, validation_accuracy=0.2943\n","Epoch 4: train_loss=2.322, validation_accuracy=0.1032\n","Epoch 5: train_loss=2.310, validation_accuracy=0.0893\n","Epoch 11: train_loss=1.813, validation_accuracy=0.2950\n","Epoch 5: train_loss=2.288, validation_accuracy=0.1719\n","Epoch 12: train_loss=1.808, validation_accuracy=0.2933\n","Epoch 13: train_loss=1.804, validation_accuracy=0.2938\n","Epoch 6: train_loss=2.310, validation_accuracy=0.0898\n","Epoch 5: train_loss=2.322, validation_accuracy=0.1032\n","Epoch 6: train_loss=2.283, validation_accuracy=0.1830\n","Epoch 14: train_loss=1.799, validation_accuracy=0.2954\n","Epoch 15: train_loss=1.796, validation_accuracy=0.2949\n","Epoch 7: train_loss=2.309, validation_accuracy=0.0903\n","Epoch 7: train_loss=2.279, validation_accuracy=0.1967\n","Epoch 16: train_loss=1.793, validation_accuracy=0.2952\n","Epoch 6: train_loss=2.322, validation_accuracy=0.1032\n","Epoch 17: train_loss=1.789, validation_accuracy=0.2953\n","Epoch 8: train_loss=2.309, validation_accuracy=0.0907\n","Epoch 18: train_loss=1.786, validation_accuracy=0.2961\n","Epoch 8: train_loss=2.275, validation_accuracy=0.2074\n","Epoch 7: train_loss=2.321, validation_accuracy=0.1032\n","Epoch 19: train_loss=1.783, validation_accuracy=0.2962\n","Epoch 9: train_loss=2.308, validation_accuracy=0.0909\n","Epoch 20: train_loss=1.780, validation_accuracy=0.2954\n","\u001b[32m[I 2023-03-07 23:18:02,128]\u001b[0m Trial 1 finished with value: 0.2954 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 11, 'activation_func[0]': 'ReLU', 'lr': 0.00010454441774068992, 'momentum': 0.912987017550458}. Best is trial 1 with value: 0.2954.\u001b[0m\n","Epoch 9: train_loss=2.271, validation_accuracy=0.2185\n","Epoch 1: train_loss=1.259, validation_accuracy=0.8356\n","Epoch 8: train_loss=2.321, validation_accuracy=0.1032\n","Epoch 10: train_loss=2.308, validation_accuracy=0.0907\n","Epoch 10: train_loss=2.267, validation_accuracy=0.2286\n","Epoch 2: train_loss=0.542, validation_accuracy=0.8388\n","Epoch 9: train_loss=2.320, validation_accuracy=0.1032\n","Epoch 3: train_loss=0.540, validation_accuracy=0.8366\n","Epoch 11: train_loss=2.307, validation_accuracy=0.0904\n","Epoch 11: train_loss=2.263, validation_accuracy=0.2404\n","Epoch 4: train_loss=0.539, validation_accuracy=0.8270\n","Epoch 10: train_loss=2.320, validation_accuracy=0.1032\n","Epoch 12: train_loss=2.307, validation_accuracy=0.0900\n","Epoch 5: train_loss=0.559, validation_accuracy=0.8440\n","Epoch 12: train_loss=2.259, validation_accuracy=0.2532\n","Epoch 6: train_loss=0.532, validation_accuracy=0.8296\n","Epoch 13: train_loss=2.306, validation_accuracy=0.0901\n","Epoch 11: train_loss=2.320, validation_accuracy=0.1032\n","Epoch 13: train_loss=2.255, validation_accuracy=0.2667\n","Epoch 7: train_loss=0.525, validation_accuracy=0.8548\n","Epoch 8: train_loss=0.495, validation_accuracy=0.8531\n","Epoch 14: train_loss=2.306, validation_accuracy=0.0904\n","Epoch 14: train_loss=2.252, validation_accuracy=0.2789\n","Epoch 12: train_loss=2.319, validation_accuracy=0.1032\n","Epoch 9: train_loss=0.539, validation_accuracy=0.8487\n","Epoch 15: train_loss=2.305, validation_accuracy=0.0907\n","Epoch 10: train_loss=0.459, validation_accuracy=0.8696\n","Epoch 15: train_loss=2.248, validation_accuracy=0.2915\n","Epoch 13: train_loss=2.319, validation_accuracy=0.1032\n","Epoch 11: train_loss=0.431, validation_accuracy=0.8538\n","Epoch 16: train_loss=2.305, validation_accuracy=0.0910\n","Epoch 16: train_loss=2.244, validation_accuracy=0.3032\n","Epoch 12: train_loss=0.466, validation_accuracy=0.8661\n","Epoch 14: train_loss=2.319, validation_accuracy=0.1032\n","Epoch 13: train_loss=0.434, validation_accuracy=0.8708\n","Epoch 17: train_loss=2.305, validation_accuracy=0.0912\n","Epoch 17: train_loss=2.241, validation_accuracy=0.3197\n","Epoch 14: train_loss=0.422, validation_accuracy=0.8713\n","Epoch 15: train_loss=2.318, validation_accuracy=0.1032\n","Epoch 18: train_loss=2.304, validation_accuracy=0.0918\n","Epoch 15: train_loss=0.431, validation_accuracy=0.8611\n","Epoch 18: train_loss=2.237, validation_accuracy=0.3342\n","Epoch 16: train_loss=0.453, validation_accuracy=0.8636\n","Epoch 16: train_loss=2.318, validation_accuracy=0.1032\n","Epoch 19: train_loss=2.304, validation_accuracy=0.0926\n","Epoch 19: train_loss=2.233, validation_accuracy=0.3475\n","Epoch 17: train_loss=0.422, validation_accuracy=0.8656\n","Epoch 18: train_loss=0.431, validation_accuracy=0.8617\n","Epoch 20: train_loss=2.303, validation_accuracy=0.0933\n","\u001b[32m[I 2023-03-07 23:18:06,225]\u001b[0m Trial 0 finished with value: 0.0933 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 23, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 31, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 49, 'activation_func[2]': 'Tanh', 'hidden_dim[3]': 26, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ELU', 'lr': 7.939600098846221e-05, 'momentum': 0.5877579268965469}. Best is trial 1 with value: 0.2954.\u001b[0m\n","Epoch 17: train_loss=2.318, validation_accuracy=0.1032\n","Epoch 20: train_loss=2.229, validation_accuracy=0.3635\n","\u001b[32m[I 2023-03-07 23:18:06,289]\u001b[0m Trial 3 finished with value: 0.3635 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 43, 'activation_func[0]': 'Sigmoid', 'hidden_dim[1]': 33, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 48, 'activation_func[2]': 'Tanh', 'lr': 8.619290335216663e-05, 'momentum': 0.6937027700202705}. Best is trial 3 with value: 0.3635.\u001b[0m\n","Epoch 19: train_loss=0.451, validation_accuracy=0.8617\n","Epoch 1: train_loss=2.372, validation_accuracy=0.1192\n","Epoch 20: train_loss=0.423, validation_accuracy=0.8787\n","Epoch 1: train_loss=2.067, validation_accuracy=0.6546\n","\u001b[32m[I 2023-03-07 23:18:06,651]\u001b[0m Trial 4 finished with value: 0.8787 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 41, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'lr': 0.005444167910312001, 'momentum': 0.9604446755272815}. Best is trial 4 with value: 0.8787.\u001b[0m\n","Epoch 18: train_loss=2.317, validation_accuracy=0.1032\n","Epoch 2: train_loss=2.356, validation_accuracy=0.1262\n","\u001b[32m[I 2023-03-07 23:18:06,792]\u001b[0m Trial 6 pruned. \u001b[0m\n","Epoch 1: train_loss=1.841, validation_accuracy=0.7525\n","Epoch 2: train_loss=1.479, validation_accuracy=0.8118\n","Epoch 2: train_loss=1.192, validation_accuracy=0.8682\n","Epoch 1: train_loss=2.192, validation_accuracy=0.5177\n","Epoch 19: train_loss=2.317, validation_accuracy=0.1032\n","Epoch 3: train_loss=1.271, validation_accuracy=0.8374\n","Epoch 2: train_loss=2.023, validation_accuracy=0.6145\n","Epoch 4: train_loss=1.113, validation_accuracy=0.8544\n","Epoch 3: train_loss=0.565, validation_accuracy=0.9078\n","Epoch 5: train_loss=0.990, validation_accuracy=0.8640\n","Epoch 20: train_loss=2.317, validation_accuracy=0.1032\n","\u001b[32m[I 2023-03-07 23:18:07,524]\u001b[0m Trial 2 finished with value: 0.1032 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 48, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 30, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 42, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'Sigmoid', 'hidden_dim[4]': 37, 'activation_func[4]': 'Tanh', 'lr': 5.2868551054559015e-05, 'momentum': 0.5037191165880734}. Best is trial 4 with value: 0.8787.\u001b[0m\n","Epoch 3: train_loss=1.906, validation_accuracy=0.6433\n","Epoch 6: train_loss=0.894, validation_accuracy=0.8694\n","Epoch 1: train_loss=1.633, validation_accuracy=0.7749\n","Epoch 4: train_loss=1.800, validation_accuracy=0.6732\n","Epoch 7: train_loss=0.816, validation_accuracy=0.8738\n","Epoch 4: train_loss=0.345, validation_accuracy=0.9266\n","Epoch 2: train_loss=1.101, validation_accuracy=0.8492\n","Epoch 8: train_loss=0.755, validation_accuracy=0.8817\n","\u001b[32m[I 2023-03-07 23:18:08,124]\u001b[0m Trial 9 pruned. \u001b[0m\n","Epoch 5: train_loss=1.699, validation_accuracy=0.7003\n","Epoch 9: train_loss=0.705, validation_accuracy=0.8782\n","Epoch 1: train_loss=2.340, validation_accuracy=0.0876\n","Epoch 5: train_loss=0.272, validation_accuracy=0.9341\n","Epoch 6: train_loss=1.601, validation_accuracy=0.7302\n","Epoch 10: train_loss=0.665, validation_accuracy=0.8848\n","Epoch 2: train_loss=2.325, validation_accuracy=0.0968\n","\u001b[32m[I 2023-03-07 23:18:08,604]\u001b[0m Trial 10 pruned. \u001b[0m\n","Epoch 11: train_loss=0.629, validation_accuracy=0.8809\n","Epoch 7: train_loss=1.507, validation_accuracy=0.7605\n","Epoch 6: train_loss=0.228, validation_accuracy=0.9446\n","Epoch 12: train_loss=0.599, validation_accuracy=0.8890\n","Epoch 1: train_loss=2.233, validation_accuracy=0.2846\n","Epoch 13: train_loss=0.573, validation_accuracy=0.8896\n","Epoch 8: train_loss=1.416, validation_accuracy=0.7860\n","Epoch 2: train_loss=2.092, validation_accuracy=0.4423\n","Epoch 14: train_loss=0.552, validation_accuracy=0.8864\n","Epoch 7: train_loss=0.198, validation_accuracy=0.9478\n","Epoch 9: train_loss=1.330, validation_accuracy=0.8097\n","Epoch 3: train_loss=1.985, validation_accuracy=0.5253\n","Epoch 15: train_loss=0.533, validation_accuracy=0.8953\n","Epoch 16: train_loss=0.517, validation_accuracy=0.8965\n","Epoch 10: train_loss=1.246, validation_accuracy=0.8237\n","\u001b[32m[I 2023-03-07 23:18:09,599]\u001b[0m Trial 8 pruned. \u001b[0m\n","Epoch 4: train_loss=1.893, validation_accuracy=0.5825\n","Epoch 8: train_loss=0.179, validation_accuracy=0.9471\n","Epoch 17: train_loss=0.501, validation_accuracy=0.8956\n","Epoch 5: train_loss=1.813, validation_accuracy=0.6199\n","Epoch 1: train_loss=2.159, validation_accuracy=0.5679\n","Epoch 18: train_loss=0.490, validation_accuracy=0.8969\n","Epoch 9: train_loss=0.164, validation_accuracy=0.9451\n","Epoch 19: train_loss=0.475, validation_accuracy=0.8938\n","Epoch 6: train_loss=1.743, validation_accuracy=0.6538\n","Epoch 2: train_loss=1.798, validation_accuracy=0.7460\n","\u001b[32m[I 2023-03-07 23:18:10,256]\u001b[0m Trial 12 pruned. \u001b[0m\n","Epoch 20: train_loss=0.465, validation_accuracy=0.8992\n","\u001b[32m[I 2023-03-07 23:18:10,323]\u001b[0m Trial 7 finished with value: 0.8992 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 16, 'activation_func[0]': 'Sigmoid', 'lr': 0.007478165655202236, 'momentum': 0.60624779548193}. Best is trial 7 with value: 0.8992.\u001b[0m\n","Epoch 7: train_loss=1.678, validation_accuracy=0.6799\n","Epoch 10: train_loss=0.155, validation_accuracy=0.9527\n","Epoch 1: train_loss=1.740, validation_accuracy=0.8031\n","Epoch 8: train_loss=1.619, validation_accuracy=0.6982\n","Epoch 1: train_loss=2.239, validation_accuracy=0.2881\n","Epoch 2: train_loss=0.694, validation_accuracy=0.8791\n","Epoch 9: train_loss=1.562, validation_accuracy=0.7124\n","Epoch 11: train_loss=0.144, validation_accuracy=0.9539\n","Epoch 2: train_loss=1.839, validation_accuracy=0.4219\n","\u001b[32m[I 2023-03-07 23:18:11,072]\u001b[0m Trial 14 pruned. \u001b[0m\n","Epoch 3: train_loss=0.467, validation_accuracy=0.8876\n","Epoch 10: train_loss=1.508, validation_accuracy=0.7244\n","Epoch 11: train_loss=1.458, validation_accuracy=0.7356\n","Epoch 4: train_loss=0.406, validation_accuracy=0.9010\n","Epoch 12: train_loss=0.131, validation_accuracy=0.9552\n","Epoch 1: train_loss=2.262, validation_accuracy=0.2881\n","Epoch 12: train_loss=1.410, validation_accuracy=0.7442\n","Epoch 5: train_loss=0.360, validation_accuracy=0.9024\n","Epoch 2: train_loss=2.167, validation_accuracy=0.4539\n","Epoch 13: train_loss=1.364, validation_accuracy=0.7512\n","Epoch 13: train_loss=0.123, validation_accuracy=0.9572\n","Epoch 6: train_loss=0.355, validation_accuracy=0.8995\n","Epoch 14: train_loss=1.321, validation_accuracy=0.7620\n","Epoch 3: train_loss=2.061, validation_accuracy=0.5416\n","Epoch 7: train_loss=0.343, validation_accuracy=0.9077\n","Epoch 14: train_loss=0.118, validation_accuracy=0.9604\n","Epoch 15: train_loss=1.280, validation_accuracy=0.7746\n","Epoch 4: train_loss=1.939, validation_accuracy=0.5829\n","Epoch 8: train_loss=0.343, validation_accuracy=0.9121\n","Epoch 16: train_loss=1.241, validation_accuracy=0.7840\n","Epoch 15: train_loss=0.111, validation_accuracy=0.9543\n","Epoch 9: train_loss=0.319, validation_accuracy=0.9060\n","Epoch 17: train_loss=1.203, validation_accuracy=0.7920\n","Epoch 5: train_loss=1.803, validation_accuracy=0.6314\n","Epoch 18: train_loss=1.167, validation_accuracy=0.8006\n","Epoch 10: train_loss=0.310, validation_accuracy=0.9146\n","Epoch 16: train_loss=0.106, validation_accuracy=0.9564\n","Epoch 6: train_loss=1.657, validation_accuracy=0.6797\n","Epoch 19: train_loss=1.132, validation_accuracy=0.8076\n","Epoch 11: train_loss=0.298, validation_accuracy=0.9140\n","Epoch 17: train_loss=0.102, validation_accuracy=0.9574\n","Epoch 7: train_loss=1.505, validation_accuracy=0.7425\n","Epoch 20: train_loss=1.100, validation_accuracy=0.8120\n","\u001b[32m[I 2023-03-07 23:18:13,575]\u001b[0m Trial 11 finished with value: 0.812 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 35, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 32, 'activation_func[1]': 'Tanh', 'lr': 0.0001981546771480927, 'momentum': 0.8373281786324531}. Best is trial 7 with value: 0.8992.\u001b[0m\n","Epoch 12: train_loss=0.294, validation_accuracy=0.9182\n","Epoch 1: train_loss=2.315, validation_accuracy=0.0673\n","Epoch 13: train_loss=0.287, validation_accuracy=0.9181\n","Epoch 18: train_loss=0.097, validation_accuracy=0.9580\n","Epoch 8: train_loss=1.351, validation_accuracy=0.7821\n","Epoch 2: train_loss=2.293, validation_accuracy=0.0921\n","\u001b[32m[I 2023-03-07 23:18:14,131]\u001b[0m Trial 16 pruned. \u001b[0m\n","Epoch 14: train_loss=0.282, validation_accuracy=0.9159\n","Epoch 9: train_loss=1.200, validation_accuracy=0.8230\n","Epoch 19: train_loss=0.090, validation_accuracy=0.9590\n","Epoch 15: train_loss=0.284, validation_accuracy=0.9185\n","Epoch 1: train_loss=2.259, validation_accuracy=0.2512\n","Epoch 10: train_loss=1.058, validation_accuracy=0.8513\n","\u001b[32m[I 2023-03-07 23:18:14,654]\u001b[0m Trial 15 pruned. \u001b[0m\n","Epoch 16: train_loss=0.277, validation_accuracy=0.9195\n","Epoch 20: train_loss=0.088, validation_accuracy=0.9590\n","\u001b[32m[I 2023-03-07 23:18:14,767]\u001b[0m Trial 5 finished with value: 0.959 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 39, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'Tanh', 'hidden_dim[3]': 23, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 23, 'activation_func[4]': 'ReLU', 'lr': 0.008478843619149027, 'momentum': 0.6698827800812975}. Best is trial 5 with value: 0.959.\u001b[0m\n","Epoch 2: train_loss=2.112, validation_accuracy=0.4428\n","\u001b[32m[I 2023-03-07 23:18:14,841]\u001b[0m Trial 17 pruned. \u001b[0m\n","Epoch 1: train_loss=2.164, validation_accuracy=0.4539\n","Epoch 17: train_loss=0.260, validation_accuracy=0.9258\n","Epoch 1: train_loss=2.251, validation_accuracy=0.2167\n","Epoch 2: train_loss=1.922, validation_accuracy=0.5684\n","\u001b[32m[I 2023-03-07 23:18:15,245]\u001b[0m Trial 18 pruned. \u001b[0m\n","Epoch 1: train_loss=2.308, validation_accuracy=0.1032\n","Epoch 18: train_loss=0.252, validation_accuracy=0.9259\n","Epoch 1: train_loss=1.844, validation_accuracy=0.6825\n","Epoch 2: train_loss=2.113, validation_accuracy=0.2953\n","\u001b[32m[I 2023-03-07 23:18:15,440]\u001b[0m Trial 19 pruned. \u001b[0m\n","Epoch 19: train_loss=0.245, validation_accuracy=0.9254\n","Epoch 2: train_loss=1.541, validation_accuracy=0.7711\n","Epoch 2: train_loss=2.283, validation_accuracy=0.1715\n","\u001b[32m[I 2023-03-07 23:18:15,612]\u001b[0m Trial 20 pruned. \u001b[0m\n","Epoch 1: train_loss=1.904, validation_accuracy=0.6999\n","Epoch 3: train_loss=1.349, validation_accuracy=0.8186\n","Epoch 20: train_loss=0.250, validation_accuracy=0.9256\n","\u001b[32m[I 2023-03-07 23:18:15,859]\u001b[0m Trial 13 finished with value: 0.9256 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 39, 'activation_func[0]': 'Sigmoid', 'hidden_dim[1]': 40, 'activation_func[1]': 'Tanh', 'lr': 0.0032435154932163404, 'momentum': 0.9657403065806035}. Best is trial 5 with value: 0.959.\u001b[0m\n","Epoch 4: train_loss=1.197, validation_accuracy=0.8398\n","\u001b[32m[I 2023-03-07 23:18:15,974]\u001b[0m Trial 21 pruned. \u001b[0m\n","Epoch 2: train_loss=1.523, validation_accuracy=0.7829\n","Epoch 1: train_loss=1.088, validation_accuracy=0.8247\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1141\n","Epoch 3: train_loss=1.297, validation_accuracy=0.8371\n","Epoch 1: train_loss=1.265, validation_accuracy=0.8560\n","Epoch 2: train_loss=0.434, validation_accuracy=0.8959\n","Epoch 2: train_loss=2.284, validation_accuracy=0.1493\n","Epoch 4: train_loss=1.133, validation_accuracy=0.8574\n","\u001b[32m[I 2023-03-07 23:18:16,520]\u001b[0m Trial 22 pruned. \u001b[0m\n","Epoch 2: train_loss=0.453, validation_accuracy=0.8978\n","Epoch 3: train_loss=2.263, validation_accuracy=0.2061\n","Epoch 3: train_loss=0.324, validation_accuracy=0.9118\n","Epoch 1: train_loss=1.755, validation_accuracy=0.7995\n","Epoch 3: train_loss=0.350, validation_accuracy=0.9091\n","Epoch 4: train_loss=2.240, validation_accuracy=0.2321\n","\u001b[32m[I 2023-03-07 23:18:16,903]\u001b[0m Trial 24 pruned. \u001b[0m\n","Epoch 2: train_loss=1.351, validation_accuracy=0.8332\n","Epoch 4: train_loss=0.277, validation_accuracy=0.9241\n","Epoch 3: train_loss=1.132, validation_accuracy=0.8547\n","Epoch 4: train_loss=0.309, validation_accuracy=0.9163\n","\u001b[32m[I 2023-03-07 23:18:17,195]\u001b[0m Trial 25 pruned. \u001b[0m\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1236\n","Epoch 4: train_loss=0.975, validation_accuracy=0.8682\n","\u001b[32m[I 2023-03-07 23:18:17,349]\u001b[0m Trial 26 pruned. \u001b[0m\n","Epoch 5: train_loss=0.243, validation_accuracy=0.9315\n","Epoch 1: train_loss=2.030, validation_accuracy=0.8052\n","Epoch 2: train_loss=2.300, validation_accuracy=0.1465\n","\u001b[32m[I 2023-03-07 23:18:17,653]\u001b[0m Trial 27 pruned. \u001b[0m\n","Epoch 6: train_loss=0.222, validation_accuracy=0.9375\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.681, validation_accuracy=0.8519\n","Epoch 1: train_loss=0.959, validation_accuracy=0.8598\n","Epoch 7: train_loss=0.204, validation_accuracy=0.9349\n","Epoch 2: train_loss=2.300, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:18:18,168]\u001b[0m Trial 29 pruned. \u001b[0m\n","Epoch 3: train_loss=0.536, validation_accuracy=0.8689\n","Epoch 2: train_loss=0.404, validation_accuracy=0.8985\n","Epoch 8: train_loss=0.189, validation_accuracy=0.9443\n","Epoch 4: train_loss=0.460, validation_accuracy=0.8807\n","\u001b[32m[I 2023-03-07 23:18:18,525]\u001b[0m Trial 28 pruned. \u001b[0m\n","Epoch 1: train_loss=2.303, validation_accuracy=0.1135\n","Epoch 3: train_loss=0.320, validation_accuracy=0.9125\n","Epoch 1: train_loss=3.517, validation_accuracy=0.2383\n","Epoch 9: train_loss=0.177, validation_accuracy=0.9467\n","Epoch 2: train_loss=2.055, validation_accuracy=0.3211\n","Epoch 4: train_loss=0.277, validation_accuracy=0.9213\n","Epoch 2: train_loss=2.300, validation_accuracy=0.1135\n","Epoch 3: train_loss=1.906, validation_accuracy=0.3678\n","Epoch 10: train_loss=0.167, validation_accuracy=0.9463\n","\u001b[32m[I 2023-03-07 23:18:19,141]\u001b[0m Trial 23 pruned. \u001b[0m\n","Epoch 5: train_loss=0.248, validation_accuracy=0.9278\n","Epoch 4: train_loss=1.808, validation_accuracy=0.4015\n","\u001b[32m[I 2023-03-07 23:18:19,301]\u001b[0m Trial 32 pruned. \u001b[0m\n","Epoch 3: train_loss=2.298, validation_accuracy=0.1135\n","Epoch 1: train_loss=2.171, validation_accuracy=0.3804\n","Epoch 6: train_loss=0.228, validation_accuracy=0.9314\n","Epoch 1: train_loss=2.367, validation_accuracy=0.1010\n","Epoch 2: train_loss=1.971, validation_accuracy=0.4760\n","Epoch 4: train_loss=2.296, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:18:19,827]\u001b[0m Trial 31 pruned. \u001b[0m\n","Epoch 7: train_loss=0.213, validation_accuracy=0.9358\n","Epoch 2: train_loss=2.350, validation_accuracy=0.1010\n","Epoch 1: train_loss=1.642, validation_accuracy=0.7329\n","Epoch 3: train_loss=1.826, validation_accuracy=0.5449\n","Epoch 8: train_loss=0.200, validation_accuracy=0.9401\n","Epoch 2: train_loss=0.901, validation_accuracy=0.8289\n","Epoch 3: train_loss=2.337, validation_accuracy=0.1010\n","Epoch 4: train_loss=1.695, validation_accuracy=0.5854\n","\u001b[32m[I 2023-03-07 23:18:20,373]\u001b[0m Trial 33 pruned. \u001b[0m\n","Epoch 9: train_loss=0.190, validation_accuracy=0.9441\n","Epoch 3: train_loss=0.632, validation_accuracy=0.8639\n","Epoch 1: train_loss=8.292, validation_accuracy=0.2002\n","Epoch 10: train_loss=0.180, validation_accuracy=0.9443\n","\u001b[32m[I 2023-03-07 23:18:20,707]\u001b[0m Trial 30 pruned. \u001b[0m\n","Epoch 4: train_loss=2.327, validation_accuracy=0.1010\n","Epoch 4: train_loss=0.492, validation_accuracy=0.8962\n","Epoch 2: train_loss=2.103, validation_accuracy=0.1995\n","\u001b[32m[I 2023-03-07 23:18:20,848]\u001b[0m Trial 36 pruned. \u001b[0m\n","Epoch 5: train_loss=0.408, validation_accuracy=0.9088\n","Epoch 1: train_loss=2.296, validation_accuracy=0.1454\n","Epoch 5: train_loss=2.320, validation_accuracy=0.1010\n","Epoch 6: train_loss=0.362, validation_accuracy=0.9150\n","Epoch 2: train_loss=2.258, validation_accuracy=0.1741\n","Epoch 1: train_loss=2.294, validation_accuracy=0.1681\n","Epoch 7: train_loss=0.341, validation_accuracy=0.9161\n","Epoch 6: train_loss=2.314, validation_accuracy=0.1010\n","Epoch 3: train_loss=2.226, validation_accuracy=0.2010\n","Epoch 8: train_loss=0.319, validation_accuracy=0.9171\n","Epoch 2: train_loss=2.270, validation_accuracy=0.2470\n","\u001b[32m[I 2023-03-07 23:18:21,644]\u001b[0m Trial 38 pruned. \u001b[0m\n","Epoch 4: train_loss=2.198, validation_accuracy=0.2306\n","\u001b[32m[I 2023-03-07 23:18:21,775]\u001b[0m Trial 37 pruned. \u001b[0m\n","Epoch 7: train_loss=2.309, validation_accuracy=0.1010\n","Epoch 9: train_loss=0.297, validation_accuracy=0.9225\n","Epoch 1: train_loss=2.244, validation_accuracy=0.3298\n","Epoch 10: train_loss=0.289, validation_accuracy=0.9205\n","Epoch 8: train_loss=2.306, validation_accuracy=0.1010\n","Epoch 1: train_loss=2.257, validation_accuracy=0.3195\n","Epoch 2: train_loss=2.147, validation_accuracy=0.4082\n","Epoch 11: train_loss=0.282, validation_accuracy=0.9184\n","Epoch 9: train_loss=2.303, validation_accuracy=0.1125\n","Epoch 12: train_loss=0.276, validation_accuracy=0.9257\n","Epoch 3: train_loss=2.044, validation_accuracy=0.4544\n","Epoch 2: train_loss=2.084, validation_accuracy=0.4862\n","\u001b[32m[I 2023-03-07 23:18:22,635]\u001b[0m Trial 40 pruned. \u001b[0m\n","Epoch 13: train_loss=0.268, validation_accuracy=0.9283\n","Epoch 10: train_loss=2.301, validation_accuracy=0.1310\n","\u001b[32m[I 2023-03-07 23:18:22,798]\u001b[0m Trial 34 pruned. \u001b[0m\n","Epoch 4: train_loss=1.925, validation_accuracy=0.4931\n","Epoch 14: train_loss=0.260, validation_accuracy=0.9293\n","Epoch 1: train_loss=2.118, validation_accuracy=0.5339\n","Epoch 5: train_loss=1.791, validation_accuracy=0.5502\n","Epoch 1: train_loss=2.192, validation_accuracy=0.5738\n","Epoch 15: train_loss=0.258, validation_accuracy=0.9265\n","Epoch 2: train_loss=1.830, validation_accuracy=0.6546\n","\u001b[32m[I 2023-03-07 23:18:23,365]\u001b[0m Trial 41 pruned. \u001b[0m\n","Epoch 16: train_loss=0.253, validation_accuracy=0.9288\n","Epoch 6: train_loss=1.652, validation_accuracy=0.5813\n","Epoch 2: train_loss=1.217, validation_accuracy=0.7778\n","Epoch 17: train_loss=0.247, validation_accuracy=0.9335\n","Epoch 1: train_loss=2.262, validation_accuracy=0.1895\n","Epoch 7: train_loss=1.514, validation_accuracy=0.6380\n","Epoch 18: train_loss=0.242, validation_accuracy=0.9331\n","Epoch 3: train_loss=0.709, validation_accuracy=0.8126\n","Epoch 2: train_loss=2.144, validation_accuracy=0.3023\n","Epoch 8: train_loss=1.383, validation_accuracy=0.6896\n","Epoch 19: train_loss=0.240, validation_accuracy=0.9330\n","Epoch 4: train_loss=0.665, validation_accuracy=0.7835\n","Epoch 20: train_loss=0.233, validation_accuracy=0.9299\n","\u001b[32m[I 2023-03-07 23:18:24,294]\u001b[0m Trial 35 finished with value: 0.9299 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 19, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 18, 'activation_func[1]': 'Tanh', 'lr': 0.0009030804635597559, 'momentum': 0.9730470091899082}. Best is trial 5 with value: 0.959.\u001b[0m\n","Epoch 3: train_loss=2.051, validation_accuracy=0.4054\n","Epoch 9: train_loss=1.260, validation_accuracy=0.7312\n","Epoch 10: train_loss=1.147, validation_accuracy=0.7602\n","\u001b[32m[I 2023-03-07 23:18:24,566]\u001b[0m Trial 39 pruned. \u001b[0m\n","Epoch 4: train_loss=1.978, validation_accuracy=0.4794\n","\u001b[32m[I 2023-03-07 23:18:24,592]\u001b[0m Trial 43 pruned. \u001b[0m\n","Epoch 5: train_loss=0.638, validation_accuracy=0.8282\n","Epoch 1: train_loss=2.307, validation_accuracy=0.0991\n","Epoch 1: train_loss=2.252, validation_accuracy=0.2469\n","Epoch 1: train_loss=2.211, validation_accuracy=0.4649\n","Epoch 6: train_loss=0.587, validation_accuracy=0.8158\n","Epoch 2: train_loss=2.297, validation_accuracy=0.1475\n","Epoch 2: train_loss=2.166, validation_accuracy=0.3710\n","\u001b[32m[I 2023-03-07 23:18:25,185]\u001b[0m Trial 45 pruned. \u001b[0m\n","Epoch 2: train_loss=1.982, validation_accuracy=0.6461\n","\u001b[32m[I 2023-03-07 23:18:25,209]\u001b[0m Trial 46 pruned. \u001b[0m\n","Epoch 7: train_loss=0.564, validation_accuracy=0.8378\n","Epoch 3: train_loss=2.287, validation_accuracy=0.2009\n","Epoch 1: train_loss=1.794, validation_accuracy=0.7272\n","Epoch 1: train_loss=2.263, validation_accuracy=0.2104\n","Epoch 8: train_loss=0.526, validation_accuracy=0.8530\n","Epoch 4: train_loss=2.279, validation_accuracy=0.2354\n","Epoch 2: train_loss=1.120, validation_accuracy=0.8499\n","Epoch 2: train_loss=2.122, validation_accuracy=0.5267\n","\u001b[32m[I 2023-03-07 23:18:25,936]\u001b[0m Trial 48 pruned. \u001b[0m\n","Epoch 9: train_loss=0.505, validation_accuracy=0.8455\n","Epoch 3: train_loss=0.753, validation_accuracy=0.8808\n","Epoch 5: train_loss=2.270, validation_accuracy=0.2927\n","Epoch 1: train_loss=2.286, validation_accuracy=0.2122\n","Epoch 4: train_loss=0.574, validation_accuracy=0.8966\n","Epoch 10: train_loss=0.490, validation_accuracy=0.8605\n","\u001b[32m[I 2023-03-07 23:18:26,337]\u001b[0m Trial 42 pruned. \u001b[0m\n","Epoch 6: train_loss=2.261, validation_accuracy=0.3924\n","Epoch 2: train_loss=2.245, validation_accuracy=0.3069\n","Epoch 5: train_loss=0.482, validation_accuracy=0.9001\n","\u001b[32m[I 2023-03-07 23:18:26,514]\u001b[0m Trial 49 pruned. \u001b[0m\n","Epoch 1: train_loss=5.391, validation_accuracy=0.2524\n","Epoch 6: train_loss=0.426, validation_accuracy=0.9061\n","Epoch 2: train_loss=2.208, validation_accuracy=0.3628\n","\u001b[32m[I 2023-03-07 23:18:26,792]\u001b[0m Trial 50 pruned. \u001b[0m\n","Epoch 1: train_loss=1.864, validation_accuracy=0.7554\n","Epoch 7: train_loss=2.251, validation_accuracy=0.4316\n","Epoch 1: train_loss=2.123, validation_accuracy=0.4973\n","Epoch 7: train_loss=0.396, validation_accuracy=0.9105\n","Epoch 2: train_loss=1.246, validation_accuracy=0.8348\n","Epoch 2: train_loss=1.936, validation_accuracy=0.6159\n","Epoch 8: train_loss=2.240, validation_accuracy=0.4250\n","Epoch 8: train_loss=0.369, validation_accuracy=0.9109\n","Epoch 3: train_loss=0.893, validation_accuracy=0.8518\n","Epoch 3: train_loss=1.807, validation_accuracy=0.6589\n","Epoch 9: train_loss=2.228, validation_accuracy=0.4123\n","Epoch 9: train_loss=0.355, validation_accuracy=0.9092\n","Epoch 4: train_loss=1.689, validation_accuracy=0.6959\n","Epoch 4: train_loss=0.694, validation_accuracy=0.8769\n","Epoch 5: train_loss=1.581, validation_accuracy=0.7481\n","Epoch 10: train_loss=0.336, validation_accuracy=0.9155\n","Epoch 5: train_loss=0.582, validation_accuracy=0.8830\n","Epoch 10: train_loss=2.214, validation_accuracy=0.4027\n","\u001b[32m[I 2023-03-07 23:18:27,963]\u001b[0m Trial 44 pruned. \u001b[0m\n","Epoch 6: train_loss=1.482, validation_accuracy=0.7554\n","Epoch 11: train_loss=0.321, validation_accuracy=0.9169\n","Epoch 6: train_loss=0.509, validation_accuracy=0.8887\n","Epoch 7: train_loss=1.392, validation_accuracy=0.7766\n","Epoch 1: train_loss=2.328, validation_accuracy=0.1039\n","Epoch 8: train_loss=1.310, validation_accuracy=0.7951\n","Epoch 7: train_loss=0.467, validation_accuracy=0.8968\n","Epoch 12: train_loss=0.319, validation_accuracy=0.9159\n","Epoch 9: train_loss=1.236, validation_accuracy=0.8033\n","Epoch 8: train_loss=0.432, validation_accuracy=0.8999\n","Epoch 2: train_loss=2.301, validation_accuracy=0.1403\n","Epoch 13: train_loss=0.310, validation_accuracy=0.9193\n","Epoch 10: train_loss=1.171, validation_accuracy=0.8051\n","\u001b[32m[I 2023-03-07 23:18:28,851]\u001b[0m Trial 52 pruned. \u001b[0m\n","Epoch 14: train_loss=0.299, validation_accuracy=0.9151\n","Epoch 9: train_loss=0.408, validation_accuracy=0.9053\n","Epoch 3: train_loss=2.283, validation_accuracy=0.1831\n","Epoch 15: train_loss=0.300, validation_accuracy=0.9201\n","Epoch 10: train_loss=0.388, validation_accuracy=0.8981\n","\u001b[32m[I 2023-03-07 23:18:29,264]\u001b[0m Trial 51 pruned. \u001b[0m\n","Epoch 4: train_loss=2.269, validation_accuracy=0.2213\n","\u001b[32m[I 2023-03-07 23:18:29,339]\u001b[0m Trial 53 pruned. \u001b[0m\n","Epoch 1: train_loss=2.081, validation_accuracy=0.6277\n","Epoch 16: train_loss=0.287, validation_accuracy=0.9184\n","Epoch 1: train_loss=2.224, validation_accuracy=0.2462\n","Epoch 17: train_loss=0.284, validation_accuracy=0.9204\n","Epoch 1: train_loss=1.999, validation_accuracy=0.5568\n","Epoch 2: train_loss=2.066, validation_accuracy=0.3963\n","\u001b[32m[I 2023-03-07 23:18:29,885]\u001b[0m Trial 55 pruned. \u001b[0m\n","Epoch 18: train_loss=0.278, validation_accuracy=0.9196\n","Epoch 2: train_loss=1.255, validation_accuracy=0.8184\n","Epoch 2: train_loss=1.127, validation_accuracy=0.6440\n","Epoch 1: train_loss=2.068, validation_accuracy=0.4522\n","Epoch 19: train_loss=0.275, validation_accuracy=0.9261\n","Epoch 3: train_loss=1.121, validation_accuracy=0.6685\n","Epoch 20: train_loss=0.269, validation_accuracy=0.9237\n","\u001b[32m[I 2023-03-07 23:18:30,478]\u001b[0m Trial 47 finished with value: 0.9237 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 40, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 36, 'activation_func[1]': 'Tanh', 'lr': 0.001505284061338305, 'momentum': 0.9207639027337571}. Best is trial 5 with value: 0.959.\u001b[0m\n","Epoch 2: train_loss=1.718, validation_accuracy=0.6498\n","Epoch 3: train_loss=0.604, validation_accuracy=0.9063\n","Epoch 4: train_loss=1.023, validation_accuracy=0.6699\n","\u001b[32m[I 2023-03-07 23:18:30,799]\u001b[0m Trial 56 pruned. \u001b[0m\n","Epoch 3: train_loss=1.494, validation_accuracy=0.7344\n","Epoch 1: train_loss=1.039, validation_accuracy=0.8774\n","Epoch 4: train_loss=1.326, validation_accuracy=0.7745\n","Epoch 4: train_loss=0.359, validation_accuracy=0.9271\n","Epoch 1: train_loss=0.864, validation_accuracy=0.8947\n","Epoch 2: train_loss=0.368, validation_accuracy=0.9061\n","Epoch 5: train_loss=1.197, validation_accuracy=0.8018\n","Epoch 2: train_loss=0.316, validation_accuracy=0.9189\n","Epoch 3: train_loss=0.293, validation_accuracy=0.9200\n","Epoch 5: train_loss=0.264, validation_accuracy=0.9397\n","Epoch 6: train_loss=1.094, validation_accuracy=0.8213\n","Epoch 4: train_loss=0.255, validation_accuracy=0.9291\n","Epoch 3: train_loss=0.242, validation_accuracy=0.9395\n","Epoch 7: train_loss=1.009, validation_accuracy=0.8366\n","Epoch 6: train_loss=0.212, validation_accuracy=0.9424\n","Epoch 5: train_loss=0.231, validation_accuracy=0.9298\n","Epoch 4: train_loss=0.204, validation_accuracy=0.9459\n","Epoch 8: train_loss=0.936, validation_accuracy=0.8473\n","Epoch 6: train_loss=0.210, validation_accuracy=0.9361\n","Epoch 5: train_loss=0.177, validation_accuracy=0.9499\n","Epoch 7: train_loss=0.183, validation_accuracy=0.9469\n","Epoch 9: train_loss=0.874, validation_accuracy=0.8580\n","Epoch 7: train_loss=0.196, validation_accuracy=0.9402\n","Epoch 6: train_loss=0.159, validation_accuracy=0.9545\n","Epoch 10: train_loss=0.819, validation_accuracy=0.8673\n","Epoch 8: train_loss=0.162, validation_accuracy=0.9530\n","Epoch 8: train_loss=0.184, validation_accuracy=0.9400\n","Epoch 11: train_loss=0.770, validation_accuracy=0.8740\n","Epoch 7: train_loss=0.142, validation_accuracy=0.9494\n","Epoch 9: train_loss=0.175, validation_accuracy=0.9459\n","Epoch 12: train_loss=0.728, validation_accuracy=0.8783\n","Epoch 9: train_loss=0.146, validation_accuracy=0.9512\n","Epoch 8: train_loss=0.132, validation_accuracy=0.9572\n","Epoch 10: train_loss=0.165, validation_accuracy=0.9457\n","\u001b[32m[I 2023-03-07 23:18:33,807]\u001b[0m Trial 58 pruned. \u001b[0m\n","Epoch 13: train_loss=0.689, validation_accuracy=0.8828\n","Epoch 9: train_loss=0.121, validation_accuracy=0.9553\n","Epoch 10: train_loss=0.134, validation_accuracy=0.9506\n","Epoch 1: train_loss=1.165, validation_accuracy=0.8327\n","Epoch 14: train_loss=0.655, validation_accuracy=0.8878\n","Epoch 10: train_loss=0.113, validation_accuracy=0.9561\n","Epoch 2: train_loss=0.409, validation_accuracy=0.8968\n","Epoch 15: train_loss=0.623, validation_accuracy=0.8915\n","Epoch 11: train_loss=0.123, validation_accuracy=0.9514\n","Epoch 11: train_loss=0.107, validation_accuracy=0.9605\n","Epoch 3: train_loss=0.315, validation_accuracy=0.9218\n","Epoch 16: train_loss=0.595, validation_accuracy=0.8949\n","Epoch 4: train_loss=0.258, validation_accuracy=0.9296\n","Epoch 12: train_loss=0.102, validation_accuracy=0.9616\n","Epoch 17: train_loss=0.569, validation_accuracy=0.8987\n","Epoch 12: train_loss=0.114, validation_accuracy=0.9521\n","Epoch 5: train_loss=0.225, validation_accuracy=0.9296\n","Epoch 18: train_loss=0.545, validation_accuracy=0.9017\n","Epoch 13: train_loss=0.096, validation_accuracy=0.9637\n","Epoch 6: train_loss=0.211, validation_accuracy=0.9159\n","Epoch 13: train_loss=0.106, validation_accuracy=0.9572\n","Epoch 19: train_loss=0.523, validation_accuracy=0.9036\n","Epoch 14: train_loss=0.091, validation_accuracy=0.9614\n","Epoch 7: train_loss=0.192, validation_accuracy=0.9379\n","Epoch 20: train_loss=0.503, validation_accuracy=0.9062\n","\u001b[32m[I 2023-03-07 23:18:36,133]\u001b[0m Trial 57 finished with value: 0.9062 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 37, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 14, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 34, 'activation_func[3]': 'Tanh', 'lr': 0.00022126771282166818, 'momentum': 0.867772893425697}. Best is trial 5 with value: 0.959.\u001b[0m\n","Epoch 14: train_loss=0.098, validation_accuracy=0.9565\n","Epoch 15: train_loss=0.087, validation_accuracy=0.9630\n","Epoch 8: train_loss=0.174, validation_accuracy=0.9440\n","Epoch 1: train_loss=2.064, validation_accuracy=0.7103\n","Epoch 9: train_loss=0.165, validation_accuracy=0.9475\n","Epoch 16: train_loss=0.081, validation_accuracy=0.9644\n","Epoch 2: train_loss=1.642, validation_accuracy=0.7837\n","Epoch 15: train_loss=0.093, validation_accuracy=0.9565\n","Epoch 10: train_loss=0.157, validation_accuracy=0.9490\n","\u001b[32m[I 2023-03-07 23:18:36,905]\u001b[0m Trial 60 pruned. \u001b[0m\n","Epoch 17: train_loss=0.078, validation_accuracy=0.9632\n","Epoch 3: train_loss=1.294, validation_accuracy=0.8290\n","Epoch 1: train_loss=2.276, validation_accuracy=0.2343\n","Epoch 16: train_loss=0.087, validation_accuracy=0.9578\n","Epoch 4: train_loss=1.019, validation_accuracy=0.8563\n","Epoch 18: train_loss=0.075, validation_accuracy=0.9647\n","Epoch 5: train_loss=0.820, validation_accuracy=0.8766\n","Epoch 2: train_loss=2.032, validation_accuracy=0.3551\n","\u001b[32m[I 2023-03-07 23:18:37,601]\u001b[0m Trial 62 pruned. \u001b[0m\n","Epoch 19: train_loss=0.071, validation_accuracy=0.9652\n","Epoch 17: train_loss=0.082, validation_accuracy=0.9597\n","Epoch 6: train_loss=0.682, validation_accuracy=0.8880\n","Epoch 1: train_loss=1.682, validation_accuracy=0.7502\n","Epoch 20: train_loss=0.069, validation_accuracy=0.9652\n","\u001b[32m[I 2023-03-07 23:18:38,124]\u001b[0m Trial 59 finished with value: 0.9652 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 20, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 29, 'activation_func[4]': 'ReLU', 'lr': 0.006618632605407135, 'momentum': 0.6593978045574274}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 2: train_loss=1.038, validation_accuracy=0.8694\n","Epoch 7: train_loss=0.588, validation_accuracy=0.8941\n","Epoch 18: train_loss=0.078, validation_accuracy=0.9585\n","Epoch 3: train_loss=0.693, validation_accuracy=0.8932\n","Epoch 8: train_loss=0.521, validation_accuracy=0.8973\n","Epoch 1: train_loss=2.322, validation_accuracy=0.0966\n","Epoch 4: train_loss=0.501, validation_accuracy=0.9239\n","\u001b[32m[I 2023-03-07 23:18:38,757]\u001b[0m Trial 63 pruned. \u001b[0m\n","Epoch 9: train_loss=0.472, validation_accuracy=0.9000\n","Epoch 19: train_loss=0.072, validation_accuracy=0.9591\n","Epoch 2: train_loss=2.320, validation_accuracy=0.0987\n","\u001b[32m[I 2023-03-07 23:18:38,980]\u001b[0m Trial 64 pruned. \u001b[0m\n","Epoch 10: train_loss=0.436, validation_accuracy=0.9055\n","\u001b[32m[I 2023-03-07 23:18:39,134]\u001b[0m Trial 61 pruned. \u001b[0m\n","Epoch 1: train_loss=2.286, validation_accuracy=0.2151\n","Epoch 1: train_loss=1.921, validation_accuracy=0.6955\n","Epoch 20: train_loss=0.067, validation_accuracy=0.9620\n","\u001b[32m[I 2023-03-07 23:18:39,438]\u001b[0m Trial 54 finished with value: 0.962 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 44, 'activation_func[2]': 'Sigmoid', 'hidden_dim[3]': 50, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 28, 'activation_func[4]': 'ELU', 'lr': 0.00633473792035958, 'momentum': 0.8027814264632909}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 2: train_loss=1.551, validation_accuracy=0.8152\n","Epoch 1: train_loss=2.171, validation_accuracy=0.4737\n","Epoch 2: train_loss=2.218, validation_accuracy=0.3521\n","\u001b[32m[I 2023-03-07 23:18:39,649]\u001b[0m Trial 65 pruned. \u001b[0m\n","Epoch 3: train_loss=1.320, validation_accuracy=0.8607\n","Epoch 1: train_loss=3.578, validation_accuracy=0.1938\n","Epoch 2: train_loss=1.925, validation_accuracy=0.6217\n","\u001b[32m[I 2023-03-07 23:18:39,961]\u001b[0m Trial 67 pruned. \u001b[0m\n","Epoch 4: train_loss=1.133, validation_accuracy=0.8868\n","\u001b[32m[I 2023-03-07 23:18:40,044]\u001b[0m Trial 66 pruned. \u001b[0m\n","Epoch 1: train_loss=2.115, validation_accuracy=0.6773\n","Epoch 2: train_loss=2.075, validation_accuracy=0.2495\n","Epoch 3: train_loss=1.910, validation_accuracy=0.3300\n","Epoch 1: train_loss=2.304, validation_accuracy=0.1348\n","Epoch 4: train_loss=1.796, validation_accuracy=0.3560\n","Epoch 5: train_loss=1.720, validation_accuracy=0.3691\n","Epoch 2: train_loss=1.406, validation_accuracy=0.7733\n","Epoch 1: train_loss=2.278, validation_accuracy=0.2646\n","\u001b[32m[I 2023-03-07 23:18:40,614]\u001b[0m Trial 68 pruned. \u001b[0m\n","Epoch 6: train_loss=1.669, validation_accuracy=0.3718\n","Epoch 2: train_loss=2.253, validation_accuracy=0.2751\n","Epoch 1: train_loss=1.898, validation_accuracy=0.6826\n","Epoch 7: train_loss=1.635, validation_accuracy=0.3738\n","Epoch 2: train_loss=2.197, validation_accuracy=0.4669\n","\u001b[32m[I 2023-03-07 23:18:41,102]\u001b[0m Trial 71 pruned. \u001b[0m\n","Epoch 8: train_loss=1.611, validation_accuracy=0.3765\n","Epoch 2: train_loss=0.807, validation_accuracy=0.8229\n","Epoch 3: train_loss=2.208, validation_accuracy=0.4820\n","Epoch 9: train_loss=1.592, validation_accuracy=0.3782\n","Epoch 1: train_loss=1.682, validation_accuracy=0.7330\n","Epoch 10: train_loss=1.574, validation_accuracy=0.3791\n","\u001b[32m[I 2023-03-07 23:18:41,526]\u001b[0m Trial 69 pruned. \u001b[0m\n","Epoch 3: train_loss=0.692, validation_accuracy=0.7897\n","Epoch 2: train_loss=1.114, validation_accuracy=0.8154\n","Epoch 4: train_loss=2.135, validation_accuracy=0.5440\n","\u001b[32m[I 2023-03-07 23:18:41,728]\u001b[0m Trial 70 pruned. \u001b[0m\n","Epoch 4: train_loss=0.753, validation_accuracy=0.7633\n","\u001b[32m[I 2023-03-07 23:18:41,866]\u001b[0m Trial 72 pruned. \u001b[0m\n","Epoch 3: train_loss=0.900, validation_accuracy=0.8550\n","Epoch 1: train_loss=2.196, validation_accuracy=0.4243\n","Epoch 1: train_loss=2.227, validation_accuracy=0.5635\n","Epoch 4: train_loss=0.767, validation_accuracy=0.8667\n","Epoch 1: train_loss=2.290, validation_accuracy=0.2563\n","Epoch 5: train_loss=0.678, validation_accuracy=0.8754\n","Epoch 2: train_loss=2.059, validation_accuracy=0.6504\n","Epoch 2: train_loss=1.802, validation_accuracy=0.6648\n","\u001b[32m[I 2023-03-07 23:18:42,570]\u001b[0m Trial 74 pruned. \u001b[0m\n","Epoch 6: train_loss=0.611, validation_accuracy=0.8849\n","Epoch 3: train_loss=1.882, validation_accuracy=0.6780\n","Epoch 2: train_loss=2.256, validation_accuracy=0.2301\n","\u001b[32m[I 2023-03-07 23:18:42,754]\u001b[0m Trial 75 pruned. \u001b[0m\n","Epoch 1: train_loss=1.932, validation_accuracy=0.5219\n","Epoch 7: train_loss=0.561, validation_accuracy=0.8877\n","Epoch 4: train_loss=1.684, validation_accuracy=0.7133\n","\u001b[32m[I 2023-03-07 23:18:42,930]\u001b[0m Trial 76 pruned. \u001b[0m\n","Epoch 2: train_loss=1.228, validation_accuracy=0.6520\n","Epoch 1: train_loss=2.262, validation_accuracy=0.3668\n","Epoch 8: train_loss=0.522, validation_accuracy=0.8897\n","Epoch 3: train_loss=0.984, validation_accuracy=0.6904\n","Epoch 9: train_loss=0.490, validation_accuracy=0.8941\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1184\n","Epoch 2: train_loss=1.936, validation_accuracy=0.5264\n","Epoch 4: train_loss=0.888, validation_accuracy=0.7119\n","Epoch 10: train_loss=0.464, validation_accuracy=0.8979\n","\u001b[32m[I 2023-03-07 23:18:43,590]\u001b[0m Trial 73 pruned. \u001b[0m\n","Epoch 2: train_loss=2.294, validation_accuracy=0.1584\n","\u001b[32m[I 2023-03-07 23:18:43,743]\u001b[0m Trial 79 pruned. \u001b[0m\n","Epoch 5: train_loss=0.828, validation_accuracy=0.7213\n","Epoch 3: train_loss=1.311, validation_accuracy=0.7182\n","Epoch 1: train_loss=2.140, validation_accuracy=0.4605\n","Epoch 6: train_loss=0.786, validation_accuracy=0.7292\n","Epoch 1: train_loss=2.064, validation_accuracy=0.5454\n","Epoch 4: train_loss=0.954, validation_accuracy=0.7524\n","\u001b[32m[I 2023-03-07 23:18:44,121]\u001b[0m Trial 78 pruned. \u001b[0m\n","Epoch 2: train_loss=1.886, validation_accuracy=0.6181\n","Epoch 7: train_loss=0.756, validation_accuracy=0.7302\n","Epoch 2: train_loss=1.724, validation_accuracy=0.6788\n","Epoch 1: train_loss=1.546, validation_accuracy=0.7970\n","Epoch 3: train_loss=1.739, validation_accuracy=0.6908\n","Epoch 8: train_loss=0.733, validation_accuracy=0.7368\n","Epoch 3: train_loss=1.492, validation_accuracy=0.7522\n","Epoch 2: train_loss=0.902, validation_accuracy=0.8563\n","Epoch 9: train_loss=0.712, validation_accuracy=0.7400\n","Epoch 4: train_loss=1.617, validation_accuracy=0.7323\n","\u001b[32m[I 2023-03-07 23:18:44,792]\u001b[0m Trial 80 pruned. \u001b[0m\n","Epoch 4: train_loss=1.300, validation_accuracy=0.7944\n","Epoch 3: train_loss=0.680, validation_accuracy=0.8738\n","Epoch 10: train_loss=0.693, validation_accuracy=0.7424\n","\u001b[32m[I 2023-03-07 23:18:45,031]\u001b[0m Trial 77 pruned. \u001b[0m\n","Epoch 1: train_loss=1.835, validation_accuracy=0.7497\n","Epoch 5: train_loss=1.140, validation_accuracy=0.8236\n","Epoch 4: train_loss=0.570, validation_accuracy=0.8861\n","Epoch 2: train_loss=1.270, validation_accuracy=0.8229\n","Epoch 6: train_loss=1.006, validation_accuracy=0.8407\n","Epoch 5: train_loss=0.503, validation_accuracy=0.8935\n","Epoch 1: train_loss=2.295, validation_accuracy=0.1773\n","Epoch 3: train_loss=0.951, validation_accuracy=0.8549\n","Epoch 7: train_loss=0.896, validation_accuracy=0.8597\n","Epoch 6: train_loss=0.460, validation_accuracy=0.8989\n","Epoch 8: train_loss=0.805, validation_accuracy=0.8701\n","Epoch 4: train_loss=0.750, validation_accuracy=0.8747\n","Epoch 2: train_loss=2.271, validation_accuracy=0.2026\n","\u001b[32m[I 2023-03-07 23:18:46,009]\u001b[0m Trial 84 pruned. \u001b[0m\n","Epoch 7: train_loss=0.426, validation_accuracy=0.9006\n","Epoch 9: train_loss=0.729, validation_accuracy=0.8800\n","Epoch 5: train_loss=0.623, validation_accuracy=0.8836\n","Epoch 8: train_loss=0.401, validation_accuracy=0.9057\n","Epoch 1: train_loss=2.128, validation_accuracy=0.5503\n","Epoch 10: train_loss=0.668, validation_accuracy=0.8849\n","\u001b[32m[I 2023-03-07 23:18:46,501]\u001b[0m Trial 81 pruned. \u001b[0m\n","Epoch 6: train_loss=0.540, validation_accuracy=0.8936\n","Epoch 9: train_loss=0.378, validation_accuracy=0.9079\n","Epoch 1: train_loss=2.364, validation_accuracy=0.2931\n","Epoch 2: train_loss=1.644, validation_accuracy=0.7433\n","\u001b[32m[I 2023-03-07 23:18:46,844]\u001b[0m Trial 85 pruned. \u001b[0m\n","Epoch 7: train_loss=0.484, validation_accuracy=0.8933\n","Epoch 10: train_loss=0.363, validation_accuracy=0.9071\n","Epoch 1: train_loss=1.677, validation_accuracy=0.6661\n","Epoch 2: train_loss=2.183, validation_accuracy=0.1897\n","Epoch 8: train_loss=0.445, validation_accuracy=0.9020\n","Epoch 11: train_loss=0.349, validation_accuracy=0.9119\n","Epoch 2: train_loss=1.328, validation_accuracy=0.7367\n","\u001b[32m[I 2023-03-07 23:18:47,228]\u001b[0m Trial 87 pruned. \u001b[0m\n","Epoch 3: train_loss=2.128, validation_accuracy=0.1733\n","Epoch 9: train_loss=0.410, validation_accuracy=0.9059\n","Epoch 12: train_loss=0.335, validation_accuracy=0.9144\n","Epoch 1: train_loss=1.907, validation_accuracy=0.6970\n","Epoch 4: train_loss=2.062, validation_accuracy=0.1475\n","\u001b[32m[I 2023-03-07 23:18:47,593]\u001b[0m Trial 86 pruned. \u001b[0m\n","Epoch 13: train_loss=0.326, validation_accuracy=0.9142\n","Epoch 10: train_loss=0.389, validation_accuracy=0.9081\n","Epoch 2: train_loss=1.238, validation_accuracy=0.8071\n","Epoch 14: train_loss=0.316, validation_accuracy=0.9167\n","Epoch 11: train_loss=0.369, validation_accuracy=0.9100\n","Epoch 1: train_loss=2.265, validation_accuracy=0.2746\n","Epoch 3: train_loss=0.833, validation_accuracy=0.8580\n","Epoch 15: train_loss=0.306, validation_accuracy=0.9182\n","Epoch 12: train_loss=0.349, validation_accuracy=0.9125\n","Epoch 2: train_loss=2.184, validation_accuracy=0.3319\n","\u001b[32m[I 2023-03-07 23:18:48,409]\u001b[0m Trial 89 pruned. \u001b[0m\n","Epoch 4: train_loss=0.634, validation_accuracy=0.8669\n","\u001b[32m[I 2023-03-07 23:18:48,439]\u001b[0m Trial 88 pruned. \u001b[0m\n","Epoch 16: train_loss=0.300, validation_accuracy=0.9209\n","Epoch 13: train_loss=0.335, validation_accuracy=0.9151\n","Epoch 1: train_loss=1.851, validation_accuracy=0.5989\n","Epoch 1: train_loss=1.151, validation_accuracy=0.8719\n","Epoch 17: train_loss=0.292, validation_accuracy=0.9201\n","Epoch 2: train_loss=0.830, validation_accuracy=0.8152\n","Epoch 14: train_loss=0.322, validation_accuracy=0.9201\n","Epoch 18: train_loss=0.286, validation_accuracy=0.9219\n","Epoch 2: train_loss=0.378, validation_accuracy=0.9039\n","Epoch 3: train_loss=0.531, validation_accuracy=0.8619\n","Epoch 15: train_loss=0.313, validation_accuracy=0.9208\n","Epoch 19: train_loss=0.281, validation_accuracy=0.9216\n","Epoch 4: train_loss=0.426, validation_accuracy=0.8839\n","Epoch 3: train_loss=0.289, validation_accuracy=0.9253\n","Epoch 16: train_loss=0.306, validation_accuracy=0.9173\n","Epoch 20: train_loss=0.277, validation_accuracy=0.9213\n","\u001b[32m[I 2023-03-07 23:18:49,697]\u001b[0m Trial 82 finished with value: 0.9213 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 46, 'activation_func[0]': 'Tanh', 'lr': 0.000900707618435953, 'momentum': 0.8763923724767356}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 5: train_loss=0.369, validation_accuracy=0.9003\n","Epoch 4: train_loss=0.252, validation_accuracy=0.9311\n","Epoch 17: train_loss=0.294, validation_accuracy=0.9185\n","Epoch 6: train_loss=0.334, validation_accuracy=0.9079\n","Epoch 1: train_loss=2.062, validation_accuracy=0.8567\n","Epoch 5: train_loss=0.228, validation_accuracy=0.9375\n","Epoch 18: train_loss=0.289, validation_accuracy=0.9248\n","Epoch 7: train_loss=0.311, validation_accuracy=0.9107\n","Epoch 2: train_loss=0.434, validation_accuracy=0.8975\n","Epoch 6: train_loss=0.206, validation_accuracy=0.9398\n","Epoch 19: train_loss=0.280, validation_accuracy=0.9243\n","Epoch 8: train_loss=0.295, validation_accuracy=0.9170\n","Epoch 3: train_loss=0.342, validation_accuracy=0.9137\n","Epoch 9: train_loss=0.282, validation_accuracy=0.9193\n","Epoch 20: train_loss=0.271, validation_accuracy=0.9235\n","\u001b[32m[I 2023-03-07 23:18:50,758]\u001b[0m Trial 83 finished with value: 0.9235 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 41, 'activation_func[0]': 'Tanh', 'hidden_dim[1]': 37, 'activation_func[1]': 'Tanh', 'lr': 0.0021270981937836437, 'momentum': 0.8189606605894664}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 7: train_loss=0.195, validation_accuracy=0.9455\n","Epoch 4: train_loss=0.302, validation_accuracy=0.9220\n","Epoch 10: train_loss=0.271, validation_accuracy=0.9218\n","Epoch 1: train_loss=2.474, validation_accuracy=0.6057\n","Epoch 8: train_loss=0.182, validation_accuracy=0.9438\n","Epoch 5: train_loss=0.280, validation_accuracy=0.9249\n","Epoch 2: train_loss=0.974, validation_accuracy=0.7995\n","Epoch 11: train_loss=0.261, validation_accuracy=0.9256\n","Epoch 9: train_loss=0.173, validation_accuracy=0.9458\n","Epoch 3: train_loss=0.760, validation_accuracy=0.8293\n","Epoch 6: train_loss=0.264, validation_accuracy=0.9273\n","Epoch 12: train_loss=0.253, validation_accuracy=0.9262\n","Epoch 4: train_loss=0.657, validation_accuracy=0.8460\n","Epoch 10: train_loss=0.168, validation_accuracy=0.9428\n","\u001b[32m[I 2023-03-07 23:18:51,695]\u001b[0m Trial 91 pruned. \u001b[0m\n","Epoch 7: train_loss=0.250, validation_accuracy=0.9303\n","Epoch 13: train_loss=0.246, validation_accuracy=0.9286\n","Epoch 5: train_loss=0.541, validation_accuracy=0.8630\n","Epoch 1: train_loss=1.612, validation_accuracy=0.7847\n","Epoch 14: train_loss=0.241, validation_accuracy=0.9283\n","Epoch 8: train_loss=0.241, validation_accuracy=0.9333\n","Epoch 6: train_loss=0.490, validation_accuracy=0.8719\n","Epoch 7: train_loss=0.447, validation_accuracy=0.8774\n","Epoch 15: train_loss=0.235, validation_accuracy=0.9305\n","Epoch 2: train_loss=0.788, validation_accuracy=0.8682\n","Epoch 9: train_loss=0.233, validation_accuracy=0.9328\n","Epoch 8: train_loss=0.418, validation_accuracy=0.8867\n","Epoch 16: train_loss=0.231, validation_accuracy=0.9321\n","Epoch 3: train_loss=0.543, validation_accuracy=0.8841\n","Epoch 10: train_loss=0.226, validation_accuracy=0.9344\n","Epoch 9: train_loss=0.398, validation_accuracy=0.8921\n","Epoch 17: train_loss=0.227, validation_accuracy=0.9320\n","Epoch 4: train_loss=0.455, validation_accuracy=0.8935\n","Epoch 10: train_loss=0.383, validation_accuracy=0.8948\n","Epoch 11: train_loss=0.219, validation_accuracy=0.9347\n","Epoch 18: train_loss=0.223, validation_accuracy=0.9321\n","Epoch 11: train_loss=0.374, validation_accuracy=0.8966\n","Epoch 5: train_loss=0.422, validation_accuracy=0.9014\n","Epoch 12: train_loss=0.215, validation_accuracy=0.9350\n","Epoch 19: train_loss=0.220, validation_accuracy=0.9340\n","Epoch 12: train_loss=0.365, validation_accuracy=0.8966\n","Epoch 6: train_loss=0.394, validation_accuracy=0.9021\n","Epoch 13: train_loss=0.359, validation_accuracy=0.8916\n","Epoch 20: train_loss=0.215, validation_accuracy=0.9328\n","\u001b[32m[I 2023-03-07 23:18:53,557]\u001b[0m Trial 90 finished with value: 0.9328 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 15, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 25, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ELU', 'lr': 0.00012336909772295046, 'momentum': 0.9754948570787956}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 13: train_loss=0.210, validation_accuracy=0.9371\n","Epoch 7: train_loss=0.368, validation_accuracy=0.8975\n","Epoch 14: train_loss=0.351, validation_accuracy=0.8946\n","Epoch 1: train_loss=1.858, validation_accuracy=0.7150\n","Epoch 14: train_loss=0.206, validation_accuracy=0.9344\n","Epoch 15: train_loss=0.348, validation_accuracy=0.8992\n","Epoch 8: train_loss=0.360, validation_accuracy=0.9022\n","Epoch 2: train_loss=1.349, validation_accuracy=0.7965\n","Epoch 16: train_loss=0.344, validation_accuracy=0.8911\n","Epoch 15: train_loss=0.203, validation_accuracy=0.9379\n","Epoch 9: train_loss=0.346, validation_accuracy=0.9003\n","Epoch 17: train_loss=0.341, validation_accuracy=0.9017\n","Epoch 3: train_loss=1.052, validation_accuracy=0.8361\n","Epoch 16: train_loss=0.199, validation_accuracy=0.9368\n","Epoch 18: train_loss=0.337, validation_accuracy=0.8995\n","Epoch 10: train_loss=0.356, validation_accuracy=0.9032\n","\u001b[32m[I 2023-03-07 23:18:54,662]\u001b[0m Trial 94 pruned. \u001b[0m\n","Epoch 4: train_loss=0.850, validation_accuracy=0.8574\n","\u001b[32m[I 2023-03-07 23:18:54,750]\u001b[0m Trial 95 pruned. \u001b[0m\n","Epoch 17: train_loss=0.195, validation_accuracy=0.9394\n","Epoch 19: train_loss=0.332, validation_accuracy=0.9011\n","Epoch 1: train_loss=1.194, validation_accuracy=0.8615\n","Epoch 20: train_loss=0.331, validation_accuracy=0.8953\n","\u001b[32m[I 2023-03-07 23:18:55,097]\u001b[0m Trial 93 finished with value: 0.8953 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 27, 'activation_func[0]': 'ReLU', 'lr': 0.0006678789306780017, 'momentum': 0.8026145019248172}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 1: train_loss=1.741, validation_accuracy=0.7940\n","Epoch 18: train_loss=0.192, validation_accuracy=0.9369\n","Epoch 2: train_loss=0.386, validation_accuracy=0.8873\n","Epoch 2: train_loss=1.233, validation_accuracy=0.8559\n","Epoch 1: train_loss=1.342, validation_accuracy=0.7831\n","Epoch 19: train_loss=0.190, validation_accuracy=0.9391\n","Epoch 3: train_loss=0.983, validation_accuracy=0.8789\n","Epoch 3: train_loss=0.290, validation_accuracy=0.9257\n","Epoch 2: train_loss=0.661, validation_accuracy=0.8545\n","Epoch 20: train_loss=0.188, validation_accuracy=0.9411\n","\u001b[32m[I 2023-03-07 23:18:55,757]\u001b[0m Trial 92 finished with value: 0.9411 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'lr': 0.0008093747928779895, 'momentum': 0.8865133325413869}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 4: train_loss=0.821, validation_accuracy=0.8889\n","Epoch 3: train_loss=0.495, validation_accuracy=0.7906\n","Epoch 4: train_loss=0.245, validation_accuracy=0.9291\n","Epoch 1: train_loss=2.037, validation_accuracy=0.5950\n","Epoch 5: train_loss=0.711, validation_accuracy=0.8950\n","Epoch 4: train_loss=0.405, validation_accuracy=0.8967\n","\u001b[32m[I 2023-03-07 23:18:56,320]\u001b[0m Trial 98 pruned. \u001b[0m\n","Epoch 5: train_loss=0.219, validation_accuracy=0.9312\n","Epoch 6: train_loss=0.634, validation_accuracy=0.8997\n","Epoch 2: train_loss=1.068, validation_accuracy=0.4457\n","\u001b[32m[I 2023-03-07 23:18:56,533]\u001b[0m Trial 99 pruned. \u001b[0m\n","Epoch 6: train_loss=0.205, validation_accuracy=0.9341\n","Epoch 1: train_loss=2.484, validation_accuracy=0.7909\n","Epoch 7: train_loss=0.575, validation_accuracy=0.9023\n","Epoch 1: train_loss=2.273, validation_accuracy=0.7809\n","Epoch 2: train_loss=0.558, validation_accuracy=0.8868\n","Epoch 7: train_loss=0.190, validation_accuracy=0.9402\n","Epoch 8: train_loss=0.528, validation_accuracy=0.9048\n","Epoch 2: train_loss=0.582, validation_accuracy=0.8665\n","Epoch 3: train_loss=0.391, validation_accuracy=0.9032\n","Epoch 8: train_loss=0.179, validation_accuracy=0.9452\n","Epoch 9: train_loss=0.492, validation_accuracy=0.9073\n","Epoch 3: train_loss=0.416, validation_accuracy=0.8950\n","Epoch 4: train_loss=0.327, validation_accuracy=0.9128\n","Epoch 10: train_loss=0.464, validation_accuracy=0.9125\n","Epoch 9: train_loss=0.170, validation_accuracy=0.9464\n","Epoch 4: train_loss=0.344, validation_accuracy=0.9090\n","Epoch 5: train_loss=0.294, validation_accuracy=0.9172\n","Epoch 11: train_loss=0.439, validation_accuracy=0.9085\n","Epoch 10: train_loss=0.162, validation_accuracy=0.9462\n","\u001b[32m[I 2023-03-07 23:18:57,897]\u001b[0m Trial 96 pruned. \u001b[0m\n","Epoch 5: train_loss=0.308, validation_accuracy=0.9162\n","Epoch 6: train_loss=0.275, validation_accuracy=0.9182\n","Epoch 1: train_loss=2.534, validation_accuracy=0.1137\n","Epoch 12: train_loss=0.419, validation_accuracy=0.9135\n","Epoch 2: train_loss=2.274, validation_accuracy=0.1376\n","Epoch 6: train_loss=0.289, validation_accuracy=0.9148\n","Epoch 7: train_loss=0.262, validation_accuracy=0.9210\n","Epoch 13: train_loss=0.401, validation_accuracy=0.9139\n","Epoch 3: train_loss=2.209, validation_accuracy=0.1749\n","Epoch 7: train_loss=0.276, validation_accuracy=0.9210\n","Epoch 8: train_loss=0.250, validation_accuracy=0.9214\n","Epoch 4: train_loss=2.163, validation_accuracy=0.1810\n","\u001b[32m[I 2023-03-07 23:18:58,691]\u001b[0m Trial 102 pruned. \u001b[0m\n","Epoch 14: train_loss=0.386, validation_accuracy=0.9174\n","Epoch 8: train_loss=0.264, validation_accuracy=0.9230\n","Epoch 15: train_loss=0.372, validation_accuracy=0.9193\n","Epoch 9: train_loss=0.242, validation_accuracy=0.9233\n","Epoch 1: train_loss=0.867, validation_accuracy=0.8993\n","Epoch 9: train_loss=0.252, validation_accuracy=0.9227\n","Epoch 16: train_loss=0.360, validation_accuracy=0.9188\n","Epoch 10: train_loss=0.233, validation_accuracy=0.9261\n","Epoch 2: train_loss=0.286, validation_accuracy=0.9279\n","Epoch 17: train_loss=0.350, validation_accuracy=0.9207\n","Epoch 10: train_loss=0.243, validation_accuracy=0.9263\n","Epoch 11: train_loss=0.226, validation_accuracy=0.9241\n","Epoch 3: train_loss=0.224, validation_accuracy=0.9378\n","Epoch 18: train_loss=0.341, validation_accuracy=0.9215\n","Epoch 12: train_loss=0.221, validation_accuracy=0.9287\n","Epoch 11: train_loss=0.234, validation_accuracy=0.9292\n","Epoch 19: train_loss=0.331, validation_accuracy=0.9217\n","Epoch 12: train_loss=0.228, validation_accuracy=0.9291\n","Epoch 13: train_loss=0.215, validation_accuracy=0.9290\n","Epoch 4: train_loss=0.189, validation_accuracy=0.9406\n","Epoch 20: train_loss=0.323, validation_accuracy=0.9215\n","\u001b[32m[I 2023-03-07 23:19:00,282]\u001b[0m Trial 97 finished with value: 0.9215 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 43, 'activation_func[0]': 'Sigmoid', 'lr': 0.0036310066628164575, 'momentum': 0.7197139368191213}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 13: train_loss=0.224, validation_accuracy=0.9310\n","Epoch 14: train_loss=0.211, validation_accuracy=0.9304\n","Epoch 5: train_loss=0.166, validation_accuracy=0.9477\n","Epoch 1: train_loss=2.362, validation_accuracy=0.0892\n","Epoch 14: train_loss=0.220, validation_accuracy=0.9287\n","Epoch 15: train_loss=0.206, validation_accuracy=0.9328\n","Epoch 6: train_loss=0.150, validation_accuracy=0.9488\n","Epoch 2: train_loss=2.293, validation_accuracy=0.1494\n","Epoch 15: train_loss=0.216, validation_accuracy=0.9316\n","Epoch 16: train_loss=0.203, validation_accuracy=0.9326\n","Epoch 7: train_loss=0.136, validation_accuracy=0.9541\n","Epoch 3: train_loss=2.262, validation_accuracy=0.3658\n","Epoch 16: train_loss=0.212, validation_accuracy=0.9296\n","Epoch 17: train_loss=0.200, validation_accuracy=0.9332\n","Epoch 4: train_loss=2.251, validation_accuracy=0.3818\n","Epoch 8: train_loss=0.125, validation_accuracy=0.9576\n","Epoch 17: train_loss=0.207, validation_accuracy=0.9343\n","Epoch 18: train_loss=0.197, validation_accuracy=0.9348\n","Epoch 5: train_loss=2.236, validation_accuracy=0.3475\n","Epoch 9: train_loss=0.120, validation_accuracy=0.9567\n","Epoch 18: train_loss=0.204, validation_accuracy=0.9343\n","Epoch 19: train_loss=0.194, validation_accuracy=0.9333\n","Epoch 6: train_loss=2.211, validation_accuracy=0.4032\n","Epoch 19: train_loss=0.202, validation_accuracy=0.9328\n","Epoch 10: train_loss=0.111, validation_accuracy=0.9576\n","Epoch 20: train_loss=0.191, validation_accuracy=0.9361\n","\u001b[32m[I 2023-03-07 23:19:02,123]\u001b[0m Trial 100 finished with value: 0.9361 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'lr': 0.0005706454522333578, 'momentum': 0.8963870537064971}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 7: train_loss=2.184, validation_accuracy=0.3995\n","Epoch 20: train_loss=0.199, validation_accuracy=0.9355\n","\u001b[32m[I 2023-03-07 23:19:02,377]\u001b[0m Trial 101 finished with value: 0.9355 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 48, 'activation_func[0]': 'ELU', 'lr': 0.0009394771370323995, 'momentum': 0.8915179150750204}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 1: train_loss=2.061, validation_accuracy=0.8213\n","Epoch 11: train_loss=0.106, validation_accuracy=0.9587\n","Epoch 8: train_loss=2.157, validation_accuracy=0.4324\n","Epoch 2: train_loss=0.579, validation_accuracy=0.8696\n","Epoch 1: train_loss=2.315, validation_accuracy=0.7407\n","Epoch 9: train_loss=2.126, validation_accuracy=0.4564\n","Epoch 12: train_loss=0.101, validation_accuracy=0.9605\n","Epoch 3: train_loss=0.468, validation_accuracy=0.8831\n","Epoch 2: train_loss=0.693, validation_accuracy=0.8555\n","Epoch 10: train_loss=2.090, validation_accuracy=0.4591\n","\u001b[32m[I 2023-03-07 23:19:02,998]\u001b[0m Trial 104 pruned. \u001b[0m\n","Epoch 13: train_loss=0.095, validation_accuracy=0.9599\n","Epoch 4: train_loss=0.416, validation_accuracy=0.8912\n","Epoch 3: train_loss=0.482, validation_accuracy=0.8953\n","Epoch 1: train_loss=2.310, validation_accuracy=0.1033\n","Epoch 14: train_loss=0.091, validation_accuracy=0.9605\n","Epoch 5: train_loss=0.382, validation_accuracy=0.8976\n","Epoch 4: train_loss=0.387, validation_accuracy=0.9070\n","Epoch 6: train_loss=0.356, validation_accuracy=0.8989\n","Epoch 15: train_loss=0.088, validation_accuracy=0.9620\n","Epoch 2: train_loss=2.298, validation_accuracy=0.1325\n","\u001b[32m[I 2023-03-07 23:19:03,814]\u001b[0m Trial 107 pruned. \u001b[0m\n","Epoch 5: train_loss=0.334, validation_accuracy=0.9154\n","Epoch 7: train_loss=0.337, validation_accuracy=0.9034\n","Epoch 16: train_loss=0.084, validation_accuracy=0.9581\n","Epoch 6: train_loss=0.301, validation_accuracy=0.9214\n","Epoch 1: train_loss=2.182, validation_accuracy=0.4157\n","Epoch 8: train_loss=0.321, validation_accuracy=0.9064\n","Epoch 7: train_loss=0.280, validation_accuracy=0.9242\n","Epoch 17: train_loss=0.081, validation_accuracy=0.9612\n","Epoch 2: train_loss=1.966, validation_accuracy=0.5731\n","\u001b[32m[I 2023-03-07 23:19:04,549]\u001b[0m Trial 108 pruned. \u001b[0m\n","Epoch 9: train_loss=0.309, validation_accuracy=0.9112\n","Epoch 8: train_loss=0.265, validation_accuracy=0.9257\n","Epoch 18: train_loss=0.077, validation_accuracy=0.9601\n","Epoch 1: train_loss=1.877, validation_accuracy=0.8418\n","Epoch 10: train_loss=0.299, validation_accuracy=0.9127\n","\u001b[32m[I 2023-03-07 23:19:04,917]\u001b[0m Trial 105 pruned. \u001b[0m\n","Epoch 9: train_loss=0.252, validation_accuracy=0.9286\n","Epoch 19: train_loss=0.075, validation_accuracy=0.9598\n","Epoch 2: train_loss=0.464, validation_accuracy=0.8993\n","Epoch 10: train_loss=0.241, validation_accuracy=0.9313\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1297\n","Epoch 20: train_loss=0.072, validation_accuracy=0.9621\n","\u001b[32m[I 2023-03-07 23:19:05,436]\u001b[0m Trial 103 finished with value: 0.9621 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 13, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'lr': 0.008143921245454754, 'momentum': 0.6558634570333829}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 3: train_loss=0.344, validation_accuracy=0.9137\n","Epoch 11: train_loss=0.231, validation_accuracy=0.9334\n","Epoch 1: train_loss=2.295, validation_accuracy=0.2118\n","Epoch 4: train_loss=0.297, validation_accuracy=0.9192\n","Epoch 2: train_loss=2.301, validation_accuracy=0.1057\n","\u001b[32m[I 2023-03-07 23:19:05,779]\u001b[0m Trial 110 pruned. \u001b[0m\n","Epoch 12: train_loss=0.223, validation_accuracy=0.9373\n","Epoch 2: train_loss=2.202, validation_accuracy=0.2547\n","\u001b[32m[I 2023-03-07 23:19:05,992]\u001b[0m Trial 111 pruned. \u001b[0m\n","Epoch 5: train_loss=0.270, validation_accuracy=0.9270\n","Epoch 1: train_loss=2.242, validation_accuracy=0.2656\n","Epoch 13: train_loss=0.216, validation_accuracy=0.9362\n","Epoch 1: train_loss=1.161, validation_accuracy=0.8488\n","Epoch 6: train_loss=0.253, validation_accuracy=0.9274\n","Epoch 2: train_loss=0.616, validation_accuracy=0.8820\n","Epoch 14: train_loss=0.209, validation_accuracy=0.9381\n","Epoch 7: train_loss=0.238, validation_accuracy=0.9314\n","Epoch 2: train_loss=1.941, validation_accuracy=0.3818\n","\u001b[32m[I 2023-03-07 23:19:06,606]\u001b[0m Trial 112 pruned. \u001b[0m\n","Epoch 3: train_loss=0.490, validation_accuracy=0.8946\n","Epoch 15: train_loss=0.203, validation_accuracy=0.9412\n","Epoch 8: train_loss=0.228, validation_accuracy=0.9346\n","Epoch 4: train_loss=0.425, validation_accuracy=0.9036\n","\u001b[32m[I 2023-03-07 23:19:06,866]\u001b[0m Trial 113 pruned. \u001b[0m\n","Epoch 1: train_loss=0.914, validation_accuracy=0.8946\n","Epoch 16: train_loss=0.199, validation_accuracy=0.9419\n","Epoch 9: train_loss=0.218, validation_accuracy=0.9359\n","Epoch 1: train_loss=3.570, validation_accuracy=0.8084\n","Epoch 10: train_loss=0.211, validation_accuracy=0.9379\n","Epoch 17: train_loss=0.195, validation_accuracy=0.9424\n","Epoch 2: train_loss=0.295, validation_accuracy=0.9291\n","Epoch 2: train_loss=0.620, validation_accuracy=0.8522\n","Epoch 11: train_loss=0.204, validation_accuracy=0.9394\n","Epoch 18: train_loss=0.191, validation_accuracy=0.9432\n","Epoch 3: train_loss=0.515, validation_accuracy=0.8714\n","Epoch 3: train_loss=0.217, validation_accuracy=0.9376\n","Epoch 12: train_loss=0.198, validation_accuracy=0.9405\n","Epoch 19: train_loss=0.187, validation_accuracy=0.9425\n","Epoch 4: train_loss=0.437, validation_accuracy=0.8905\n","Epoch 4: train_loss=0.182, validation_accuracy=0.9476\n","Epoch 13: train_loss=0.193, validation_accuracy=0.9411\n","Epoch 20: train_loss=0.184, validation_accuracy=0.9427\n","\u001b[32m[I 2023-03-07 23:19:08,152]\u001b[0m Trial 106 finished with value: 0.9427 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 48, 'activation_func[0]': 'ELU', 'lr': 0.0007054782987412582, 'momentum': 0.8556387321871426}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 5: train_loss=0.384, validation_accuracy=0.8972\n","Epoch 5: train_loss=0.158, validation_accuracy=0.9534\n","Epoch 14: train_loss=0.188, validation_accuracy=0.9427\n","Epoch 6: train_loss=0.353, validation_accuracy=0.8989\n","Epoch 1: train_loss=1.417, validation_accuracy=0.8116\n","Epoch 15: train_loss=0.183, validation_accuracy=0.9439\n","Epoch 7: train_loss=0.334, validation_accuracy=0.9049\n","Epoch 6: train_loss=0.141, validation_accuracy=0.9519\n","Epoch 16: train_loss=0.178, validation_accuracy=0.9444\n","Epoch 2: train_loss=0.646, validation_accuracy=0.9008\n","Epoch 8: train_loss=0.318, validation_accuracy=0.9090\n","Epoch 7: train_loss=0.130, validation_accuracy=0.9550\n","Epoch 17: train_loss=0.174, validation_accuracy=0.9469\n","Epoch 9: train_loss=0.306, validation_accuracy=0.9119\n","Epoch 3: train_loss=0.408, validation_accuracy=0.9169\n","Epoch 8: train_loss=0.119, validation_accuracy=0.9604\n","Epoch 18: train_loss=0.171, validation_accuracy=0.9450\n","Epoch 10: train_loss=0.296, validation_accuracy=0.9145\n","\u001b[32m[I 2023-03-07 23:19:09,521]\u001b[0m Trial 115 pruned. \u001b[0m\n","Epoch 4: train_loss=0.312, validation_accuracy=0.9317\n","Epoch 19: train_loss=0.167, validation_accuracy=0.9473\n","Epoch 9: train_loss=0.109, validation_accuracy=0.9492\n","Epoch 1: train_loss=1.987, validation_accuracy=0.6017\n","Epoch 20: train_loss=0.164, validation_accuracy=0.9473\n","\u001b[32m[I 2023-03-07 23:19:10,012]\u001b[0m Trial 109 finished with value: 0.9473 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'lr': 0.00044647042569951717, 'momentum': 0.891794220173803}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 5: train_loss=0.262, validation_accuracy=0.9415\n","Epoch 2: train_loss=1.410, validation_accuracy=0.7264\n","\u001b[32m[I 2023-03-07 23:19:10,132]\u001b[0m Trial 117 pruned. \u001b[0m\n","Epoch 10: train_loss=0.103, validation_accuracy=0.9579\n","Epoch 1: train_loss=1.097, validation_accuracy=0.8582\n","Epoch 1: train_loss=1.745, validation_accuracy=0.8053\n","Epoch 6: train_loss=0.231, validation_accuracy=0.9462\n","Epoch 11: train_loss=0.095, validation_accuracy=0.9617\n","Epoch 2: train_loss=0.426, validation_accuracy=0.8929\n","Epoch 2: train_loss=0.555, validation_accuracy=0.8638\n","Epoch 7: train_loss=0.207, validation_accuracy=0.9473\n","Epoch 3: train_loss=0.341, validation_accuracy=0.9027\n","Epoch 12: train_loss=0.088, validation_accuracy=0.9632\n","Epoch 3: train_loss=0.423, validation_accuracy=0.8883\n","Epoch 4: train_loss=0.301, validation_accuracy=0.9162\n","\u001b[32m[I 2023-03-07 23:19:11,130]\u001b[0m Trial 118 pruned. \u001b[0m\n","Epoch 4: train_loss=0.350, validation_accuracy=0.9046\n","Epoch 8: train_loss=0.189, validation_accuracy=0.9459\n","Epoch 13: train_loss=0.082, validation_accuracy=0.9609\n","Epoch 1: train_loss=1.425, validation_accuracy=0.8590\n","Epoch 5: train_loss=0.306, validation_accuracy=0.9148\n","Epoch 9: train_loss=0.173, validation_accuracy=0.9514\n","Epoch 14: train_loss=0.079, validation_accuracy=0.9632\n","Epoch 6: train_loss=0.278, validation_accuracy=0.9217\n","Epoch 2: train_loss=0.483, validation_accuracy=0.8891\n","Epoch 15: train_loss=0.075, validation_accuracy=0.9632\n","Epoch 7: train_loss=0.259, validation_accuracy=0.9234\n","Epoch 10: train_loss=0.160, validation_accuracy=0.9563\n","Epoch 3: train_loss=0.380, validation_accuracy=0.9036\n","Epoch 8: train_loss=0.244, validation_accuracy=0.9256\n","Epoch 16: train_loss=0.070, validation_accuracy=0.9667\n","Epoch 4: train_loss=0.325, validation_accuracy=0.9137\n","Epoch 11: train_loss=0.148, validation_accuracy=0.9571\n","Epoch 9: train_loss=0.232, validation_accuracy=0.9295\n","Epoch 5: train_loss=0.289, validation_accuracy=0.9208\n","Epoch 17: train_loss=0.066, validation_accuracy=0.9656\n","Epoch 12: train_loss=0.144, validation_accuracy=0.9586\n","Epoch 10: train_loss=0.222, validation_accuracy=0.9324\n","Epoch 6: train_loss=0.261, validation_accuracy=0.9275\n","Epoch 18: train_loss=0.123, validation_accuracy=0.9647\n","Epoch 11: train_loss=0.214, validation_accuracy=0.9327\n","Epoch 13: train_loss=0.131, validation_accuracy=0.9586\n","Epoch 7: train_loss=0.241, validation_accuracy=0.9295\n","Epoch 12: train_loss=0.206, validation_accuracy=0.9335\n","Epoch 19: train_loss=0.063, validation_accuracy=0.9640\n","Epoch 8: train_loss=0.224, validation_accuracy=0.9344\n","Epoch 14: train_loss=0.123, validation_accuracy=0.9582\n","Epoch 13: train_loss=0.200, validation_accuracy=0.9356\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9649\n","\u001b[32m[I 2023-03-07 23:19:13,716]\u001b[0m Trial 114 finished with value: 0.9649 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'lr': 0.00997265126351053, 'momentum': 0.613786589962803}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 9: train_loss=0.211, validation_accuracy=0.9368\n","Epoch 14: train_loss=0.195, validation_accuracy=0.9361\n","Epoch 15: train_loss=0.119, validation_accuracy=0.9598\n","Epoch 1: train_loss=2.252, validation_accuracy=0.8122\n","Epoch 10: train_loss=0.200, validation_accuracy=0.9374\n","Epoch 15: train_loss=0.190, validation_accuracy=0.9373\n","Epoch 2: train_loss=0.577, validation_accuracy=0.8576\n","Epoch 11: train_loss=0.190, validation_accuracy=0.9400\n","Epoch 16: train_loss=0.111, validation_accuracy=0.9612\n","Epoch 16: train_loss=0.185, validation_accuracy=0.9372\n","Epoch 3: train_loss=0.447, validation_accuracy=0.8830\n","Epoch 12: train_loss=0.183, validation_accuracy=0.9409\n","Epoch 17: train_loss=0.182, validation_accuracy=0.9393\n","Epoch 17: train_loss=0.107, validation_accuracy=0.9625\n","Epoch 4: train_loss=0.381, validation_accuracy=0.8932\n","Epoch 13: train_loss=0.176, validation_accuracy=0.9413\n","Epoch 18: train_loss=0.178, validation_accuracy=0.9389\n","Epoch 5: train_loss=0.351, validation_accuracy=0.9011\n","Epoch 18: train_loss=0.102, validation_accuracy=0.9606\n","Epoch 14: train_loss=0.170, validation_accuracy=0.9431\n","Epoch 19: train_loss=0.175, validation_accuracy=0.9400\n","Epoch 6: train_loss=0.332, validation_accuracy=0.9067\n","Epoch 15: train_loss=0.165, validation_accuracy=0.9427\n","Epoch 20: train_loss=0.171, validation_accuracy=0.9409\n","\u001b[32m[I 2023-03-07 23:19:15,507]\u001b[0m Trial 119 finished with value: 0.9409 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 46, 'activation_func[0]': 'ELU', 'lr': 0.0004550463566551358, 'momentum': 0.8470273899516683}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 19: train_loss=0.096, validation_accuracy=0.9615\n","Epoch 7: train_loss=0.318, validation_accuracy=0.9106\n","Epoch 16: train_loss=0.160, validation_accuracy=0.9440\n","Epoch 8: train_loss=0.304, validation_accuracy=0.9150\n","Epoch 1: train_loss=2.166, validation_accuracy=0.5468\n","Epoch 20: train_loss=0.093, validation_accuracy=0.9642\n","\u001b[32m[I 2023-03-07 23:19:15,963]\u001b[0m Trial 116 finished with value: 0.9642 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 10, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 26, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 34, 'activation_func[4]': 'Tanh', 'lr': 0.008367828475408113, 'momentum': 0.6480938362850919}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 17: train_loss=0.155, validation_accuracy=0.9452\n","Epoch 1: train_loss=272.110, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.294, validation_accuracy=0.9124\n","Epoch 2: train_loss=1.747, validation_accuracy=0.7228\n","\u001b[32m[I 2023-03-07 23:19:16,298]\u001b[0m Trial 122 pruned. \u001b[0m\n","Epoch 18: train_loss=0.151, validation_accuracy=0.9454\n","Epoch 2: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.285, validation_accuracy=0.9147\n","\u001b[32m[I 2023-03-07 23:19:16,496]\u001b[0m Trial 121 pruned. \u001b[0m\n","Epoch 3: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.147, validation_accuracy=0.9457\n","Epoch 1: train_loss=1.369, validation_accuracy=0.7959\n","Epoch 4: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.144, validation_accuracy=0.9453\n","\u001b[32m[I 2023-03-07 23:19:17,014]\u001b[0m Trial 120 finished with value: 0.9453 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'lr': 0.00022614555114967266, 'momentum': 0.8979577659911958}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 5: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 1: train_loss=2.315, validation_accuracy=0.1200\n","Epoch 2: train_loss=0.641, validation_accuracy=0.8842\n","Epoch 6: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 1: train_loss=1.356, validation_accuracy=0.8079\n","Epoch 7: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 2: train_loss=2.265, validation_accuracy=0.1996\n","Epoch 3: train_loss=0.425, validation_accuracy=0.9209\n","Epoch 8: train_loss=2.301, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.637, validation_accuracy=0.9020\n","Epoch 9: train_loss=2.302, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.323, validation_accuracy=0.9332\n","Epoch 3: train_loss=2.234, validation_accuracy=0.2212\n","Epoch 10: train_loss=2.301, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:19:18,085]\u001b[0m Trial 123 pruned. \u001b[0m\n","Epoch 3: train_loss=0.413, validation_accuracy=0.9246\n","Epoch 5: train_loss=0.269, validation_accuracy=0.9364\n","Epoch 4: train_loss=2.211, validation_accuracy=0.3897\n","\u001b[32m[I 2023-03-07 23:19:18,411]\u001b[0m Trial 125 pruned. \u001b[0m\n","Epoch 1: train_loss=1.670, validation_accuracy=0.7416\n","Epoch 4: train_loss=0.304, validation_accuracy=0.9418\n","Epoch 6: train_loss=0.232, validation_accuracy=0.9453\n","Epoch 1: train_loss=2.347, validation_accuracy=0.1023\n","Epoch 2: train_loss=0.956, validation_accuracy=0.8606\n","Epoch 5: train_loss=0.248, validation_accuracy=0.9472\n","Epoch 2: train_loss=2.325, validation_accuracy=0.1183\n","Epoch 7: train_loss=0.207, validation_accuracy=0.9397\n","Epoch 3: train_loss=2.297, validation_accuracy=0.1355\n","Epoch 3: train_loss=0.672, validation_accuracy=0.8873\n","Epoch 6: train_loss=0.214, validation_accuracy=0.9463\n","Epoch 8: train_loss=0.183, validation_accuracy=0.9479\n","Epoch 4: train_loss=2.271, validation_accuracy=0.1438\n","Epoch 4: train_loss=0.522, validation_accuracy=0.9042\n","\u001b[32m[I 2023-03-07 23:19:19,621]\u001b[0m Trial 127 pruned. \u001b[0m\n","Epoch 7: train_loss=0.188, validation_accuracy=0.9524\n","Epoch 9: train_loss=0.168, validation_accuracy=0.9538\n","Epoch 5: train_loss=2.252, validation_accuracy=0.1505\n","Epoch 6: train_loss=2.237, validation_accuracy=0.1556\n","Epoch 1: train_loss=1.508, validation_accuracy=0.7862\n","Epoch 8: train_loss=0.170, validation_accuracy=0.9537\n","Epoch 10: train_loss=0.157, validation_accuracy=0.9531\n","Epoch 7: train_loss=2.224, validation_accuracy=0.1600\n","Epoch 2: train_loss=0.741, validation_accuracy=0.8920\n","Epoch 9: train_loss=0.154, validation_accuracy=0.9485\n","Epoch 11: train_loss=0.146, validation_accuracy=0.9559\n","Epoch 8: train_loss=2.212, validation_accuracy=0.1648\n","Epoch 3: train_loss=0.483, validation_accuracy=0.9201\n","Epoch 10: train_loss=0.141, validation_accuracy=0.9564\n","Epoch 9: train_loss=2.201, validation_accuracy=0.1689\n","Epoch 12: train_loss=0.136, validation_accuracy=0.9549\n","Epoch 10: train_loss=2.191, validation_accuracy=0.1748\n","\u001b[32m[I 2023-03-07 23:19:21,077]\u001b[0m Trial 128 pruned. \u001b[0m\n","Epoch 4: train_loss=0.370, validation_accuracy=0.9302\n","Epoch 11: train_loss=0.131, validation_accuracy=0.9548\n","Epoch 13: train_loss=0.127, validation_accuracy=0.9518\n","Epoch 1: train_loss=2.639, validation_accuracy=0.1895\n","Epoch 2: train_loss=2.095, validation_accuracy=0.1957\n","Epoch 5: train_loss=0.308, validation_accuracy=0.9361\n","Epoch 12: train_loss=0.121, validation_accuracy=0.9594\n","Epoch 14: train_loss=0.122, validation_accuracy=0.9587\n","Epoch 3: train_loss=2.084, validation_accuracy=0.1975\n","Epoch 4: train_loss=2.079, validation_accuracy=0.1970\n","Epoch 6: train_loss=0.265, validation_accuracy=0.9437\n","Epoch 13: train_loss=0.113, validation_accuracy=0.9574\n","Epoch 15: train_loss=0.115, validation_accuracy=0.9577\n","Epoch 5: train_loss=2.075, validation_accuracy=0.1970\n","Epoch 6: train_loss=2.072, validation_accuracy=0.1990\n","Epoch 7: train_loss=0.236, validation_accuracy=0.9474\n","Epoch 14: train_loss=0.107, validation_accuracy=0.9586\n","Epoch 16: train_loss=0.109, validation_accuracy=0.9594\n","Epoch 7: train_loss=2.069, validation_accuracy=0.1983\n","Epoch 8: train_loss=2.067, validation_accuracy=0.1989\n","Epoch 9: train_loss=2.064, validation_accuracy=0.2085\n","Epoch 8: train_loss=0.209, validation_accuracy=0.9496\n","Epoch 17: train_loss=0.105, validation_accuracy=0.9594\n","Epoch 15: train_loss=0.101, validation_accuracy=0.9622\n","Epoch 10: train_loss=2.062, validation_accuracy=0.2074\n","\u001b[32m[I 2023-03-07 23:19:22,751]\u001b[0m Trial 130 pruned. \u001b[0m\n","Epoch 9: train_loss=0.192, validation_accuracy=0.9529\n","Epoch 18: train_loss=0.101, validation_accuracy=0.9574\n","Epoch 16: train_loss=0.095, validation_accuracy=0.9631\n","Epoch 1: train_loss=1.776, validation_accuracy=0.8106\n","Epoch 10: train_loss=0.175, validation_accuracy=0.9538\n","\u001b[32m[I 2023-03-07 23:19:23,333]\u001b[0m Trial 129 pruned. \u001b[0m\n","Epoch 2: train_loss=0.597, validation_accuracy=0.8448\n","Epoch 19: train_loss=0.096, validation_accuracy=0.9585\n","Epoch 17: train_loss=0.090, validation_accuracy=0.9610\n","Epoch 3: train_loss=0.481, validation_accuracy=0.8672\n","Epoch 20: train_loss=0.092, validation_accuracy=0.9594\n","Epoch 1: train_loss=2.015, validation_accuracy=0.6288\n","\u001b[32m[I 2023-03-07 23:19:23,711]\u001b[0m Trial 124 finished with value: 0.9594 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 10, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 26, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 34, 'activation_func[4]': 'Tanh', 'lr': 0.008310004212272714, 'momentum': 0.6454615864934776}. Best is trial 59 with value: 0.9652.\u001b[0m\n","Epoch 18: train_loss=0.088, validation_accuracy=0.9634\n","Epoch 4: train_loss=0.420, validation_accuracy=0.8789\n","\u001b[32m[I 2023-03-07 23:19:23,938]\u001b[0m Trial 131 pruned. \u001b[0m\n","Epoch 2: train_loss=1.591, validation_accuracy=0.7380\n","Epoch 1: train_loss=1.903, validation_accuracy=0.8221\n","\u001b[32m[I 2023-03-07 23:19:24,042]\u001b[0m Trial 132 pruned. \u001b[0m\n","Epoch 19: train_loss=0.083, validation_accuracy=0.9655\n","Epoch 1: train_loss=2.319, validation_accuracy=0.0974\n","Epoch 2: train_loss=0.591, validation_accuracy=0.8629\n","Epoch 1: train_loss=1.791, validation_accuracy=0.8069\n","Epoch 20: train_loss=0.078, validation_accuracy=0.9655\n","\u001b[32m[I 2023-03-07 23:19:24,441]\u001b[0m Trial 126 finished with value: 0.9655 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 46, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'Tanh', 'lr': 0.008265709658987918, 'momentum': 0.6583799244653356}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 2: train_loss=2.318, validation_accuracy=0.0974\n","Epoch 3: train_loss=0.468, validation_accuracy=0.8799\n","Epoch 2: train_loss=0.623, validation_accuracy=0.8507\n","Epoch 3: train_loss=2.318, validation_accuracy=0.0974\n","Epoch 1: train_loss=1.325, validation_accuracy=0.8166\n","Epoch 4: train_loss=0.402, validation_accuracy=0.8919\n","Epoch 3: train_loss=0.507, validation_accuracy=0.8748\n","Epoch 4: train_loss=2.318, validation_accuracy=0.0974\n","Epoch 2: train_loss=0.661, validation_accuracy=0.8975\n","Epoch 5: train_loss=0.359, validation_accuracy=0.9019\n","Epoch 4: train_loss=0.442, validation_accuracy=0.8880\n","\u001b[32m[I 2023-03-07 23:19:25,288]\u001b[0m Trial 135 pruned. \u001b[0m\n","Epoch 5: train_loss=2.317, validation_accuracy=0.0974\n","Epoch 6: train_loss=0.328, validation_accuracy=0.9063\n","Epoch 1: train_loss=2.087, validation_accuracy=0.5812\n","Epoch 3: train_loss=0.437, validation_accuracy=0.9213\n","Epoch 6: train_loss=2.317, validation_accuracy=0.0974\n","Epoch 7: train_loss=0.306, validation_accuracy=0.9110\n","Epoch 2: train_loss=1.747, validation_accuracy=0.7410\n","Epoch 7: train_loss=2.317, validation_accuracy=0.0974\n","Epoch 4: train_loss=0.327, validation_accuracy=0.9358\n","Epoch 3: train_loss=1.546, validation_accuracy=0.7929\n","Epoch 8: train_loss=0.287, validation_accuracy=0.9152\n","Epoch 8: train_loss=2.316, validation_accuracy=0.0974\n","Epoch 5: train_loss=0.267, validation_accuracy=0.9422\n","Epoch 4: train_loss=1.380, validation_accuracy=0.8263\n","Epoch 9: train_loss=0.272, validation_accuracy=0.9169\n","Epoch 9: train_loss=2.316, validation_accuracy=0.0974\n","Epoch 5: train_loss=1.233, validation_accuracy=0.8531\n","Epoch 10: train_loss=0.260, validation_accuracy=0.9202\n","Epoch 6: train_loss=0.230, validation_accuracy=0.9488\n","Epoch 10: train_loss=2.316, validation_accuracy=0.0974\n","\u001b[32m[I 2023-03-07 23:19:26,757]\u001b[0m Trial 134 pruned. \u001b[0m\n","Epoch 6: train_loss=1.110, validation_accuracy=0.8666\n","Epoch 11: train_loss=0.249, validation_accuracy=0.9217\n","Epoch 1: train_loss=1.747, validation_accuracy=0.6369\n","Epoch 7: train_loss=0.204, validation_accuracy=0.9488\n","Epoch 7: train_loss=1.009, validation_accuracy=0.8763\n","Epoch 2: train_loss=0.873, validation_accuracy=0.7972\n","Epoch 12: train_loss=0.240, validation_accuracy=0.9227\n","Epoch 8: train_loss=0.922, validation_accuracy=0.8831\n","Epoch 8: train_loss=0.183, validation_accuracy=0.9526\n","Epoch 3: train_loss=0.599, validation_accuracy=0.8438\n","Epoch 13: train_loss=0.233, validation_accuracy=0.9258\n","Epoch 9: train_loss=0.848, validation_accuracy=0.8909\n","Epoch 4: train_loss=0.495, validation_accuracy=0.8724\n","Epoch 9: train_loss=0.169, validation_accuracy=0.9527\n","Epoch 14: train_loss=0.225, validation_accuracy=0.9266\n","Epoch 10: train_loss=0.783, validation_accuracy=0.8952\n","Epoch 5: train_loss=0.434, validation_accuracy=0.8884\n","Epoch 10: train_loss=0.157, validation_accuracy=0.9580\n","Epoch 15: train_loss=0.219, validation_accuracy=0.9274\n","Epoch 11: train_loss=0.727, validation_accuracy=0.8993\n","Epoch 6: train_loss=0.393, validation_accuracy=0.8991\n","Epoch 16: train_loss=0.212, validation_accuracy=0.9299\n","Epoch 12: train_loss=0.678, validation_accuracy=0.9034\n","Epoch 7: train_loss=0.363, validation_accuracy=0.9051\n","Epoch 11: train_loss=0.147, validation_accuracy=0.9550\n","Epoch 8: train_loss=0.340, validation_accuracy=0.9088\n","Epoch 13: train_loss=0.635, validation_accuracy=0.9068\n","Epoch 17: train_loss=0.207, validation_accuracy=0.9318\n","Epoch 12: train_loss=0.140, validation_accuracy=0.9602\n","Epoch 9: train_loss=0.322, validation_accuracy=0.9119\n","Epoch 14: train_loss=0.597, validation_accuracy=0.9102\n","Epoch 18: train_loss=0.202, validation_accuracy=0.9320\n","Epoch 10: train_loss=0.307, validation_accuracy=0.9148\n","Epoch 13: train_loss=0.128, validation_accuracy=0.9597\n","Epoch 15: train_loss=0.564, validation_accuracy=0.9138\n","Epoch 19: train_loss=0.197, validation_accuracy=0.9334\n","Epoch 11: train_loss=0.295, validation_accuracy=0.9187\n","Epoch 16: train_loss=0.534, validation_accuracy=0.9155\n","Epoch 14: train_loss=0.124, validation_accuracy=0.9587\n","Epoch 20: train_loss=0.193, validation_accuracy=0.9334\n","\u001b[32m[I 2023-03-07 23:19:29,734]\u001b[0m Trial 133 finished with value: 0.9334 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 50, 'activation_func[0]': 'ELU', 'lr': 0.00020989776263841521, 'momentum': 0.8435433717663864}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 12: train_loss=0.284, validation_accuracy=0.9215\n","Epoch 17: train_loss=0.507, validation_accuracy=0.9174\n","Epoch 13: train_loss=0.275, validation_accuracy=0.9236\n","Epoch 15: train_loss=0.116, validation_accuracy=0.9583\n","Epoch 1: train_loss=1.452, validation_accuracy=0.8290\n","Epoch 18: train_loss=0.482, validation_accuracy=0.9202\n","Epoch 14: train_loss=0.266, validation_accuracy=0.9239\n","Epoch 16: train_loss=0.109, validation_accuracy=0.9617\n","Epoch 2: train_loss=0.668, validation_accuracy=0.8947\n","Epoch 19: train_loss=0.460, validation_accuracy=0.9228\n","Epoch 15: train_loss=0.259, validation_accuracy=0.9252\n","Epoch 20: train_loss=0.440, validation_accuracy=0.9228\n","\u001b[32m[I 2023-03-07 23:19:30,759]\u001b[0m Trial 137 finished with value: 0.9228 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 24, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 31, 'activation_func[1]': 'Sigmoid', 'lr': 0.0004907016561399186, 'momentum': 0.9368312516144108}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 16: train_loss=0.252, validation_accuracy=0.9275\n","Epoch 3: train_loss=0.430, validation_accuracy=0.9169\n","Epoch 17: train_loss=0.105, validation_accuracy=0.9633\n","Epoch 1: train_loss=1.749, validation_accuracy=0.8156\n","Epoch 17: train_loss=0.246, validation_accuracy=0.9286\n","Epoch 18: train_loss=0.102, validation_accuracy=0.9626\n","Epoch 4: train_loss=0.326, validation_accuracy=0.9328\n","Epoch 2: train_loss=0.506, validation_accuracy=0.8739\n","Epoch 18: train_loss=0.240, validation_accuracy=0.9307\n","Epoch 5: train_loss=0.273, validation_accuracy=0.9417\n","Epoch 19: train_loss=0.098, validation_accuracy=0.9626\n","Epoch 3: train_loss=0.399, validation_accuracy=0.8918\n","Epoch 19: train_loss=0.235, validation_accuracy=0.9318\n","Epoch 4: train_loss=0.347, validation_accuracy=0.9062\n","Epoch 20: train_loss=0.230, validation_accuracy=0.9322\n","\u001b[32m[I 2023-03-07 23:19:31,898]\u001b[0m Trial 138 finished with value: 0.9322 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 21, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'lr': 0.000456411044088754, 'momentum': 0.724147752448436}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 20: train_loss=0.093, validation_accuracy=0.9622\n","\u001b[32m[I 2023-03-07 23:19:31,948]\u001b[0m Trial 136 finished with value: 0.9622 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'Tanh', 'lr': 0.008162210310646486, 'momentum': 0.6513712122667923}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 6: train_loss=0.233, validation_accuracy=0.9428\n","Epoch 5: train_loss=0.314, validation_accuracy=0.9134\n","Epoch 1: train_loss=2.541, validation_accuracy=0.7606\n","Epoch 7: train_loss=0.208, validation_accuracy=0.9460\n","Epoch 1: train_loss=1.273, validation_accuracy=0.8638\n","Epoch 6: train_loss=0.293, validation_accuracy=0.9126\n","Epoch 2: train_loss=0.777, validation_accuracy=0.8189\n","Epoch 8: train_loss=0.187, validation_accuracy=0.9501\n","Epoch 7: train_loss=0.278, validation_accuracy=0.9179\n","Epoch 2: train_loss=0.551, validation_accuracy=0.9102\n","Epoch 3: train_loss=0.617, validation_accuracy=0.8484\n","Epoch 8: train_loss=0.265, validation_accuracy=0.9190\n","Epoch 9: train_loss=0.172, validation_accuracy=0.9521\n","Epoch 3: train_loss=0.361, validation_accuracy=0.9299\n","Epoch 4: train_loss=0.533, validation_accuracy=0.8642\n","\u001b[32m[I 2023-03-07 23:19:33,134]\u001b[0m Trial 141 pruned. \u001b[0m\n","Epoch 9: train_loss=0.255, validation_accuracy=0.9223\n","Epoch 10: train_loss=0.159, validation_accuracy=0.9504\n","\u001b[32m[I 2023-03-07 23:19:33,455]\u001b[0m Trial 139 pruned. \u001b[0m\n","Epoch 4: train_loss=0.280, validation_accuracy=0.9400\n","Epoch 10: train_loss=0.245, validation_accuracy=0.9243\n","Epoch 1: train_loss=1.434, validation_accuracy=0.8207\n","Epoch 1: train_loss=1.850, validation_accuracy=0.5625\n","Epoch 11: train_loss=0.238, validation_accuracy=0.9274\n","Epoch 5: train_loss=0.233, validation_accuracy=0.9465\n","Epoch 2: train_loss=1.030, validation_accuracy=0.7735\n","Epoch 2: train_loss=0.756, validation_accuracy=0.8656\n","Epoch 12: train_loss=0.231, validation_accuracy=0.9275\n","Epoch 3: train_loss=0.672, validation_accuracy=0.8306\n","Epoch 6: train_loss=0.200, validation_accuracy=0.9496\n","Epoch 13: train_loss=0.224, validation_accuracy=0.9302\n","Epoch 3: train_loss=0.507, validation_accuracy=0.9058\n","Epoch 4: train_loss=0.534, validation_accuracy=0.8539\n","Epoch 7: train_loss=0.175, validation_accuracy=0.9523\n","Epoch 14: train_loss=0.219, validation_accuracy=0.9318\n","Epoch 5: train_loss=0.468, validation_accuracy=0.8722\n","Epoch 4: train_loss=0.385, validation_accuracy=0.9242\n","\u001b[32m[I 2023-03-07 23:19:34,790]\u001b[0m Trial 143 pruned. \u001b[0m\n","Epoch 15: train_loss=0.213, validation_accuracy=0.9306\n","Epoch 6: train_loss=0.427, validation_accuracy=0.8814\n","Epoch 8: train_loss=0.157, validation_accuracy=0.9556\n","Epoch 7: train_loss=0.396, validation_accuracy=0.8897\n","Epoch 16: train_loss=0.208, validation_accuracy=0.9337\n","Epoch 1: train_loss=1.388, validation_accuracy=0.8572\n","Epoch 9: train_loss=0.144, validation_accuracy=0.9558\n","Epoch 8: train_loss=0.374, validation_accuracy=0.8969\n","Epoch 17: train_loss=0.202, validation_accuracy=0.9358\n","Epoch 2: train_loss=0.626, validation_accuracy=0.9083\n","Epoch 9: train_loss=0.354, validation_accuracy=0.9013\n","Epoch 10: train_loss=0.133, validation_accuracy=0.9612\n","Epoch 18: train_loss=0.199, validation_accuracy=0.9350\n","Epoch 10: train_loss=0.338, validation_accuracy=0.9043\n","Epoch 3: train_loss=0.410, validation_accuracy=0.9276\n","Epoch 19: train_loss=0.194, validation_accuracy=0.9328\n","Epoch 11: train_loss=0.122, validation_accuracy=0.9573\n","Epoch 11: train_loss=0.325, validation_accuracy=0.9070\n","Epoch 4: train_loss=0.314, validation_accuracy=0.9387\n","Epoch 20: train_loss=0.192, validation_accuracy=0.9369\n","\u001b[32m[I 2023-03-07 23:19:36,352]\u001b[0m Trial 140 finished with value: 0.9369 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 45, 'activation_func[0]': 'ELU', 'lr': 0.0004089741024349859, 'momentum': 0.910470212088267}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 12: train_loss=0.314, validation_accuracy=0.9097\n","Epoch 12: train_loss=0.114, validation_accuracy=0.9609\n","Epoch 13: train_loss=0.303, validation_accuracy=0.9125\n","Epoch 5: train_loss=0.264, validation_accuracy=0.9428\n","Epoch 1: train_loss=1.504, validation_accuracy=0.7829\n","Epoch 14: train_loss=0.294, validation_accuracy=0.9154\n","Epoch 13: train_loss=0.108, validation_accuracy=0.9627\n","Epoch 15: train_loss=0.286, validation_accuracy=0.9168\n","Epoch 6: train_loss=0.226, validation_accuracy=0.9473\n","Epoch 2: train_loss=0.732, validation_accuracy=0.8808\n","Epoch 14: train_loss=0.100, validation_accuracy=0.9623\n","Epoch 16: train_loss=0.279, validation_accuracy=0.9174\n","Epoch 7: train_loss=0.202, validation_accuracy=0.9455\n","Epoch 17: train_loss=0.272, validation_accuracy=0.9191\n","Epoch 3: train_loss=0.487, validation_accuracy=0.9131\n","Epoch 15: train_loss=0.096, validation_accuracy=0.9647\n","Epoch 18: train_loss=0.265, validation_accuracy=0.9207\n","Epoch 8: train_loss=0.181, validation_accuracy=0.9545\n","Epoch 4: train_loss=0.378, validation_accuracy=0.9205\n","\u001b[32m[I 2023-03-07 23:19:38,173]\u001b[0m Trial 146 pruned. \u001b[0m\n","Epoch 19: train_loss=0.260, validation_accuracy=0.9221\n","Epoch 16: train_loss=0.090, validation_accuracy=0.9649\n","Epoch 20: train_loss=0.254, validation_accuracy=0.9216\n","\u001b[32m[I 2023-03-07 23:19:38,436]\u001b[0m Trial 144 finished with value: 0.9216 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 20, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'lr': 0.00039899442779022177, 'momentum': 0.7227746868443019}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 1: train_loss=1.256, validation_accuracy=0.7849\n","Epoch 9: train_loss=0.169, validation_accuracy=0.9557\n","Epoch 17: train_loss=0.086, validation_accuracy=0.9638\n","Epoch 2: train_loss=0.724, validation_accuracy=0.8090\n","Epoch 1: train_loss=1.366, validation_accuracy=0.8454\n","Epoch 10: train_loss=0.151, validation_accuracy=0.9553\n","\u001b[32m[I 2023-03-07 23:19:38,863]\u001b[0m Trial 145 pruned. \u001b[0m\n","Epoch 3: train_loss=1.272, validation_accuracy=0.3670\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9632\n","Epoch 1: train_loss=1.693, validation_accuracy=0.7789\n","Epoch 4: train_loss=1.922, validation_accuracy=0.2826\n","Epoch 2: train_loss=0.653, validation_accuracy=0.9052\n","Epoch 19: train_loss=0.080, validation_accuracy=0.9661\n","Epoch 5: train_loss=2.386, validation_accuracy=0.1032\n","Epoch 2: train_loss=0.662, validation_accuracy=0.8457\n","Epoch 3: train_loss=0.435, validation_accuracy=0.9256\n","Epoch 6: train_loss=2.436, validation_accuracy=0.1032\n","Epoch 20: train_loss=0.075, validation_accuracy=0.9648\n","Epoch 3: train_loss=0.522, validation_accuracy=0.8658\n","\u001b[32m[I 2023-03-07 23:19:39,788]\u001b[0m Trial 142 finished with value: 0.9648 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 46, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'Tanh', 'lr': 0.008137574223992208, 'momentum': 0.6461318317031466}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 7: train_loss=2.347, validation_accuracy=0.0980\n","Epoch 1: train_loss=1.576, validation_accuracy=0.8413\n","Epoch 4: train_loss=0.338, validation_accuracy=0.9348\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8819\n","\u001b[32m[I 2023-03-07 23:19:40,109]\u001b[0m Trial 149 pruned. \u001b[0m\n","Epoch 8: train_loss=2.393, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.489, validation_accuracy=0.8861\n","Epoch 9: train_loss=2.411, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.281, validation_accuracy=0.9401\n","Epoch 3: train_loss=0.383, validation_accuracy=0.9038\n","Epoch 1: train_loss=1.313, validation_accuracy=0.8513\n","Epoch 10: train_loss=2.343, validation_accuracy=0.1009\n","\u001b[32m[I 2023-03-07 23:19:40,644]\u001b[0m Trial 147 pruned. \u001b[0m\n","Epoch 4: train_loss=0.328, validation_accuracy=0.9140\n","Epoch 6: train_loss=0.244, validation_accuracy=0.9445\n","Epoch 5: train_loss=0.289, validation_accuracy=0.9206\n","Epoch 1: train_loss=1.519, validation_accuracy=0.8655\n","Epoch 2: train_loss=0.566, validation_accuracy=0.9110\n","Epoch 6: train_loss=0.263, validation_accuracy=0.9261\n","Epoch 7: train_loss=0.217, validation_accuracy=0.9450\n","Epoch 2: train_loss=0.414, validation_accuracy=0.9054\n","Epoch 7: train_loss=0.244, validation_accuracy=0.9294\n","Epoch 3: train_loss=0.374, validation_accuracy=0.9264\n","Epoch 3: train_loss=0.323, validation_accuracy=0.9198\n","Epoch 8: train_loss=0.229, validation_accuracy=0.9355\n","Epoch 8: train_loss=0.197, validation_accuracy=0.9506\n","Epoch 4: train_loss=0.298, validation_accuracy=0.9352\n","Epoch 9: train_loss=0.219, validation_accuracy=0.9348\n","Epoch 4: train_loss=0.283, validation_accuracy=0.9232\n","Epoch 9: train_loss=0.182, validation_accuracy=0.9540\n","Epoch 10: train_loss=0.210, validation_accuracy=0.9364\n","Epoch 5: train_loss=0.257, validation_accuracy=0.9270\n","Epoch 5: train_loss=0.252, validation_accuracy=0.9414\n","Epoch 11: train_loss=0.201, validation_accuracy=0.9364\n","Epoch 10: train_loss=0.167, validation_accuracy=0.9537\n","\u001b[32m[I 2023-03-07 23:19:42,419]\u001b[0m Trial 148 pruned. \u001b[0m\n","Epoch 6: train_loss=0.241, validation_accuracy=0.9308\n","Epoch 12: train_loss=0.195, validation_accuracy=0.9361\n","Epoch 6: train_loss=0.219, validation_accuracy=0.9415\n","Epoch 1: train_loss=1.633, validation_accuracy=0.6769\n","Epoch 13: train_loss=0.190, validation_accuracy=0.9399\n","Epoch 7: train_loss=0.227, validation_accuracy=0.9353\n","Epoch 2: train_loss=0.887, validation_accuracy=0.7936\n","Epoch 14: train_loss=0.185, validation_accuracy=0.9398\n","Epoch 7: train_loss=0.194, validation_accuracy=0.9476\n","Epoch 8: train_loss=0.217, validation_accuracy=0.9355\n","Epoch 15: train_loss=0.180, validation_accuracy=0.9389\n","Epoch 3: train_loss=0.652, validation_accuracy=0.8370\n","Epoch 8: train_loss=0.178, validation_accuracy=0.9487\n","Epoch 16: train_loss=0.176, validation_accuracy=0.9404\n","Epoch 9: train_loss=0.208, validation_accuracy=0.9367\n","Epoch 4: train_loss=0.548, validation_accuracy=0.8595\n","Epoch 17: train_loss=0.173, validation_accuracy=0.9412\n","Epoch 10: train_loss=0.201, validation_accuracy=0.9392\n","Epoch 5: train_loss=0.487, validation_accuracy=0.8731\n","Epoch 9: train_loss=0.162, validation_accuracy=0.9511\n","Epoch 18: train_loss=0.168, validation_accuracy=0.9418\n","Epoch 6: train_loss=0.444, validation_accuracy=0.8841\n","Epoch 11: train_loss=0.195, validation_accuracy=0.9396\n","Epoch 19: train_loss=0.166, validation_accuracy=0.9416\n","Epoch 10: train_loss=0.150, validation_accuracy=0.9534\n","\u001b[32m[I 2023-03-07 23:19:44,257]\u001b[0m Trial 151 pruned. \u001b[0m\n","Epoch 20: train_loss=0.163, validation_accuracy=0.9445\n","\u001b[32m[I 2023-03-07 23:19:44,328]\u001b[0m Trial 150 finished with value: 0.9445 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 46, 'activation_func[0]': 'ReLU', 'lr': 0.0004007049523305083, 'momentum': 0.87931824065642}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 7: train_loss=0.411, validation_accuracy=0.8931\n","Epoch 12: train_loss=0.189, validation_accuracy=0.9402\n","Epoch 1: train_loss=1.476, validation_accuracy=0.8452\n","Epoch 8: train_loss=0.383, validation_accuracy=0.8986\n","Epoch 13: train_loss=0.184, validation_accuracy=0.9426\n","Epoch 1: train_loss=1.671, validation_accuracy=0.7284\n","Epoch 2: train_loss=0.463, validation_accuracy=0.8885\n","Epoch 9: train_loss=0.360, validation_accuracy=0.9042\n","Epoch 3: train_loss=0.362, validation_accuracy=0.9037\n","Epoch 14: train_loss=0.179, validation_accuracy=0.9416\n","Epoch 10: train_loss=0.340, validation_accuracy=0.9103\n","Epoch 2: train_loss=0.999, validation_accuracy=0.8033\n","\u001b[32m[I 2023-03-07 23:19:45,222]\u001b[0m Trial 154 pruned. \u001b[0m\n","Epoch 4: train_loss=0.311, validation_accuracy=0.9117\n","Epoch 15: train_loss=0.175, validation_accuracy=0.9405\n","Epoch 5: train_loss=0.282, validation_accuracy=0.9172\n","Epoch 11: train_loss=0.324, validation_accuracy=0.9123\n","Epoch 1: train_loss=2.187, validation_accuracy=0.2997\n","Epoch 6: train_loss=0.263, validation_accuracy=0.9219\n","Epoch 16: train_loss=0.171, validation_accuracy=0.9434\n","Epoch 2: train_loss=2.006, validation_accuracy=0.5001\n","Epoch 12: train_loss=0.310, validation_accuracy=0.9139\n","Epoch 7: train_loss=0.247, validation_accuracy=0.9253\n","Epoch 3: train_loss=1.912, validation_accuracy=0.5839\n","Epoch 17: train_loss=0.168, validation_accuracy=0.9450\n","Epoch 8: train_loss=0.235, validation_accuracy=0.9264\n","Epoch 13: train_loss=0.298, validation_accuracy=0.9176\n","Epoch 4: train_loss=1.848, validation_accuracy=0.6360\n","\u001b[32m[I 2023-03-07 23:19:46,208]\u001b[0m Trial 156 pruned. \u001b[0m\n","Epoch 9: train_loss=0.227, validation_accuracy=0.9287\n","Epoch 14: train_loss=0.288, validation_accuracy=0.9194\n","Epoch 18: train_loss=0.164, validation_accuracy=0.9448\n","Epoch 10: train_loss=0.219, validation_accuracy=0.9290\n","Epoch 1: train_loss=3.953, validation_accuracy=0.2825\n","Epoch 15: train_loss=0.279, validation_accuracy=0.9206\n","Epoch 19: train_loss=0.162, validation_accuracy=0.9462\n","Epoch 2: train_loss=1.527, validation_accuracy=0.4389\n","Epoch 11: train_loss=0.212, validation_accuracy=0.9318\n","Epoch 16: train_loss=0.271, validation_accuracy=0.9229\n","Epoch 3: train_loss=1.283, validation_accuracy=0.5629\n","Epoch 12: train_loss=0.206, validation_accuracy=0.9317\n","Epoch 20: train_loss=0.158, validation_accuracy=0.9439\n","\u001b[32m[I 2023-03-07 23:19:47,006]\u001b[0m Trial 152 finished with value: 0.9439 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 50, 'activation_func[0]': 'ELU', 'lr': 0.0006607313297281074, 'momentum': 0.7969477998316671}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 4: train_loss=1.090, validation_accuracy=0.6643\n","\u001b[32m[I 2023-03-07 23:19:47,138]\u001b[0m Trial 157 pruned. \u001b[0m\n","Epoch 13: train_loss=0.201, validation_accuracy=0.9335\n","Epoch 17: train_loss=0.264, validation_accuracy=0.9218\n","Epoch 1: train_loss=2.170, validation_accuracy=0.7962\n","Epoch 14: train_loss=0.196, validation_accuracy=0.9349\n","Epoch 18: train_loss=0.257, validation_accuracy=0.9243\n","Epoch 1: train_loss=2.673, validation_accuracy=0.8180\n","Epoch 2: train_loss=0.604, validation_accuracy=0.8633\n","Epoch 15: train_loss=0.191, validation_accuracy=0.9351\n","Epoch 19: train_loss=0.251, validation_accuracy=0.9261\n","Epoch 2: train_loss=0.516, validation_accuracy=0.8674\n","Epoch 16: train_loss=0.188, validation_accuracy=0.9363\n","Epoch 3: train_loss=0.435, validation_accuracy=0.8898\n","Epoch 20: train_loss=0.245, validation_accuracy=0.9283\n","\u001b[32m[I 2023-03-07 23:19:47,950]\u001b[0m Trial 153 finished with value: 0.9283 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 23, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 21, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 18, 'activation_func[2]': 'ELU', 'lr': 0.00042318833624814317, 'momentum': 0.7287583433429589}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 3: train_loss=0.415, validation_accuracy=0.8887\n","Epoch 17: train_loss=0.184, validation_accuracy=0.9369\n","Epoch 4: train_loss=0.367, validation_accuracy=0.8950\n","Epoch 18: train_loss=0.182, validation_accuracy=0.9376\n","Epoch 4: train_loss=0.361, validation_accuracy=0.9011\n","Epoch 5: train_loss=0.334, validation_accuracy=0.9026\n","Epoch 1: train_loss=1.735, validation_accuracy=0.6662\n","Epoch 19: train_loss=0.179, validation_accuracy=0.9374\n","Epoch 6: train_loss=0.313, validation_accuracy=0.9075\n","Epoch 5: train_loss=0.327, validation_accuracy=0.9075\n","Epoch 20: train_loss=0.176, validation_accuracy=0.9374\n","\u001b[32m[I 2023-03-07 23:19:48,674]\u001b[0m Trial 155 finished with value: 0.9374 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 36, 'activation_func[0]': 'ReLU', 'lr': 0.0003757333867263483, 'momentum': 0.8850671939316312}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 7: train_loss=0.299, validation_accuracy=0.9104\n","Epoch 6: train_loss=0.303, validation_accuracy=0.9144\n","Epoch 2: train_loss=0.840, validation_accuracy=0.7843\n","Epoch 8: train_loss=0.287, validation_accuracy=0.9143\n","Epoch 7: train_loss=0.286, validation_accuracy=0.9191\n","Epoch 1: train_loss=1.298, validation_accuracy=0.8153\n","Epoch 3: train_loss=0.607, validation_accuracy=0.8372\n","Epoch 9: train_loss=0.278, validation_accuracy=0.9136\n","Epoch 8: train_loss=0.272, validation_accuracy=0.9211\n","Epoch 10: train_loss=0.269, validation_accuracy=0.9189\n","\u001b[32m[I 2023-03-07 23:19:49,507]\u001b[0m Trial 158 pruned. \u001b[0m\n","Epoch 2: train_loss=0.608, validation_accuracy=0.8996\n","Epoch 4: train_loss=0.500, validation_accuracy=0.8629\n","\u001b[32m[I 2023-03-07 23:19:49,656]\u001b[0m Trial 160 pruned. \u001b[0m\n","Epoch 9: train_loss=0.263, validation_accuracy=0.9218\n","Epoch 1: train_loss=2.114, validation_accuracy=0.5208\n","Epoch 3: train_loss=0.391, validation_accuracy=0.9248\n","Epoch 1: train_loss=1.475, validation_accuracy=0.7441\n","Epoch 10: train_loss=0.256, validation_accuracy=0.9219\n","\u001b[32m[I 2023-03-07 23:19:49,940]\u001b[0m Trial 159 pruned. \u001b[0m\n","Epoch 2: train_loss=1.174, validation_accuracy=0.6255\n","Epoch 1: train_loss=1.737, validation_accuracy=0.8204\n","Epoch 3: train_loss=0.966, validation_accuracy=0.6923\n","Epoch 4: train_loss=0.292, validation_accuracy=0.9406\n","Epoch 2: train_loss=0.806, validation_accuracy=0.8488\n","\u001b[32m[I 2023-03-07 23:19:50,301]\u001b[0m Trial 162 pruned. \u001b[0m\n","Epoch 2: train_loss=0.499, validation_accuracy=0.8829\n","Epoch 4: train_loss=0.809, validation_accuracy=0.8073\n","\u001b[32m[I 2023-03-07 23:19:50,496]\u001b[0m Trial 163 pruned. \u001b[0m\n","Epoch 3: train_loss=0.388, validation_accuracy=0.8988\n","Epoch 5: train_loss=0.237, validation_accuracy=0.9462\n","Epoch 1: train_loss=1.182, validation_accuracy=0.8817\n","Epoch 4: train_loss=0.341, validation_accuracy=0.9097\n","Epoch 1: train_loss=1.468, validation_accuracy=0.7893\n","Epoch 6: train_loss=0.200, validation_accuracy=0.9469\n","Epoch 5: train_loss=0.309, validation_accuracy=0.9159\n","Epoch 2: train_loss=0.441, validation_accuracy=0.9244\n","Epoch 2: train_loss=0.708, validation_accuracy=0.8866\n","Epoch 6: train_loss=0.283, validation_accuracy=0.9248\n","Epoch 7: train_loss=0.178, validation_accuracy=0.9545\n","Epoch 7: train_loss=0.263, validation_accuracy=0.9300\n","Epoch 3: train_loss=0.298, validation_accuracy=0.9378\n","Epoch 3: train_loss=0.485, validation_accuracy=0.9028\n","Epoch 8: train_loss=0.246, validation_accuracy=0.9322\n","Epoch 8: train_loss=0.159, validation_accuracy=0.9570\n","Epoch 4: train_loss=0.237, validation_accuracy=0.9283\n","\u001b[32m[I 2023-03-07 23:19:51,939]\u001b[0m Trial 165 pruned. \u001b[0m\n","Epoch 9: train_loss=0.235, validation_accuracy=0.9349\n","Epoch 4: train_loss=0.378, validation_accuracy=0.9214\n","\u001b[32m[I 2023-03-07 23:19:52,059]\u001b[0m Trial 166 pruned. \u001b[0m\n","Epoch 9: train_loss=0.145, validation_accuracy=0.9598\n","Epoch 10: train_loss=0.224, validation_accuracy=0.9353\n","Epoch 1: train_loss=4.690, validation_accuracy=0.5002\n","Epoch 11: train_loss=0.218, validation_accuracy=0.9361\n","Epoch 1: train_loss=2.288, validation_accuracy=0.3122\n","Epoch 2: train_loss=0.980, validation_accuracy=0.7858\n","Epoch 10: train_loss=0.133, validation_accuracy=0.9605\n","Epoch 12: train_loss=0.210, validation_accuracy=0.9391\n","Epoch 3: train_loss=0.605, validation_accuracy=0.8639\n","Epoch 2: train_loss=2.254, validation_accuracy=0.3878\n","\u001b[32m[I 2023-03-07 23:19:52,885]\u001b[0m Trial 168 pruned. \u001b[0m\n","Epoch 13: train_loss=0.205, validation_accuracy=0.9380\n","Epoch 11: train_loss=0.123, validation_accuracy=0.9627\n","Epoch 4: train_loss=0.472, validation_accuracy=0.8844\n","\u001b[32m[I 2023-03-07 23:19:53,055]\u001b[0m Trial 167 pruned. \u001b[0m\n","Epoch 14: train_loss=0.201, validation_accuracy=0.9406\n","Epoch 1: train_loss=1.061, validation_accuracy=0.8771\n","Epoch 12: train_loss=0.116, validation_accuracy=0.9621\n","Epoch 15: train_loss=0.196, validation_accuracy=0.9412\n","Epoch 2: train_loss=0.357, validation_accuracy=0.9088\n","Epoch 1: train_loss=1.027, validation_accuracy=0.8838\n","Epoch 16: train_loss=0.193, validation_accuracy=0.9420\n","Epoch 13: train_loss=0.108, validation_accuracy=0.9589\n","Epoch 3: train_loss=0.286, validation_accuracy=0.9181\n","Epoch 17: train_loss=0.188, validation_accuracy=0.9435\n","Epoch 2: train_loss=0.355, validation_accuracy=0.9194\n","Epoch 18: train_loss=0.185, validation_accuracy=0.9414\n","Epoch 4: train_loss=0.252, validation_accuracy=0.9245\n","Epoch 14: train_loss=0.103, validation_accuracy=0.9636\n","Epoch 3: train_loss=0.262, validation_accuracy=0.9197\n","Epoch 19: train_loss=0.182, validation_accuracy=0.9438\n","Epoch 5: train_loss=0.231, validation_accuracy=0.9292\n","Epoch 20: train_loss=0.178, validation_accuracy=0.9406\n","\u001b[32m[I 2023-03-07 23:19:54,514]\u001b[0m Trial 164 finished with value: 0.9406 and parameters: {'n_hidden_layers': 1, 'hidden_dim[0]': 49, 'activation_func[0]': 'ReLU', 'lr': 0.0005056260893033202, 'momentum': 0.9218583173356908}. Best is trial 126 with value: 0.9655.\u001b[0m\n","Epoch 15: train_loss=0.098, validation_accuracy=0.9637\n","Epoch 4: train_loss=0.209, validation_accuracy=0.9339\n","Epoch 6: train_loss=0.215, validation_accuracy=0.9335\n","Epoch 16: train_loss=0.093, validation_accuracy=0.9652\n","Epoch 1: train_loss=1.599, validation_accuracy=0.7776\n","Epoch 7: train_loss=0.203, validation_accuracy=0.9359\n","Epoch 5: train_loss=0.184, validation_accuracy=0.9466\n","Epoch 8: train_loss=0.193, validation_accuracy=0.9375\n","Epoch 17: train_loss=0.086, validation_accuracy=0.9661\n","Epoch 2: train_loss=0.919, validation_accuracy=0.8678\n","\u001b[32m[I 2023-03-07 23:19:55,302]\u001b[0m Trial 171 pruned. \u001b[0m\n","Epoch 6: train_loss=0.165, validation_accuracy=0.9503\n","Epoch 1: train_loss=2.121, validation_accuracy=0.3684\n","Epoch 9: train_loss=0.185, validation_accuracy=0.9409\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9644\n","Epoch 2: train_loss=1.501, validation_accuracy=0.4803\n","Epoch 7: train_loss=0.148, validation_accuracy=0.9524\n","Epoch 10: train_loss=0.178, validation_accuracy=0.9422\n","Epoch 3: train_loss=1.257, validation_accuracy=0.5230\n","Epoch 19: train_loss=0.078, validation_accuracy=0.9652\n","Epoch 8: train_loss=0.137, validation_accuracy=0.9562\n","Epoch 11: train_loss=0.171, validation_accuracy=0.9432\n","Epoch 4: train_loss=1.135, validation_accuracy=0.5631\n","Epoch 5: train_loss=1.041, validation_accuracy=0.6126\n","Epoch 20: train_loss=0.077, validation_accuracy=0.9665\n","\u001b[32m[I 2023-03-07 23:19:56,432]\u001b[0m Trial 161 finished with value: 0.9665 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 43, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 11, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 30, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 33, 'activation_func[4]': 'Tanh', 'lr': 0.008498913760151463, 'momentum': 0.6533483251125577}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 12: train_loss=0.165, validation_accuracy=0.9442\n","Epoch 9: train_loss=0.126, validation_accuracy=0.9558\n","Epoch 6: train_loss=0.968, validation_accuracy=0.6819\n","Epoch 7: train_loss=0.885, validation_accuracy=0.7301\n","Epoch 13: train_loss=0.160, validation_accuracy=0.9447\n","Epoch 1: train_loss=2.320, validation_accuracy=0.1009\n","Epoch 10: train_loss=0.117, validation_accuracy=0.9610\n","Epoch 8: train_loss=0.765, validation_accuracy=0.7664\n","Epoch 14: train_loss=0.156, validation_accuracy=0.9457\n","Epoch 9: train_loss=0.677, validation_accuracy=0.7964\n","Epoch 2: train_loss=2.300, validation_accuracy=0.1530\n","\u001b[32m[I 2023-03-07 23:19:57,252]\u001b[0m Trial 173 pruned. \u001b[0m\n","Epoch 11: train_loss=0.112, validation_accuracy=0.9537\n","Epoch 10: train_loss=0.614, validation_accuracy=0.8191\n","\u001b[32m[I 2023-03-07 23:19:57,411]\u001b[0m Trial 172 pruned. \u001b[0m\n","Epoch 15: train_loss=0.152, validation_accuracy=0.9465\n","Epoch 1: train_loss=2.102, validation_accuracy=0.5627\n","Epoch 16: train_loss=0.149, validation_accuracy=0.9465\n","Epoch 2: train_loss=1.794, validation_accuracy=0.7030\n","Epoch 12: train_loss=0.105, validation_accuracy=0.9582\n","Epoch 1: train_loss=0.944, validation_accuracy=0.8860\n","Epoch 3: train_loss=1.650, validation_accuracy=0.7689\n","Epoch 17: train_loss=0.144, validation_accuracy=0.9491\n","Epoch 2: train_loss=0.321, validation_accuracy=0.9204\n","Epoch 13: train_loss=0.099, validation_accuracy=0.9615\n","Epoch 4: train_loss=1.538, validation_accuracy=0.8069\n","\u001b[32m[I 2023-03-07 23:19:58,239]\u001b[0m Trial 174 pruned. \u001b[0m\n","Epoch 18: train_loss=0.141, validation_accuracy=0.9484\n","Epoch 3: train_loss=0.237, validation_accuracy=0.9340\n","Epoch 1: train_loss=1.848, validation_accuracy=0.7338\n","Epoch 14: train_loss=0.094, validation_accuracy=0.9588\n","Epoch 19: train_loss=0.138, validation_accuracy=0.9484\n","Epoch 2: train_loss=0.597, validation_accuracy=0.8622\n","Epoch 4: train_loss=0.197, validation_accuracy=0.9427\n","Epoch 15: train_loss=0.123, validation_accuracy=0.9597\n","Epoch 20: train_loss=0.135, validation_accuracy=0.9489\n","\u001b[32m[I 2023-03-07 23:19:59,006]\u001b[0m Trial 169 finished with value: 0.9489 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ReLU', 'lr': 0.0006929851924567755, 'momentum': 0.8838667014717813}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 3: train_loss=0.435, validation_accuracy=0.8893\n","Epoch 5: train_loss=0.168, validation_accuracy=0.9465\n","Epoch 1: train_loss=2.029, validation_accuracy=0.6604\n","Epoch 4: train_loss=0.358, validation_accuracy=0.9028\n","Epoch 16: train_loss=0.087, validation_accuracy=0.9613\n","Epoch 6: train_loss=0.149, validation_accuracy=0.9491\n","Epoch 2: train_loss=1.364, validation_accuracy=0.7770\n","Epoch 5: train_loss=0.317, validation_accuracy=0.9120\n","Epoch 17: train_loss=0.083, validation_accuracy=0.9618\n","Epoch 3: train_loss=0.837, validation_accuracy=0.8657\n","Epoch 7: train_loss=0.135, validation_accuracy=0.9509\n","Epoch 6: train_loss=0.294, validation_accuracy=0.9156\n","Epoch 4: train_loss=0.570, validation_accuracy=0.9001\n","Epoch 18: train_loss=0.078, validation_accuracy=0.9628\n","Epoch 7: train_loss=0.275, validation_accuracy=0.9195\n","Epoch 8: train_loss=0.124, validation_accuracy=0.9527\n","Epoch 5: train_loss=0.442, validation_accuracy=0.9100\n","Epoch 8: train_loss=0.263, validation_accuracy=0.9215\n","Epoch 6: train_loss=0.363, validation_accuracy=0.9215\n","Epoch 19: train_loss=0.075, validation_accuracy=0.9616\n","Epoch 9: train_loss=0.115, validation_accuracy=0.9559\n","Epoch 9: train_loss=0.251, validation_accuracy=0.9230\n","Epoch 7: train_loss=0.313, validation_accuracy=0.9286\n","Epoch 10: train_loss=0.110, validation_accuracy=0.9581\n","Epoch 20: train_loss=0.073, validation_accuracy=0.9622\n","\u001b[32m[I 2023-03-07 23:20:00,879]\u001b[0m Trial 170 finished with value: 0.9622 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 17, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 27, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ELU', 'lr': 0.00832540216340496, 'momentum': 0.609343115085427}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 10: train_loss=0.242, validation_accuracy=0.9259\n","\u001b[32m[I 2023-03-07 23:20:00,905]\u001b[0m Trial 176 pruned. \u001b[0m\n","Epoch 8: train_loss=0.279, validation_accuracy=0.9302\n","Epoch 11: train_loss=0.101, validation_accuracy=0.9585\n","Epoch 9: train_loss=0.257, validation_accuracy=0.9319\n","Epoch 1: train_loss=0.969, validation_accuracy=0.8847\n","Epoch 1: train_loss=0.844, validation_accuracy=0.8997\n","Epoch 10: train_loss=0.239, validation_accuracy=0.9341\n","Epoch 12: train_loss=0.095, validation_accuracy=0.9575\n","Epoch 2: train_loss=0.348, validation_accuracy=0.9099\n","Epoch 2: train_loss=0.283, validation_accuracy=0.9350\n","Epoch 11: train_loss=0.225, validation_accuracy=0.9379\n","Epoch 3: train_loss=0.283, validation_accuracy=0.9232\n","Epoch 13: train_loss=0.091, validation_accuracy=0.9602\n","Epoch 12: train_loss=0.217, validation_accuracy=0.9376\n","Epoch 3: train_loss=0.212, validation_accuracy=0.9439\n","Epoch 4: train_loss=0.246, validation_accuracy=0.9296\n","Epoch 13: train_loss=0.205, validation_accuracy=0.9392\n","Epoch 14: train_loss=0.085, validation_accuracy=0.9631\n","Epoch 5: train_loss=0.221, validation_accuracy=0.9346\n","Epoch 14: train_loss=0.197, validation_accuracy=0.9402\n","Epoch 4: train_loss=0.182, validation_accuracy=0.9460\n","Epoch 15: train_loss=0.081, validation_accuracy=0.9609\n","Epoch 15: train_loss=0.188, validation_accuracy=0.9417\n","Epoch 6: train_loss=0.202, validation_accuracy=0.9391\n","Epoch 16: train_loss=0.075, validation_accuracy=0.9603\n","Epoch 5: train_loss=0.161, validation_accuracy=0.9423\n","Epoch 16: train_loss=0.184, validation_accuracy=0.9431\n","Epoch 7: train_loss=0.187, validation_accuracy=0.9415\n","Epoch 17: train_loss=0.178, validation_accuracy=0.9478\n","Epoch 17: train_loss=0.073, validation_accuracy=0.9610\n","Epoch 6: train_loss=0.146, validation_accuracy=0.9482\n","Epoch 8: train_loss=0.177, validation_accuracy=0.9442\n","Epoch 18: train_loss=0.170, validation_accuracy=0.9464\n","Epoch 18: train_loss=0.072, validation_accuracy=0.9630\n","Epoch 9: train_loss=0.167, validation_accuracy=0.9447\n","Epoch 19: train_loss=0.168, validation_accuracy=0.9501\n","Epoch 7: train_loss=0.133, validation_accuracy=0.9550\n","Epoch 20: train_loss=0.163, validation_accuracy=0.9478\n","\u001b[32m[I 2023-03-07 23:20:03,996]\u001b[0m Trial 177 finished with value: 0.9478 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 29, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 28, 'activation_func[1]': 'Tanh', 'hidden_dim[2]': 30, 'activation_func[2]': 'ReLU', 'lr': 0.0010692064802786498, 'momentum': 0.946307688942546}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 19: train_loss=0.066, validation_accuracy=0.9638\n","Epoch 10: train_loss=0.159, validation_accuracy=0.9464\n","Epoch 8: train_loss=0.122, validation_accuracy=0.9569\n","Epoch 1: train_loss=1.214, validation_accuracy=0.8193\n","Epoch 20: train_loss=0.065, validation_accuracy=0.9632\n","\u001b[32m[I 2023-03-07 23:20:04,336]\u001b[0m Trial 175 finished with value: 0.9632 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 15, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 30, 'activation_func[3]': 'ReLU', 'lr': 0.008526734789259832, 'momentum': 0.7047462327669582}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 11: train_loss=0.152, validation_accuracy=0.9495\n","Epoch 2: train_loss=0.511, validation_accuracy=0.8721\n","Epoch 9: train_loss=0.116, validation_accuracy=0.9574\n","Epoch 12: train_loss=0.146, validation_accuracy=0.9500\n","Epoch 1: train_loss=1.002, validation_accuracy=0.8931\n","Epoch 3: train_loss=0.395, validation_accuracy=0.8935\n","Epoch 13: train_loss=0.140, validation_accuracy=0.9518\n","Epoch 10: train_loss=0.107, validation_accuracy=0.9601\n","Epoch 2: train_loss=0.347, validation_accuracy=0.9131\n","Epoch 4: train_loss=0.337, validation_accuracy=0.9074\n","Epoch 14: train_loss=0.136, validation_accuracy=0.9531\n","Epoch 3: train_loss=0.279, validation_accuracy=0.9276\n","Epoch 11: train_loss=0.100, validation_accuracy=0.9603\n","Epoch 5: train_loss=0.301, validation_accuracy=0.9150\n","Epoch 15: train_loss=0.131, validation_accuracy=0.9527\n","Epoch 4: train_loss=0.243, validation_accuracy=0.9330\n","Epoch 6: train_loss=0.275, validation_accuracy=0.9190\n","Epoch 12: train_loss=0.093, validation_accuracy=0.9635\n","Epoch 16: train_loss=0.126, validation_accuracy=0.9527\n","Epoch 5: train_loss=0.217, validation_accuracy=0.9379\n","Epoch 7: train_loss=0.255, validation_accuracy=0.9220\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9624\n","Epoch 17: train_loss=0.123, validation_accuracy=0.9537\n","Epoch 8: train_loss=0.240, validation_accuracy=0.9275\n","Epoch 6: train_loss=0.200, validation_accuracy=0.9398\n","Epoch 18: train_loss=0.120, validation_accuracy=0.9539\n","Epoch 14: train_loss=0.085, validation_accuracy=0.9616\n","Epoch 9: train_loss=0.228, validation_accuracy=0.9303\n","Epoch 7: train_loss=0.187, validation_accuracy=0.9451\n","Epoch 19: train_loss=0.116, validation_accuracy=0.9559\n","Epoch 10: train_loss=0.217, validation_accuracy=0.9325\n","Epoch 15: train_loss=0.080, validation_accuracy=0.9640\n","Epoch 8: train_loss=0.176, validation_accuracy=0.9463\n","Epoch 20: train_loss=0.113, validation_accuracy=0.9551\n","\u001b[32m[I 2023-03-07 23:20:07,126]\u001b[0m Trial 179 finished with value: 0.9551 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ReLU', 'lr': 0.0007117762429140181, 'momentum': 0.8845170970091154}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 11: train_loss=0.208, validation_accuracy=0.9341\n","Epoch 9: train_loss=0.167, validation_accuracy=0.9471\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9536\n","Epoch 12: train_loss=0.200, validation_accuracy=0.9380\n","Epoch 1: train_loss=2.305, validation_accuracy=0.1148\n","Epoch 10: train_loss=0.160, validation_accuracy=0.9483\n","Epoch 13: train_loss=0.194, validation_accuracy=0.9385\n","Epoch 17: train_loss=0.073, validation_accuracy=0.9624\n","Epoch 2: train_loss=2.293, validation_accuracy=0.1198\n","\u001b[32m[I 2023-03-07 23:20:07,844]\u001b[0m Trial 182 pruned. \u001b[0m\n","Epoch 14: train_loss=0.188, validation_accuracy=0.9398\n","Epoch 11: train_loss=0.153, validation_accuracy=0.9481\n","Epoch 18: train_loss=0.068, validation_accuracy=0.9631\n","Epoch 1: train_loss=1.046, validation_accuracy=0.8814\n","Epoch 15: train_loss=0.182, validation_accuracy=0.9426\n","Epoch 12: train_loss=0.147, validation_accuracy=0.9514\n","Epoch 2: train_loss=0.365, validation_accuracy=0.9103\n","Epoch 16: train_loss=0.177, validation_accuracy=0.9429\n","Epoch 19: train_loss=0.067, validation_accuracy=0.9651\n","Epoch 13: train_loss=0.142, validation_accuracy=0.9512\n","Epoch 17: train_loss=0.172, validation_accuracy=0.9443\n","Epoch 3: train_loss=0.297, validation_accuracy=0.9213\n","Epoch 20: train_loss=0.063, validation_accuracy=0.9649\n","\u001b[32m[I 2023-03-07 23:20:09,014]\u001b[0m Trial 178 finished with value: 0.9649 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 17, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 17, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 25, 'activation_func[4]': 'ELU', 'lr': 0.008595015984526087, 'momentum': 0.6160656538285307}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 14: train_loss=0.137, validation_accuracy=0.9522\n","Epoch 18: train_loss=0.168, validation_accuracy=0.9446\n","Epoch 4: train_loss=0.262, validation_accuracy=0.9289\n","Epoch 15: train_loss=0.132, validation_accuracy=0.9523\n","Epoch 19: train_loss=0.164, validation_accuracy=0.9463\n","Epoch 1: train_loss=1.288, validation_accuracy=0.8403\n","Epoch 5: train_loss=0.240, validation_accuracy=0.9343\n","Epoch 16: train_loss=0.129, validation_accuracy=0.9530\n","Epoch 20: train_loss=0.160, validation_accuracy=0.9467\n","\u001b[32m[I 2023-03-07 23:20:09,658]\u001b[0m Trial 180 finished with value: 0.9467 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 29, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 34, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'lr': 0.0003172672462417977, 'momentum': 0.8993300822082843}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 2: train_loss=0.476, validation_accuracy=0.8898\n","Epoch 6: train_loss=0.223, validation_accuracy=0.9357\n","Epoch 17: train_loss=0.125, validation_accuracy=0.9545\n","Epoch 1: train_loss=2.311, validation_accuracy=0.1180\n","Epoch 7: train_loss=0.209, validation_accuracy=0.9397\n","Epoch 3: train_loss=0.366, validation_accuracy=0.9055\n","Epoch 2: train_loss=2.305, validation_accuracy=0.1251\n","Epoch 18: train_loss=0.121, validation_accuracy=0.9552\n","Epoch 8: train_loss=0.199, validation_accuracy=0.9415\n","Epoch 4: train_loss=0.318, validation_accuracy=0.9145\n","Epoch 3: train_loss=2.300, validation_accuracy=0.1309\n","Epoch 19: train_loss=0.118, validation_accuracy=0.9541\n","Epoch 9: train_loss=0.190, validation_accuracy=0.9431\n","Epoch 5: train_loss=0.289, validation_accuracy=0.9201\n","Epoch 4: train_loss=2.295, validation_accuracy=0.1383\n","Epoch 20: train_loss=0.115, validation_accuracy=0.9547\n","\u001b[32m[I 2023-03-07 23:20:10,941]\u001b[0m Trial 181 finished with value: 0.9547 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 46, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'lr': 0.0004941180867835292, 'momentum': 0.9064802287983138}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 10: train_loss=0.182, validation_accuracy=0.9444\n","Epoch 5: train_loss=2.290, validation_accuracy=0.1444\n","Epoch 6: train_loss=0.269, validation_accuracy=0.9237\n","Epoch 11: train_loss=0.176, validation_accuracy=0.9469\n","Epoch 6: train_loss=2.286, validation_accuracy=0.1633\n","Epoch 1: train_loss=1.008, validation_accuracy=0.8134\n","Epoch 7: train_loss=0.253, validation_accuracy=0.9258\n","Epoch 7: train_loss=2.282, validation_accuracy=0.1929\n","Epoch 12: train_loss=0.169, validation_accuracy=0.9476\n","Epoch 8: train_loss=0.240, validation_accuracy=0.9298\n","Epoch 2: train_loss=0.343, validation_accuracy=0.9130\n","Epoch 8: train_loss=2.277, validation_accuracy=0.2255\n","Epoch 13: train_loss=0.164, validation_accuracy=0.9483\n","Epoch 9: train_loss=0.229, validation_accuracy=0.9344\n","Epoch 9: train_loss=2.273, validation_accuracy=0.2550\n","Epoch 3: train_loss=0.253, validation_accuracy=0.9172\n","Epoch 14: train_loss=0.159, validation_accuracy=0.9475\n","Epoch 10: train_loss=2.269, validation_accuracy=0.2697\n","\u001b[32m[I 2023-03-07 23:20:12,345]\u001b[0m Trial 185 pruned. \u001b[0m\n","Epoch 10: train_loss=0.220, validation_accuracy=0.9360\n","Epoch 15: train_loss=0.155, validation_accuracy=0.9501\n","Epoch 4: train_loss=0.204, validation_accuracy=0.9413\n","Epoch 11: train_loss=0.214, validation_accuracy=0.9371\n","Epoch 16: train_loss=0.151, validation_accuracy=0.9501\n","Epoch 1: train_loss=0.894, validation_accuracy=0.8979\n","Epoch 5: train_loss=0.179, validation_accuracy=0.9479\n","Epoch 12: train_loss=0.207, validation_accuracy=0.9383\n","Epoch 17: train_loss=0.148, validation_accuracy=0.9508\n","Epoch 2: train_loss=0.297, validation_accuracy=0.9277\n","Epoch 6: train_loss=0.155, validation_accuracy=0.9456\n","Epoch 13: train_loss=0.201, validation_accuracy=0.9388\n","Epoch 18: train_loss=0.144, validation_accuracy=0.9508\n","Epoch 3: train_loss=0.220, validation_accuracy=0.9383\n","Epoch 7: train_loss=0.144, validation_accuracy=0.9516\n","Epoch 19: train_loss=0.142, validation_accuracy=0.9525\n","Epoch 14: train_loss=0.195, validation_accuracy=0.9415\n","Epoch 4: train_loss=0.186, validation_accuracy=0.9463\n","Epoch 20: train_loss=0.138, validation_accuracy=0.9520\n","\u001b[32m[I 2023-03-07 23:20:14,008]\u001b[0m Trial 183 finished with value: 0.952 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'lr': 0.0007148343899762977, 'momentum': 0.8743630551802362}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 15: train_loss=0.191, validation_accuracy=0.9419\n","Epoch 8: train_loss=0.131, validation_accuracy=0.9581\n","Epoch 5: train_loss=0.163, validation_accuracy=0.9519\n","Epoch 16: train_loss=0.187, validation_accuracy=0.9426\n","Epoch 1: train_loss=1.377, validation_accuracy=0.8237\n","Epoch 9: train_loss=0.119, validation_accuracy=0.9608\n","Epoch 17: train_loss=0.182, validation_accuracy=0.9422\n","Epoch 6: train_loss=0.145, validation_accuracy=0.9564\n","Epoch 2: train_loss=0.450, validation_accuracy=0.8986\n","Epoch 10: train_loss=0.113, validation_accuracy=0.9583\n","Epoch 18: train_loss=0.178, validation_accuracy=0.9435\n","Epoch 7: train_loss=0.129, validation_accuracy=0.9596\n","Epoch 3: train_loss=0.299, validation_accuracy=0.9226\n","Epoch 11: train_loss=0.107, validation_accuracy=0.9619\n","Epoch 19: train_loss=0.175, validation_accuracy=0.9450\n","Epoch 4: train_loss=0.256, validation_accuracy=0.9359\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9593\n","Epoch 12: train_loss=0.099, validation_accuracy=0.9624\n","Epoch 20: train_loss=0.172, validation_accuracy=0.9458\n","\u001b[32m[I 2023-03-07 23:20:15,732]\u001b[0m Trial 184 finished with value: 0.9458 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 37, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ReLU', 'lr': 0.00045887212626951024, 'momentum': 0.9409453176772944}. Best is trial 161 with value: 0.9665.\u001b[0m\n","Epoch 5: train_loss=0.208, validation_accuracy=0.9422\n","Epoch 9: train_loss=0.113, validation_accuracy=0.9607\n","Epoch 13: train_loss=0.094, validation_accuracy=0.9632\n","Epoch 1: train_loss=0.922, validation_accuracy=0.8886\n","Epoch 6: train_loss=0.182, validation_accuracy=0.9423\n","Epoch 10: train_loss=0.103, validation_accuracy=0.9592\n","Epoch 14: train_loss=0.089, validation_accuracy=0.9649\n","Epoch 7: train_loss=0.165, validation_accuracy=0.9493\n","Epoch 2: train_loss=0.285, validation_accuracy=0.9352\n","Epoch 11: train_loss=0.095, validation_accuracy=0.9599\n","Epoch 15: train_loss=0.085, validation_accuracy=0.9643\n","Epoch 8: train_loss=0.150, validation_accuracy=0.9485\n","Epoch 3: train_loss=0.202, validation_accuracy=0.9418\n","Epoch 12: train_loss=0.093, validation_accuracy=0.9640\n","Epoch 16: train_loss=0.081, validation_accuracy=0.9633\n","Epoch 9: train_loss=0.139, validation_accuracy=0.9535\n","Epoch 4: train_loss=0.176, validation_accuracy=0.9446\n","Epoch 13: train_loss=0.085, validation_accuracy=0.9573\n","Epoch 17: train_loss=0.078, validation_accuracy=0.9650\n","Epoch 10: train_loss=0.127, validation_accuracy=0.9549\n","\u001b[32m[I 2023-03-07 23:20:17,700]\u001b[0m Trial 188 pruned. \u001b[0m\n","Epoch 5: train_loss=0.151, validation_accuracy=0.9546\n","Epoch 14: train_loss=0.082, validation_accuracy=0.9645\n","Epoch 18: train_loss=0.073, validation_accuracy=0.9640\n","Epoch 1: train_loss=2.326, validation_accuracy=0.1493\n","Epoch 6: train_loss=0.134, validation_accuracy=0.9380\n","Epoch 15: train_loss=0.080, validation_accuracy=0.9637\n","Epoch 19: train_loss=0.073, validation_accuracy=0.9666\n","Epoch 7: train_loss=0.122, validation_accuracy=0.9525\n","Epoch 16: train_loss=0.072, validation_accuracy=0.9634\n","Epoch 2: train_loss=2.258, validation_accuracy=0.2216\n","Epoch 20: train_loss=0.068, validation_accuracy=0.9667\n","\u001b[32m[I 2023-03-07 23:20:18,637]\u001b[0m Trial 186 finished with value: 0.9667 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 17, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 25, 'activation_func[4]': 'ELU', 'lr': 0.008864144293451538, 'momentum': 0.6105040428833017}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 8: train_loss=0.114, validation_accuracy=0.9595\n","Epoch 17: train_loss=0.069, validation_accuracy=0.9637\n","Epoch 1: train_loss=0.837, validation_accuracy=0.8887\n","Epoch 3: train_loss=2.217, validation_accuracy=0.4083\n","Epoch 2: train_loss=0.326, validation_accuracy=0.9140\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9612\n","Epoch 18: train_loss=0.065, validation_accuracy=0.9644\n","Epoch 4: train_loss=2.184, validation_accuracy=0.4768\n","Epoch 3: train_loss=0.262, validation_accuracy=0.9246\n","Epoch 19: train_loss=0.063, validation_accuracy=0.9643\n","Epoch 10: train_loss=0.094, validation_accuracy=0.9633\n","Epoch 5: train_loss=2.153, validation_accuracy=0.4874\n","Epoch 4: train_loss=0.225, validation_accuracy=0.9341\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9640\n","\u001b[32m[I 2023-03-07 23:20:20,124]\u001b[0m Trial 187 finished with value: 0.964 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 17, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 18, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ELU', 'lr': 0.009940769097860411, 'momentum': 0.6058287983861556}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 11: train_loss=0.090, validation_accuracy=0.9623\n","Epoch 5: train_loss=0.201, validation_accuracy=0.9385\n","Epoch 6: train_loss=2.118, validation_accuracy=0.4963\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9624\n","Epoch 1: train_loss=1.105, validation_accuracy=0.8677\n","Epoch 6: train_loss=0.184, validation_accuracy=0.9423\n","Epoch 7: train_loss=2.080, validation_accuracy=0.5013\n","Epoch 13: train_loss=0.079, validation_accuracy=0.9645\n","Epoch 2: train_loss=0.401, validation_accuracy=0.9094\n","Epoch 7: train_loss=0.172, validation_accuracy=0.9460\n","Epoch 8: train_loss=2.042, validation_accuracy=0.5150\n","Epoch 14: train_loss=0.079, validation_accuracy=0.9614\n","Epoch 3: train_loss=0.297, validation_accuracy=0.9279\n","Epoch 8: train_loss=0.161, validation_accuracy=0.9466\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9653\n","Epoch 9: train_loss=0.153, validation_accuracy=0.9496\n","Epoch 9: train_loss=2.002, validation_accuracy=0.5243Epoch 4: train_loss=0.240, validation_accuracy=0.9350\n","\n","\u001b[32m[I 2023-03-07 23:20:21,748]\u001b[0m Trial 192 pruned. \u001b[0m\n","Epoch 10: train_loss=0.145, validation_accuracy=0.9512\n","Epoch 1: train_loss=2.131, validation_accuracy=0.5427\n","Epoch 16: train_loss=0.069, validation_accuracy=0.9629\n","Epoch 10: train_loss=1.961, validation_accuracy=0.5465\n","\u001b[32m[I 2023-03-07 23:20:22,195]\u001b[0m Trial 190 pruned. \u001b[0m\n","Epoch 2: train_loss=1.619, validation_accuracy=0.6925\n","\u001b[32m[I 2023-03-07 23:20:22,324]\u001b[0m Trial 193 pruned. \u001b[0m\n","Epoch 11: train_loss=0.138, validation_accuracy=0.9509\n","Epoch 17: train_loss=0.067, validation_accuracy=0.9633\n","Epoch 1: train_loss=0.685, validation_accuracy=0.9173\n","Epoch 12: train_loss=0.132, validation_accuracy=0.9535\n","Epoch 1: train_loss=2.180, validation_accuracy=0.4464\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9598\n","Epoch 2: train_loss=0.227, validation_accuracy=0.9339\n","Epoch 13: train_loss=0.128, validation_accuracy=0.9549\n","Epoch 2: train_loss=1.861, validation_accuracy=0.5931\n","\u001b[32m[I 2023-03-07 23:20:23,167]\u001b[0m Trial 195 pruned. \u001b[0m\n","Epoch 19: train_loss=0.059, validation_accuracy=0.9653\n","Epoch 3: train_loss=0.179, validation_accuracy=0.9452\n","Epoch 14: train_loss=0.123, validation_accuracy=0.9513\n","Epoch 1: train_loss=2.310, validation_accuracy=0.1482\n","Epoch 20: train_loss=0.054, validation_accuracy=0.9644\n","\u001b[32m[I 2023-03-07 23:20:23,702]\u001b[0m Trial 189 finished with value: 0.9644 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 17, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 31, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 29, 'activation_func[4]': 'ELU', 'lr': 0.008474165688864005, 'momentum': 0.6771244201561408}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 15: train_loss=0.118, validation_accuracy=0.9539\n","Epoch 4: train_loss=0.155, validation_accuracy=0.9494\n","Epoch 2: train_loss=2.292, validation_accuracy=0.1794\n","Epoch 16: train_loss=0.115, validation_accuracy=0.9544\n","Epoch 5: train_loss=0.141, validation_accuracy=0.9508\n","Epoch 1: train_loss=1.178, validation_accuracy=0.8658\n","Epoch 3: train_loss=2.268, validation_accuracy=0.1917\n","Epoch 17: train_loss=0.112, validation_accuracy=0.9559\n","Epoch 6: train_loss=0.129, validation_accuracy=0.9510\n","Epoch 2: train_loss=0.402, validation_accuracy=0.8911\n","Epoch 4: train_loss=2.224, validation_accuracy=0.2449\n","Epoch 18: train_loss=0.108, validation_accuracy=0.9538\n","Epoch 7: train_loss=0.118, validation_accuracy=0.9543\n","Epoch 5: train_loss=2.140, validation_accuracy=0.3180\n","Epoch 3: train_loss=0.286, validation_accuracy=0.9277\n","Epoch 19: train_loss=0.105, validation_accuracy=0.9563\n","Epoch 8: train_loss=0.112, validation_accuracy=0.9567\n","Epoch 6: train_loss=2.003, validation_accuracy=0.3145\n","Epoch 20: train_loss=0.102, validation_accuracy=0.9561\n","\u001b[32m[I 2023-03-07 23:20:25,381]\u001b[0m Trial 191 finished with value: 0.9561 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 30, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 35, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 39, 'activation_func[2]': 'ReLU', 'lr': 0.0013806897473726467, 'momentum': 0.8489605593385529}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 4: train_loss=0.238, validation_accuracy=0.9355\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9586\n","Epoch 7: train_loss=1.865, validation_accuracy=0.3044\n","Epoch 1: train_loss=1.572, validation_accuracy=0.7824\n","Epoch 5: train_loss=0.202, validation_accuracy=0.9414\n","Epoch 10: train_loss=0.101, validation_accuracy=0.9611\n","Epoch 8: train_loss=1.744, validation_accuracy=0.3080\n","Epoch 2: train_loss=0.754, validation_accuracy=0.8446\n","\u001b[32m[I 2023-03-07 23:20:26,258]\u001b[0m Trial 198 pruned. \u001b[0m\n","Epoch 11: train_loss=0.096, validation_accuracy=0.9602\n","Epoch 6: train_loss=0.181, validation_accuracy=0.9452\n","Epoch 9: train_loss=1.613, validation_accuracy=0.3362\n","Epoch 12: train_loss=0.090, validation_accuracy=0.9588\n","Epoch 1: train_loss=2.292, validation_accuracy=0.2066\n","Epoch 7: train_loss=0.164, validation_accuracy=0.9493\n","Epoch 10: train_loss=1.492, validation_accuracy=0.3841\n","\u001b[32m[I 2023-03-07 23:20:26,888]\u001b[0m Trial 196 pruned. \u001b[0m\n","Epoch 13: train_loss=0.087, validation_accuracy=0.9612\n","Epoch 2: train_loss=2.250, validation_accuracy=0.3929\n","\u001b[32m[I 2023-03-07 23:20:27,145]\u001b[0m Trial 199 pruned. \u001b[0m\n","Epoch 1: train_loss=0.855, validation_accuracy=0.8933\n","Epoch 8: train_loss=0.152, validation_accuracy=0.9509\n","Epoch 14: train_loss=0.084, validation_accuracy=0.9609\n","Epoch 2: train_loss=0.331, validation_accuracy=0.9180\n","Epoch 1: train_loss=0.736, validation_accuracy=0.9032\n","Epoch 9: train_loss=0.140, validation_accuracy=0.9499\n","Epoch 3: train_loss=0.266, validation_accuracy=0.9309\n","Epoch 2: train_loss=0.306, validation_accuracy=0.9234\n","Epoch 15: train_loss=0.081, validation_accuracy=0.9613\n","Epoch 10: train_loss=0.131, validation_accuracy=0.9553\n","\u001b[32m[I 2023-03-07 23:20:28,040]\u001b[0m Trial 197 pruned. \u001b[0m\n","Epoch 4: train_loss=0.230, validation_accuracy=0.9334\n","Epoch 3: train_loss=0.255, validation_accuracy=0.9296\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9631\n","Epoch 5: train_loss=0.207, validation_accuracy=0.9380\n","Epoch 1: train_loss=0.672, validation_accuracy=0.9179\n","Epoch 4: train_loss=0.226, validation_accuracy=0.9344\n","Epoch 17: train_loss=0.074, validation_accuracy=0.9621\n","Epoch 6: train_loss=0.190, validation_accuracy=0.9407\n","Epoch 5: train_loss=0.206, validation_accuracy=0.9387\n","Epoch 2: train_loss=0.249, validation_accuracy=0.9333\n","Epoch 18: train_loss=0.073, validation_accuracy=0.9575\n","Epoch 7: train_loss=0.176, validation_accuracy=0.9428\n","Epoch 6: train_loss=0.192, validation_accuracy=0.9418\n","Epoch 3: train_loss=0.202, validation_accuracy=0.9426\n","Epoch 19: train_loss=0.069, validation_accuracy=0.9627\n","Epoch 8: train_loss=0.166, validation_accuracy=0.9462\n","Epoch 7: train_loss=0.182, validation_accuracy=0.9420\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9460\n","Epoch 9: train_loss=0.157, validation_accuracy=0.9485\n","Epoch 20: train_loss=0.067, validation_accuracy=0.9610\n","\u001b[32m[I 2023-03-07 23:20:29,768]\u001b[0m Trial 194 finished with value: 0.961 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 41, 'activation_func[3]': 'ReLU', 'lr': 0.0038848054834377437, 'momentum': 0.901934854816803}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 8: train_loss=0.173, validation_accuracy=0.9432\n","Epoch 5: train_loss=0.161, validation_accuracy=0.9477\n","Epoch 10: train_loss=0.149, validation_accuracy=0.9493\n","Epoch 9: train_loss=0.164, validation_accuracy=0.9458\n","Epoch 1: train_loss=1.116, validation_accuracy=0.8831\n","Epoch 6: train_loss=0.150, validation_accuracy=0.9514\n","Epoch 11: train_loss=0.142, validation_accuracy=0.9493\n","Epoch 10: train_loss=0.157, validation_accuracy=0.9469\n","Epoch 2: train_loss=0.340, validation_accuracy=0.9228\n","Epoch 7: train_loss=0.141, validation_accuracy=0.9491\n","Epoch 12: train_loss=0.137, validation_accuracy=0.9507\n","Epoch 11: train_loss=0.152, validation_accuracy=0.9470\n","Epoch 8: train_loss=0.133, validation_accuracy=0.9539\n","Epoch 3: train_loss=0.243, validation_accuracy=0.9403\n","Epoch 13: train_loss=0.132, validation_accuracy=0.9513\n","Epoch 12: train_loss=0.146, validation_accuracy=0.9471\n","Epoch 4: train_loss=0.200, validation_accuracy=0.9458\n","Epoch 9: train_loss=0.126, validation_accuracy=0.9528\n","Epoch 14: train_loss=0.127, validation_accuracy=0.9530\n","Epoch 13: train_loss=0.142, validation_accuracy=0.9501\n","Epoch 15: train_loss=0.123, validation_accuracy=0.9535\n","Epoch 10: train_loss=0.121, validation_accuracy=0.9568\n","Epoch 5: train_loss=0.169, validation_accuracy=0.9501\n","Epoch 14: train_loss=0.137, validation_accuracy=0.9506\n","Epoch 16: train_loss=0.119, validation_accuracy=0.9543\n","Epoch 11: train_loss=0.114, validation_accuracy=0.9552\n","Epoch 6: train_loss=0.150, validation_accuracy=0.9557\n","Epoch 15: train_loss=0.133, validation_accuracy=0.9515\n","Epoch 17: train_loss=0.116, validation_accuracy=0.9552\n","Epoch 12: train_loss=0.108, validation_accuracy=0.9566\n","Epoch 7: train_loss=0.138, validation_accuracy=0.9603\n","Epoch 16: train_loss=0.130, validation_accuracy=0.9523\n","Epoch 18: train_loss=0.112, validation_accuracy=0.9553\n","Epoch 13: train_loss=0.104, validation_accuracy=0.9580\n","Epoch 8: train_loss=0.128, validation_accuracy=0.9559\n","Epoch 17: train_loss=0.127, validation_accuracy=0.9531\n","Epoch 19: train_loss=0.109, validation_accuracy=0.9559\n","Epoch 14: train_loss=0.100, validation_accuracy=0.9606\n","Epoch 9: train_loss=0.120, validation_accuracy=0.9629\n","Epoch 18: train_loss=0.124, validation_accuracy=0.9543\n","Epoch 20: train_loss=0.106, validation_accuracy=0.9576\n","\u001b[32m[I 2023-03-07 23:20:33,631]\u001b[0m Trial 200 finished with value: 0.9576 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ReLU', 'lr': 0.0005210799733146523, 'momentum': 0.9036865042396816}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 15: train_loss=0.097, validation_accuracy=0.9582\n","Epoch 19: train_loss=0.121, validation_accuracy=0.9539\n","Epoch 10: train_loss=0.110, validation_accuracy=0.9624\n","Epoch 1: train_loss=1.378, validation_accuracy=0.8108\n","Epoch 16: train_loss=0.093, validation_accuracy=0.9588\n","Epoch 2: train_loss=0.507, validation_accuracy=0.8838\n","Epoch 20: train_loss=0.117, validation_accuracy=0.9538\n","\u001b[32m[I 2023-03-07 23:20:34,247]\u001b[0m Trial 201 finished with value: 0.9538 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 30, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 35, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 40, 'activation_func[2]': 'ReLU', 'lr': 0.0016853558563215288, 'momentum': 0.8566142863308627}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 11: train_loss=0.104, validation_accuracy=0.9593\n","Epoch 3: train_loss=0.367, validation_accuracy=0.9063\n","Epoch 17: train_loss=0.091, validation_accuracy=0.9600\n","Epoch 1: train_loss=0.659, validation_accuracy=0.9146\n","Epoch 12: train_loss=0.100, validation_accuracy=0.9654\n","Epoch 4: train_loss=0.312, validation_accuracy=0.9132\n","Epoch 18: train_loss=0.087, validation_accuracy=0.9598\n","Epoch 5: train_loss=0.280, validation_accuracy=0.9211\n","Epoch 2: train_loss=0.242, validation_accuracy=0.9403\n","Epoch 13: train_loss=0.092, validation_accuracy=0.9665\n","Epoch 19: train_loss=0.085, validation_accuracy=0.9609\n","Epoch 6: train_loss=0.259, validation_accuracy=0.9243\n","Epoch 3: train_loss=0.190, validation_accuracy=0.9467\n","Epoch 14: train_loss=0.088, validation_accuracy=0.9674\n","Epoch 7: train_loss=0.242, validation_accuracy=0.9281\n","Epoch 20: train_loss=0.083, validation_accuracy=0.9589\n","\u001b[32m[I 2023-03-07 23:20:35,699]\u001b[0m Trial 202 finished with value: 0.9589 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 33, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 33, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 44, 'activation_func[2]': 'ReLU', 'lr': 0.0012926315465821652, 'momentum': 0.9549673381332077}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 4: train_loss=0.163, validation_accuracy=0.9538\n","Epoch 15: train_loss=0.087, validation_accuracy=0.9644\n","Epoch 8: train_loss=0.231, validation_accuracy=0.9323\n","Epoch 1: train_loss=1.095, validation_accuracy=0.8731\n","Epoch 5: train_loss=0.145, validation_accuracy=0.9556\n","Epoch 16: train_loss=0.080, validation_accuracy=0.9652\n","Epoch 9: train_loss=0.217, validation_accuracy=0.9327\n","Epoch 2: train_loss=0.346, validation_accuracy=0.9223\n","Epoch 10: train_loss=0.208, validation_accuracy=0.9350\n","Epoch 17: train_loss=0.076, validation_accuracy=0.9648\n","Epoch 6: train_loss=0.130, validation_accuracy=0.9578\n","Epoch 11: train_loss=0.200, validation_accuracy=0.9377\n","Epoch 3: train_loss=0.246, validation_accuracy=0.9386\n","Epoch 18: train_loss=0.073, validation_accuracy=0.9635\n","Epoch 7: train_loss=0.119, validation_accuracy=0.9568\n","Epoch 12: train_loss=0.192, validation_accuracy=0.9365\n","Epoch 4: train_loss=0.205, validation_accuracy=0.9439\n","Epoch 19: train_loss=0.070, validation_accuracy=0.9658\n","Epoch 13: train_loss=0.186, validation_accuracy=0.9379\n","Epoch 8: train_loss=0.111, validation_accuracy=0.9622\n","Epoch 5: train_loss=0.177, validation_accuracy=0.9452\n","Epoch 14: train_loss=0.180, validation_accuracy=0.9395\n","Epoch 20: train_loss=0.072, validation_accuracy=0.9667\n","\u001b[32m[I 2023-03-07 23:20:37,710]\u001b[0m Trial 203 finished with value: 0.9667 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 17, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 23, 'activation_func[4]': 'ELU', 'lr': 0.008707796509421497, 'momentum': 0.6713950949253803}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 9: train_loss=0.104, validation_accuracy=0.9607\n","Epoch 15: train_loss=0.175, validation_accuracy=0.9399\n","Epoch 6: train_loss=0.160, validation_accuracy=0.9523\n","Epoch 1: train_loss=1.255, validation_accuracy=0.8619\n","Epoch 10: train_loss=0.097, validation_accuracy=0.9632\n","Epoch 16: train_loss=0.171, validation_accuracy=0.9382\n","Epoch 7: train_loss=0.142, validation_accuracy=0.9526\n","Epoch 17: train_loss=0.167, validation_accuracy=0.9413\n","Epoch 2: train_loss=0.405, validation_accuracy=0.9002\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9629\n","Epoch 8: train_loss=0.134, validation_accuracy=0.9538\n","Epoch 18: train_loss=0.163, validation_accuracy=0.9428\n","Epoch 3: train_loss=0.302, validation_accuracy=0.9241\n","Epoch 12: train_loss=0.086, validation_accuracy=0.9630\n","Epoch 9: train_loss=0.123, validation_accuracy=0.9557\n","Epoch 19: train_loss=0.159, validation_accuracy=0.9438\n","Epoch 4: train_loss=0.243, validation_accuracy=0.9355\n","Epoch 20: train_loss=0.157, validation_accuracy=0.9440\n","\u001b[32m[I 2023-03-07 23:20:39,312]\u001b[0m Trial 204 finished with value: 0.944 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ReLU', 'lr': 0.0010154215930993937, 'momentum': 0.9059813831281652}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 13: train_loss=0.082, validation_accuracy=0.9629\n","Epoch 10: train_loss=0.183, validation_accuracy=0.9556\n","\u001b[32m[I 2023-03-07 23:20:39,444]\u001b[0m Trial 206 pruned. \u001b[0m\n","Epoch 5: train_loss=0.212, validation_accuracy=0.9322\n","Epoch 1: train_loss=0.942, validation_accuracy=0.8338\n","Epoch 14: train_loss=0.077, validation_accuracy=0.9634\n","Epoch 1: train_loss=0.609, validation_accuracy=0.9208\n","Epoch 6: train_loss=0.188, validation_accuracy=0.9472\n","Epoch 15: train_loss=0.073, validation_accuracy=0.9643\n","Epoch 2: train_loss=0.314, validation_accuracy=0.9273\n","Epoch 2: train_loss=0.238, validation_accuracy=0.9432\n","Epoch 7: train_loss=0.169, validation_accuracy=0.9483\n","Epoch 16: train_loss=0.070, validation_accuracy=0.9643\n","Epoch 3: train_loss=0.223, validation_accuracy=0.9330\n","Epoch 3: train_loss=0.189, validation_accuracy=0.9465\n","Epoch 8: train_loss=0.155, validation_accuracy=0.9472\n","Epoch 4: train_loss=0.184, validation_accuracy=0.9463\n","Epoch 17: train_loss=0.066, validation_accuracy=0.9651\n","Epoch 9: train_loss=0.142, validation_accuracy=0.9528\n","Epoch 4: train_loss=0.163, validation_accuracy=0.9527\n","Epoch 5: train_loss=0.155, validation_accuracy=0.9508\n","Epoch 18: train_loss=0.064, validation_accuracy=0.9647\n","Epoch 10: train_loss=0.145, validation_accuracy=0.9499\n","\u001b[32m[I 2023-03-07 23:20:41,328]\u001b[0m Trial 207 pruned. \u001b[0m\n","Epoch 5: train_loss=0.144, validation_accuracy=0.9539\n","Epoch 6: train_loss=0.136, validation_accuracy=0.9567\n","Epoch 19: train_loss=0.062, validation_accuracy=0.9637\n","Epoch 1: train_loss=1.131, validation_accuracy=0.8261\n","Epoch 6: train_loss=0.131, validation_accuracy=0.9593\n","Epoch 7: train_loss=0.124, validation_accuracy=0.9574\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9654\n","\u001b[32m[I 2023-03-07 23:20:42,135]\u001b[0m Trial 205 finished with value: 0.9654 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 37, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 39, 'activation_func[3]': 'ReLU', 'lr': 0.0031289789949557234, 'momentum': 0.8420255618949246}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 2: train_loss=0.473, validation_accuracy=0.8954\n","Epoch 7: train_loss=0.118, validation_accuracy=0.9589\n","Epoch 8: train_loss=0.113, validation_accuracy=0.9608\n","Epoch 3: train_loss=0.338, validation_accuracy=0.9155\n","Epoch 1: train_loss=0.926, validation_accuracy=0.8712\n","Epoch 8: train_loss=0.109, validation_accuracy=0.9586\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9616\n","Epoch 4: train_loss=0.278, validation_accuracy=0.9302\n","\u001b[32m[I 2023-03-07 23:20:42,922]\u001b[0m Trial 210 pruned. \u001b[0m\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9287\n","Epoch 9: train_loss=0.101, validation_accuracy=0.9618\n","Epoch 10: train_loss=0.100, validation_accuracy=0.9607\n","Epoch 1: train_loss=1.034, validation_accuracy=0.8616\n","Epoch 3: train_loss=0.229, validation_accuracy=0.9381\n","Epoch 10: train_loss=0.095, validation_accuracy=0.9610\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9612\n","Epoch 2: train_loss=0.336, validation_accuracy=0.9247\n","Epoch 11: train_loss=0.089, validation_accuracy=0.9619\n","Epoch 4: train_loss=0.191, validation_accuracy=0.9448\n","Epoch 12: train_loss=0.087, validation_accuracy=0.9601\n","Epoch 3: train_loss=0.250, validation_accuracy=0.9352\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9644\n","Epoch 13: train_loss=0.083, validation_accuracy=0.9630\n","Epoch 5: train_loss=0.167, validation_accuracy=0.9458\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9446\n","Epoch 14: train_loss=0.077, validation_accuracy=0.9643\n","Epoch 13: train_loss=0.078, validation_accuracy=0.9634\n","Epoch 5: train_loss=0.180, validation_accuracy=0.9452\n","Epoch 6: train_loss=0.148, validation_accuracy=0.9510\n","Epoch 15: train_loss=0.073, validation_accuracy=0.9643\n","Epoch 14: train_loss=0.074, validation_accuracy=0.9623\n","Epoch 6: train_loss=0.163, validation_accuracy=0.9499\n","Epoch 7: train_loss=0.140, validation_accuracy=0.9562\n","Epoch 16: train_loss=0.072, validation_accuracy=0.9532\n","Epoch 15: train_loss=0.070, validation_accuracy=0.9637\n","Epoch 7: train_loss=0.147, validation_accuracy=0.9498\n","Epoch 8: train_loss=0.128, validation_accuracy=0.9544\n","Epoch 17: train_loss=0.068, validation_accuracy=0.9657\n","Epoch 16: train_loss=0.067, validation_accuracy=0.9637\n","Epoch 8: train_loss=0.136, validation_accuracy=0.9525\n","Epoch 9: train_loss=0.121, validation_accuracy=0.9576\n","Epoch 18: train_loss=0.066, validation_accuracy=0.9661\n","Epoch 9: train_loss=0.128, validation_accuracy=0.9577\n","Epoch 17: train_loss=0.064, validation_accuracy=0.9643\n","Epoch 10: train_loss=0.114, validation_accuracy=0.9504\n","\u001b[32m[I 2023-03-07 23:20:46,478]\u001b[0m Trial 211 pruned. \u001b[0m\n","Epoch 10: train_loss=0.119, validation_accuracy=0.9573\n","\u001b[32m[I 2023-03-07 23:20:46,499]\u001b[0m Trial 212 pruned. \u001b[0m\n","Epoch 19: train_loss=0.061, validation_accuracy=0.9664\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9647\n","Epoch 1: train_loss=0.897, validation_accuracy=0.9039\n","Epoch 1: train_loss=0.809, validation_accuracy=0.8997\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9664\n","\u001b[32m[I 2023-03-07 23:20:46,874]\u001b[0m Trial 208 finished with value: 0.9664 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 17, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 16, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 22, 'activation_func[4]': 'ELU', 'lr': 0.009697869093904058, 'momentum': 0.6741741549778199}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9637\n","Epoch 2: train_loss=0.313, validation_accuracy=0.9330\n","Epoch 2: train_loss=0.289, validation_accuracy=0.9277\n","Epoch 1: train_loss=2.306, validation_accuracy=0.1787\n","Epoch 20: train_loss=0.056, validation_accuracy=0.9611\n","\u001b[32m[I 2023-03-07 23:20:47,385]\u001b[0m Trial 209 finished with value: 0.9611 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 34, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 34, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 44, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 50, 'activation_func[3]': 'ReLU', 'lr': 0.0037697286356033824, 'momentum': 0.863692304077495}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 3: train_loss=0.234, validation_accuracy=0.9425\n","Epoch 3: train_loss=0.227, validation_accuracy=0.9355\n","Epoch 2: train_loss=2.291, validation_accuracy=0.2492\n","\u001b[32m[I 2023-03-07 23:20:47,659]\u001b[0m Trial 215 pruned. \u001b[0m\n","Epoch 4: train_loss=0.182, validation_accuracy=0.9475\n","Epoch 4: train_loss=0.196, validation_accuracy=0.9430\n","Epoch 1: train_loss=2.320, validation_accuracy=0.1010\n","Epoch 1: train_loss=0.660, validation_accuracy=0.9206\n","Epoch 5: train_loss=0.161, validation_accuracy=0.9536\n","Epoch 5: train_loss=0.175, validation_accuracy=0.9507\n","Epoch 2: train_loss=2.302, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:20:48,347]\u001b[0m Trial 216 pruned. \u001b[0m\n","Epoch 6: train_loss=0.139, validation_accuracy=0.9455\n","Epoch 2: train_loss=0.224, validation_accuracy=0.9423\n","Epoch 6: train_loss=0.159, validation_accuracy=0.9499\n","Epoch 7: train_loss=0.127, validation_accuracy=0.9600\n","Epoch 1: train_loss=1.054, validation_accuracy=0.8522\n","Epoch 3: train_loss=0.178, validation_accuracy=0.9505\n","Epoch 7: train_loss=0.147, validation_accuracy=0.9538\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9605\n","Epoch 8: train_loss=0.135, validation_accuracy=0.9559\n","Epoch 2: train_loss=0.348, validation_accuracy=0.9186\n","Epoch 4: train_loss=0.152, validation_accuracy=0.9531\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9624\n","Epoch 9: train_loss=0.127, validation_accuracy=0.9568\n","Epoch 5: train_loss=0.135, validation_accuracy=0.9543\n","Epoch 3: train_loss=0.246, validation_accuracy=0.9357\n","Epoch 10: train_loss=0.096, validation_accuracy=0.9652\n","Epoch 10: train_loss=0.119, validation_accuracy=0.9580\n","Epoch 11: train_loss=0.093, validation_accuracy=0.9657\n","Epoch 4: train_loss=0.204, validation_accuracy=0.9404\n","Epoch 6: train_loss=0.120, validation_accuracy=0.9588\n","Epoch 11: train_loss=0.113, validation_accuracy=0.9589\n","Epoch 12: train_loss=0.085, validation_accuracy=0.9646\n","Epoch 7: train_loss=0.110, validation_accuracy=0.9610\n","Epoch 5: train_loss=0.175, validation_accuracy=0.9506\n","Epoch 13: train_loss=0.080, validation_accuracy=0.9643\n","Epoch 12: train_loss=0.106, validation_accuracy=0.9592\n","Epoch 14: train_loss=0.076, validation_accuracy=0.9636\n","Epoch 8: train_loss=0.101, validation_accuracy=0.9618\n","Epoch 6: train_loss=0.155, validation_accuracy=0.9512\n","Epoch 13: train_loss=0.102, validation_accuracy=0.9608\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9657\n","Epoch 14: train_loss=0.097, validation_accuracy=0.9614\n","Epoch 9: train_loss=0.094, validation_accuracy=0.9588\n","Epoch 7: train_loss=0.139, validation_accuracy=0.9522\n","Epoch 16: train_loss=0.066, validation_accuracy=0.9679\n","Epoch 15: train_loss=0.092, validation_accuracy=0.9620\n","Epoch 10: train_loss=0.089, validation_accuracy=0.9612\n","Epoch 8: train_loss=0.126, validation_accuracy=0.9545\n","Epoch 17: train_loss=0.063, validation_accuracy=0.9674\n","Epoch 16: train_loss=0.089, validation_accuracy=0.9622\n","Epoch 18: train_loss=0.060, validation_accuracy=0.9640\n","Epoch 11: train_loss=0.084, validation_accuracy=0.9591\n","Epoch 9: train_loss=0.120, validation_accuracy=0.9564\n","Epoch 17: train_loss=0.085, validation_accuracy=0.9634\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9660\n","Epoch 12: train_loss=0.078, validation_accuracy=0.9619\n","Epoch 10: train_loss=0.112, validation_accuracy=0.9603\n","Epoch 18: train_loss=0.082, validation_accuracy=0.9626\n","Epoch 20: train_loss=0.055, validation_accuracy=0.9664\n","\u001b[32m[I 2023-03-07 23:20:52,514]\u001b[0m Trial 213 finished with value: 0.9664 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 46, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 16, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 24, 'activation_func[4]': 'ReLU', 'lr': 0.0089477024523417, 'momentum': 0.6149419063638304}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 19: train_loss=0.078, validation_accuracy=0.9636\n","Epoch 13: train_loss=0.074, validation_accuracy=0.9630\n","Epoch 11: train_loss=0.104, validation_accuracy=0.9568\n","Epoch 1: train_loss=1.126, validation_accuracy=0.8616\n","Epoch 20: train_loss=0.075, validation_accuracy=0.9650\n","\u001b[32m[I 2023-03-07 23:20:53,112]\u001b[0m Trial 214 finished with value: 0.965 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ReLU', 'lr': 0.0005482105493172281, 'momentum': 0.9640030544799757}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 14: train_loss=0.071, validation_accuracy=0.9655\n","Epoch 2: train_loss=0.415, validation_accuracy=0.8935\n","Epoch 12: train_loss=0.097, validation_accuracy=0.9619\n","Epoch 3: train_loss=0.340, validation_accuracy=0.9081\n","Epoch 15: train_loss=0.068, validation_accuracy=0.9629\n","Epoch 1: train_loss=2.126, validation_accuracy=0.5599\n","Epoch 13: train_loss=0.091, validation_accuracy=0.9637\n","Epoch 4: train_loss=0.295, validation_accuracy=0.9211\n","Epoch 16: train_loss=0.064, validation_accuracy=0.9615\n","Epoch 2: train_loss=1.613, validation_accuracy=0.7444\n","Epoch 14: train_loss=0.087, validation_accuracy=0.9628\n","Epoch 5: train_loss=0.265, validation_accuracy=0.9263\n","Epoch 17: train_loss=0.061, validation_accuracy=0.9631\n","Epoch 15: train_loss=0.084, validation_accuracy=0.9640\n","Epoch 3: train_loss=1.119, validation_accuracy=0.8419\n","Epoch 6: train_loss=0.245, validation_accuracy=0.9296\n","Epoch 7: train_loss=0.228, validation_accuracy=0.9331\n","Epoch 18: train_loss=0.059, validation_accuracy=0.9633\n","Epoch 16: train_loss=0.079, validation_accuracy=0.9626\n","Epoch 4: train_loss=0.791, validation_accuracy=0.8854\n","Epoch 8: train_loss=0.216, validation_accuracy=0.9371\n","Epoch 19: train_loss=0.055, validation_accuracy=0.9630\n","Epoch 17: train_loss=0.075, validation_accuracy=0.9620\n","Epoch 9: train_loss=0.205, validation_accuracy=0.9387\n","Epoch 5: train_loss=0.574, validation_accuracy=0.9115\n","Epoch 10: train_loss=0.196, validation_accuracy=0.9401\n","Epoch 18: train_loss=0.071, validation_accuracy=0.9636\n","Epoch 20: train_loss=0.053, validation_accuracy=0.9628\n","\u001b[32m[I 2023-03-07 23:20:55,506]\u001b[0m Trial 217 finished with value: 0.9628 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 34, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 41, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 45, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 41, 'activation_func[3]': 'ReLU', 'lr': 0.004796316518458112, 'momentum': 0.8907905112316866}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 6: train_loss=0.424, validation_accuracy=0.9251\n","Epoch 11: train_loss=0.190, validation_accuracy=0.9406\n","Epoch 19: train_loss=0.068, validation_accuracy=0.9622\n","Epoch 1: train_loss=0.837, validation_accuracy=0.9160\n","Epoch 7: train_loss=0.328, validation_accuracy=0.9335\n","Epoch 12: train_loss=0.183, validation_accuracy=0.9429\n","Epoch 20: train_loss=0.065, validation_accuracy=0.9630\n","\u001b[32m[I 2023-03-07 23:20:56,330]\u001b[0m Trial 218 finished with value: 0.963 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 17, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 14, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 23, 'activation_func[4]': 'ELU', 'lr': 0.00944000852621988, 'momentum': 0.6455772659567901}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 13: train_loss=0.176, validation_accuracy=0.9440\n","Epoch 2: train_loss=0.239, validation_accuracy=0.9368\n","Epoch 8: train_loss=0.269, validation_accuracy=0.9363\n","Epoch 1: train_loss=1.237, validation_accuracy=0.8698\n","Epoch 14: train_loss=0.171, validation_accuracy=0.9458\n","Epoch 3: train_loss=0.184, validation_accuracy=0.9466\n","Epoch 9: train_loss=0.230, validation_accuracy=0.9415\n","Epoch 2: train_loss=0.367, validation_accuracy=0.9186\n","Epoch 15: train_loss=0.166, validation_accuracy=0.9464\n","Epoch 4: train_loss=0.156, validation_accuracy=0.9515\n","Epoch 3: train_loss=0.260, validation_accuracy=0.9329\n","Epoch 16: train_loss=0.161, validation_accuracy=0.9459\n","Epoch 10: train_loss=0.203, validation_accuracy=0.9471\n","Epoch 17: train_loss=0.157, validation_accuracy=0.9485\n","Epoch 4: train_loss=0.214, validation_accuracy=0.9406\n","Epoch 5: train_loss=0.136, validation_accuracy=0.9555\n","Epoch 11: train_loss=0.182, validation_accuracy=0.9496\n","Epoch 18: train_loss=0.153, validation_accuracy=0.9489\n","Epoch 5: train_loss=0.184, validation_accuracy=0.9444\n","Epoch 6: train_loss=0.122, validation_accuracy=0.9568\n","Epoch 19: train_loss=0.149, validation_accuracy=0.9484\n","Epoch 12: train_loss=0.166, validation_accuracy=0.9522\n","Epoch 6: train_loss=0.162, validation_accuracy=0.9471\n","Epoch 7: train_loss=0.111, validation_accuracy=0.9554\n","Epoch 20: train_loss=0.146, validation_accuracy=0.9503\n","\u001b[32m[I 2023-03-07 23:20:58,553]\u001b[0m Trial 219 finished with value: 0.9503 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 37, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'lr': 0.00026879814924966763, 'momentum': 0.9344715006976548}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 7: train_loss=0.147, validation_accuracy=0.9472\n","Epoch 13: train_loss=0.153, validation_accuracy=0.9538\n","Epoch 8: train_loss=0.135, validation_accuracy=0.9559\n","Epoch 1: train_loss=1.007, validation_accuracy=0.9018\n","Epoch 8: train_loss=0.102, validation_accuracy=0.9621\n","Epoch 14: train_loss=0.142, validation_accuracy=0.9559\n","Epoch 9: train_loss=0.127, validation_accuracy=0.9572\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9265\n","Epoch 9: train_loss=0.094, validation_accuracy=0.9635\n","Epoch 10: train_loss=0.114, validation_accuracy=0.9526\n","\u001b[32m[I 2023-03-07 23:20:59,487]\u001b[0m Trial 222 pruned. \u001b[0m\n","Epoch 3: train_loss=0.229, validation_accuracy=0.9399\n","Epoch 15: train_loss=0.133, validation_accuracy=0.9533\n","Epoch 10: train_loss=0.088, validation_accuracy=0.9648\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9419\n","Epoch 1: train_loss=1.017, validation_accuracy=0.8756\n","Epoch 16: train_loss=0.125, validation_accuracy=0.9581\n","Epoch 5: train_loss=0.167, validation_accuracy=0.9417\n","Epoch 11: train_loss=0.082, validation_accuracy=0.9642\n","Epoch 2: train_loss=0.326, validation_accuracy=0.9076\n","Epoch 17: train_loss=0.118, validation_accuracy=0.9590\n","Epoch 6: train_loss=0.151, validation_accuracy=0.9535\n","Epoch 12: train_loss=0.078, validation_accuracy=0.9638\n","Epoch 3: train_loss=0.227, validation_accuracy=0.9419\n","Epoch 7: train_loss=0.135, validation_accuracy=0.9570\n","Epoch 18: train_loss=0.111, validation_accuracy=0.9584\n","Epoch 4: train_loss=0.184, validation_accuracy=0.9478\n","Epoch 13: train_loss=0.074, validation_accuracy=0.9665\n","Epoch 8: train_loss=0.125, validation_accuracy=0.9571\n","Epoch 19: train_loss=0.106, validation_accuracy=0.9610\n","Epoch 5: train_loss=0.159, validation_accuracy=0.9510\n","Epoch 9: train_loss=0.115, validation_accuracy=0.9586\n","Epoch 14: train_loss=0.068, validation_accuracy=0.9654\n","Epoch 20: train_loss=0.101, validation_accuracy=0.9601\n","\u001b[32m[I 2023-03-07 23:21:01,632]\u001b[0m Trial 220 finished with value: 0.9601 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 38, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 45, 'activation_func[2]': 'Sigmoid', 'hidden_dim[3]': 50, 'activation_func[3]': 'ReLU', 'lr': 0.0032757270515891054, 'momentum': 0.8443993123216326}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 6: train_loss=0.143, validation_accuracy=0.9538\n","Epoch 10: train_loss=0.106, validation_accuracy=0.9558\n","\u001b[32m[I 2023-03-07 23:21:01,711]\u001b[0m Trial 223 pruned. \u001b[0m\n","Epoch 15: train_loss=0.065, validation_accuracy=0.9661\n","Epoch 1: train_loss=1.242, validation_accuracy=0.8508\n","Epoch 1: train_loss=1.158, validation_accuracy=0.8378\n","Epoch 7: train_loss=0.130, validation_accuracy=0.9515\n","Epoch 2: train_loss=0.454, validation_accuracy=0.9077\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9661\n","Epoch 2: train_loss=0.356, validation_accuracy=0.9251\n","Epoch 8: train_loss=0.114, validation_accuracy=0.9552\n","Epoch 3: train_loss=0.324, validation_accuracy=0.9128\n","Epoch 3: train_loss=0.251, validation_accuracy=0.9352\n","Epoch 17: train_loss=0.058, validation_accuracy=0.9669\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9585\n","Epoch 4: train_loss=0.262, validation_accuracy=0.9358\n","\u001b[32m[I 2023-03-07 23:21:02,867]\u001b[0m Trial 225 pruned. \u001b[0m\n","Epoch 4: train_loss=0.202, validation_accuracy=0.9397\n","\u001b[32m[I 2023-03-07 23:21:03,032]\u001b[0m Trial 226 pruned. \u001b[0m\n","Epoch 10: train_loss=0.099, validation_accuracy=0.9605\n","Epoch 18: train_loss=0.055, validation_accuracy=0.9668\n","Epoch 1: train_loss=1.015, validation_accuracy=0.8790\n","Epoch 1: train_loss=1.005, validation_accuracy=0.8889\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9640\n","Epoch 19: train_loss=0.053, validation_accuracy=0.9671\n","Epoch 2: train_loss=0.341, validation_accuracy=0.9186\n","Epoch 12: train_loss=0.087, validation_accuracy=0.9647\n","Epoch 2: train_loss=0.342, validation_accuracy=0.9222\n","Epoch 20: train_loss=0.051, validation_accuracy=0.9642\n","\u001b[32m[I 2023-03-07 23:21:04,034]\u001b[0m Trial 221 finished with value: 0.9642 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 34, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 46, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 40, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.004261919785304908, 'momentum': 0.8855936480889399}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 3: train_loss=0.255, validation_accuracy=0.9371\n","Epoch 13: train_loss=0.081, validation_accuracy=0.9598\n","Epoch 3: train_loss=0.261, validation_accuracy=0.9315\n","Epoch 1: train_loss=1.918, validation_accuracy=0.6400\n","Epoch 14: train_loss=0.076, validation_accuracy=0.9637\n","Epoch 4: train_loss=0.211, validation_accuracy=0.9435\n","Epoch 4: train_loss=0.218, validation_accuracy=0.9377\n","\u001b[32m[I 2023-03-07 23:21:04,615]\u001b[0m Trial 228 pruned. \u001b[0m\n","Epoch 2: train_loss=1.203, validation_accuracy=0.8326\n","\u001b[32m[I 2023-03-07 23:21:04,762]\u001b[0m Trial 229 pruned. \u001b[0m\n","Epoch 15: train_loss=0.072, validation_accuracy=0.9657\n","Epoch 5: train_loss=0.184, validation_accuracy=0.9450\n","Epoch 1: train_loss=2.272, validation_accuracy=0.2487\n","Epoch 1: train_loss=1.328, validation_accuracy=0.8544\n","Epoch 16: train_loss=0.072, validation_accuracy=0.9588\n","Epoch 6: train_loss=0.166, validation_accuracy=0.9524\n","Epoch 2: train_loss=2.127, validation_accuracy=0.3567\n","\u001b[32m[I 2023-03-07 23:21:05,508]\u001b[0m Trial 230 pruned. \u001b[0m\n","Epoch 17: train_loss=0.064, validation_accuracy=0.9663\n","Epoch 2: train_loss=0.588, validation_accuracy=0.9046\n","Epoch 7: train_loss=0.151, validation_accuracy=0.9507\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9610\n","Epoch 1: train_loss=1.103, validation_accuracy=0.8663\n","Epoch 3: train_loss=0.393, validation_accuracy=0.9279\n","Epoch 8: train_loss=0.139, validation_accuracy=0.9529\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9628\n","Epoch 2: train_loss=0.364, validation_accuracy=0.9066\n","Epoch 4: train_loss=0.300, validation_accuracy=0.9389\n","\u001b[32m[I 2023-03-07 23:21:06,394]\u001b[0m Trial 231 pruned. \u001b[0m\n","Epoch 20: train_loss=0.055, validation_accuracy=0.9655\n","\u001b[32m[I 2023-03-07 23:21:06,642]\u001b[0m Trial 224 finished with value: 0.9655 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 43, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 21, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ReLU', 'lr': 0.009917654719507119, 'momentum': 0.6927732967947662}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 9: train_loss=0.129, validation_accuracy=0.9576\n","Epoch 3: train_loss=0.266, validation_accuracy=0.9304\n","Epoch 1: train_loss=1.045, validation_accuracy=0.8937\n","Epoch 1: train_loss=0.983, validation_accuracy=0.8915\n","Epoch 10: train_loss=0.122, validation_accuracy=0.9585\n","Epoch 4: train_loss=0.218, validation_accuracy=0.9382\n","\u001b[32m[I 2023-03-07 23:21:07,192]\u001b[0m Trial 232 pruned. \u001b[0m\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9318\n","Epoch 2: train_loss=0.310, validation_accuracy=0.9215\n","Epoch 11: train_loss=0.113, validation_accuracy=0.9577\n","Epoch 1: train_loss=0.888, validation_accuracy=0.9019\n","Epoch 3: train_loss=0.227, validation_accuracy=0.9377\n","Epoch 3: train_loss=0.238, validation_accuracy=0.9309\n","Epoch 2: train_loss=0.286, validation_accuracy=0.9324\n","Epoch 12: train_loss=0.109, validation_accuracy=0.9603\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9390\n","Epoch 4: train_loss=0.194, validation_accuracy=0.9433\n","Epoch 3: train_loss=0.208, validation_accuracy=0.9355\n","Epoch 5: train_loss=0.186, validation_accuracy=0.9422\n","Epoch 13: train_loss=0.102, validation_accuracy=0.9579\n","Epoch 5: train_loss=0.167, validation_accuracy=0.9486\n","Epoch 4: train_loss=0.174, validation_accuracy=0.9482\n","Epoch 6: train_loss=0.171, validation_accuracy=0.9469\n","Epoch 14: train_loss=0.095, validation_accuracy=0.9622\n","Epoch 6: train_loss=0.155, validation_accuracy=0.9537\n","Epoch 7: train_loss=0.160, validation_accuracy=0.9498\n","Epoch 5: train_loss=0.151, validation_accuracy=0.9518\n","Epoch 15: train_loss=0.092, validation_accuracy=0.9618\n","Epoch 7: train_loss=0.138, validation_accuracy=0.9534\n","Epoch 8: train_loss=0.152, validation_accuracy=0.9510\n","Epoch 6: train_loss=0.135, validation_accuracy=0.9532\n","Epoch 16: train_loss=0.086, validation_accuracy=0.9620\n","Epoch 8: train_loss=0.130, validation_accuracy=0.9568\n","Epoch 9: train_loss=0.143, validation_accuracy=0.9517\n","Epoch 7: train_loss=0.122, validation_accuracy=0.9581\n","Epoch 10: train_loss=0.135, validation_accuracy=0.9532\n","Epoch 8: train_loss=0.110, validation_accuracy=0.9604\n","Epoch 9: train_loss=0.119, validation_accuracy=0.9582\n","Epoch 17: train_loss=0.083, validation_accuracy=0.9607\n","Epoch 11: train_loss=0.129, validation_accuracy=0.9564\n","Epoch 9: train_loss=0.102, validation_accuracy=0.9528\n","Epoch 10: train_loss=0.112, validation_accuracy=0.9549\n","\u001b[32m[I 2023-03-07 23:21:10,276]\u001b[0m Trial 233 pruned. \u001b[0m\n","Epoch 18: train_loss=0.079, validation_accuracy=0.9623\n","Epoch 12: train_loss=0.124, validation_accuracy=0.9552\n","Epoch 10: train_loss=0.096, validation_accuracy=0.9610\n","Epoch 1: train_loss=0.944, validation_accuracy=0.8957\n","Epoch 19: train_loss=0.077, validation_accuracy=0.9650\n","Epoch 13: train_loss=0.119, validation_accuracy=0.9571\n","Epoch 11: train_loss=0.091, validation_accuracy=0.9573\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9152\n","Epoch 14: train_loss=0.114, validation_accuracy=0.9585\n","Epoch 20: train_loss=0.072, validation_accuracy=0.9630\n","\u001b[32m[I 2023-03-07 23:21:11,228]\u001b[0m Trial 227 finished with value: 0.963 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 48, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 25, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 35, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 31, 'activation_func[4]': 'ELU', 'lr': 0.005076287644640943, 'momentum': 0.6701003524561392}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 12: train_loss=0.087, validation_accuracy=0.9634\n","Epoch 3: train_loss=0.232, validation_accuracy=0.9378\n","Epoch 15: train_loss=0.110, validation_accuracy=0.9580\n","Epoch 1: train_loss=1.185, validation_accuracy=0.8599\n","Epoch 13: train_loss=0.083, validation_accuracy=0.9628\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9419\n","Epoch 16: train_loss=0.106, validation_accuracy=0.9588\n","Epoch 2: train_loss=0.398, validation_accuracy=0.9000\n","Epoch 14: train_loss=0.074, validation_accuracy=0.9649\n","Epoch 5: train_loss=0.165, validation_accuracy=0.9474\n","Epoch 3: train_loss=0.294, validation_accuracy=0.9194\n","Epoch 17: train_loss=0.103, validation_accuracy=0.9592\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9659\n","Epoch 6: train_loss=0.148, validation_accuracy=0.9509\n","Epoch 4: train_loss=0.243, validation_accuracy=0.9299\n","Epoch 18: train_loss=0.100, validation_accuracy=0.9589\n","Epoch 5: train_loss=0.216, validation_accuracy=0.9363\n","Epoch 16: train_loss=0.068, validation_accuracy=0.9665\n","Epoch 7: train_loss=0.135, validation_accuracy=0.9477\n","Epoch 19: train_loss=0.096, validation_accuracy=0.9590\n","Epoch 6: train_loss=0.195, validation_accuracy=0.9420\n","Epoch 8: train_loss=0.124, validation_accuracy=0.9522\n","Epoch 17: train_loss=0.062, validation_accuracy=0.9673\n","Epoch 20: train_loss=0.093, validation_accuracy=0.9594\n","\u001b[32m[I 2023-03-07 23:21:13,123]\u001b[0m Trial 234 finished with value: 0.9594 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 37, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ReLU', 'lr': 0.0005584263925402671, 'momentum': 0.9633606797098175}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 7: train_loss=0.179, validation_accuracy=0.9452\n","Epoch 9: train_loss=0.114, validation_accuracy=0.9547\n","Epoch 18: train_loss=0.060, validation_accuracy=0.9661\n","Epoch 1: train_loss=1.109, validation_accuracy=0.8861\n","Epoch 8: train_loss=0.166, validation_accuracy=0.9440\n","Epoch 10: train_loss=0.109, validation_accuracy=0.9595\n","Epoch 19: train_loss=0.057, validation_accuracy=0.9646\n","Epoch 2: train_loss=0.312, validation_accuracy=0.9256\n","Epoch 9: train_loss=0.156, validation_accuracy=0.9488\n","Epoch 11: train_loss=0.100, validation_accuracy=0.9590\n","Epoch 20: train_loss=0.053, validation_accuracy=0.9623\n","\u001b[32m[I 2023-03-07 23:21:14,127]\u001b[0m Trial 235 finished with value: 0.9623 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 43, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 21, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ReLU', 'lr': 0.008657353698141407, 'momentum': 0.6947075138006842}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 10: train_loss=0.147, validation_accuracy=0.9507\n","Epoch 3: train_loss=0.213, validation_accuracy=0.9334\n","Epoch 12: train_loss=0.095, validation_accuracy=0.9568\n","Epoch 11: train_loss=0.140, validation_accuracy=0.9521\n","Epoch 1: train_loss=1.148, validation_accuracy=0.8603\n","Epoch 4: train_loss=0.175, validation_accuracy=0.9473\n","Epoch 13: train_loss=0.091, validation_accuracy=0.9605\n","Epoch 12: train_loss=0.135, validation_accuracy=0.9512\n","Epoch 2: train_loss=0.363, validation_accuracy=0.9172\n","Epoch 5: train_loss=0.150, validation_accuracy=0.9534\n","Epoch 14: train_loss=0.086, validation_accuracy=0.9644\n","Epoch 13: train_loss=0.131, validation_accuracy=0.9516\n","Epoch 3: train_loss=0.260, validation_accuracy=0.9318\n","Epoch 6: train_loss=0.136, validation_accuracy=0.9550\n","Epoch 15: train_loss=0.079, validation_accuracy=0.9627\n","Epoch 14: train_loss=0.125, validation_accuracy=0.9532\n","Epoch 4: train_loss=0.215, validation_accuracy=0.9425\n","Epoch 7: train_loss=0.121, validation_accuracy=0.9608\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9633\n","Epoch 15: train_loss=0.121, validation_accuracy=0.9551\n","Epoch 5: train_loss=0.183, validation_accuracy=0.9490\n","Epoch 16: train_loss=0.117, validation_accuracy=0.9558\n","Epoch 8: train_loss=0.109, validation_accuracy=0.9582\n","Epoch 17: train_loss=0.075, validation_accuracy=0.9646\n","Epoch 17: train_loss=0.113, validation_accuracy=0.9537\n","Epoch 6: train_loss=0.162, validation_accuracy=0.9498\n","Epoch 9: train_loss=0.102, validation_accuracy=0.9595\n","Epoch 18: train_loss=0.073, validation_accuracy=0.9648\n","Epoch 18: train_loss=0.111, validation_accuracy=0.9563\n","Epoch 7: train_loss=0.148, validation_accuracy=0.9550\n","Epoch 10: train_loss=0.097, validation_accuracy=0.9618\n","Epoch 19: train_loss=0.068, validation_accuracy=0.9645\n","Epoch 19: train_loss=0.108, validation_accuracy=0.9549\n","Epoch 8: train_loss=0.134, validation_accuracy=0.9583\n","Epoch 11: train_loss=0.088, validation_accuracy=0.9615\n","Epoch 20: train_loss=0.066, validation_accuracy=0.9667\n","\u001b[32m[I 2023-03-07 23:21:17,099]\u001b[0m Trial 236 finished with value: 0.9667 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 43, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 20, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 30, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ReLU', 'lr': 0.007542239376465994, 'momentum': 0.694294561641976}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 20: train_loss=0.105, validation_accuracy=0.9547\n","\u001b[32m[I 2023-03-07 23:21:17,194]\u001b[0m Trial 237 finished with value: 0.9547 and parameters: {'n_hidden_layers': 2, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'lr': 0.00028473903957242606, 'momentum': 0.9846756215059975}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 9: train_loss=0.123, validation_accuracy=0.9570\n","Epoch 12: train_loss=0.083, validation_accuracy=0.9616\n","Epoch 1: train_loss=1.091, validation_accuracy=0.8630\n","Epoch 1: train_loss=0.919, validation_accuracy=0.8961\n","Epoch 10: train_loss=0.116, validation_accuracy=0.9599\n","Epoch 2: train_loss=0.315, validation_accuracy=0.9238\n","Epoch 13: train_loss=0.078, validation_accuracy=0.9620\n","Epoch 2: train_loss=0.317, validation_accuracy=0.9280\n","Epoch 3: train_loss=0.234, validation_accuracy=0.9357\n","Epoch 11: train_loss=0.106, validation_accuracy=0.9594\n","Epoch 14: train_loss=0.075, validation_accuracy=0.9663\n","Epoch 3: train_loss=0.235, validation_accuracy=0.9376\n","Epoch 4: train_loss=0.196, validation_accuracy=0.9440\n","Epoch 12: train_loss=0.099, validation_accuracy=0.9604\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9443\n","Epoch 15: train_loss=0.070, validation_accuracy=0.9629\n","Epoch 5: train_loss=0.173, validation_accuracy=0.9522\n","Epoch 5: train_loss=0.167, validation_accuracy=0.9507\n","Epoch 13: train_loss=0.095, validation_accuracy=0.9623\n","Epoch 16: train_loss=0.065, validation_accuracy=0.9641\n","Epoch 6: train_loss=0.156, validation_accuracy=0.9535\n","Epoch 6: train_loss=0.150, validation_accuracy=0.9524\n","Epoch 14: train_loss=0.088, validation_accuracy=0.9632\n","Epoch 17: train_loss=0.062, validation_accuracy=0.9590\n","Epoch 7: train_loss=0.143, validation_accuracy=0.9553\n","Epoch 7: train_loss=0.138, validation_accuracy=0.9508\n","Epoch 15: train_loss=0.084, validation_accuracy=0.9639\n","Epoch 18: train_loss=0.059, validation_accuracy=0.9689\n","Epoch 8: train_loss=0.132, validation_accuracy=0.9555\n","Epoch 8: train_loss=0.123, validation_accuracy=0.9581\n","Epoch 16: train_loss=0.080, validation_accuracy=0.9655\n","Epoch 19: train_loss=0.654, validation_accuracy=0.9086\n","Epoch 9: train_loss=0.125, validation_accuracy=0.9593\n","Epoch 9: train_loss=0.114, validation_accuracy=0.9589\n","Epoch 17: train_loss=0.076, validation_accuracy=0.9640\n","Epoch 20: train_loss=0.263, validation_accuracy=0.9379\n","\u001b[32m[I 2023-03-07 23:21:20,368]\u001b[0m Trial 238 finished with value: 0.9379 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 45, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 22, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 23, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 25, 'activation_func[4]': 'ReLU', 'lr': 0.009988615974018445, 'momentum': 0.6726088702675261}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 10: train_loss=0.107, validation_accuracy=0.9557\n","Epoch 10: train_loss=0.115, validation_accuracy=0.9603\n","\u001b[32m[I 2023-03-07 23:21:20,388]\u001b[0m Trial 241 pruned. \u001b[0m\n","Epoch 18: train_loss=0.071, validation_accuracy=0.9616\n","Epoch 11: train_loss=0.109, validation_accuracy=0.9593\n","Epoch 1: train_loss=1.265, validation_accuracy=0.8504\n","Epoch 1: train_loss=0.829, validation_accuracy=0.9135\n","Epoch 19: train_loss=0.068, validation_accuracy=0.9658\n","Epoch 12: train_loss=0.105, validation_accuracy=0.9601\n","Epoch 2: train_loss=0.428, validation_accuracy=0.9009\n","Epoch 2: train_loss=0.264, validation_accuracy=0.9358\n","Epoch 20: train_loss=0.065, validation_accuracy=0.9655\n","\u001b[32m[I 2023-03-07 23:21:21,313]\u001b[0m Trial 239 finished with value: 0.9655 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 47, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 14, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 32, 'activation_func[4]': 'ReLU', 'lr': 0.00599149411598388, 'momentum': 0.6492748299982766}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 3: train_loss=0.304, validation_accuracy=0.9204\n","Epoch 13: train_loss=0.097, validation_accuracy=0.9613\n","Epoch 3: train_loss=0.198, validation_accuracy=0.9456\n","Epoch 4: train_loss=0.254, validation_accuracy=0.9301\n","Epoch 14: train_loss=0.091, validation_accuracy=0.9666\n","Epoch 1: train_loss=1.133, validation_accuracy=0.8863\n","Epoch 4: train_loss=0.163, validation_accuracy=0.9479\n","Epoch 5: train_loss=0.223, validation_accuracy=0.9348\n","Epoch 15: train_loss=0.090, validation_accuracy=0.9528\n","Epoch 2: train_loss=0.330, validation_accuracy=0.9227\n","Epoch 5: train_loss=0.140, validation_accuracy=0.9564\n","Epoch 6: train_loss=0.205, validation_accuracy=0.9397\n","Epoch 16: train_loss=0.085, validation_accuracy=0.9674\n","Epoch 3: train_loss=0.246, validation_accuracy=0.9351\n","Epoch 6: train_loss=0.123, validation_accuracy=0.9582\n","Epoch 17: train_loss=0.081, validation_accuracy=0.9666\n","Epoch 7: train_loss=0.190, validation_accuracy=0.9423\n","Epoch 4: train_loss=0.206, validation_accuracy=0.9418\n","Epoch 7: train_loss=0.110, validation_accuracy=0.9605\n","Epoch 8: train_loss=0.177, validation_accuracy=0.9436\n","Epoch 18: train_loss=0.080, validation_accuracy=0.9605\n","Epoch 5: train_loss=0.181, validation_accuracy=0.9466\n","Epoch 19: train_loss=0.075, validation_accuracy=0.9662\n","Epoch 9: train_loss=0.167, validation_accuracy=0.9460\n","Epoch 8: train_loss=0.100, validation_accuracy=0.9621\n","Epoch 6: train_loss=0.163, validation_accuracy=0.9523\n","Epoch 10: train_loss=0.159, validation_accuracy=0.9482\n","Epoch 20: train_loss=0.071, validation_accuracy=0.9658\n","\u001b[32m[I 2023-03-07 23:21:23,582]\u001b[0m Trial 240 finished with value: 0.9658 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 20, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 30, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ReLU', 'lr': 0.007383602442032001, 'momentum': 0.6932209152393833}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 9: train_loss=0.092, validation_accuracy=0.9650\n","Epoch 7: train_loss=0.148, validation_accuracy=0.9548\n","Epoch 11: train_loss=0.151, validation_accuracy=0.9479\n","Epoch 10: train_loss=0.084, validation_accuracy=0.9646\n","Epoch 1: train_loss=0.855, validation_accuracy=0.8934\n","Epoch 8: train_loss=0.135, validation_accuracy=0.9554\n","Epoch 12: train_loss=0.144, validation_accuracy=0.9508\n","Epoch 9: train_loss=0.126, validation_accuracy=0.9501\n","Epoch 2: train_loss=0.284, validation_accuracy=0.9316\n","Epoch 11: train_loss=0.079, validation_accuracy=0.9648\n","Epoch 13: train_loss=0.139, validation_accuracy=0.9496\n","Epoch 10: train_loss=0.119, validation_accuracy=0.9542\n","\u001b[32m[I 2023-03-07 23:21:24,660]\u001b[0m Trial 244 pruned. \u001b[0m\n","Epoch 3: train_loss=0.212, validation_accuracy=0.9408\n","Epoch 12: train_loss=0.072, validation_accuracy=0.9631\n","Epoch 14: train_loss=0.133, validation_accuracy=0.9508\n","Epoch 4: train_loss=0.176, validation_accuracy=0.9510\n","Epoch 1: train_loss=1.022, validation_accuracy=0.8579\n","Epoch 15: train_loss=0.128, validation_accuracy=0.9522\n","Epoch 13: train_loss=0.068, validation_accuracy=0.9670\n","Epoch 5: train_loss=0.153, validation_accuracy=0.9517\n","Epoch 2: train_loss=0.383, validation_accuracy=0.9118\n","Epoch 16: train_loss=0.124, validation_accuracy=0.9521\n","Epoch 14: train_loss=0.062, validation_accuracy=0.9674\n","Epoch 6: train_loss=0.134, validation_accuracy=0.9588\n","Epoch 17: train_loss=0.120, validation_accuracy=0.9526\n","Epoch 3: train_loss=0.275, validation_accuracy=0.9294\n","Epoch 15: train_loss=0.060, validation_accuracy=0.9663\n","Epoch 18: train_loss=0.117, validation_accuracy=0.9529\n","Epoch 7: train_loss=0.122, validation_accuracy=0.9614\n","Epoch 4: train_loss=0.224, validation_accuracy=0.9373\n","\u001b[32m[I 2023-03-07 23:21:26,213]\u001b[0m Trial 246 pruned. \u001b[0m\n","Epoch 16: train_loss=0.055, validation_accuracy=0.9686\n","Epoch 19: train_loss=0.114, validation_accuracy=0.9544\n","Epoch 8: train_loss=0.109, validation_accuracy=0.9641\n","Epoch 1: train_loss=0.969, validation_accuracy=0.8800\n","Epoch 17: train_loss=0.052, validation_accuracy=0.9694\n","Epoch 20: train_loss=0.110, validation_accuracy=0.9537\n","\u001b[32m[I 2023-03-07 23:21:26,791]\u001b[0m Trial 243 finished with value: 0.9537 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 37, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ReLU', 'lr': 0.0002993821980565865, 'momentum': 0.982259556697808}. Best is trial 186 with value: 0.9667.\u001b[0m\n","Epoch 9: train_loss=0.100, validation_accuracy=0.9620\n","Epoch 2: train_loss=0.330, validation_accuracy=0.9228\n","Epoch 18: train_loss=0.053, validation_accuracy=0.9656\n","Epoch 10: train_loss=0.092, validation_accuracy=0.9639\n","Epoch 1: train_loss=0.907, validation_accuracy=0.9126\n","Epoch 3: train_loss=0.238, validation_accuracy=0.9351\n","Epoch 19: train_loss=0.046, validation_accuracy=0.9686\n","Epoch 11: train_loss=0.085, validation_accuracy=0.9676\n","Epoch 4: train_loss=0.200, validation_accuracy=0.9431\n","Epoch 2: train_loss=0.261, validation_accuracy=0.9361\n","Epoch 20: train_loss=0.044, validation_accuracy=0.9673\n","\u001b[32m[I 2023-03-07 23:21:27,785]\u001b[0m Trial 242 finished with value: 0.9673 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 49, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 27, 'activation_func[4]': 'ReLU', 'lr': 0.009825752594767246, 'momentum': 0.6856525901665953}. Best is trial 242 with value: 0.9673.\u001b[0m\n","Epoch 12: train_loss=0.080, validation_accuracy=0.9665\n","Epoch 5: train_loss=0.173, validation_accuracy=0.9485\n","Epoch 3: train_loss=0.198, validation_accuracy=0.9456\n","Epoch 1: train_loss=0.959, validation_accuracy=0.9009\n","Epoch 13: train_loss=0.075, validation_accuracy=0.9662\n","Epoch 6: train_loss=0.156, validation_accuracy=0.9458\n","Epoch 4: train_loss=0.165, validation_accuracy=0.9511\n","Epoch 7: train_loss=0.143, validation_accuracy=0.9537\n","Epoch 14: train_loss=0.071, validation_accuracy=0.9672\n","Epoch 2: train_loss=0.295, validation_accuracy=0.9164\n","Epoch 8: train_loss=0.130, validation_accuracy=0.9537\n","Epoch 5: train_loss=0.144, validation_accuracy=0.9525\n","Epoch 3: train_loss=0.214, validation_accuracy=0.9439\n","Epoch 15: train_loss=0.066, validation_accuracy=0.9670\n","Epoch 9: train_loss=0.121, validation_accuracy=0.9573\n","Epoch 4: train_loss=0.174, validation_accuracy=0.9525\n","Epoch 16: train_loss=0.062, validation_accuracy=0.9692\n","Epoch 6: train_loss=0.126, validation_accuracy=0.9575\n","Epoch 10: train_loss=0.111, validation_accuracy=0.9592\n","Epoch 17: train_loss=0.059, validation_accuracy=0.9672\n","Epoch 5: train_loss=0.150, validation_accuracy=0.9544\n","Epoch 7: train_loss=0.115, validation_accuracy=0.9614\n","Epoch 11: train_loss=0.107, validation_accuracy=0.9550\n","Epoch 18: train_loss=0.055, validation_accuracy=0.9687\n","Epoch 6: train_loss=0.129, validation_accuracy=0.9583\n","Epoch 8: train_loss=0.105, validation_accuracy=0.9634\n","Epoch 12: train_loss=0.098, validation_accuracy=0.9618\n","Epoch 19: train_loss=0.056, validation_accuracy=0.9668\n","Epoch 7: train_loss=0.118, validation_accuracy=0.9609\n","Epoch 13: train_loss=0.093, validation_accuracy=0.9630\n","Epoch 9: train_loss=0.097, validation_accuracy=0.9605\n","Epoch 20: train_loss=0.053, validation_accuracy=0.9691\n","\u001b[32m[I 2023-03-07 23:21:30,598]\u001b[0m Trial 245 finished with value: 0.9691 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 47, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 20, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 24, 'activation_func[4]': 'ReLU', 'lr': 0.007505164016879355, 'momentum': 0.712220390044562}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 8: train_loss=0.105, validation_accuracy=0.9601\n","Epoch 14: train_loss=0.089, validation_accuracy=0.9655\n","Epoch 10: train_loss=0.089, validation_accuracy=0.9626\n","Epoch 1: train_loss=1.012, validation_accuracy=0.8816\n","Epoch 9: train_loss=0.096, validation_accuracy=0.9628\n","Epoch 15: train_loss=0.084, validation_accuracy=0.9666\n","Epoch 11: train_loss=0.083, validation_accuracy=0.9628\n","Epoch 10: train_loss=0.090, validation_accuracy=0.9657\n","Epoch 2: train_loss=0.331, validation_accuracy=0.9245\n","Epoch 16: train_loss=0.079, validation_accuracy=0.9654\n","Epoch 11: train_loss=0.084, validation_accuracy=0.9640\n","Epoch 3: train_loss=0.240, validation_accuracy=0.9382\n","Epoch 17: train_loss=0.144, validation_accuracy=0.9668\n","Epoch 12: train_loss=0.077, validation_accuracy=0.9650\n","Epoch 12: train_loss=0.078, validation_accuracy=0.9670\n","Epoch 18: train_loss=0.075, validation_accuracy=0.9657\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9410\n","\u001b[32m[I 2023-03-07 23:21:32,150]\u001b[0m Trial 250 pruned. \u001b[0m\n","Epoch 13: train_loss=0.072, validation_accuracy=0.9658\n","Epoch 13: train_loss=0.072, validation_accuracy=0.9668\n","Epoch 19: train_loss=0.070, validation_accuracy=0.9677\n","Epoch 1: train_loss=2.288, validation_accuracy=0.2400\n","Epoch 14: train_loss=0.068, validation_accuracy=0.9657\n","Epoch 20: train_loss=0.066, validation_accuracy=0.9682\n","\u001b[32m[I 2023-03-07 23:21:32,825]\u001b[0m Trial 247 finished with value: 0.9682 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 22, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 30, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 28, 'activation_func[4]': 'ReLU', 'lr': 0.0075380187518308325, 'momentum': 0.6543364945615826}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 14: train_loss=0.068, validation_accuracy=0.9689\n","Epoch 2: train_loss=2.248, validation_accuracy=0.3173\n","\u001b[32m[I 2023-03-07 23:21:32,920]\u001b[0m Trial 251 pruned. \u001b[0m\n","Epoch 15: train_loss=0.064, validation_accuracy=0.9671\n","Epoch 1: train_loss=1.297, validation_accuracy=0.7655\n","Epoch 15: train_loss=0.065, validation_accuracy=0.9683\n","Epoch 1: train_loss=1.116, validation_accuracy=0.8597\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9670\n","Epoch 2: train_loss=0.448, validation_accuracy=0.8985\n","\u001b[32m[I 2023-03-07 23:21:33,541]\u001b[0m Trial 252 pruned. \u001b[0m\n","Epoch 2: train_loss=0.406, validation_accuracy=0.9041\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9663\n","Epoch 3: train_loss=0.296, validation_accuracy=0.9200\n","Epoch 1: train_loss=2.225, validation_accuracy=0.4880\n","Epoch 17: train_loss=0.057, validation_accuracy=0.9676\n","Epoch 17: train_loss=0.058, validation_accuracy=0.9673\n","Epoch 4: train_loss=0.237, validation_accuracy=0.9321\n","Epoch 2: train_loss=2.025, validation_accuracy=0.6402\n","\u001b[32m[I 2023-03-07 23:21:34,242]\u001b[0m Trial 254 pruned. \u001b[0m\n","Epoch 18: train_loss=0.054, validation_accuracy=0.9651\n","Epoch 18: train_loss=0.054, validation_accuracy=0.9681\n","Epoch 5: train_loss=0.204, validation_accuracy=0.9372\n","Epoch 1: train_loss=0.975, validation_accuracy=0.8768\n","Epoch 19: train_loss=0.050, validation_accuracy=0.9689\n","Epoch 6: train_loss=0.183, validation_accuracy=0.9409\n","Epoch 19: train_loss=0.051, validation_accuracy=0.9692\n","Epoch 2: train_loss=0.331, validation_accuracy=0.9221\n","Epoch 20: train_loss=0.050, validation_accuracy=0.9646\n","\u001b[32m[I 2023-03-07 23:21:35,060]\u001b[0m Trial 249 finished with value: 0.9646 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 49, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.009846889553146682, 'momentum': 0.6866659029882082}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 7: train_loss=0.166, validation_accuracy=0.9443\n","Epoch 20: train_loss=0.048, validation_accuracy=0.9675\n","\u001b[32m[I 2023-03-07 23:21:35,304]\u001b[0m Trial 248 finished with value: 0.9675 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 34, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 41, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 46, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.005554176568270687, 'momentum': 0.8754539876837699}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 8: train_loss=0.155, validation_accuracy=0.9465\n","Epoch 3: train_loss=0.233, validation_accuracy=0.9369\n","Epoch 1: train_loss=0.867, validation_accuracy=0.8918\n","Epoch 9: train_loss=0.146, validation_accuracy=0.9492\n","Epoch 2: train_loss=0.308, validation_accuracy=0.9235\n","Epoch 1: train_loss=0.868, validation_accuracy=0.9157\n","Epoch 4: train_loss=0.192, validation_accuracy=0.9429\n","Epoch 10: train_loss=0.138, validation_accuracy=0.9491\n","Epoch 3: train_loss=0.236, validation_accuracy=0.9335\n","Epoch 5: train_loss=0.165, validation_accuracy=0.9500\n","Epoch 2: train_loss=0.235, validation_accuracy=0.9395\n","Epoch 11: train_loss=0.131, validation_accuracy=0.9514\n","Epoch 4: train_loss=0.198, validation_accuracy=0.9412\n","Epoch 6: train_loss=0.146, validation_accuracy=0.9553\n","Epoch 12: train_loss=0.124, validation_accuracy=0.9527\n","Epoch 3: train_loss=0.177, validation_accuracy=0.9486\n","Epoch 5: train_loss=0.175, validation_accuracy=0.9435\n","Epoch 7: train_loss=0.133, validation_accuracy=0.9584\n","Epoch 13: train_loss=0.120, validation_accuracy=0.9514\n","Epoch 4: train_loss=0.150, validation_accuracy=0.9543\n","Epoch 6: train_loss=0.157, validation_accuracy=0.9465\n","Epoch 14: train_loss=0.116, validation_accuracy=0.9545\n","Epoch 8: train_loss=0.119, validation_accuracy=0.9585\n","Epoch 7: train_loss=0.145, validation_accuracy=0.9485\n","Epoch 15: train_loss=0.112, validation_accuracy=0.9537\n","Epoch 5: train_loss=0.129, validation_accuracy=0.9577\n","Epoch 9: train_loss=0.111, validation_accuracy=0.9615\n","Epoch 8: train_loss=0.135, validation_accuracy=0.9517\n","Epoch 16: train_loss=0.107, validation_accuracy=0.9552\n","Epoch 10: train_loss=0.103, validation_accuracy=0.9581\n","\u001b[32m[I 2023-03-07 23:21:38,048]\u001b[0m Trial 255 pruned. \u001b[0m\n","Epoch 6: train_loss=0.115, validation_accuracy=0.9595\n","Epoch 17: train_loss=0.104, validation_accuracy=0.9555\n","Epoch 9: train_loss=0.127, validation_accuracy=0.9526\n","Epoch 7: train_loss=0.105, validation_accuracy=0.9603\n","Epoch 1: train_loss=0.930, validation_accuracy=0.8806\n","Epoch 18: train_loss=0.101, validation_accuracy=0.9560\n","Epoch 10: train_loss=0.118, validation_accuracy=0.9541\n","Epoch 19: train_loss=0.098, validation_accuracy=0.9563\n","Epoch 11: train_loss=0.113, validation_accuracy=0.9562\n","Epoch 8: train_loss=0.097, validation_accuracy=0.9626\n","Epoch 2: train_loss=0.292, validation_accuracy=0.9306\n","Epoch 20: train_loss=0.094, validation_accuracy=0.9558\n","\u001b[32m[I 2023-03-07 23:21:39,133]\u001b[0m Trial 253 finished with value: 0.9558 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 38, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ReLU', 'lr': 0.00031618409464137347, 'momentum': 0.9909316991058059}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 12: train_loss=0.108, validation_accuracy=0.9583\n","Epoch 9: train_loss=0.088, validation_accuracy=0.9639\n","Epoch 3: train_loss=0.224, validation_accuracy=0.9412\n","Epoch 13: train_loss=0.102, validation_accuracy=0.9605\n","Epoch 1: train_loss=0.920, validation_accuracy=0.9001\n","Epoch 10: train_loss=0.082, validation_accuracy=0.9643\n","Epoch 4: train_loss=0.186, validation_accuracy=0.9478\n","Epoch 2: train_loss=0.310, validation_accuracy=0.9162\n","Epoch 14: train_loss=0.098, validation_accuracy=0.9576\n","Epoch 3: train_loss=0.231, validation_accuracy=0.9367\n","Epoch 11: train_loss=0.077, validation_accuracy=0.9639\n","Epoch 15: train_loss=0.094, validation_accuracy=0.9590\n","Epoch 5: train_loss=0.162, validation_accuracy=0.9506\n","Epoch 4: train_loss=0.191, validation_accuracy=0.9433\n","Epoch 16: train_loss=0.091, validation_accuracy=0.9598\n","Epoch 12: train_loss=0.072, validation_accuracy=0.9647\n","Epoch 6: train_loss=0.144, validation_accuracy=0.9560\n","Epoch 5: train_loss=0.164, validation_accuracy=0.9511\n","Epoch 17: train_loss=0.087, validation_accuracy=0.9608\n","Epoch 13: train_loss=0.068, validation_accuracy=0.9654\n","Epoch 7: train_loss=0.133, validation_accuracy=0.9578\n","Epoch 6: train_loss=0.145, validation_accuracy=0.9525\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9604\n","Epoch 14: train_loss=0.063, validation_accuracy=0.9651\n","Epoch 7: train_loss=0.131, validation_accuracy=0.9583\n","Epoch 19: train_loss=0.080, validation_accuracy=0.9596\n","Epoch 8: train_loss=0.122, validation_accuracy=0.9599\n","Epoch 8: train_loss=0.119, validation_accuracy=0.9570\n","Epoch 20: train_loss=0.079, validation_accuracy=0.9622\n","\u001b[32m[I 2023-03-07 23:21:41,845]\u001b[0m Trial 256 finished with value: 0.9622 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 24, 'activation_func[2]': 'ReLU', 'lr': 0.0005534997345258454, 'momentum': 0.9593390768420952}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 15: train_loss=0.059, validation_accuracy=0.9673\n","Epoch 9: train_loss=0.113, validation_accuracy=0.9613\n","Epoch 9: train_loss=0.109, validation_accuracy=0.9611\n","Epoch 1: train_loss=0.839, validation_accuracy=0.8969\n","Epoch 16: train_loss=0.055, validation_accuracy=0.9669\n","Epoch 10: train_loss=0.105, validation_accuracy=0.9601\n","Epoch 10: train_loss=0.102, validation_accuracy=0.9633\n","Epoch 2: train_loss=0.288, validation_accuracy=0.9257\n","Epoch 17: train_loss=0.053, validation_accuracy=0.9638\n","Epoch 11: train_loss=0.095, validation_accuracy=0.9573\n","Epoch 11: train_loss=0.099, validation_accuracy=0.9642\n","Epoch 3: train_loss=0.225, validation_accuracy=0.9344\n","Epoch 12: train_loss=0.090, validation_accuracy=0.9619\n","Epoch 18: train_loss=0.050, validation_accuracy=0.9673\n","Epoch 4: train_loss=0.193, validation_accuracy=0.9410\n","Epoch 12: train_loss=0.094, validation_accuracy=0.9619\n","Epoch 13: train_loss=0.085, validation_accuracy=0.9638\n","Epoch 19: train_loss=0.047, validation_accuracy=0.9671\n","Epoch 5: train_loss=0.172, validation_accuracy=0.9428\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9649\n","Epoch 14: train_loss=0.081, validation_accuracy=0.9616\n","Epoch 20: train_loss=0.043, validation_accuracy=0.9663\n","\u001b[32m[I 2023-03-07 23:21:43,919]\u001b[0m Trial 257 finished with value: 0.9663 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 34, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 41, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 46, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 25, 'activation_func[4]': 'ReLU', 'lr': 0.006185515349172376, 'momentum': 0.8676686135576416}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 6: train_loss=0.157, validation_accuracy=0.9475\n","Epoch 15: train_loss=0.077, validation_accuracy=0.9658\n","Epoch 14: train_loss=0.083, validation_accuracy=0.9646\n","Epoch 7: train_loss=0.144, validation_accuracy=0.9522\n","Epoch 16: train_loss=0.075, validation_accuracy=0.9667\n","Epoch 1: train_loss=0.794, validation_accuracy=0.9166\n","Epoch 15: train_loss=0.079, validation_accuracy=0.9662\n","Epoch 8: train_loss=0.133, validation_accuracy=0.9528\n","Epoch 17: train_loss=0.069, validation_accuracy=0.9673\n","Epoch 2: train_loss=0.244, validation_accuracy=0.9380\n","Epoch 9: train_loss=0.124, validation_accuracy=0.9536\n","Epoch 18: train_loss=0.067, validation_accuracy=0.9639\n","Epoch 16: train_loss=0.075, validation_accuracy=0.9651\n","Epoch 19: train_loss=0.064, validation_accuracy=0.9553\n","Epoch 10: train_loss=0.117, validation_accuracy=0.9566\n","Epoch 3: train_loss=0.185, validation_accuracy=0.9454\n","Epoch 17: train_loss=0.072, validation_accuracy=0.9642\n","Epoch 20: train_loss=0.060, validation_accuracy=0.9667\n","\u001b[32m[I 2023-03-07 23:21:45,611]\u001b[0m Trial 259 finished with value: 0.9667 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 47, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 24, 'activation_func[4]': 'ReLU', 'lr': 0.007526665678519363, 'momentum': 0.6655768109388902}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 11: train_loss=0.110, validation_accuracy=0.9573\n","Epoch 4: train_loss=0.154, validation_accuracy=0.9544\n","Epoch 18: train_loss=0.069, validation_accuracy=0.9655\n","Epoch 12: train_loss=0.105, validation_accuracy=0.9583\n","Epoch 1: train_loss=0.766, validation_accuracy=0.9129\n","Epoch 5: train_loss=0.133, validation_accuracy=0.9557\n","Epoch 13: train_loss=0.099, validation_accuracy=0.9587\n","Epoch 19: train_loss=0.067, validation_accuracy=0.9668\n","Epoch 2: train_loss=0.227, validation_accuracy=0.9422\n","Epoch 14: train_loss=0.094, validation_accuracy=0.9587\n","Epoch 6: train_loss=0.118, validation_accuracy=0.9610\n","Epoch 20: train_loss=0.062, validation_accuracy=0.9647\n","\u001b[32m[I 2023-03-07 23:21:46,852]\u001b[0m Trial 258 finished with value: 0.9647 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 36, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 43, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 42, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.004001570700352267, 'momentum': 0.7978743489261483}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 3: train_loss=0.169, validation_accuracy=0.9521\n","Epoch 15: train_loss=0.090, validation_accuracy=0.9604\n","Epoch 1: train_loss=2.291, validation_accuracy=0.1938\n","Epoch 7: train_loss=0.106, validation_accuracy=0.9623\n","Epoch 16: train_loss=0.086, validation_accuracy=0.9602\n","Epoch 4: train_loss=0.139, validation_accuracy=0.9557\n","Epoch 2: train_loss=2.170, validation_accuracy=0.4756\n","Epoch 8: train_loss=0.097, validation_accuracy=0.9552\n","Epoch 17: train_loss=0.082, validation_accuracy=0.9610\n","Epoch 3: train_loss=1.784, validation_accuracy=0.7013\n","Epoch 5: train_loss=0.119, validation_accuracy=0.9601\n","Epoch 4: train_loss=1.033, validation_accuracy=0.8312\n","\u001b[32m[I 2023-03-07 23:21:48,088]\u001b[0m Trial 263 pruned. \u001b[0m\n","Epoch 18: train_loss=0.080, validation_accuracy=0.9619\n","Epoch 9: train_loss=0.089, validation_accuracy=0.9641\n","Epoch 6: train_loss=0.105, validation_accuracy=0.9592\n","Epoch 19: train_loss=0.077, validation_accuracy=0.9623\n","Epoch 1: train_loss=1.188, validation_accuracy=0.8703\n","Epoch 10: train_loss=0.083, validation_accuracy=0.9646\n","Epoch 7: train_loss=0.096, validation_accuracy=0.9638\n","Epoch 20: train_loss=0.074, validation_accuracy=0.9630\n","\u001b[32m[I 2023-03-07 23:21:48,820]\u001b[0m Trial 260 finished with value: 0.963 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'lr': 0.0005400592031714299, 'momentum': 0.9594886047926627}. Best is trial 245 with value: 0.9691.\u001b[0m\n","Epoch 2: train_loss=0.341, validation_accuracy=0.9203\n","Epoch 11: train_loss=0.075, validation_accuracy=0.9631\n","Epoch 3: train_loss=0.228, validation_accuracy=0.9370\n","Epoch 1: train_loss=0.945, validation_accuracy=0.8822\n","Epoch 8: train_loss=0.086, validation_accuracy=0.9648\n","Epoch 12: train_loss=0.070, validation_accuracy=0.9690\n","Epoch 4: train_loss=0.187, validation_accuracy=0.9462\n","Epoch 2: train_loss=0.335, validation_accuracy=0.9144\n","Epoch 9: train_loss=0.078, validation_accuracy=0.9652\n","Epoch 5: train_loss=0.163, validation_accuracy=0.9520\n","Epoch 3: train_loss=0.257, validation_accuracy=0.9293\n","Epoch 13: train_loss=0.064, validation_accuracy=0.9668\n","Epoch 10: train_loss=0.073, validation_accuracy=0.9637\n","Epoch 6: train_loss=0.145, validation_accuracy=0.9494\n","Epoch 4: train_loss=0.218, validation_accuracy=0.9372\n","Epoch 14: train_loss=0.060, validation_accuracy=0.9667\n","Epoch 7: train_loss=0.133, validation_accuracy=0.9508\n","Epoch 5: train_loss=0.193, validation_accuracy=0.9425\n","Epoch 11: train_loss=0.065, validation_accuracy=0.9659\n","Epoch 8: train_loss=0.121, validation_accuracy=0.9587\n","Epoch 6: train_loss=0.176, validation_accuracy=0.9470\n","Epoch 15: train_loss=0.056, validation_accuracy=0.9686\n","Epoch 12: train_loss=0.061, validation_accuracy=0.9653\n","Epoch 9: train_loss=0.113, validation_accuracy=0.9600\n","Epoch 7: train_loss=0.162, validation_accuracy=0.9491\n","Epoch 16: train_loss=0.051, validation_accuracy=0.9667\n","Epoch 10: train_loss=0.107, validation_accuracy=0.9637\n","Epoch 13: train_loss=0.058, validation_accuracy=0.9687\n","Epoch 8: train_loss=0.152, validation_accuracy=0.9534\n","Epoch 11: train_loss=0.099, validation_accuracy=0.9635\n","Epoch 17: train_loss=0.048, validation_accuracy=0.9688\n","Epoch 9: train_loss=0.142, validation_accuracy=0.9504\n","Epoch 14: train_loss=0.053, validation_accuracy=0.9679\n","Epoch 12: train_loss=0.094, validation_accuracy=0.9634\n","Epoch 10: train_loss=0.136, validation_accuracy=0.9550\n","Epoch 18: train_loss=0.046, validation_accuracy=0.9688\n","Epoch 15: train_loss=0.048, validation_accuracy=0.9673\n","Epoch 13: train_loss=0.090, validation_accuracy=0.9638\n","Epoch 11: train_loss=0.128, validation_accuracy=0.9552\n","Epoch 19: train_loss=0.043, validation_accuracy=0.9691\n","Epoch 14: train_loss=0.085, validation_accuracy=0.9635\n","Epoch 12: train_loss=0.122, validation_accuracy=0.9567\n","Epoch 16: train_loss=0.046, validation_accuracy=0.9692\n","Epoch 15: train_loss=0.080, validation_accuracy=0.9626\n","Epoch 13: train_loss=0.116, validation_accuracy=0.9571\n","Epoch 20: train_loss=0.040, validation_accuracy=0.9700\n","\u001b[32m[I 2023-03-07 23:21:53,144]\u001b[0m Trial 261 finished with value: 0.97 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 41, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 47, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 37, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.0057429240762823085, 'momentum': 0.872636762299169}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 17: train_loss=0.042, validation_accuracy=0.9689\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9653\n","Epoch 14: train_loss=0.111, validation_accuracy=0.9573\n","Epoch 1: train_loss=0.925, validation_accuracy=0.9002\n","Epoch 18: train_loss=0.040, validation_accuracy=0.9689\n","Epoch 17: train_loss=0.072, validation_accuracy=0.9665\n","Epoch 15: train_loss=0.108, validation_accuracy=0.9574\n","Epoch 2: train_loss=0.320, validation_accuracy=0.9210\n","Epoch 16: train_loss=0.104, validation_accuracy=0.9603\n","Epoch 18: train_loss=0.070, validation_accuracy=0.9640\n","Epoch 19: train_loss=0.036, validation_accuracy=0.9673\n","Epoch 3: train_loss=0.239, validation_accuracy=0.9345\n","Epoch 17: train_loss=0.099, validation_accuracy=0.9609\n","Epoch 19: train_loss=0.066, validation_accuracy=0.9679\n","Epoch 4: train_loss=0.197, validation_accuracy=0.9404\n","\u001b[32m[I 2023-03-07 23:21:54,520]\u001b[0m Trial 266 pruned. \u001b[0m\n","Epoch 20: train_loss=0.034, validation_accuracy=0.9681\n","\u001b[32m[I 2023-03-07 23:21:54,571]\u001b[0m Trial 262 finished with value: 0.9681 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 49, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 50, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 37, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 22, 'activation_func[4]': 'ReLU', 'lr': 0.006614441138949666, 'momentum': 0.8820898674228903}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 18: train_loss=0.096, validation_accuracy=0.9598\n","Epoch 20: train_loss=0.064, validation_accuracy=0.9648\n","\u001b[32m[I 2023-03-07 23:21:54,749]\u001b[0m Trial 264 finished with value: 0.9648 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 38, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 25, 'activation_func[4]': 'ReLU', 'lr': 0.007498036534661354, 'momentum': 0.6845384750505851}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=0.764, validation_accuracy=0.9133\n","Epoch 1: train_loss=0.984, validation_accuracy=0.7866\n","Epoch 19: train_loss=0.094, validation_accuracy=0.9605\n","Epoch 2: train_loss=0.254, validation_accuracy=0.9363\n","Epoch 1: train_loss=1.049, validation_accuracy=0.8282\n","Epoch 2: train_loss=0.317, validation_accuracy=0.9172\n","Epoch 20: train_loss=0.091, validation_accuracy=0.9604\n","\u001b[32m[I 2023-03-07 23:21:55,450]\u001b[0m Trial 265 finished with value: 0.9604 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'lr': 0.000533491303114983, 'momentum': 0.961366558637597}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 3: train_loss=0.197, validation_accuracy=0.9464\n","Epoch 2: train_loss=0.318, validation_accuracy=0.9289\n","Epoch 3: train_loss=0.234, validation_accuracy=0.9373\n","Epoch 4: train_loss=0.170, validation_accuracy=0.9511\n","Epoch 1: train_loss=1.336, validation_accuracy=0.8338\n","Epoch 3: train_loss=0.229, validation_accuracy=0.9326\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9339\n","\u001b[32m[I 2023-03-07 23:21:56,067]\u001b[0m Trial 268 pruned. \u001b[0m\n","Epoch 5: train_loss=0.152, validation_accuracy=0.9517\n","Epoch 2: train_loss=0.446, validation_accuracy=0.8992\n","\u001b[32m[I 2023-03-07 23:21:56,248]\u001b[0m Trial 270 pruned. \u001b[0m\n","Epoch 4: train_loss=0.187, validation_accuracy=0.9480\n","Epoch 6: train_loss=0.140, validation_accuracy=0.9544\n","Epoch 1: train_loss=2.091, validation_accuracy=0.6155\n","Epoch 1: train_loss=0.916, validation_accuracy=0.8974\n","Epoch 5: train_loss=0.161, validation_accuracy=0.9521\n","Epoch 7: train_loss=0.130, validation_accuracy=0.9557\n","Epoch 2: train_loss=1.410, validation_accuracy=0.7680\n","\u001b[32m[I 2023-03-07 23:21:56,940]\u001b[0m Trial 271 pruned. \u001b[0m\n","Epoch 2: train_loss=0.290, validation_accuracy=0.9242\n","Epoch 6: train_loss=0.144, validation_accuracy=0.9540\n","Epoch 8: train_loss=0.121, validation_accuracy=0.9566\n","Epoch 1: train_loss=2.314, validation_accuracy=0.0982\n","Epoch 3: train_loss=0.225, validation_accuracy=0.9354\n","Epoch 7: train_loss=0.130, validation_accuracy=0.9587\n","Epoch 9: train_loss=0.114, validation_accuracy=0.9562\n","Epoch 2: train_loss=2.311, validation_accuracy=0.0987\n","\u001b[32m[I 2023-03-07 23:21:57,702]\u001b[0m Trial 273 pruned. \u001b[0m\n","Epoch 4: train_loss=0.194, validation_accuracy=0.9411\n","Epoch 10: train_loss=0.109, validation_accuracy=0.9586\n","Epoch 8: train_loss=0.116, validation_accuracy=0.9593\n","Epoch 5: train_loss=0.172, validation_accuracy=0.9443\n","Epoch 1: train_loss=0.991, validation_accuracy=0.8676\n","Epoch 11: train_loss=0.103, validation_accuracy=0.9582\n","Epoch 9: train_loss=0.107, validation_accuracy=0.9616\n","Epoch 2: train_loss=0.431, validation_accuracy=0.8915\n","Epoch 6: train_loss=0.158, validation_accuracy=0.9489\n","Epoch 12: train_loss=0.099, validation_accuracy=0.9594\n","Epoch 10: train_loss=0.098, validation_accuracy=0.9616\n","Epoch 3: train_loss=0.343, validation_accuracy=0.9063\n","Epoch 13: train_loss=0.094, validation_accuracy=0.9609\n","Epoch 7: train_loss=0.145, validation_accuracy=0.9491\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9613\n","Epoch 4: train_loss=0.297, validation_accuracy=0.9179\n","Epoch 14: train_loss=0.090, validation_accuracy=0.9621\n","Epoch 8: train_loss=0.135, validation_accuracy=0.9512\n","Epoch 5: train_loss=0.265, validation_accuracy=0.9272\n","Epoch 12: train_loss=0.085, validation_accuracy=0.9643\n","Epoch 15: train_loss=0.086, validation_accuracy=0.9615\n","Epoch 9: train_loss=0.127, validation_accuracy=0.9533\n","Epoch 6: train_loss=0.243, validation_accuracy=0.9290\n","Epoch 13: train_loss=0.081, validation_accuracy=0.9643\n","Epoch 16: train_loss=0.085, validation_accuracy=0.9619\n","Epoch 10: train_loss=0.119, validation_accuracy=0.9541\n","Epoch 7: train_loss=0.224, validation_accuracy=0.9363\n","Epoch 17: train_loss=0.081, validation_accuracy=0.9616\n","Epoch 14: train_loss=0.076, validation_accuracy=0.9617\n","Epoch 11: train_loss=0.112, validation_accuracy=0.9559\n","Epoch 8: train_loss=0.208, validation_accuracy=0.9384\n","Epoch 18: train_loss=0.078, validation_accuracy=0.9617\n","Epoch 15: train_loss=0.073, validation_accuracy=0.9660\n","Epoch 9: train_loss=0.192, validation_accuracy=0.9430\n","Epoch 12: train_loss=0.107, validation_accuracy=0.9566\n","Epoch 19: train_loss=0.074, validation_accuracy=0.9632\n","Epoch 16: train_loss=0.067, validation_accuracy=0.9673\n","Epoch 10: train_loss=0.181, validation_accuracy=0.9441\n","Epoch 13: train_loss=0.102, validation_accuracy=0.9566\n","Epoch 20: train_loss=0.073, validation_accuracy=0.9607\n","\u001b[32m[I 2023-03-07 23:22:00,914]\u001b[0m Trial 267 finished with value: 0.9607 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 38, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ReLU', 'lr': 0.0008723225279065934, 'momentum': 0.968416664008404}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 17: train_loss=0.063, validation_accuracy=0.9649\n","Epoch 11: train_loss=0.171, validation_accuracy=0.9455\n","Epoch 14: train_loss=0.097, validation_accuracy=0.9579\n","Epoch 1: train_loss=0.895, validation_accuracy=0.8922\n","Epoch 12: train_loss=0.166, validation_accuracy=0.9460\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9641\n","Epoch 2: train_loss=0.312, validation_accuracy=0.9227\n","Epoch 15: train_loss=0.093, validation_accuracy=0.9583\n","Epoch 13: train_loss=0.161, validation_accuracy=0.9486\n","Epoch 3: train_loss=0.245, validation_accuracy=0.9320\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9690\n","Epoch 16: train_loss=0.089, validation_accuracy=0.9585\n","Epoch 14: train_loss=0.155, validation_accuracy=0.9481\n","Epoch 4: train_loss=0.208, validation_accuracy=0.9390\n","Epoch 20: train_loss=0.054, validation_accuracy=0.9642\n","\u001b[32m[I 2023-03-07 23:22:02,266]\u001b[0m Trial 269 finished with value: 0.9642 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 46, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 22, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 30, 'activation_func[4]': 'ReLU', 'lr': 0.007854667457115359, 'momentum': 0.665783408724708}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 17: train_loss=0.086, validation_accuracy=0.9584\n","Epoch 15: train_loss=0.152, validation_accuracy=0.9494\n","Epoch 5: train_loss=0.183, validation_accuracy=0.9447\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9591\n","Epoch 6: train_loss=0.168, validation_accuracy=0.9481\n","Epoch 1: train_loss=0.846, validation_accuracy=0.9087\n","Epoch 16: train_loss=0.142, validation_accuracy=0.9508\n","Epoch 7: train_loss=0.155, validation_accuracy=0.9498\n","Epoch 17: train_loss=0.141, validation_accuracy=0.9505\n","Epoch 19: train_loss=0.080, validation_accuracy=0.9597\n","Epoch 2: train_loss=0.272, validation_accuracy=0.9308\n","Epoch 8: train_loss=0.144, validation_accuracy=0.9506\n","Epoch 18: train_loss=0.133, validation_accuracy=0.9529\n","Epoch 20: train_loss=0.077, validation_accuracy=0.9595\n","Epoch 3: train_loss=0.208, validation_accuracy=0.9439\n","\u001b[32m[I 2023-03-07 23:22:03,358]\u001b[0m Trial 272 finished with value: 0.9595 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 33, 'activation_func[2]': 'ReLU', 'lr': 0.0005778266012307173, 'momentum': 0.959053533709578}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 9: train_loss=0.134, validation_accuracy=0.9538\n","Epoch 19: train_loss=0.128, validation_accuracy=0.9551\n","Epoch 4: train_loss=0.172, validation_accuracy=0.9470\n","Epoch 1: train_loss=0.951, validation_accuracy=0.9005\n","Epoch 10: train_loss=0.128, validation_accuracy=0.9524\n","Epoch 20: train_loss=0.124, validation_accuracy=0.9540\n","\u001b[32m[I 2023-03-07 23:22:03,904]\u001b[0m Trial 274 finished with value: 0.954 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 32, 'activation_func[2]': 'ReLU', 'lr': 0.0003662842187589869, 'momentum': 0.9966987991280872}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 11: train_loss=0.122, validation_accuracy=0.9549\n","Epoch 5: train_loss=0.151, validation_accuracy=0.9438\n","Epoch 2: train_loss=0.333, validation_accuracy=0.9223\n","Epoch 12: train_loss=0.115, validation_accuracy=0.9553\n","Epoch 6: train_loss=0.137, validation_accuracy=0.9565\n","Epoch 1: train_loss=1.894, validation_accuracy=0.7265\n","Epoch 3: train_loss=0.250, validation_accuracy=0.9359\n","Epoch 13: train_loss=0.111, validation_accuracy=0.9562\n","Epoch 7: train_loss=0.124, validation_accuracy=0.9590\n","Epoch 4: train_loss=0.211, validation_accuracy=0.9395\n","\u001b[32m[I 2023-03-07 23:22:04,935]\u001b[0m Trial 277 pruned. \u001b[0m\n","Epoch 14: train_loss=0.106, validation_accuracy=0.9552\n","Epoch 2: train_loss=0.853, validation_accuracy=0.8781\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9612\n","Epoch 15: train_loss=0.103, validation_accuracy=0.9573\n","Epoch 1: train_loss=1.816, validation_accuracy=0.7768\n","Epoch 3: train_loss=0.426, validation_accuracy=0.9162\n","Epoch 9: train_loss=0.104, validation_accuracy=0.9605\n","Epoch 16: train_loss=0.100, validation_accuracy=0.9589\n","Epoch 2: train_loss=1.175, validation_accuracy=0.8639\n","\u001b[32m[I 2023-03-07 23:22:05,726]\u001b[0m Trial 279 pruned. \u001b[0m\n","Epoch 17: train_loss=0.095, validation_accuracy=0.9579\n","Epoch 10: train_loss=0.107, validation_accuracy=0.9569\n","\u001b[32m[I 2023-03-07 23:22:05,876]\u001b[0m Trial 276 pruned. \u001b[0m\n","Epoch 4: train_loss=0.304, validation_accuracy=0.9330\n","Epoch 18: train_loss=0.094, validation_accuracy=0.9581\n","Epoch 1: train_loss=1.936, validation_accuracy=0.6994\n","Epoch 1: train_loss=0.882, validation_accuracy=0.8841\n","Epoch 19: train_loss=0.090, validation_accuracy=0.9582\n","Epoch 2: train_loss=1.299, validation_accuracy=0.8526\n","Epoch 5: train_loss=0.246, validation_accuracy=0.9384\n","Epoch 20: train_loss=0.088, validation_accuracy=0.9583\n","\u001b[32m[I 2023-03-07 23:22:06,671]\u001b[0m Trial 275 finished with value: 0.9583 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 32, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ReLU', 'lr': 0.0008390539224885007, 'momentum': 0.9725463329322457}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 2: train_loss=0.293, validation_accuracy=0.9278\n","Epoch 3: train_loss=0.891, validation_accuracy=0.8928\n","Epoch 6: train_loss=0.215, validation_accuracy=0.9473\n","Epoch 3: train_loss=0.220, validation_accuracy=0.9433\n","Epoch 1: train_loss=1.017, validation_accuracy=0.8960\n","Epoch 4: train_loss=0.664, validation_accuracy=0.9128\n","Epoch 4: train_loss=0.171, validation_accuracy=0.9484\n","Epoch 2: train_loss=0.300, validation_accuracy=0.9293\n","Epoch 7: train_loss=0.192, validation_accuracy=0.9468\n","Epoch 5: train_loss=0.526, validation_accuracy=0.9246\n","Epoch 5: train_loss=0.147, validation_accuracy=0.9534\n","Epoch 3: train_loss=0.218, validation_accuracy=0.9396\n","Epoch 6: train_loss=0.435, validation_accuracy=0.9307\n","Epoch 6: train_loss=0.133, validation_accuracy=0.9570\n","Epoch 8: train_loss=0.175, validation_accuracy=0.9515\n","Epoch 4: train_loss=0.185, validation_accuracy=0.9479\n","Epoch 7: train_loss=0.371, validation_accuracy=0.9365\n","Epoch 7: train_loss=0.120, validation_accuracy=0.9580\n","Epoch 5: train_loss=0.155, validation_accuracy=0.9478\n","Epoch 9: train_loss=0.158, validation_accuracy=0.9482\n","Epoch 8: train_loss=0.110, validation_accuracy=0.9608\n","Epoch 8: train_loss=0.324, validation_accuracy=0.9411\n","Epoch 6: train_loss=0.140, validation_accuracy=0.9516\n","Epoch 10: train_loss=0.150, validation_accuracy=0.9499\n","Epoch 9: train_loss=0.101, validation_accuracy=0.9612\n","Epoch 9: train_loss=0.287, validation_accuracy=0.9454\n","Epoch 7: train_loss=0.129, validation_accuracy=0.9572\n","Epoch 10: train_loss=0.096, validation_accuracy=0.9599\n","Epoch 10: train_loss=0.258, validation_accuracy=0.9491\n","Epoch 8: train_loss=0.114, validation_accuracy=0.9586\n","Epoch 11: train_loss=0.138, validation_accuracy=0.9533\n","Epoch 11: train_loss=0.087, validation_accuracy=0.9616\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9588\n","Epoch 11: train_loss=0.234, validation_accuracy=0.9519\n","Epoch 12: train_loss=0.129, validation_accuracy=0.9505\n","Epoch 12: train_loss=0.083, validation_accuracy=0.9623\n","Epoch 10: train_loss=0.104, validation_accuracy=0.9613\n","Epoch 12: train_loss=0.214, validation_accuracy=0.9530\n","Epoch 13: train_loss=0.076, validation_accuracy=0.9645\n","Epoch 11: train_loss=0.091, validation_accuracy=0.9630\n","Epoch 13: train_loss=0.121, validation_accuracy=0.9577\n","Epoch 13: train_loss=0.198, validation_accuracy=0.9551\n","Epoch 14: train_loss=0.074, validation_accuracy=0.9613\n","Epoch 12: train_loss=0.085, validation_accuracy=0.9608\n","Epoch 14: train_loss=0.184, validation_accuracy=0.9561\n","Epoch 14: train_loss=0.113, validation_accuracy=0.9566\n","Epoch 13: train_loss=0.082, validation_accuracy=0.9640\n","Epoch 15: train_loss=0.067, validation_accuracy=0.9645\n","Epoch 15: train_loss=0.173, validation_accuracy=0.9566\n","Epoch 14: train_loss=0.077, validation_accuracy=0.9650\n","Epoch 16: train_loss=0.063, validation_accuracy=0.9636\n","Epoch 15: train_loss=0.108, validation_accuracy=0.9546\n","Epoch 16: train_loss=0.162, validation_accuracy=0.9583\n","Epoch 15: train_loss=0.072, validation_accuracy=0.9642\n","Epoch 17: train_loss=0.063, validation_accuracy=0.9662\n","Epoch 17: train_loss=0.154, validation_accuracy=0.9594\n","Epoch 16: train_loss=0.101, validation_accuracy=0.9555\n","Epoch 16: train_loss=0.069, validation_accuracy=0.9623\n","Epoch 18: train_loss=0.058, validation_accuracy=0.9671\n","Epoch 17: train_loss=0.066, validation_accuracy=0.9632\n","Epoch 18: train_loss=0.145, validation_accuracy=0.9591\n","Epoch 19: train_loss=0.054, validation_accuracy=0.9655\n","Epoch 17: train_loss=0.096, validation_accuracy=0.9587\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9658\n","Epoch 19: train_loss=0.138, validation_accuracy=0.9622\n","Epoch 20: train_loss=0.051, validation_accuracy=0.9599\n","\u001b[32m[I 2023-03-07 23:22:12,870]\u001b[0m Trial 281 finished with value: 0.9599 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 47, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 19, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 18, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 29, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 28, 'activation_func[4]': 'ReLU', 'lr': 0.008560286316694109, 'momentum': 0.6988921554152693}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 19: train_loss=0.059, validation_accuracy=0.9651\n","Epoch 18: train_loss=0.095, validation_accuracy=0.9556\n","Epoch 20: train_loss=0.130, validation_accuracy=0.9615\n","\u001b[32m[I 2023-03-07 23:22:13,164]\u001b[0m Trial 280 finished with value: 0.9615 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 35, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 33, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'Sigmoid', 'lr': 0.001062359890590886, 'momentum': 0.9614974013967748}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=1.055, validation_accuracy=0.8836\n","Epoch 20: train_loss=0.056, validation_accuracy=0.9648\n","\u001b[32m[I 2023-03-07 23:22:13,487]\u001b[0m Trial 282 finished with value: 0.9648 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 49, 'activation_func[0]': 'ReLU', 'hidden_dim[1]': 18, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 26, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.007667374435274437, 'momentum': 0.6863390645361543}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=1.017, validation_accuracy=0.7955\n","Epoch 19: train_loss=0.089, validation_accuracy=0.9609\n","Epoch 2: train_loss=0.324, validation_accuracy=0.9163\n","Epoch 1: train_loss=2.285, validation_accuracy=0.1750\n","Epoch 2: train_loss=0.350, validation_accuracy=0.9106\n","Epoch 3: train_loss=0.235, validation_accuracy=0.9361\n","Epoch 20: train_loss=0.084, validation_accuracy=0.9641\n","\u001b[32m[I 2023-03-07 23:22:14,188]\u001b[0m Trial 278 finished with value: 0.9641 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 50, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 50, 'activation_func[2]': 'Tanh', 'hidden_dim[3]': 35, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 24, 'activation_func[4]': 'ReLU', 'lr': 0.007802372551522126, 'momentum': 0.8286515197592281}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 2: train_loss=2.226, validation_accuracy=0.2656\n","\u001b[32m[I 2023-03-07 23:22:14,221]\u001b[0m Trial 285 pruned. \u001b[0m\n","Epoch 3: train_loss=0.262, validation_accuracy=0.9336\n","Epoch 4: train_loss=0.196, validation_accuracy=0.9414\n","\u001b[32m[I 2023-03-07 23:22:14,470]\u001b[0m Trial 283 pruned. \u001b[0m\n","Epoch 1: train_loss=2.288, validation_accuracy=0.1171\n","Epoch 1: train_loss=0.966, validation_accuracy=0.8831\n","Epoch 4: train_loss=0.222, validation_accuracy=0.9417\n","\u001b[32m[I 2023-03-07 23:22:14,619]\u001b[0m Trial 284 pruned. \u001b[0m\n","Epoch 2: train_loss=2.228, validation_accuracy=0.4116\n","\u001b[32m[I 2023-03-07 23:22:14,897]\u001b[0m Trial 286 pruned. \u001b[0m\n","Epoch 1: train_loss=2.122, validation_accuracy=0.3270\n","Epoch 2: train_loss=0.333, validation_accuracy=0.9220\n","Epoch 1: train_loss=2.276, validation_accuracy=0.3644\n","Epoch 1: train_loss=0.852, validation_accuracy=0.9016\n","Epoch 3: train_loss=0.244, validation_accuracy=0.9342\n","Epoch 2: train_loss=1.440, validation_accuracy=0.6918\n","\u001b[32m[I 2023-03-07 23:22:15,361]\u001b[0m Trial 288 pruned. \u001b[0m\n","Epoch 2: train_loss=0.274, validation_accuracy=0.9320\n","Epoch 2: train_loss=2.025, validation_accuracy=0.4395\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9186\n","\u001b[32m[I 2023-03-07 23:22:15,665]\u001b[0m Trial 287 pruned. \u001b[0m\n","Epoch 1: train_loss=2.139, validation_accuracy=0.5572\n","Epoch 3: train_loss=0.211, validation_accuracy=0.9432\n","Epoch 3: train_loss=1.244, validation_accuracy=0.7666\n","Epoch 1: train_loss=0.908, validation_accuracy=0.8916\n","Epoch 4: train_loss=0.179, validation_accuracy=0.9481\n","Epoch 2: train_loss=1.725, validation_accuracy=0.7236\n","\u001b[32m[I 2023-03-07 23:22:16,188]\u001b[0m Trial 291 pruned. \u001b[0m\n","Epoch 4: train_loss=0.656, validation_accuracy=0.8767\n","Epoch 2: train_loss=0.315, validation_accuracy=0.9304\n","Epoch 5: train_loss=0.159, validation_accuracy=0.9499\n","Epoch 1: train_loss=1.993, validation_accuracy=0.6428\n","Epoch 6: train_loss=0.146, validation_accuracy=0.9502\n","Epoch 5: train_loss=0.446, validation_accuracy=0.9038\n","Epoch 3: train_loss=0.235, validation_accuracy=0.9332\n","Epoch 2: train_loss=1.438, validation_accuracy=0.8164\n","Epoch 7: train_loss=0.135, validation_accuracy=0.9576\n","Epoch 4: train_loss=0.200, validation_accuracy=0.9463\n","Epoch 6: train_loss=0.361, validation_accuracy=0.9217\n","Epoch 8: train_loss=0.125, validation_accuracy=0.9566\n","Epoch 3: train_loss=1.083, validation_accuracy=0.8816\n","Epoch 5: train_loss=0.168, validation_accuracy=0.9488\n","Epoch 7: train_loss=0.313, validation_accuracy=0.9263\n","Epoch 9: train_loss=0.119, validation_accuracy=0.9546\n","Epoch 4: train_loss=0.822, validation_accuracy=0.9041\n","\u001b[32m[I 2023-03-07 23:22:17,713]\u001b[0m Trial 293 pruned. \u001b[0m\n","Epoch 6: train_loss=0.153, validation_accuracy=0.9535\n","Epoch 10: train_loss=0.113, validation_accuracy=0.9580\n","Epoch 8: train_loss=0.281, validation_accuracy=0.9282\n","Epoch 1: train_loss=1.061, validation_accuracy=0.8503\n","Epoch 7: train_loss=0.139, validation_accuracy=0.9562\n","Epoch 11: train_loss=0.107, validation_accuracy=0.9574\n","Epoch 9: train_loss=0.258, validation_accuracy=0.9309\n","Epoch 2: train_loss=0.412, validation_accuracy=0.9117\n","Epoch 12: train_loss=0.103, validation_accuracy=0.9606\n","Epoch 8: train_loss=0.127, validation_accuracy=0.9585\n","Epoch 13: train_loss=0.096, validation_accuracy=0.9599\n","Epoch 3: train_loss=0.282, validation_accuracy=0.9324\n","Epoch 10: train_loss=0.237, validation_accuracy=0.9360\n","\u001b[32m[I 2023-03-07 23:22:18,985]\u001b[0m Trial 289 pruned. \u001b[0m\n","Epoch 9: train_loss=0.117, validation_accuracy=0.9591\n","Epoch 14: train_loss=0.092, validation_accuracy=0.9597\n","Epoch 4: train_loss=0.233, validation_accuracy=0.6885\n","\u001b[32m[I 2023-03-07 23:22:19,261]\u001b[0m Trial 294 pruned. \u001b[0m\n","Epoch 10: train_loss=0.110, validation_accuracy=0.9589\n","\u001b[32m[I 2023-03-07 23:22:19,393]\u001b[0m Trial 292 pruned. \u001b[0m\n","Epoch 1: train_loss=1.518, validation_accuracy=0.7351\n","Epoch 15: train_loss=0.089, validation_accuracy=0.9584\n","Epoch 1: train_loss=1.289, validation_accuracy=0.7744\n","Epoch 1: train_loss=0.756, validation_accuracy=0.9020\n","Epoch 16: train_loss=0.087, validation_accuracy=0.9584\n","Epoch 2: train_loss=0.654, validation_accuracy=0.8424\n","\u001b[32m[I 2023-03-07 23:22:19,881]\u001b[0m Trial 295 pruned. \u001b[0m\n","Epoch 2: train_loss=0.276, validation_accuracy=0.9309\n","Epoch 2: train_loss=0.360, validation_accuracy=0.9251\n","Epoch 17: train_loss=0.083, validation_accuracy=0.9585\n","Epoch 1: train_loss=0.985, validation_accuracy=0.8989\n","Epoch 3: train_loss=0.212, validation_accuracy=0.9390\n","Epoch 18: train_loss=0.079, validation_accuracy=0.9590\n","Epoch 3: train_loss=0.247, validation_accuracy=0.9368\n","Epoch 2: train_loss=0.313, validation_accuracy=0.9188\n","Epoch 4: train_loss=0.181, validation_accuracy=0.9451\n","Epoch 19: train_loss=0.078, validation_accuracy=0.9597\n","Epoch 4: train_loss=0.205, validation_accuracy=0.9424\n","\u001b[32m[I 2023-03-07 23:22:20,743]\u001b[0m Trial 296 pruned. \u001b[0m\n","Epoch 5: train_loss=0.162, validation_accuracy=0.9487\n","Epoch 3: train_loss=0.256, validation_accuracy=0.9286\n","Epoch 20: train_loss=0.075, validation_accuracy=0.9581\n","\u001b[32m[I 2023-03-07 23:22:21,008]\u001b[0m Trial 290 finished with value: 0.9581 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 32, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 34, 'activation_func[2]': 'ReLU', 'lr': 0.0010942235379092333, 'momentum': 0.9644409307476696}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=2.288, validation_accuracy=0.2475\n","Epoch 6: train_loss=0.148, validation_accuracy=0.9497\n","Epoch 4: train_loss=0.226, validation_accuracy=0.9354\n","Epoch 2: train_loss=2.220, validation_accuracy=0.3357\n","Epoch 1: train_loss=2.269, validation_accuracy=0.2926\n","Epoch 7: train_loss=0.137, validation_accuracy=0.9524\n","Epoch 5: train_loss=0.207, validation_accuracy=0.9375\n","Epoch 3: train_loss=2.099, validation_accuracy=0.4917\n","Epoch 2: train_loss=2.156, validation_accuracy=0.4787\n","\u001b[32m[I 2023-03-07 23:22:21,777]\u001b[0m Trial 300 pruned. \u001b[0m\n","Epoch 8: train_loss=0.128, validation_accuracy=0.9529\n","Epoch 6: train_loss=0.193, validation_accuracy=0.9407\n","Epoch 4: train_loss=1.865, validation_accuracy=0.5554\n","\u001b[32m[I 2023-03-07 23:22:21,995]\u001b[0m Trial 299 pruned. \u001b[0m\n","Epoch 9: train_loss=0.121, validation_accuracy=0.9537\n","Epoch 1: train_loss=1.139, validation_accuracy=0.8624\n","Epoch 7: train_loss=0.183, validation_accuracy=0.9410\n","Epoch 10: train_loss=0.114, validation_accuracy=0.9542\n","Epoch 2: train_loss=0.386, validation_accuracy=0.9049\n","Epoch 1: train_loss=2.262, validation_accuracy=0.3607\n","Epoch 8: train_loss=0.173, validation_accuracy=0.9470\n","Epoch 11: train_loss=0.109, validation_accuracy=0.9575\n","Epoch 3: train_loss=0.298, validation_accuracy=0.9236\n","Epoch 9: train_loss=0.165, validation_accuracy=0.9460\n","Epoch 12: train_loss=0.104, validation_accuracy=0.9542\n","Epoch 2: train_loss=1.628, validation_accuracy=0.6503\n","Epoch 4: train_loss=0.252, validation_accuracy=0.9302\n","Epoch 10: train_loss=0.158, validation_accuracy=0.9467\n","Epoch 13: train_loss=0.101, validation_accuracy=0.9574\n","Epoch 5: train_loss=0.222, validation_accuracy=0.9347\n","Epoch 3: train_loss=0.974, validation_accuracy=0.7083\n","Epoch 11: train_loss=0.153, validation_accuracy=0.9473\n","Epoch 14: train_loss=0.098, validation_accuracy=0.9555\n","Epoch 6: train_loss=0.200, validation_accuracy=0.9355\n","Epoch 15: train_loss=0.094, validation_accuracy=0.9559\n","Epoch 12: train_loss=0.150, validation_accuracy=0.9503\n","Epoch 4: train_loss=0.884, validation_accuracy=0.7608\n","Epoch 7: train_loss=0.186, validation_accuracy=0.9412\n","Epoch 16: train_loss=0.090, validation_accuracy=0.9582\n","Epoch 13: train_loss=0.144, validation_accuracy=0.9493\n","Epoch 8: train_loss=0.174, validation_accuracy=0.9449\n","Epoch 17: train_loss=0.086, validation_accuracy=0.9593\n","Epoch 5: train_loss=0.809, validation_accuracy=0.7644\n","Epoch 14: train_loss=0.141, validation_accuracy=0.9470\n","Epoch 9: train_loss=0.165, validation_accuracy=0.9456\n","Epoch 18: train_loss=0.085, validation_accuracy=0.9594\n","Epoch 15: train_loss=0.138, validation_accuracy=0.9497\n","Epoch 6: train_loss=0.787, validation_accuracy=0.7762\n","Epoch 10: train_loss=0.157, validation_accuracy=0.9478\n","Epoch 19: train_loss=0.083, validation_accuracy=0.9579\n","Epoch 16: train_loss=0.134, validation_accuracy=0.9537\n","Epoch 20: train_loss=0.080, validation_accuracy=0.9615\n","\u001b[32m[I 2023-03-07 23:22:25,214]\u001b[0m Trial 297 finished with value: 0.9615 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 28, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 43, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'lr': 0.0014388100211977148, 'momentum': 0.9710557543043424}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 11: train_loss=0.150, validation_accuracy=0.9507\n","Epoch 7: train_loss=0.729, validation_accuracy=0.7727\n","Epoch 17: train_loss=0.132, validation_accuracy=0.9520\n","Epoch 12: train_loss=0.143, validation_accuracy=0.9495\n","Epoch 1: train_loss=2.290, validation_accuracy=0.1238\n","Epoch 18: train_loss=0.129, validation_accuracy=0.9528\n","Epoch 8: train_loss=0.764, validation_accuracy=0.8028\n","Epoch 13: train_loss=0.139, validation_accuracy=0.9502\n","Epoch 19: train_loss=0.125, validation_accuracy=0.9527\n","Epoch 2: train_loss=2.269, validation_accuracy=0.1942\n","\u001b[32m[I 2023-03-07 23:22:26,181]\u001b[0m Trial 303 pruned. \u001b[0m\n","Epoch 14: train_loss=0.134, validation_accuracy=0.9504\n","Epoch 20: train_loss=0.124, validation_accuracy=0.9549\n","Epoch 9: train_loss=0.660, validation_accuracy=0.7815\n","\u001b[32m[I 2023-03-07 23:22:26,454]\u001b[0m Trial 298 finished with value: 0.9549 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 38, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 45, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 26, 'activation_func[2]': 'ReLU', 'lr': 0.0009752475109568084, 'momentum': 0.955330900840683}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=2.091, validation_accuracy=0.4955\n","Epoch 15: train_loss=0.130, validation_accuracy=0.9530\n","Epoch 1: train_loss=1.924, validation_accuracy=0.6821\n","Epoch 10: train_loss=0.686, validation_accuracy=0.8029\n","\u001b[32m[I 2023-03-07 23:22:26,915]\u001b[0m Trial 302 pruned. \u001b[0m\n","Epoch 2: train_loss=1.616, validation_accuracy=0.6883\n","\u001b[32m[I 2023-03-07 23:22:26,959]\u001b[0m Trial 304 pruned. \u001b[0m\n","Epoch 16: train_loss=0.124, validation_accuracy=0.9521\n","Epoch 2: train_loss=1.004, validation_accuracy=0.8518\n","Epoch 17: train_loss=0.121, validation_accuracy=0.9528\n","Epoch 1: train_loss=1.007, validation_accuracy=0.8916\n","Epoch 1: train_loss=2.286, validation_accuracy=0.2510\n","Epoch 3: train_loss=0.558, validation_accuracy=0.9107\n","Epoch 18: train_loss=0.119, validation_accuracy=0.9534\n","Epoch 2: train_loss=0.328, validation_accuracy=0.9206\n","Epoch 2: train_loss=2.216, validation_accuracy=0.2817\n","\u001b[32m[I 2023-03-07 23:22:27,956]\u001b[0m Trial 306 pruned. \u001b[0m\n","Epoch 19: train_loss=0.115, validation_accuracy=0.9536\n","Epoch 3: train_loss=0.241, validation_accuracy=0.9332\n","Epoch 4: train_loss=0.367, validation_accuracy=0.9311\n","Epoch 20: train_loss=0.112, validation_accuracy=0.9551\n","\u001b[32m[I 2023-03-07 23:22:28,403]\u001b[0m Trial 301 finished with value: 0.9551 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 36, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 29, 'activation_func[2]': 'ReLU', 'lr': 0.0008377602359862162, 'momentum': 0.9454583710012627}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 4: train_loss=0.204, validation_accuracy=0.9408\n","\u001b[32m[I 2023-03-07 23:22:28,412]\u001b[0m Trial 307 pruned. \u001b[0m\n","Epoch 1: train_loss=2.307, validation_accuracy=0.1078\n","Epoch 5: train_loss=0.272, validation_accuracy=0.9448\n","Epoch 1: train_loss=0.763, validation_accuracy=0.9001\n","Epoch 1: train_loss=2.515, validation_accuracy=0.1010\n","Epoch 6: train_loss=0.220, validation_accuracy=0.9464\n","Epoch 2: train_loss=2.291, validation_accuracy=0.1408\n","\u001b[32m[I 2023-03-07 23:22:28,954]\u001b[0m Trial 308 pruned. \u001b[0m\n","Epoch 2: train_loss=0.293, validation_accuracy=0.9248\n","Epoch 2: train_loss=2.302, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:22:29,253]\u001b[0m Trial 309 pruned. \u001b[0m\n","Epoch 7: train_loss=0.190, validation_accuracy=0.9490\n","Epoch 1: train_loss=1.006, validation_accuracy=0.8929\n","Epoch 3: train_loss=0.234, validation_accuracy=0.9338\n","Epoch 1: train_loss=0.858, validation_accuracy=0.8971\n","Epoch 8: train_loss=0.168, validation_accuracy=0.9525\n","Epoch 2: train_loss=0.289, validation_accuracy=0.9283\n","Epoch 4: train_loss=0.202, validation_accuracy=0.9384\n","Epoch 2: train_loss=0.307, validation_accuracy=0.9224\n","Epoch 3: train_loss=0.217, validation_accuracy=0.9345\n","Epoch 9: train_loss=0.153, validation_accuracy=0.9547\n","Epoch 5: train_loss=0.179, validation_accuracy=0.9437\n","Epoch 3: train_loss=0.260, validation_accuracy=0.9287\n","Epoch 4: train_loss=0.187, validation_accuracy=0.9429\n","Epoch 6: train_loss=0.164, validation_accuracy=0.9457\n","Epoch 10: train_loss=0.140, validation_accuracy=0.9547\n","Epoch 4: train_loss=0.233, validation_accuracy=0.9334\n","Epoch 7: train_loss=0.151, validation_accuracy=0.9484\n","Epoch 5: train_loss=0.170, validation_accuracy=0.9427\n","Epoch 5: train_loss=0.216, validation_accuracy=0.9331\n","Epoch 11: train_loss=0.130, validation_accuracy=0.9560\n","Epoch 8: train_loss=0.143, validation_accuracy=0.9505\n","Epoch 6: train_loss=0.156, validation_accuracy=0.9480\n","Epoch 6: train_loss=0.205, validation_accuracy=0.9351\n","Epoch 12: train_loss=0.123, validation_accuracy=0.9579\n","Epoch 9: train_loss=0.134, validation_accuracy=0.9500\n","Epoch 7: train_loss=0.198, validation_accuracy=0.9388\n","Epoch 7: train_loss=0.147, validation_accuracy=0.9487\n","Epoch 13: train_loss=0.117, validation_accuracy=0.9589\n","Epoch 10: train_loss=0.127, validation_accuracy=0.9527\n","Epoch 8: train_loss=0.190, validation_accuracy=0.9377\n","Epoch 8: train_loss=0.138, validation_accuracy=0.9483\n","Epoch 14: train_loss=0.109, validation_accuracy=0.9588\n","Epoch 11: train_loss=0.121, validation_accuracy=0.9526\n","Epoch 9: train_loss=0.184, validation_accuracy=0.9381\n","Epoch 9: train_loss=0.131, validation_accuracy=0.9516\n","Epoch 10: train_loss=0.179, validation_accuracy=0.9399\n","\u001b[32m[I 2023-03-07 23:22:32,335]\u001b[0m Trial 312 pruned. \u001b[0m\n","Epoch 12: train_loss=0.116, validation_accuracy=0.9537\n","Epoch 15: train_loss=0.103, validation_accuracy=0.9598\n","Epoch 10: train_loss=0.126, validation_accuracy=0.9525\n","Epoch 13: train_loss=0.111, validation_accuracy=0.9559\n","Epoch 16: train_loss=0.098, validation_accuracy=0.9607\n","Epoch 11: train_loss=0.121, validation_accuracy=0.9511\n","Epoch 1: train_loss=0.904, validation_accuracy=0.8992\n","Epoch 14: train_loss=0.106, validation_accuracy=0.9561\n","Epoch 17: train_loss=0.093, validation_accuracy=0.9618\n","Epoch 12: train_loss=0.116, validation_accuracy=0.9541\n","Epoch 15: train_loss=0.102, validation_accuracy=0.9549\n","Epoch 2: train_loss=0.289, validation_accuracy=0.9311\n","Epoch 18: train_loss=0.088, validation_accuracy=0.9615\n","Epoch 13: train_loss=0.111, validation_accuracy=0.9541\n","Epoch 16: train_loss=0.098, validation_accuracy=0.9561\n","Epoch 14: train_loss=0.109, validation_accuracy=0.9558\n","Epoch 19: train_loss=0.084, validation_accuracy=0.9611\n","Epoch 3: train_loss=0.216, validation_accuracy=0.9451\n","Epoch 17: train_loss=0.095, validation_accuracy=0.9571\n","Epoch 15: train_loss=0.104, validation_accuracy=0.9557\n","Epoch 20: train_loss=0.081, validation_accuracy=0.9631\n","\u001b[32m[I 2023-03-07 23:22:34,459]\u001b[0m Trial 305 finished with value: 0.9631 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 27, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 43, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 32, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 37, 'activation_func[3]': 'Sigmoid', 'lr': 0.0015056666402684827, 'momentum': 0.9788704964547201}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 18: train_loss=0.090, validation_accuracy=0.9585\n","Epoch 4: train_loss=0.179, validation_accuracy=0.9505\n","Epoch 16: train_loss=0.100, validation_accuracy=0.9564\n","Epoch 19: train_loss=0.088, validation_accuracy=0.9598\n","Epoch 1: train_loss=2.225, validation_accuracy=0.2609\n","Epoch 17: train_loss=0.097, validation_accuracy=0.9559\n","Epoch 20: train_loss=0.085, validation_accuracy=0.9601\n","Epoch 5: train_loss=0.156, validation_accuracy=0.9547\n","\u001b[32m[I 2023-03-07 23:22:35,120]\u001b[0m Trial 310 finished with value: 0.9601 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 29, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 43, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 32, 'activation_func[2]': 'ReLU', 'lr': 0.0012615439172181313, 'momentum': 0.9383065333147137}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 18: train_loss=0.095, validation_accuracy=0.9568\n","Epoch 1: train_loss=1.910, validation_accuracy=0.7650\n","Epoch 6: train_loss=0.139, validation_accuracy=0.9569\n","Epoch 2: train_loss=1.731, validation_accuracy=0.7436\n","Epoch 19: train_loss=0.090, validation_accuracy=0.9578\n","Epoch 2: train_loss=1.043, validation_accuracy=0.8737\n","Epoch 20: train_loss=0.089, validation_accuracy=0.9570\n","\u001b[32m[I 2023-03-07 23:22:36,137]\u001b[0m Trial 311 finished with value: 0.957 and parameters: {'n_hidden_layers': 3, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 39, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ReLU', 'lr': 0.00108551577325593, 'momentum': 0.9620564180088738}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 7: train_loss=0.128, validation_accuracy=0.9606\n","Epoch 3: train_loss=0.817, validation_accuracy=0.9031\n","Epoch 3: train_loss=0.575, validation_accuracy=0.9160\n","Epoch 4: train_loss=0.372, validation_accuracy=0.9331\n","Epoch 1: train_loss=1.265, validation_accuracy=0.8224\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9613\n","Epoch 4: train_loss=0.410, validation_accuracy=0.9207\n","Epoch 5: train_loss=0.277, validation_accuracy=0.9427\n","Epoch 2: train_loss=0.613, validation_accuracy=0.9023\n","\u001b[32m[I 2023-03-07 23:22:37,180]\u001b[0m Trial 316 pruned. \u001b[0m\n","Epoch 9: train_loss=0.107, validation_accuracy=0.9605\n","Epoch 6: train_loss=0.226, validation_accuracy=0.9491\n","Epoch 5: train_loss=0.287, validation_accuracy=0.9362\n","Epoch 1: train_loss=1.923, validation_accuracy=0.7751\n","Epoch 7: train_loss=0.195, validation_accuracy=0.9545\n","Epoch 10: train_loss=0.099, validation_accuracy=0.9632\n","Epoch 6: train_loss=0.225, validation_accuracy=0.9419\n","Epoch 2: train_loss=1.193, validation_accuracy=0.8834\n","Epoch 8: train_loss=0.173, validation_accuracy=0.9569\n","Epoch 11: train_loss=0.093, validation_accuracy=0.9648\n","Epoch 3: train_loss=0.785, validation_accuracy=0.9053\n","Epoch 9: train_loss=0.155, validation_accuracy=0.9584\n","Epoch 7: train_loss=0.191, validation_accuracy=0.9438\n","Epoch 12: train_loss=0.088, validation_accuracy=0.9651\n","Epoch 4: train_loss=0.570, validation_accuracy=0.9181\n","Epoch 10: train_loss=0.143, validation_accuracy=0.9611\n","Epoch 8: train_loss=0.165, validation_accuracy=0.9529\n","Epoch 11: train_loss=0.133, validation_accuracy=0.9599\n","Epoch 5: train_loss=0.450, validation_accuracy=0.9267\n","Epoch 13: train_loss=0.082, validation_accuracy=0.9647\n","Epoch 12: train_loss=0.124, validation_accuracy=0.9607\n","Epoch 6: train_loss=0.375, validation_accuracy=0.9323\n","Epoch 9: train_loss=0.144, validation_accuracy=0.9559\n","Epoch 14: train_loss=0.077, validation_accuracy=0.9644\n","Epoch 13: train_loss=0.117, validation_accuracy=0.9620\n","Epoch 7: train_loss=0.324, validation_accuracy=0.9365\n","Epoch 14: train_loss=0.110, validation_accuracy=0.9614\n","Epoch 15: train_loss=0.074, validation_accuracy=0.9648\n","Epoch 10: train_loss=0.126, validation_accuracy=0.9527\n","Epoch 8: train_loss=0.288, validation_accuracy=0.9391\n","Epoch 15: train_loss=0.104, validation_accuracy=0.9638\n","Epoch 9: train_loss=0.260, validation_accuracy=0.9418\n","Epoch 16: train_loss=0.069, validation_accuracy=0.9669\n","Epoch 11: train_loss=0.117, validation_accuracy=0.9598\n","Epoch 16: train_loss=0.099, validation_accuracy=0.9623\n","Epoch 10: train_loss=0.239, validation_accuracy=0.9445\n","\u001b[32m[I 2023-03-07 23:22:41,026]\u001b[0m Trial 317 pruned. \u001b[0m\n","Epoch 17: train_loss=0.065, validation_accuracy=0.9670\n","Epoch 17: train_loss=0.097, validation_accuracy=0.9624\n","Epoch 12: train_loss=0.106, validation_accuracy=0.9590\n","Epoch 18: train_loss=0.094, validation_accuracy=0.9630\n","Epoch 1: train_loss=2.304, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.061, validation_accuracy=0.9647\n","Epoch 19: train_loss=0.088, validation_accuracy=0.9630\n","Epoch 13: train_loss=0.099, validation_accuracy=0.9577\n","Epoch 2: train_loss=2.300, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.060, validation_accuracy=0.9686\n","Epoch 20: train_loss=0.085, validation_accuracy=0.9639\n","\u001b[32m[I 2023-03-07 23:22:42,100]\u001b[0m Trial 315 finished with value: 0.9639 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 28, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 32, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 36, 'activation_func[3]': 'Sigmoid', 'lr': 0.0015973319567289832, 'momentum': 0.9746226169805846}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 3: train_loss=2.296, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.090, validation_accuracy=0.9583\n","Epoch 1: train_loss=1.818, validation_accuracy=0.7522\n","Epoch 20: train_loss=0.056, validation_accuracy=0.9661\n","\u001b[32m[I 2023-03-07 23:22:42,578]\u001b[0m Trial 313 finished with value: 0.9661 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 40, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 41, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 19, 'activation_func[4]': 'ReLU', 'lr': 0.002655112225052003, 'momentum': 0.8743618334600702}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 4: train_loss=2.292, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.869, validation_accuracy=0.8986\n","Epoch 1: train_loss=1.705, validation_accuracy=0.7946\n","Epoch 15: train_loss=0.084, validation_accuracy=0.9626\n","Epoch 5: train_loss=2.279, validation_accuracy=0.2704\n","Epoch 3: train_loss=0.456, validation_accuracy=0.9264\n","Epoch 2: train_loss=0.650, validation_accuracy=0.8770\n","Epoch 6: train_loss=2.215, validation_accuracy=0.2298\n","Epoch 4: train_loss=0.311, validation_accuracy=0.9391\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9606\n","Epoch 3: train_loss=0.421, validation_accuracy=0.8652\n","Epoch 7: train_loss=1.975, validation_accuracy=0.2890\n","Epoch 5: train_loss=0.245, validation_accuracy=0.9474\n","Epoch 4: train_loss=0.433, validation_accuracy=0.8690\n","\u001b[32m[I 2023-03-07 23:22:44,328]\u001b[0m Trial 320 pruned. \u001b[0m\n","Epoch 8: train_loss=1.630, validation_accuracy=0.5855\n","Epoch 6: train_loss=0.205, validation_accuracy=0.9502\n","Epoch 17: train_loss=0.072, validation_accuracy=0.9627\n","Epoch 7: train_loss=0.179, validation_accuracy=0.9533\n","Epoch 9: train_loss=1.142, validation_accuracy=0.6901\n","Epoch 1: train_loss=1.457, validation_accuracy=0.8180\n","Epoch 18: train_loss=0.067, validation_accuracy=0.9632\n","Epoch 8: train_loss=0.159, validation_accuracy=0.9545\n","Epoch 10: train_loss=0.872, validation_accuracy=0.7604\n","\u001b[32m[I 2023-03-07 23:22:45,278]\u001b[0m Trial 318 pruned. \u001b[0m\n","Epoch 2: train_loss=0.741, validation_accuracy=0.8822\n","\u001b[32m[I 2023-03-07 23:22:45,414]\u001b[0m Trial 321 pruned. \u001b[0m\n","Epoch 9: train_loss=0.144, validation_accuracy=0.9562\n","Epoch 19: train_loss=0.064, validation_accuracy=0.9644\n","Epoch 1: train_loss=1.561, validation_accuracy=0.7510\n","Epoch 10: train_loss=0.133, validation_accuracy=0.9579\n","Epoch 1: train_loss=2.220, validation_accuracy=0.3591\n","Epoch 11: train_loss=0.123, validation_accuracy=0.9603\n","Epoch 20: train_loss=0.060, validation_accuracy=0.9627\n","\u001b[32m[I 2023-03-07 23:22:46,310]\u001b[0m Trial 314 finished with value: 0.9627 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 50, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 50, 'activation_func[2]': 'Sigmoid', 'hidden_dim[3]': 33, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 31, 'activation_func[4]': 'ReLU', 'lr': 0.009367639270517423, 'momentum': 0.7738108929461261}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 2: train_loss=0.926, validation_accuracy=0.8697\n","\u001b[32m[I 2023-03-07 23:22:46,426]\u001b[0m Trial 322 pruned. \u001b[0m\n","Epoch 2: train_loss=1.495, validation_accuracy=0.7473\n","Epoch 12: train_loss=0.114, validation_accuracy=0.9590\n","Epoch 1: train_loss=1.942, validation_accuracy=0.7150\n","Epoch 1: train_loss=1.952, validation_accuracy=0.7317\n","Epoch 13: train_loss=0.110, validation_accuracy=0.9596\n","Epoch 3: train_loss=0.635, validation_accuracy=0.8603\n","Epoch 2: train_loss=1.114, validation_accuracy=0.8740\n","Epoch 2: train_loss=1.265, validation_accuracy=0.8584\n","Epoch 14: train_loss=0.102, validation_accuracy=0.9604\n","Epoch 3: train_loss=0.642, validation_accuracy=0.9105\n","Epoch 4: train_loss=0.419, validation_accuracy=0.8956\n","Epoch 15: train_loss=0.096, validation_accuracy=0.9628\n","Epoch 3: train_loss=0.855, validation_accuracy=0.8989\n","Epoch 4: train_loss=0.433, validation_accuracy=0.9280\n","Epoch 16: train_loss=0.091, validation_accuracy=0.9622\n","Epoch 4: train_loss=0.630, validation_accuracy=0.9148\n","\u001b[32m[I 2023-03-07 23:22:48,102]\u001b[0m Trial 325 pruned. \u001b[0m\n","Epoch 5: train_loss=0.350, validation_accuracy=0.9115\n","Epoch 5: train_loss=0.332, validation_accuracy=0.9354\n","Epoch 17: train_loss=0.087, validation_accuracy=0.9626\n","Epoch 6: train_loss=0.275, validation_accuracy=0.9400\n","Epoch 6: train_loss=0.329, validation_accuracy=0.9120\n","Epoch 1: train_loss=1.954, validation_accuracy=0.6102\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9623\n","Epoch 7: train_loss=0.240, validation_accuracy=0.9459\n","Epoch 2: train_loss=1.398, validation_accuracy=0.7773\n","\u001b[32m[I 2023-03-07 23:22:49,057]\u001b[0m Trial 326 pruned. \u001b[0m\n","Epoch 7: train_loss=0.301, validation_accuracy=0.9153\n","Epoch 19: train_loss=0.080, validation_accuracy=0.9628\n","Epoch 8: train_loss=0.213, validation_accuracy=0.9476\n","Epoch 20: train_loss=0.077, validation_accuracy=0.9619\n","\u001b[32m[I 2023-03-07 23:22:49,427]\u001b[0m Trial 319 finished with value: 0.9619 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 29, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 43, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'Sigmoid', 'lr': 0.0016751361593890911, 'momentum': 0.977762101280324}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 8: train_loss=0.296, validation_accuracy=0.9191\n","Epoch 1: train_loss=2.030, validation_accuracy=0.5821\n","Epoch 9: train_loss=0.194, validation_accuracy=0.9533\n","Epoch 1: train_loss=1.721, validation_accuracy=0.7214\n","Epoch 10: train_loss=0.179, validation_accuracy=0.9529\n","Epoch 9: train_loss=0.280, validation_accuracy=0.9087\n","Epoch 2: train_loss=1.323, validation_accuracy=0.7881\n","Epoch 2: train_loss=0.896, validation_accuracy=0.8937\n","\u001b[32m[I 2023-03-07 23:22:50,130]\u001b[0m Trial 328 pruned. \u001b[0m\n","Epoch 11: train_loss=0.166, validation_accuracy=0.9547\n","Epoch 10: train_loss=0.282, validation_accuracy=0.9228\n","\u001b[32m[I 2023-03-07 23:22:50,428]\u001b[0m Trial 323 pruned. \u001b[0m\n","Epoch 3: train_loss=0.863, validation_accuracy=0.8843\n","Epoch 12: train_loss=0.153, validation_accuracy=0.9541\n","Epoch 1: train_loss=0.791, validation_accuracy=0.9008\n","Epoch 1: train_loss=1.705, validation_accuracy=0.7895\n","Epoch 13: train_loss=0.145, validation_accuracy=0.9571\n","Epoch 4: train_loss=0.596, validation_accuracy=0.9138\n","\u001b[32m[I 2023-03-07 23:22:50,971]\u001b[0m Trial 327 pruned. \u001b[0m\n","Epoch 2: train_loss=0.925, validation_accuracy=0.8856\n","\u001b[32m[I 2023-03-07 23:22:51,133]\u001b[0m Trial 330 pruned. \u001b[0m\n","Epoch 2: train_loss=0.282, validation_accuracy=0.9286\n","Epoch 14: train_loss=0.137, validation_accuracy=0.9553\n","Epoch 1: train_loss=0.894, validation_accuracy=0.9100\n","Epoch 1: train_loss=2.311, validation_accuracy=0.1144\n","Epoch 15: train_loss=0.131, validation_accuracy=0.9579\n","Epoch 3: train_loss=0.220, validation_accuracy=0.9398\n","Epoch 2: train_loss=2.262, validation_accuracy=0.2946\n","Epoch 2: train_loss=0.255, validation_accuracy=0.9318\n","Epoch 16: train_loss=0.123, validation_accuracy=0.9593\n","Epoch 3: train_loss=2.063, validation_accuracy=0.3424\n","Epoch 4: train_loss=0.179, validation_accuracy=0.9432\n","Epoch 3: train_loss=0.195, validation_accuracy=0.9425\n","Epoch 17: train_loss=0.119, validation_accuracy=0.9593\n","Epoch 4: train_loss=1.677, validation_accuracy=0.4337\n","\u001b[32m[I 2023-03-07 23:22:52,412]\u001b[0m Trial 332 pruned. \u001b[0m\n","Epoch 5: train_loss=0.156, validation_accuracy=0.9499\n","Epoch 18: train_loss=0.114, validation_accuracy=0.9561\n","Epoch 4: train_loss=0.161, validation_accuracy=0.9477\n","Epoch 1: train_loss=2.298, validation_accuracy=0.2035\n","Epoch 19: train_loss=0.108, validation_accuracy=0.9615\n","Epoch 6: train_loss=0.140, validation_accuracy=0.9541\n","Epoch 5: train_loss=0.140, validation_accuracy=0.9519\n","Epoch 20: train_loss=0.104, validation_accuracy=0.9609\n","\u001b[32m[I 2023-03-07 23:22:53,312]\u001b[0m Trial 324 finished with value: 0.9609 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 25, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 32, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 31, 'activation_func[3]': 'Sigmoid', 'lr': 0.001211483113726843, 'momentum': 0.9778736605453563}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 2: train_loss=2.267, validation_accuracy=0.2826\n","\u001b[32m[I 2023-03-07 23:22:53,397]\u001b[0m Trial 333 pruned. \u001b[0m\n","Epoch 7: train_loss=0.124, validation_accuracy=0.9589\n","Epoch 6: train_loss=0.126, validation_accuracy=0.9543\n","Epoch 1: train_loss=2.191, validation_accuracy=0.5164\n","Epoch 1: train_loss=2.319, validation_accuracy=0.1010\n","Epoch 2: train_loss=2.295, validation_accuracy=0.2055\n","Epoch 8: train_loss=0.116, validation_accuracy=0.9608\n","Epoch 7: train_loss=0.114, validation_accuracy=0.9609\n","Epoch 2: train_loss=1.773, validation_accuracy=0.7170\n","Epoch 3: train_loss=2.284, validation_accuracy=0.1140\n","Epoch 3: train_loss=1.215, validation_accuracy=0.8079\n","Epoch 8: train_loss=0.104, validation_accuracy=0.9617\n","Epoch 9: train_loss=0.106, validation_accuracy=0.9585\n","Epoch 4: train_loss=2.263, validation_accuracy=0.2894\n","\u001b[32m[I 2023-03-07 23:22:54,585]\u001b[0m Trial 335 pruned. \u001b[0m\n","Epoch 4: train_loss=0.828, validation_accuracy=0.8607\n","\u001b[32m[I 2023-03-07 23:22:54,768]\u001b[0m Trial 334 pruned. \u001b[0m\n","Epoch 9: train_loss=0.096, validation_accuracy=0.9594\n","Epoch 1: train_loss=1.760, validation_accuracy=0.7321\n","Epoch 10: train_loss=0.099, validation_accuracy=0.9595\n","\u001b[32m[I 2023-03-07 23:22:55,030]\u001b[0m Trial 329 pruned. \u001b[0m\n","Epoch 2: train_loss=0.676, validation_accuracy=0.8717\n","Epoch 1: train_loss=0.988, validation_accuracy=0.9077\n","Epoch 10: train_loss=0.088, validation_accuracy=0.9645\n","Epoch 1: train_loss=0.847, validation_accuracy=0.9022\n","Epoch 3: train_loss=0.454, validation_accuracy=0.8621\n","Epoch 2: train_loss=0.243, validation_accuracy=0.9383\n","Epoch 11: train_loss=0.083, validation_accuracy=0.9627\n","Epoch 4: train_loss=0.539, validation_accuracy=0.8237\n","\u001b[32m[I 2023-03-07 23:22:55,956]\u001b[0m Trial 336 pruned. \u001b[0m\n","Epoch 2: train_loss=0.291, validation_accuracy=0.9280\n","Epoch 3: train_loss=0.173, validation_accuracy=0.9488\n","Epoch 12: train_loss=0.078, validation_accuracy=0.9659\n","Epoch 1: train_loss=1.808, validation_accuracy=0.7604\n","Epoch 3: train_loss=0.227, validation_accuracy=0.9405\n","Epoch 2: train_loss=0.902, validation_accuracy=0.8780\n","Epoch 4: train_loss=0.137, validation_accuracy=0.9545\n","Epoch 13: train_loss=0.073, validation_accuracy=0.9626\n","Epoch 4: train_loss=0.192, validation_accuracy=0.9432\n","Epoch 3: train_loss=0.504, validation_accuracy=0.9055\n","Epoch 14: train_loss=0.069, validation_accuracy=0.9663\n","Epoch 5: train_loss=0.118, validation_accuracy=0.9574\n","Epoch 4: train_loss=0.367, validation_accuracy=0.9185\n","Epoch 5: train_loss=0.171, validation_accuracy=0.9500\n","Epoch 15: train_loss=0.065, validation_accuracy=0.9666\n","Epoch 5: train_loss=0.301, validation_accuracy=0.9279\n","Epoch 6: train_loss=0.103, validation_accuracy=0.9581\n","Epoch 6: train_loss=0.153, validation_accuracy=0.9516\n","Epoch 6: train_loss=0.260, validation_accuracy=0.9359\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9656\n","Epoch 7: train_loss=0.092, validation_accuracy=0.9629\n","Epoch 7: train_loss=0.225, validation_accuracy=0.9421\n","Epoch 7: train_loss=0.140, validation_accuracy=0.9569\n","Epoch 17: train_loss=0.058, validation_accuracy=0.9671\n","Epoch 8: train_loss=0.202, validation_accuracy=0.9469\n","Epoch 8: train_loss=0.082, validation_accuracy=0.9629\n","Epoch 8: train_loss=0.127, validation_accuracy=0.9546\n","Epoch 18: train_loss=0.054, validation_accuracy=0.9652\n","Epoch 9: train_loss=0.180, validation_accuracy=0.9504\n","Epoch 9: train_loss=0.074, validation_accuracy=0.9637\n","Epoch 9: train_loss=0.120, validation_accuracy=0.9594\n","Epoch 19: train_loss=0.053, validation_accuracy=0.9667\n","Epoch 10: train_loss=0.167, validation_accuracy=0.9541\n","Epoch 10: train_loss=0.068, validation_accuracy=0.9667\n","Epoch 10: train_loss=0.112, validation_accuracy=0.9607\n","Epoch 11: train_loss=0.152, validation_accuracy=0.9546\n","Epoch 20: train_loss=0.049, validation_accuracy=0.9651\n","\u001b[32m[I 2023-03-07 23:22:59,911]\u001b[0m Trial 331 finished with value: 0.9651 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 40, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 48, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 24, 'activation_func[4]': 'ReLU', 'lr': 0.003030007692120076, 'momentum': 0.8786091999989931}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 12: train_loss=0.142, validation_accuracy=0.9565\n","Epoch 11: train_loss=0.104, validation_accuracy=0.9585\n","Epoch 11: train_loss=0.061, validation_accuracy=0.9661\n","Epoch 1: train_loss=1.040, validation_accuracy=0.8759\n","Epoch 13: train_loss=0.133, validation_accuracy=0.9588\n","Epoch 12: train_loss=0.099, validation_accuracy=0.9621\n","Epoch 2: train_loss=0.344, validation_accuracy=0.9208\n","Epoch 12: train_loss=0.054, validation_accuracy=0.9671\n","Epoch 14: train_loss=0.125, validation_accuracy=0.9578\n","Epoch 3: train_loss=0.255, validation_accuracy=0.9356\n","Epoch 13: train_loss=0.094, validation_accuracy=0.9636\n","Epoch 15: train_loss=0.120, validation_accuracy=0.9590\n","Epoch 13: train_loss=0.050, validation_accuracy=0.9675\n","Epoch 4: train_loss=0.213, validation_accuracy=0.9432\n","Epoch 16: train_loss=0.115, validation_accuracy=0.9620\n","Epoch 14: train_loss=0.089, validation_accuracy=0.9625\n","Epoch 5: train_loss=0.184, validation_accuracy=0.9471\n","Epoch 14: train_loss=0.046, validation_accuracy=0.9660\n","Epoch 17: train_loss=0.109, validation_accuracy=0.9579\n","Epoch 15: train_loss=0.084, validation_accuracy=0.9629\n","Epoch 6: train_loss=0.166, validation_accuracy=0.9538\n","Epoch 18: train_loss=0.106, validation_accuracy=0.9585\n","Epoch 15: train_loss=0.042, validation_accuracy=0.9695\n","Epoch 7: train_loss=0.150, validation_accuracy=0.9535\n","Epoch 19: train_loss=0.103, validation_accuracy=0.9615\n","Epoch 16: train_loss=0.081, validation_accuracy=0.9655\n","Epoch 16: train_loss=0.041, validation_accuracy=0.9703\n","Epoch 20: train_loss=0.096, validation_accuracy=0.9631\n","\u001b[32m[I 2023-03-07 23:23:02,989]\u001b[0m Trial 339 finished with value: 0.9631 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 26, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'Sigmoid', 'lr': 0.0012112035791263553, 'momentum': 0.9847568559433886}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 8: train_loss=0.137, validation_accuracy=0.9550\n","Epoch 17: train_loss=0.077, validation_accuracy=0.9645\n","Epoch 9: train_loss=0.130, validation_accuracy=0.9605\n","Epoch 1: train_loss=1.899, validation_accuracy=0.7118\n","Epoch 17: train_loss=0.037, validation_accuracy=0.9664\n","Epoch 18: train_loss=0.075, validation_accuracy=0.9648\n","Epoch 10: train_loss=0.118, validation_accuracy=0.9588\n","\u001b[32m[I 2023-03-07 23:23:03,792]\u001b[0m Trial 340 pruned. \u001b[0m\n","Epoch 2: train_loss=1.003, validation_accuracy=0.8685\n","Epoch 18: train_loss=0.034, validation_accuracy=0.9690\n","Epoch 19: train_loss=0.072, validation_accuracy=0.9655\n","Epoch 3: train_loss=0.563, validation_accuracy=0.9071\n","Epoch 1: train_loss=1.005, validation_accuracy=0.8461\n","Epoch 19: train_loss=0.031, validation_accuracy=0.9677\n","Epoch 4: train_loss=0.374, validation_accuracy=0.9273\n","Epoch 2: train_loss=0.354, validation_accuracy=0.8396\n","\u001b[32m[I 2023-03-07 23:23:04,637]\u001b[0m Trial 342 pruned. \u001b[0m\n","Epoch 20: train_loss=0.069, validation_accuracy=0.9645\n","\u001b[32m[I 2023-03-07 23:23:04,707]\u001b[0m Trial 338 finished with value: 0.9645 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 36, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 47, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 39, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 28, 'activation_func[4]': 'ELU', 'lr': 0.002864843693496344, 'momentum': 0.8326721059720948}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 5: train_loss=0.281, validation_accuracy=0.9397\n","Epoch 1: train_loss=2.275, validation_accuracy=0.2108\n","Epoch 20: train_loss=0.029, validation_accuracy=0.9686\n","\u001b[32m[I 2023-03-07 23:23:05,125]\u001b[0m Trial 337 finished with value: 0.9686 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 44, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 42, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 17, 'activation_func[4]': 'ReLU', 'lr': 0.005127450530574592, 'momentum': 0.9158476163045027}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=1.005, validation_accuracy=0.8109\n","Epoch 6: train_loss=0.229, validation_accuracy=0.9429\n","Epoch 2: train_loss=2.094, validation_accuracy=0.3064\n","\u001b[32m[I 2023-03-07 23:23:05,529]\u001b[0m Trial 343 pruned. \u001b[0m\n","Epoch 1: train_loss=1.015, validation_accuracy=0.8737\n","Epoch 2: train_loss=0.330, validation_accuracy=0.9193\n","Epoch 7: train_loss=0.194, validation_accuracy=0.9479\n","Epoch 2: train_loss=0.351, validation_accuracy=0.9122\n","Epoch 3: train_loss=0.255, validation_accuracy=0.9346\n","Epoch 1: train_loss=2.307, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.172, validation_accuracy=0.9530\n","Epoch 3: train_loss=0.261, validation_accuracy=0.9307\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9396\n","\u001b[32m[I 2023-03-07 23:23:06,478]\u001b[0m Trial 344 pruned. \u001b[0m\n","Epoch 2: train_loss=2.267, validation_accuracy=0.2279\n","Epoch 9: train_loss=0.153, validation_accuracy=0.9562\n","Epoch 4: train_loss=0.215, validation_accuracy=0.9388\n","\u001b[32m[I 2023-03-07 23:23:06,750]\u001b[0m Trial 345 pruned. \u001b[0m\n","Epoch 1: train_loss=2.020, validation_accuracy=0.6627\n","Epoch 3: train_loss=2.212, validation_accuracy=0.3665\n","Epoch 10: train_loss=0.140, validation_accuracy=0.9572\n","Epoch 1: train_loss=0.941, validation_accuracy=0.8849\n","Epoch 2: train_loss=1.478, validation_accuracy=0.7894\n","Epoch 4: train_loss=2.084, validation_accuracy=0.4027\n","\u001b[32m[I 2023-03-07 23:23:07,379]\u001b[0m Trial 346 pruned. \u001b[0m\n","Epoch 11: train_loss=0.128, validation_accuracy=0.9600\n","Epoch 3: train_loss=1.129, validation_accuracy=0.8571\n","Epoch 2: train_loss=0.329, validation_accuracy=0.9192\n","Epoch 12: train_loss=0.118, validation_accuracy=0.9594\n","Epoch 1: train_loss=1.002, validation_accuracy=0.8973\n","Epoch 4: train_loss=0.885, validation_accuracy=0.8934\n","\u001b[32m[I 2023-03-07 23:23:08,141]\u001b[0m Trial 347 pruned. \u001b[0m\n","Epoch 13: train_loss=0.110, validation_accuracy=0.9609\n","Epoch 3: train_loss=0.247, validation_accuracy=0.9346\n","Epoch 2: train_loss=0.312, validation_accuracy=0.9308\n","Epoch 14: train_loss=0.102, validation_accuracy=0.9617\n","Epoch 1: train_loss=0.944, validation_accuracy=0.9153\n","Epoch 4: train_loss=0.209, validation_accuracy=0.9395\n","\u001b[32m[I 2023-03-07 23:23:08,777]\u001b[0m Trial 348 pruned. \u001b[0m\n","Epoch 3: train_loss=0.223, validation_accuracy=0.9479\n","Epoch 15: train_loss=0.095, validation_accuracy=0.9630\n","Epoch 1: train_loss=2.262, validation_accuracy=0.4120\n","Epoch 2: train_loss=0.233, validation_accuracy=0.9459\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9513\n","Epoch 16: train_loss=0.090, validation_accuracy=0.9628\n","Epoch 2: train_loss=2.113, validation_accuracy=0.5905\n","Epoch 17: train_loss=0.088, validation_accuracy=0.9632\n","Epoch 5: train_loss=0.151, validation_accuracy=0.9541\n","Epoch 3: train_loss=0.160, validation_accuracy=0.9543\n","Epoch 3: train_loss=1.834, validation_accuracy=0.6679\n","Epoch 18: train_loss=0.082, validation_accuracy=0.9639\n","Epoch 6: train_loss=0.133, validation_accuracy=0.9582\n","Epoch 4: train_loss=0.129, validation_accuracy=0.9606\n","Epoch 4: train_loss=1.501, validation_accuracy=0.7467\n","\u001b[32m[I 2023-03-07 23:23:10,348]\u001b[0m Trial 351 pruned. \u001b[0m\n","Epoch 19: train_loss=0.079, validation_accuracy=0.9633\n","Epoch 7: train_loss=0.121, validation_accuracy=0.9598\n","Epoch 20: train_loss=0.074, validation_accuracy=0.9636\n","\u001b[32m[I 2023-03-07 23:23:10,779]\u001b[0m Trial 341 finished with value: 0.9636 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 26, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 34, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 39, 'activation_func[3]': 'Sigmoid', 'lr': 0.0012876380774773455, 'momentum': 0.9852254569247009}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=1.268, validation_accuracy=0.8784\n","Epoch 5: train_loss=0.110, validation_accuracy=0.9623\n","Epoch 8: train_loss=0.107, validation_accuracy=0.9631\n","Epoch 1: train_loss=1.029, validation_accuracy=0.9019\n","Epoch 2: train_loss=0.555, validation_accuracy=0.9157\n","Epoch 6: train_loss=0.097, validation_accuracy=0.9626\n","Epoch 9: train_loss=0.097, validation_accuracy=0.9643\n","Epoch 2: train_loss=0.297, validation_accuracy=0.9344\n","Epoch 3: train_loss=0.369, validation_accuracy=0.9339\n","Epoch 3: train_loss=0.211, validation_accuracy=0.9450\n","Epoch 10: train_loss=0.091, validation_accuracy=0.9648\n","Epoch 7: train_loss=0.086, validation_accuracy=0.9651\n","Epoch 4: train_loss=0.281, validation_accuracy=0.9429\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9459\n","Epoch 11: train_loss=0.082, validation_accuracy=0.9656\n","Epoch 5: train_loss=0.231, validation_accuracy=0.9448\n","Epoch 8: train_loss=0.078, validation_accuracy=0.9638\n","Epoch 5: train_loss=0.168, validation_accuracy=0.9522\n","Epoch 6: train_loss=0.201, validation_accuracy=0.9527\n","Epoch 12: train_loss=0.076, validation_accuracy=0.9656\n","Epoch 6: train_loss=0.138, validation_accuracy=0.9565\n","Epoch 9: train_loss=0.069, validation_accuracy=0.9660\n","Epoch 7: train_loss=0.174, validation_accuracy=0.9549\n","Epoch 13: train_loss=0.073, validation_accuracy=0.9627\n","Epoch 7: train_loss=0.125, validation_accuracy=0.9592\n","Epoch 8: train_loss=0.156, validation_accuracy=0.9550\n","Epoch 10: train_loss=0.063, validation_accuracy=0.9675\n","Epoch 14: train_loss=0.067, validation_accuracy=0.9672\n","Epoch 8: train_loss=0.116, validation_accuracy=0.9605\n","Epoch 9: train_loss=0.141, validation_accuracy=0.9609\n","Epoch 15: train_loss=0.126, validation_accuracy=0.9486\n","Epoch 11: train_loss=0.059, validation_accuracy=0.9662\n","Epoch 9: train_loss=0.105, validation_accuracy=0.9613\n","Epoch 10: train_loss=0.128, validation_accuracy=0.9593\n","\u001b[32m[I 2023-03-07 23:23:14,450]\u001b[0m Trial 352 pruned. \u001b[0m\n","Epoch 10: train_loss=0.098, validation_accuracy=0.9616\n","Epoch 16: train_loss=0.077, validation_accuracy=0.9700\n","Epoch 12: train_loss=0.053, validation_accuracy=0.9664\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9636\n","Epoch 1: train_loss=2.029, validation_accuracy=0.5749\n","Epoch 17: train_loss=0.058, validation_accuracy=0.9703\n","Epoch 13: train_loss=0.047, validation_accuracy=0.9667\n","Epoch 12: train_loss=0.091, validation_accuracy=0.9612\n","Epoch 18: train_loss=0.055, validation_accuracy=0.9663\n","Epoch 2: train_loss=1.177, validation_accuracy=0.8174\n","Epoch 13: train_loss=0.082, validation_accuracy=0.9655\n","Epoch 14: train_loss=0.045, validation_accuracy=0.9661\n","Epoch 19: train_loss=0.052, validation_accuracy=0.9698\n","Epoch 3: train_loss=0.584, validation_accuracy=0.9158\n","Epoch 14: train_loss=0.078, validation_accuracy=0.9659\n","Epoch 20: train_loss=0.049, validation_accuracy=0.9695\n","\u001b[32m[I 2023-03-07 23:23:16,484]\u001b[0m Trial 349 finished with value: 0.9695 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 46, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 15, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 24, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 31, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 23, 'activation_func[4]': 'ReLU', 'lr': 0.008920825801247563, 'momentum': 0.6557641178433408}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 15: train_loss=0.043, validation_accuracy=0.9679\n","Epoch 15: train_loss=0.079, validation_accuracy=0.9642\n","Epoch 4: train_loss=0.346, validation_accuracy=0.9434\n","Epoch 1: train_loss=0.975, validation_accuracy=0.8867\n","Epoch 16: train_loss=0.039, validation_accuracy=0.9674\n","Epoch 16: train_loss=0.070, validation_accuracy=0.9639\n","Epoch 5: train_loss=0.237, validation_accuracy=0.9503\n","Epoch 2: train_loss=0.299, validation_accuracy=0.9300\n","Epoch 17: train_loss=0.065, validation_accuracy=0.9677\n","Epoch 17: train_loss=0.035, validation_accuracy=0.9688\n","Epoch 6: train_loss=0.185, validation_accuracy=0.9520\n","Epoch 18: train_loss=0.063, validation_accuracy=0.9660\n","Epoch 3: train_loss=0.232, validation_accuracy=0.9401\n","Epoch 18: train_loss=0.035, validation_accuracy=0.9708\n","Epoch 19: train_loss=0.061, validation_accuracy=0.9649\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9491\n","Epoch 7: train_loss=0.154, validation_accuracy=0.9594\n","Epoch 20: train_loss=0.058, validation_accuracy=0.9658\n","\u001b[32m[I 2023-03-07 23:23:18,678]\u001b[0m Trial 353 finished with value: 0.9658 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 22, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 19, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 28, 'activation_func[4]': 'ReLU', 'lr': 0.009859385425521523, 'momentum': 0.6285893845796897}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 19: train_loss=0.031, validation_accuracy=0.9677\n","Epoch 5: train_loss=0.154, validation_accuracy=0.9503\n","Epoch 8: train_loss=0.133, validation_accuracy=0.9614\n","Epoch 1: train_loss=0.928, validation_accuracy=0.8981\n","Epoch 6: train_loss=0.138, validation_accuracy=0.9495\n","Epoch 20: train_loss=0.029, validation_accuracy=0.9655\n","\u001b[32m[I 2023-03-07 23:23:19,458]\u001b[0m Trial 350 finished with value: 0.9655 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 44, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 44, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 42, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 32, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 16, 'activation_func[4]': 'ReLU', 'lr': 0.005736747854509068, 'momentum': 0.9201634054172273}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 9: train_loss=0.116, validation_accuracy=0.9626\n","Epoch 2: train_loss=0.298, validation_accuracy=0.9231\n","Epoch 1: train_loss=1.180, validation_accuracy=0.8917\n","Epoch 7: train_loss=0.125, validation_accuracy=0.9540\n","Epoch 3: train_loss=0.214, validation_accuracy=0.9425\n","Epoch 10: train_loss=0.104, validation_accuracy=0.9613\n","Epoch 2: train_loss=0.318, validation_accuracy=0.9251\n","Epoch 8: train_loss=0.116, validation_accuracy=0.9566\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9496\n","Epoch 3: train_loss=0.234, validation_accuracy=0.9414\n","Epoch 11: train_loss=0.092, validation_accuracy=0.9647\n","Epoch 9: train_loss=0.104, validation_accuracy=0.9585\n","Epoch 5: train_loss=0.158, validation_accuracy=0.9536\n","Epoch 4: train_loss=0.191, validation_accuracy=0.9454\n","Epoch 10: train_loss=0.101, validation_accuracy=0.9586\n","\u001b[32m[I 2023-03-07 23:23:21,186]\u001b[0m Trial 355 pruned. \u001b[0m\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9654\n","Epoch 6: train_loss=0.138, validation_accuracy=0.9568\n","Epoch 5: train_loss=0.168, validation_accuracy=0.9505\n","Epoch 1: train_loss=1.106, validation_accuracy=0.8838\n","Epoch 7: train_loss=0.123, validation_accuracy=0.9595\n","Epoch 6: train_loss=0.152, validation_accuracy=0.9531\n","Epoch 13: train_loss=0.076, validation_accuracy=0.9588\n","Epoch 7: train_loss=0.137, validation_accuracy=0.9547\n","Epoch 2: train_loss=0.336, validation_accuracy=0.9203\n","Epoch 8: train_loss=0.113, validation_accuracy=0.9593\n","Epoch 14: train_loss=0.071, validation_accuracy=0.9653\n","Epoch 8: train_loss=0.126, validation_accuracy=0.9558\n","Epoch 3: train_loss=0.239, validation_accuracy=0.9354\n","Epoch 9: train_loss=0.107, validation_accuracy=0.9632\n","Epoch 15: train_loss=0.064, validation_accuracy=0.9668\n","Epoch 9: train_loss=0.119, validation_accuracy=0.9579\n","Epoch 4: train_loss=0.195, validation_accuracy=0.9434\n","Epoch 10: train_loss=0.097, validation_accuracy=0.9638\n","Epoch 10: train_loss=0.110, validation_accuracy=0.9596\n","\u001b[32m[I 2023-03-07 23:23:23,201]\u001b[0m Trial 357 pruned. \u001b[0m\n","Epoch 16: train_loss=0.059, validation_accuracy=0.9654\n","Epoch 11: train_loss=0.090, validation_accuracy=0.9646\n","Epoch 5: train_loss=0.177, validation_accuracy=0.9485\n","Epoch 1: train_loss=2.231, validation_accuracy=0.2521\n","Epoch 12: train_loss=0.086, validation_accuracy=0.9641\n","Epoch 6: train_loss=0.152, validation_accuracy=0.9521\n","Epoch 17: train_loss=0.055, validation_accuracy=0.9666\n","Epoch 2: train_loss=1.858, validation_accuracy=0.7312\n","Epoch 13: train_loss=0.081, validation_accuracy=0.9669\n","Epoch 7: train_loss=0.136, validation_accuracy=0.9530\n","Epoch 3: train_loss=1.243, validation_accuracy=0.8467\n","Epoch 18: train_loss=0.051, validation_accuracy=0.9671\n","Epoch 14: train_loss=0.076, validation_accuracy=0.9617\n","Epoch 8: train_loss=0.125, validation_accuracy=0.9579\n","Epoch 4: train_loss=0.749, validation_accuracy=0.9003\n","\u001b[32m[I 2023-03-07 23:23:24,811]\u001b[0m Trial 359 pruned. \u001b[0m\n","Epoch 19: train_loss=0.049, validation_accuracy=0.9665\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9678\n","Epoch 9: train_loss=0.117, validation_accuracy=0.9567\n","Epoch 1: train_loss=1.817, validation_accuracy=0.7155\n","Epoch 16: train_loss=0.069, validation_accuracy=0.9663\n","Epoch 20: train_loss=0.045, validation_accuracy=0.9665\n","\u001b[32m[I 2023-03-07 23:23:25,555]\u001b[0m Trial 354 finished with value: 0.9665 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 47, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 44, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 49, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 31, 'activation_func[3]': 'Sigmoid', 'hidden_dim[4]': 16, 'activation_func[4]': 'ReLU', 'lr': 0.005122085042366926, 'momentum': 0.9080341114183185}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 2: train_loss=0.892, validation_accuracy=0.8689\n","Epoch 10: train_loss=0.108, validation_accuracy=0.9578\n","\u001b[32m[I 2023-03-07 23:23:25,704]\u001b[0m Trial 358 pruned. \u001b[0m\n","Epoch 17: train_loss=0.063, validation_accuracy=0.9641\n","Epoch 3: train_loss=0.466, validation_accuracy=0.9130\n","Epoch 1: train_loss=2.110, validation_accuracy=0.3175\n","Epoch 18: train_loss=0.062, validation_accuracy=0.9679\n","Epoch 4: train_loss=0.313, validation_accuracy=0.9343\n","Epoch 2: train_loss=1.343, validation_accuracy=0.7077\n","Epoch 5: train_loss=0.249, validation_accuracy=0.9376\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9691\n","Epoch 3: train_loss=0.765, validation_accuracy=0.8262\n","Epoch 6: train_loss=0.213, validation_accuracy=0.9441\n","Epoch 20: train_loss=0.056, validation_accuracy=0.9674\n","\u001b[32m[I 2023-03-07 23:23:26,980]\u001b[0m Trial 356 finished with value: 0.9674 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 23, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 21, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 23, 'activation_func[4]': 'ReLU', 'lr': 0.009882707351082182, 'momentum': 0.6259670077148837}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 7: train_loss=0.188, validation_accuracy=0.9451\n","Epoch 4: train_loss=0.718, validation_accuracy=0.7674\n","\u001b[32m[I 2023-03-07 23:23:27,226]\u001b[0m Trial 361 pruned. \u001b[0m\n","Epoch 1: train_loss=0.961, validation_accuracy=0.8917\n","Epoch 1: train_loss=1.796, validation_accuracy=0.8066\n","Epoch 8: train_loss=0.169, validation_accuracy=0.9498\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9263\n","Epoch 9: train_loss=0.153, validation_accuracy=0.9503\n","Epoch 2: train_loss=1.065, validation_accuracy=0.8785\n","Epoch 10: train_loss=0.142, validation_accuracy=0.9512\n","Epoch 3: train_loss=0.720, validation_accuracy=0.9055\n","Epoch 3: train_loss=0.222, validation_accuracy=0.9394\n","Epoch 11: train_loss=0.131, validation_accuracy=0.9531\n","Epoch 4: train_loss=0.538, validation_accuracy=0.9225\n","Epoch 4: train_loss=0.185, validation_accuracy=0.9456\n","Epoch 12: train_loss=0.124, validation_accuracy=0.9555\n","Epoch 5: train_loss=0.432, validation_accuracy=0.9297\n","Epoch 5: train_loss=0.160, validation_accuracy=0.9519\n","Epoch 13: train_loss=0.113, validation_accuracy=0.9576\n","Epoch 6: train_loss=0.364, validation_accuracy=0.9373\n","Epoch 14: train_loss=0.105, validation_accuracy=0.9607\n","Epoch 6: train_loss=0.141, validation_accuracy=0.9545\n","Epoch 7: train_loss=0.317, validation_accuracy=0.9410\n","Epoch 15: train_loss=0.101, validation_accuracy=0.9579\n","Epoch 7: train_loss=0.127, validation_accuracy=0.9581\n","Epoch 8: train_loss=0.282, validation_accuracy=0.9450\n","Epoch 16: train_loss=0.096, validation_accuracy=0.9581\n","Epoch 8: train_loss=0.119, validation_accuracy=0.9574\n","Epoch 9: train_loss=0.256, validation_accuracy=0.9472\n","Epoch 17: train_loss=0.090, validation_accuracy=0.9602\n","Epoch 9: train_loss=0.111, validation_accuracy=0.9603\n","Epoch 10: train_loss=0.234, validation_accuracy=0.9468\n","\u001b[32m[I 2023-03-07 23:23:30,295]\u001b[0m Trial 363 pruned. \u001b[0m\n","Epoch 18: train_loss=0.085, validation_accuracy=0.9593\n","Epoch 10: train_loss=0.102, validation_accuracy=0.9615\n","Epoch 19: train_loss=0.083, validation_accuracy=0.9612\n","Epoch 1: train_loss=0.998, validation_accuracy=0.8967\n","Epoch 20: train_loss=0.079, validation_accuracy=0.9599\n","\u001b[32m[I 2023-03-07 23:23:30,933]\u001b[0m Trial 360 finished with value: 0.9599 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 26, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 49, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 34, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 38, 'activation_func[3]': 'Sigmoid', 'lr': 0.0016394504125850256, 'momentum': 0.9848630477504522}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 11: train_loss=0.097, validation_accuracy=0.9625\n","Epoch 2: train_loss=0.339, validation_accuracy=0.9080\n","\u001b[32m[I 2023-03-07 23:23:31,067]\u001b[0m Trial 364 pruned. \u001b[0m\n","Epoch 12: train_loss=0.090, validation_accuracy=0.9606\n","Epoch 1: train_loss=0.913, validation_accuracy=0.8863\n","Epoch 1: train_loss=1.042, validation_accuracy=0.8848\n","Epoch 13: train_loss=0.086, validation_accuracy=0.9632\n","Epoch 2: train_loss=0.339, validation_accuracy=0.9240\n","Epoch 2: train_loss=0.341, validation_accuracy=0.9094\n","\u001b[32m[I 2023-03-07 23:23:31,875]\u001b[0m Trial 366 pruned. \u001b[0m\n","Epoch 14: train_loss=0.084, validation_accuracy=0.9615\n","Epoch 3: train_loss=0.251, validation_accuracy=0.9308\n","Epoch 1: train_loss=2.022, validation_accuracy=0.6238\n","Epoch 15: train_loss=0.077, validation_accuracy=0.9638\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9427\n","\u001b[32m[I 2023-03-07 23:23:32,294]\u001b[0m Trial 365 pruned. \u001b[0m\n","Epoch 2: train_loss=1.398, validation_accuracy=0.7876\n","Epoch 16: train_loss=0.075, validation_accuracy=0.9651\n","Epoch 1: train_loss=1.940, validation_accuracy=0.7166\n","Epoch 3: train_loss=0.964, validation_accuracy=0.8636\n","Epoch 17: train_loss=0.070, validation_accuracy=0.9657\n","Epoch 2: train_loss=1.032, validation_accuracy=0.8736\n","Epoch 4: train_loss=0.695, validation_accuracy=0.8974\n","\u001b[32m[I 2023-03-07 23:23:33,118]\u001b[0m Trial 367 pruned. \u001b[0m\n","Epoch 3: train_loss=0.538, validation_accuracy=0.9089\n","Epoch 18: train_loss=0.067, validation_accuracy=0.9641\n","Epoch 1: train_loss=2.304, validation_accuracy=0.1236\n","Epoch 4: train_loss=0.362, validation_accuracy=0.9256\n","Epoch 19: train_loss=0.066, validation_accuracy=0.9656\n","Epoch 5: train_loss=0.286, validation_accuracy=0.9345\n","Epoch 2: train_loss=2.281, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:23:33,973]\u001b[0m Trial 369 pruned. \u001b[0m\n","Epoch 20: train_loss=0.062, validation_accuracy=0.9668\n","\u001b[32m[I 2023-03-07 23:23:34,007]\u001b[0m Trial 362 finished with value: 0.9668 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 23, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 21, 'activation_func[4]': 'ReLU', 'lr': 0.009443646715105666, 'momentum': 0.6242296436241667}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 6: train_loss=0.245, validation_accuracy=0.9391\n","Epoch 1: train_loss=1.821, validation_accuracy=0.7591\n","Epoch 1: train_loss=0.837, validation_accuracy=0.9109\n","Epoch 7: train_loss=0.214, validation_accuracy=0.9469\n","Epoch 2: train_loss=1.038, validation_accuracy=0.8844\n","Epoch 2: train_loss=0.285, validation_accuracy=0.9319\n","Epoch 8: train_loss=0.191, validation_accuracy=0.9510\n","Epoch 3: train_loss=0.653, validation_accuracy=0.9167\n","Epoch 3: train_loss=0.208, validation_accuracy=0.9427\n","Epoch 9: train_loss=0.173, validation_accuracy=0.9525\n","Epoch 4: train_loss=0.456, validation_accuracy=0.9346\n","Epoch 4: train_loss=0.191, validation_accuracy=0.9510\n","Epoch 10: train_loss=0.158, validation_accuracy=0.9542\n","Epoch 5: train_loss=0.351, validation_accuracy=0.9427\n","Epoch 5: train_loss=0.148, validation_accuracy=0.9514\n","Epoch 11: train_loss=0.147, validation_accuracy=0.9560\n","Epoch 6: train_loss=0.291, validation_accuracy=0.9476\n","Epoch 6: train_loss=0.132, validation_accuracy=0.9541\n","Epoch 7: train_loss=0.249, validation_accuracy=0.9494\n","Epoch 12: train_loss=0.137, validation_accuracy=0.9581\n","Epoch 8: train_loss=0.220, validation_accuracy=0.9514\n","Epoch 7: train_loss=0.120, validation_accuracy=0.9598\n","Epoch 13: train_loss=0.130, validation_accuracy=0.9584\n","Epoch 9: train_loss=0.198, validation_accuracy=0.9536\n","Epoch 8: train_loss=0.111, validation_accuracy=0.9547\n","Epoch 14: train_loss=0.122, validation_accuracy=0.9581\n","Epoch 10: train_loss=0.180, validation_accuracy=0.9568\n","Epoch 9: train_loss=0.103, validation_accuracy=0.9585\n","Epoch 15: train_loss=0.114, validation_accuracy=0.9598\n","Epoch 11: train_loss=0.166, validation_accuracy=0.9591\n","Epoch 10: train_loss=0.096, validation_accuracy=0.9606\n","Epoch 16: train_loss=0.108, validation_accuracy=0.9592\n","Epoch 12: train_loss=0.153, validation_accuracy=0.9593\n","Epoch 11: train_loss=0.089, validation_accuracy=0.9580\n","Epoch 17: train_loss=0.103, validation_accuracy=0.9606\n","Epoch 13: train_loss=0.143, validation_accuracy=0.9602\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9628\n","Epoch 18: train_loss=0.098, validation_accuracy=0.9607\n","Epoch 14: train_loss=0.133, validation_accuracy=0.9605\n","Epoch 19: train_loss=0.093, validation_accuracy=0.9622\n","Epoch 13: train_loss=0.080, validation_accuracy=0.9630\n","Epoch 15: train_loss=0.126, validation_accuracy=0.9623\n","Epoch 20: train_loss=0.088, validation_accuracy=0.9635\n","\u001b[32m[I 2023-03-07 23:23:38,938]\u001b[0m Trial 368 finished with value: 0.9635 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 28, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 40, 'activation_func[3]': 'Sigmoid', 'lr': 0.000780507280018558, 'momentum': 0.9863437099441592}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 14: train_loss=0.075, validation_accuracy=0.9622\n","Epoch 16: train_loss=0.118, validation_accuracy=0.9615\n","Epoch 1: train_loss=1.765, validation_accuracy=0.8032\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9676\n","Epoch 17: train_loss=0.113, validation_accuracy=0.9629\n","Epoch 2: train_loss=0.758, validation_accuracy=0.8925\n","Epoch 18: train_loss=0.107, validation_accuracy=0.9618\n","Epoch 16: train_loss=0.068, validation_accuracy=0.9643\n","Epoch 3: train_loss=0.403, validation_accuracy=0.9171\n","Epoch 19: train_loss=0.102, validation_accuracy=0.9608\n","Epoch 17: train_loss=0.065, validation_accuracy=0.9648\n","Epoch 4: train_loss=0.296, validation_accuracy=0.9291\n","Epoch 20: train_loss=0.098, validation_accuracy=0.9637\n","\u001b[32m[I 2023-03-07 23:23:40,197]\u001b[0m Trial 370 finished with value: 0.9637 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 44, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'Sigmoid', 'lr': 0.0020929136500123496, 'momentum': 0.9545122626235494}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 18: train_loss=0.060, validation_accuracy=0.9654\n","Epoch 5: train_loss=0.242, validation_accuracy=0.9368\n","Epoch 1: train_loss=1.783, validation_accuracy=0.8195\n","Epoch 19: train_loss=0.058, validation_accuracy=0.9679\n","Epoch 6: train_loss=0.208, validation_accuracy=0.9431\n","Epoch 2: train_loss=0.872, validation_accuracy=0.9092\n","Epoch 20: train_loss=0.054, validation_accuracy=0.9670\n","\u001b[32m[I 2023-03-07 23:23:41,007]\u001b[0m Trial 371 finished with value: 0.967 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 25, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 22, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 33, 'activation_func[4]': 'ReLU', 'lr': 0.009977928702686744, 'momentum': 0.6324597788772516}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 7: train_loss=0.183, validation_accuracy=0.9497\n","Epoch 3: train_loss=0.491, validation_accuracy=0.9263\n","Epoch 1: train_loss=1.004, validation_accuracy=0.8753\n","Epoch 8: train_loss=0.164, validation_accuracy=0.9511\n","Epoch 4: train_loss=0.353, validation_accuracy=0.9386\n","Epoch 2: train_loss=0.334, validation_accuracy=0.9213\n","Epoch 9: train_loss=0.148, validation_accuracy=0.9539\n","Epoch 5: train_loss=0.284, validation_accuracy=0.9436\n","Epoch 3: train_loss=0.241, validation_accuracy=0.9276\n","Epoch 10: train_loss=0.136, validation_accuracy=0.9567\n","Epoch 6: train_loss=0.242, validation_accuracy=0.9479\n","Epoch 4: train_loss=0.199, validation_accuracy=0.9477\n","Epoch 11: train_loss=0.124, validation_accuracy=0.9563\n","Epoch 7: train_loss=0.213, validation_accuracy=0.9492\n","Epoch 5: train_loss=0.176, validation_accuracy=0.9463\n","Epoch 12: train_loss=0.115, validation_accuracy=0.9592\n","Epoch 8: train_loss=0.190, validation_accuracy=0.9532\n","Epoch 6: train_loss=0.152, validation_accuracy=0.9521\n","Epoch 13: train_loss=0.107, validation_accuracy=0.9582\n","Epoch 9: train_loss=0.173, validation_accuracy=0.9542\n","Epoch 7: train_loss=0.139, validation_accuracy=0.9552\n","Epoch 14: train_loss=0.102, validation_accuracy=0.9608\n","Epoch 10: train_loss=0.160, validation_accuracy=0.9549\n","Epoch 8: train_loss=0.126, validation_accuracy=0.9578\n","Epoch 15: train_loss=0.097, validation_accuracy=0.9584\n","Epoch 11: train_loss=0.148, validation_accuracy=0.9565\n","Epoch 9: train_loss=0.116, validation_accuracy=0.9599\n","Epoch 16: train_loss=0.093, validation_accuracy=0.9620\n","Epoch 12: train_loss=0.138, validation_accuracy=0.9607\n","Epoch 10: train_loss=0.109, validation_accuracy=0.9604\n","Epoch 17: train_loss=0.087, validation_accuracy=0.9596\n","Epoch 13: train_loss=0.128, validation_accuracy=0.9601\n","Epoch 18: train_loss=0.083, validation_accuracy=0.9618\n","Epoch 11: train_loss=0.101, validation_accuracy=0.9620\n","Epoch 14: train_loss=0.121, validation_accuracy=0.9599\n","Epoch 19: train_loss=0.080, validation_accuracy=0.9613\n","Epoch 12: train_loss=0.094, validation_accuracy=0.9584\n","Epoch 20: train_loss=0.074, validation_accuracy=0.9629\n","Epoch 15: train_loss=0.113, validation_accuracy=0.9619\n","\u001b[32m[I 2023-03-07 23:23:45,327]\u001b[0m Trial 372 finished with value: 0.9629 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 28, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 42, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 31, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 40, 'activation_func[3]': 'Sigmoid', 'lr': 0.0013290987995302447, 'momentum': 0.9859851262084199}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9649\n","Epoch 16: train_loss=0.107, validation_accuracy=0.9608\n","Epoch 14: train_loss=0.083, validation_accuracy=0.9633\n","Epoch 1: train_loss=0.849, validation_accuracy=0.9034\n","Epoch 17: train_loss=0.103, validation_accuracy=0.9620\n","Epoch 15: train_loss=0.080, validation_accuracy=0.9637\n","Epoch 2: train_loss=0.282, validation_accuracy=0.9286\n","Epoch 18: train_loss=0.098, validation_accuracy=0.9640\n","Epoch 16: train_loss=0.076, validation_accuracy=0.9619\n","Epoch 3: train_loss=0.216, validation_accuracy=0.9312\n","Epoch 19: train_loss=0.093, validation_accuracy=0.9615\n","Epoch 17: train_loss=0.069, validation_accuracy=0.9655\n","Epoch 4: train_loss=0.180, validation_accuracy=0.9500\n","Epoch 20: train_loss=0.090, validation_accuracy=0.9632\n","\u001b[32m[I 2023-03-07 23:23:46,955]\u001b[0m Trial 373 finished with value: 0.9632 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 44, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 29, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 35, 'activation_func[3]': 'Sigmoid', 'lr': 0.00214375947165954, 'momentum': 0.9547882704669566}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 18: train_loss=0.070, validation_accuracy=0.9668\n","Epoch 5: train_loss=0.151, validation_accuracy=0.9500\n","Epoch 1: train_loss=2.300, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.063, validation_accuracy=0.9644\n","Epoch 6: train_loss=0.140, validation_accuracy=0.9493\n","Epoch 2: train_loss=2.274, validation_accuracy=0.2878\n","Epoch 20: train_loss=0.062, validation_accuracy=0.9653\n","\u001b[32m[I 2023-03-07 23:23:47,797]\u001b[0m Trial 374 finished with value: 0.9653 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 25, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 26, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 21, 'activation_func[4]': 'ReLU', 'lr': 0.009826244544398371, 'momentum': 0.6424427828683393}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 7: train_loss=0.129, validation_accuracy=0.9591\n","Epoch 3: train_loss=2.069, validation_accuracy=0.3138\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9564\n","Epoch 4: train_loss=1.583, validation_accuracy=0.5380\n","Epoch 9: train_loss=0.110, validation_accuracy=0.9609\n","Epoch 5: train_loss=1.216, validation_accuracy=0.6299\n","Epoch 10: train_loss=0.104, validation_accuracy=0.9626\n","Epoch 11: train_loss=0.096, validation_accuracy=0.9638\n","Epoch 6: train_loss=1.025, validation_accuracy=0.6698\n","Epoch 12: train_loss=0.089, validation_accuracy=0.9639\n","Epoch 7: train_loss=0.931, validation_accuracy=0.7240\n","Epoch 13: train_loss=0.086, validation_accuracy=0.9642\n","Epoch 8: train_loss=0.887, validation_accuracy=0.7417\n","Epoch 14: train_loss=0.081, validation_accuracy=0.9634\n","Epoch 9: train_loss=0.843, validation_accuracy=0.7552\n","Epoch 15: train_loss=0.077, validation_accuracy=0.9637\n","Epoch 10: train_loss=0.769, validation_accuracy=0.7834\n","\u001b[32m[I 2023-03-07 23:23:50,757]\u001b[0m Trial 376 pruned. \u001b[0m\n","Epoch 16: train_loss=0.072, validation_accuracy=0.9668\n","Epoch 1: train_loss=2.309, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.073, validation_accuracy=0.9658\n","Epoch 18: train_loss=0.066, validation_accuracy=0.9487\n","Epoch 2: train_loss=2.295, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.064, validation_accuracy=0.9659\n","Epoch 3: train_loss=2.291, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9659\n","\u001b[32m[I 2023-03-07 23:23:52,261]\u001b[0m Trial 375 finished with value: 0.9659 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 39, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 24, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 24, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 35, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 34, 'activation_func[4]': 'ReLU', 'lr': 0.009984422608779239, 'momentum': 0.6285529703432101}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 4: train_loss=2.284, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.891, validation_accuracy=0.8960\n","Epoch 5: train_loss=2.272, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.301, validation_accuracy=0.9312\n","Epoch 6: train_loss=2.250, validation_accuracy=0.2031\n","Epoch 3: train_loss=0.217, validation_accuracy=0.9438\n","Epoch 7: train_loss=2.202, validation_accuracy=0.3557\n","Epoch 4: train_loss=0.178, validation_accuracy=0.9448\n","Epoch 8: train_loss=2.100, validation_accuracy=0.2918\n","Epoch 5: train_loss=0.157, validation_accuracy=0.9542\n","Epoch 9: train_loss=1.943, validation_accuracy=0.2271\n","Epoch 6: train_loss=0.142, validation_accuracy=0.9510\n","Epoch 10: train_loss=1.800, validation_accuracy=0.2942\n","\u001b[32m[I 2023-03-07 23:23:54,762]\u001b[0m Trial 377 pruned. \u001b[0m\n","Epoch 7: train_loss=0.125, validation_accuracy=0.9557\n","Epoch 1: train_loss=1.073, validation_accuracy=0.8725\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9620\n","Epoch 2: train_loss=0.360, validation_accuracy=0.9166\n","Epoch 9: train_loss=0.168, validation_accuracy=0.9577\n","Epoch 3: train_loss=0.251, validation_accuracy=0.9360\n","Epoch 10: train_loss=0.107, validation_accuracy=0.9607\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9401\n","\u001b[32m[I 2023-03-07 23:23:56,273]\u001b[0m Trial 379 pruned. \u001b[0m\n","Epoch 11: train_loss=0.096, validation_accuracy=0.9631\n","Epoch 1: train_loss=0.665, validation_accuracy=0.9080\n","Epoch 12: train_loss=0.088, validation_accuracy=0.9643\n","Epoch 2: train_loss=0.256, validation_accuracy=0.9359\n","Epoch 13: train_loss=0.085, validation_accuracy=0.9605\n","Epoch 3: train_loss=0.199, validation_accuracy=0.9449\n","Epoch 14: train_loss=0.079, validation_accuracy=0.9631\n","Epoch 4: train_loss=0.170, validation_accuracy=0.9491\n","Epoch 15: train_loss=0.076, validation_accuracy=0.9622\n","Epoch 5: train_loss=0.148, validation_accuracy=0.9537\n","Epoch 16: train_loss=0.073, validation_accuracy=0.9652\n","Epoch 6: train_loss=0.135, validation_accuracy=0.9563\n","Epoch 17: train_loss=0.070, validation_accuracy=0.9676\n","Epoch 7: train_loss=0.123, validation_accuracy=0.9579\n","Epoch 18: train_loss=0.066, validation_accuracy=0.9658\n","Epoch 8: train_loss=0.113, validation_accuracy=0.9602\n","Epoch 19: train_loss=0.062, validation_accuracy=0.9653\n","Epoch 9: train_loss=0.108, validation_accuracy=0.9584\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9658\n","\u001b[32m[I 2023-03-07 23:23:59,393]\u001b[0m Trial 378 finished with value: 0.9658 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 25, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 35, 'activation_func[4]': 'ReLU', 'lr': 0.00931541293894628, 'momentum': 0.6321344428276063}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 10: train_loss=0.103, validation_accuracy=0.9586\n","Epoch 1: train_loss=2.310, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.098, validation_accuracy=0.9580\n","Epoch 2: train_loss=2.296, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.090, validation_accuracy=0.9589\n","Epoch 3: train_loss=2.292, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.088, validation_accuracy=0.9603\n","Epoch 4: train_loss=2.288, validation_accuracy=0.1135\n","\u001b[32m[I 2023-03-07 23:24:00,790]\u001b[0m Trial 381 pruned. \u001b[0m\n","Epoch 14: train_loss=0.081, validation_accuracy=0.9619\n","Epoch 1: train_loss=1.603, validation_accuracy=0.7969\n","Epoch 15: train_loss=0.077, validation_accuracy=0.9623\n","Epoch 2: train_loss=0.543, validation_accuracy=0.9138\n","Epoch 16: train_loss=0.076, validation_accuracy=0.9636\n","Epoch 3: train_loss=0.306, validation_accuracy=0.9290\n","Epoch 17: train_loss=0.071, validation_accuracy=0.9610\n","Epoch 4: train_loss=0.237, validation_accuracy=0.9375\n","Epoch 18: train_loss=0.068, validation_accuracy=0.9634\n","Epoch 5: train_loss=0.208, validation_accuracy=0.9438\n","Epoch 19: train_loss=0.067, validation_accuracy=0.9628\n","Epoch 6: train_loss=0.183, validation_accuracy=0.9484\n","Epoch 7: train_loss=0.166, validation_accuracy=0.9523\n","Epoch 20: train_loss=0.064, validation_accuracy=0.9623\n","\u001b[32m[I 2023-03-07 23:24:03,736]\u001b[0m Trial 380 finished with value: 0.9623 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 29, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 41, 'activation_func[3]': 'ELU', 'lr': 0.002521697146393609, 'momentum': 0.9875215968010078}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 8: train_loss=0.152, validation_accuracy=0.9542\n","Epoch 1: train_loss=0.950, validation_accuracy=0.8765\n","Epoch 9: train_loss=0.146, validation_accuracy=0.9527\n","Epoch 2: train_loss=0.444, validation_accuracy=0.8765\n","Epoch 10: train_loss=0.143, validation_accuracy=0.9536\n","Epoch 3: train_loss=0.622, validation_accuracy=0.8124\n","Epoch 11: train_loss=0.134, validation_accuracy=0.9600\n","Epoch 4: train_loss=1.773, validation_accuracy=0.1788\n","\u001b[32m[I 2023-03-07 23:24:05,139]\u001b[0m Trial 383 pruned. \u001b[0m\n","Epoch 12: train_loss=0.126, validation_accuracy=0.9580\n","Epoch 1: train_loss=37963.084, validation_accuracy=0.0892\n","Epoch 13: train_loss=0.121, validation_accuracy=0.9572\n","Epoch 2: train_loss=65.881, validation_accuracy=0.0982\n","\u001b[32m[I 2023-03-07 23:24:05,651]\u001b[0m Trial 384 pruned. \u001b[0m\n","Epoch 14: train_loss=0.123, validation_accuracy=0.9578\n","Epoch 1: train_loss=0.726, validation_accuracy=0.9155\n","Epoch 15: train_loss=0.120, validation_accuracy=0.9608\n","Epoch 2: train_loss=0.264, validation_accuracy=0.9369\n","Epoch 16: train_loss=0.119, validation_accuracy=0.9560\n","Epoch 3: train_loss=0.204, validation_accuracy=0.9451\n","Epoch 17: train_loss=0.112, validation_accuracy=0.9583\n","Epoch 4: train_loss=0.170, validation_accuracy=0.9542\n","Epoch 18: train_loss=0.118, validation_accuracy=0.9567\n","Epoch 5: train_loss=0.150, validation_accuracy=0.9533\n","Epoch 19: train_loss=0.114, validation_accuracy=0.9565\n","Epoch 20: train_loss=0.111, validation_accuracy=0.9575\n","\u001b[32m[I 2023-03-07 23:24:07,699]\u001b[0m Trial 382 finished with value: 0.9575 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 29, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 49, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 20, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 35, 'activation_func[3]': 'Sigmoid', 'lr': 0.0027722994381761835, 'momentum': 0.9845626877150749}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 6: train_loss=0.135, validation_accuracy=0.9527\n","Epoch 7: train_loss=0.123, validation_accuracy=0.9574\n","Epoch 1: train_loss=0.799, validation_accuracy=0.8988\n","Epoch 8: train_loss=0.113, validation_accuracy=0.9579\n","Epoch 2: train_loss=0.288, validation_accuracy=0.9252\n","Epoch 9: train_loss=0.104, validation_accuracy=0.9555\n","Epoch 3: train_loss=0.214, validation_accuracy=0.9429\n","Epoch 4: train_loss=0.175, validation_accuracy=0.9487\n","Epoch 10: train_loss=0.097, validation_accuracy=0.9628\n","Epoch 5: train_loss=0.157, validation_accuracy=0.9498\n","Epoch 11: train_loss=0.091, validation_accuracy=0.9583\n","Epoch 6: train_loss=0.139, validation_accuracy=0.9528\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9598\n","Epoch 7: train_loss=0.126, validation_accuracy=0.9540\n","Epoch 13: train_loss=0.080, validation_accuracy=0.9594\n","Epoch 8: train_loss=0.118, validation_accuracy=0.9571\n","Epoch 14: train_loss=0.074, validation_accuracy=0.9644\n","Epoch 9: train_loss=0.111, validation_accuracy=0.9594\n","Epoch 15: train_loss=0.071, validation_accuracy=0.9657\n","Epoch 10: train_loss=0.105, validation_accuracy=0.9580\n","Epoch 16: train_loss=0.070, validation_accuracy=0.9626\n","Epoch 11: train_loss=0.099, validation_accuracy=0.9594\n","Epoch 17: train_loss=0.066, validation_accuracy=0.9651\n","Epoch 18: train_loss=0.063, validation_accuracy=0.9651\n","Epoch 12: train_loss=0.096, validation_accuracy=0.9594\n","Epoch 19: train_loss=0.057, validation_accuracy=0.9653\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9578\n","Epoch 20: train_loss=0.053, validation_accuracy=0.9633\n","\u001b[32m[I 2023-03-07 23:24:12,275]\u001b[0m Trial 385 finished with value: 0.9633 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 24, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 36, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 35, 'activation_func[4]': 'ReLU', 'lr': 0.009957803797098484, 'momentum': 0.6256212204123417}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 14: train_loss=0.085, validation_accuracy=0.9611\n","Epoch 15: train_loss=0.082, validation_accuracy=0.9618\n","Epoch 1: train_loss=0.606, validation_accuracy=0.9245\n","Epoch 16: train_loss=0.078, validation_accuracy=0.9604\n","Epoch 2: train_loss=0.210, validation_accuracy=0.9401\n","Epoch 17: train_loss=0.073, validation_accuracy=0.9625\n","Epoch 3: train_loss=0.168, validation_accuracy=0.9477\n","Epoch 18: train_loss=0.070, validation_accuracy=0.9623\n","Epoch 4: train_loss=0.146, validation_accuracy=0.9520\n","Epoch 19: train_loss=0.069, validation_accuracy=0.9601\n","Epoch 5: train_loss=0.130, validation_accuracy=0.9551\n","Epoch 20: train_loss=0.070, validation_accuracy=0.9619\n","\u001b[32m[I 2023-03-07 23:24:14,184]\u001b[0m Trial 386 finished with value: 0.9619 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 31, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 28, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 41, 'activation_func[3]': 'ELU', 'lr': 0.002249630592582599, 'momentum': 0.9869796998611476}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 6: train_loss=0.116, validation_accuracy=0.9587\n","Epoch 1: train_loss=0.915, validation_accuracy=0.8898\n","Epoch 7: train_loss=0.108, validation_accuracy=0.9590\n","Epoch 2: train_loss=0.341, validation_accuracy=0.9209\n","Epoch 8: train_loss=0.100, validation_accuracy=0.9571\n","Epoch 3: train_loss=0.251, validation_accuracy=0.9298\n","Epoch 9: train_loss=0.095, validation_accuracy=0.9610\n","Epoch 4: train_loss=0.207, validation_accuracy=0.9463\n","Epoch 10: train_loss=0.087, validation_accuracy=0.9605\n","Epoch 11: train_loss=0.084, validation_accuracy=0.9634\n","Epoch 5: train_loss=0.177, validation_accuracy=0.9504\n","Epoch 12: train_loss=0.078, validation_accuracy=0.9635\n","Epoch 6: train_loss=0.155, validation_accuracy=0.9550\n","Epoch 13: train_loss=0.074, validation_accuracy=0.9626\n","Epoch 7: train_loss=0.140, validation_accuracy=0.9591\n","Epoch 14: train_loss=0.073, validation_accuracy=0.9642\n","Epoch 8: train_loss=0.131, validation_accuracy=0.9593\n","Epoch 15: train_loss=0.068, validation_accuracy=0.9622\n","Epoch 9: train_loss=0.118, validation_accuracy=0.9623\n","Epoch 16: train_loss=0.064, validation_accuracy=0.9627\n","Epoch 10: train_loss=0.108, validation_accuracy=0.9627\n","Epoch 17: train_loss=0.064, validation_accuracy=0.9625\n","Epoch 11: train_loss=0.102, validation_accuracy=0.9623\n","Epoch 18: train_loss=0.060, validation_accuracy=0.9623\n","Epoch 12: train_loss=0.096, validation_accuracy=0.9639\n","Epoch 19: train_loss=0.055, validation_accuracy=0.9646\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9663\n","Epoch 20: train_loss=0.054, validation_accuracy=0.9652\n","\u001b[32m[I 2023-03-07 23:24:18,891]\u001b[0m Trial 387 finished with value: 0.9652 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 30, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 30, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 39, 'activation_func[3]': 'ELU', 'lr': 0.002619798334474722, 'momentum': 0.9525786810510041}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 14: train_loss=0.085, validation_accuracy=0.9644\n","Epoch 15: train_loss=0.079, validation_accuracy=0.9665\n","Epoch 1: train_loss=0.794, validation_accuracy=0.9055\n","Epoch 16: train_loss=0.079, validation_accuracy=0.9656\n","Epoch 2: train_loss=0.273, validation_accuracy=0.9374\n","Epoch 17: train_loss=0.072, validation_accuracy=0.9643\n","Epoch 3: train_loss=0.201, validation_accuracy=0.9447\n","Epoch 18: train_loss=0.068, validation_accuracy=0.9685\n","Epoch 4: train_loss=0.167, validation_accuracy=0.9525\n","Epoch 19: train_loss=0.066, validation_accuracy=0.9680\n","Epoch 5: train_loss=0.143, validation_accuracy=0.9523\n","Epoch 20: train_loss=0.064, validation_accuracy=0.9691\n","\u001b[32m[I 2023-03-07 23:24:21,017]\u001b[0m Trial 388 finished with value: 0.9691 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 37, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 23, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 23, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 35, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 36, 'activation_func[4]': 'ReLU', 'lr': 0.008547443429361274, 'momentum': 0.6331733455488138}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 6: train_loss=0.128, validation_accuracy=0.9584\n","Epoch 1: train_loss=2.113, validation_accuracy=0.3710\n","Epoch 7: train_loss=0.116, validation_accuracy=0.9578\n","Epoch 2: train_loss=1.575, validation_accuracy=0.6310\n","\u001b[32m[I 2023-03-07 23:24:21,799]\u001b[0m Trial 390 pruned. \u001b[0m\n","Epoch 8: train_loss=0.104, validation_accuracy=0.9620\n","Epoch 9: train_loss=0.096, validation_accuracy=0.9632\n","Epoch 1: train_loss=0.846, validation_accuracy=0.9045\n","Epoch 10: train_loss=0.089, validation_accuracy=0.9664\n","Epoch 2: train_loss=0.300, validation_accuracy=0.9166\n","Epoch 11: train_loss=0.082, validation_accuracy=0.9608\n","Epoch 3: train_loss=0.231, validation_accuracy=0.9289\n","Epoch 12: train_loss=0.079, validation_accuracy=0.9653\n","Epoch 4: train_loss=0.197, validation_accuracy=0.9289\n","\u001b[32m[I 2023-03-07 23:24:23,225]\u001b[0m Trial 391 pruned. \u001b[0m\n","Epoch 13: train_loss=0.074, validation_accuracy=0.9668\n","Epoch 1: train_loss=0.740, validation_accuracy=0.8762\n","Epoch 14: train_loss=0.068, validation_accuracy=0.9663\n","Epoch 2: train_loss=0.462, validation_accuracy=0.8845\n","Epoch 15: train_loss=0.065, validation_accuracy=0.9654\n","Epoch 3: train_loss=2.218, validation_accuracy=0.2268\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9695\n","Epoch 4: train_loss=4.448, validation_accuracy=0.0974\n","\u001b[32m[I 2023-03-07 23:24:24,529]\u001b[0m Trial 392 pruned. \u001b[0m\n","Epoch 17: train_loss=0.058, validation_accuracy=0.9694\n","Epoch 1: train_loss=0.890, validation_accuracy=0.8983\n","Epoch 18: train_loss=0.055, validation_accuracy=0.9673\n","Epoch 2: train_loss=0.295, validation_accuracy=0.9291\n","Epoch 19: train_loss=0.052, validation_accuracy=0.9669\n","Epoch 3: train_loss=0.228, validation_accuracy=0.9358\n","Epoch 20: train_loss=0.049, validation_accuracy=0.9698\n","\u001b[32m[I 2023-03-07 23:24:25,898]\u001b[0m Trial 389 finished with value: 0.9698 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 40, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 26, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 24, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 33, 'activation_func[4]': 'ReLU', 'lr': 0.0073053157218730975, 'momentum': 0.7467845478388544}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 4: train_loss=0.192, validation_accuracy=0.9436\n","Epoch 5: train_loss=0.163, validation_accuracy=0.9489\n","Epoch 1: train_loss=0.714, validation_accuracy=0.9107\n","Epoch 6: train_loss=0.147, validation_accuracy=0.9533\n","Epoch 2: train_loss=0.256, validation_accuracy=0.9281\n","Epoch 3: train_loss=0.204, validation_accuracy=0.9407\n","Epoch 7: train_loss=0.133, validation_accuracy=0.9569\n","Epoch 4: train_loss=0.172, validation_accuracy=0.9437\n","Epoch 8: train_loss=0.123, validation_accuracy=0.9578\n","Epoch 5: train_loss=0.152, validation_accuracy=0.9490\n","Epoch 9: train_loss=0.136, validation_accuracy=0.9568\n","Epoch 6: train_loss=0.137, validation_accuracy=0.9513\n","Epoch 10: train_loss=0.106, validation_accuracy=0.9586\n","\u001b[32m[I 2023-03-07 23:24:27,910]\u001b[0m Trial 393 pruned. \u001b[0m\n","Epoch 7: train_loss=0.128, validation_accuracy=0.9527\n","Epoch 1: train_loss=1.837, validation_accuracy=0.6978\n","Epoch 8: train_loss=0.117, validation_accuracy=0.9550\n","Epoch 2: train_loss=0.802, validation_accuracy=0.8048\n","\u001b[32m[I 2023-03-07 23:24:28,594]\u001b[0m Trial 395 pruned. \u001b[0m\n","Epoch 9: train_loss=0.111, validation_accuracy=0.9537\n","Epoch 1: train_loss=0.919, validation_accuracy=0.9145\n","Epoch 10: train_loss=0.104, validation_accuracy=0.9567\n","Epoch 2: train_loss=0.274, validation_accuracy=0.9402\n","Epoch 11: train_loss=0.098, validation_accuracy=0.9567\n","Epoch 3: train_loss=0.200, validation_accuracy=0.9480\n","Epoch 12: train_loss=0.093, validation_accuracy=0.9581\n","Epoch 4: train_loss=0.164, validation_accuracy=0.9543\n","Epoch 13: train_loss=0.089, validation_accuracy=0.9571\n","Epoch 5: train_loss=0.144, validation_accuracy=0.9554\n","Epoch 14: train_loss=0.086, validation_accuracy=0.9584\n","Epoch 6: train_loss=0.131, validation_accuracy=0.9558\n","Epoch 15: train_loss=0.082, validation_accuracy=0.9584\n","Epoch 7: train_loss=0.118, validation_accuracy=0.9581\n","Epoch 16: train_loss=0.078, validation_accuracy=0.9581\n","Epoch 8: train_loss=0.112, validation_accuracy=0.9564\n","Epoch 17: train_loss=0.076, validation_accuracy=0.9624\n","Epoch 9: train_loss=0.102, validation_accuracy=0.9615\n","Epoch 18: train_loss=0.074, validation_accuracy=0.9601\n","Epoch 10: train_loss=0.095, validation_accuracy=0.9630\n","Epoch 19: train_loss=0.071, validation_accuracy=0.9591\n","Epoch 11: train_loss=0.089, validation_accuracy=0.9640\n","Epoch 20: train_loss=0.068, validation_accuracy=0.9603\n","\u001b[32m[I 2023-03-07 23:24:32,211]\u001b[0m Trial 394 finished with value: 0.9603 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 26, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 48, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 26, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 45, 'activation_func[3]': 'ELU', 'lr': 0.0021001777904690023, 'momentum': 0.945812806517538}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 12: train_loss=0.084, validation_accuracy=0.9642\n","Epoch 1: train_loss=0.795, validation_accuracy=0.9058\n","Epoch 13: train_loss=0.080, validation_accuracy=0.9653\n","Epoch 2: train_loss=0.268, validation_accuracy=0.9331\n","Epoch 14: train_loss=0.077, validation_accuracy=0.9640\n","Epoch 3: train_loss=0.211, validation_accuracy=0.9424\n","Epoch 15: train_loss=0.073, validation_accuracy=0.9666\n","Epoch 4: train_loss=0.184, validation_accuracy=0.9461\n","Epoch 16: train_loss=0.071, validation_accuracy=0.9643\n","Epoch 5: train_loss=0.167, validation_accuracy=0.9467\n","Epoch 17: train_loss=0.066, validation_accuracy=0.9643\n","Epoch 6: train_loss=0.154, validation_accuracy=0.9507\n","Epoch 18: train_loss=0.066, validation_accuracy=0.9650\n","Epoch 7: train_loss=0.143, validation_accuracy=0.9530\n","Epoch 19: train_loss=0.062, validation_accuracy=0.9678\n","Epoch 8: train_loss=0.136, validation_accuracy=0.9542\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9648\n","\u001b[32m[I 2023-03-07 23:24:34,982]\u001b[0m Trial 396 finished with value: 0.9648 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 33, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 47, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 30, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 37, 'activation_func[3]': 'Tanh', 'lr': 0.0037892912213089856, 'momentum': 0.9555518388892578}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 9: train_loss=0.128, validation_accuracy=0.9547\n","Epoch 1: train_loss=0.953, validation_accuracy=0.9137\n","Epoch 10: train_loss=0.122, validation_accuracy=0.9560\n","Epoch 2: train_loss=0.309, validation_accuracy=0.9385\n","Epoch 11: train_loss=0.117, validation_accuracy=0.9577\n","Epoch 3: train_loss=0.222, validation_accuracy=0.9479\n","Epoch 12: train_loss=0.112, validation_accuracy=0.9587\n","Epoch 4: train_loss=0.182, validation_accuracy=0.9535\n","Epoch 13: train_loss=0.108, validation_accuracy=0.9548\n","Epoch 5: train_loss=0.156, validation_accuracy=0.9544\n","Epoch 14: train_loss=0.104, validation_accuracy=0.9586\n","Epoch 6: train_loss=0.141, validation_accuracy=0.9579\n","Epoch 15: train_loss=0.101, validation_accuracy=0.9588\n","Epoch 7: train_loss=0.127, validation_accuracy=0.9590\n","Epoch 16: train_loss=0.097, validation_accuracy=0.9601\n","Epoch 8: train_loss=0.118, validation_accuracy=0.9597\n","Epoch 17: train_loss=0.094, validation_accuracy=0.9604\n","Epoch 9: train_loss=0.108, validation_accuracy=0.9600\n","Epoch 18: train_loss=0.092, validation_accuracy=0.9591\n","Epoch 10: train_loss=0.101, validation_accuracy=0.9594\n","Epoch 19: train_loss=0.089, validation_accuracy=0.9597\n","Epoch 20: train_loss=0.086, validation_accuracy=0.9609\n","\u001b[32m[I 2023-03-07 23:24:38,575]\u001b[0m Trial 397 finished with value: 0.9609 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 27, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 49, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 27, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 41, 'activation_func[3]': 'ELU', 'lr': 0.002003372505361139, 'momentum': 0.9274381918929824}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 11: train_loss=0.094, validation_accuracy=0.9634\n","Epoch 12: train_loss=0.088, validation_accuracy=0.9608\n","Epoch 13: train_loss=0.084, validation_accuracy=0.9635\n","Epoch 14: train_loss=0.079, validation_accuracy=0.9636\n","Epoch 15: train_loss=0.075, validation_accuracy=0.9636\n","Epoch 16: train_loss=0.072, validation_accuracy=0.9660\n","Epoch 17: train_loss=0.068, validation_accuracy=0.9650\n","Epoch 18: train_loss=0.063, validation_accuracy=0.9665\n","Epoch 19: train_loss=0.062, validation_accuracy=0.9632\n","Epoch 20: train_loss=0.059, validation_accuracy=0.9633\n","\u001b[32m[I 2023-03-07 23:24:40,269]\u001b[0m Trial 398 finished with value: 0.9633 and parameters: {'n_hidden_layers': 4, 'hidden_dim[0]': 33, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 46, 'activation_func[1]': 'ReLU', 'hidden_dim[2]': 30, 'activation_func[2]': 'ELU', 'hidden_dim[3]': 37, 'activation_func[3]': 'Tanh', 'lr': 0.00397582815957558, 'momentum': 0.9151352889554629}. Best is trial 261 with value: 0.97.\u001b[0m\n","Epoch 1: train_loss=0.775, validation_accuracy=0.9169\n","Epoch 2: train_loss=0.246, validation_accuracy=0.9381\n","Epoch 3: train_loss=0.186, validation_accuracy=0.9324\n","Epoch 4: train_loss=0.154, validation_accuracy=0.9547\n","Epoch 5: train_loss=0.134, validation_accuracy=0.9562\n","Epoch 6: train_loss=0.120, validation_accuracy=0.9613\n","Epoch 7: train_loss=0.109, validation_accuracy=0.9626\n","Epoch 8: train_loss=0.100, validation_accuracy=0.9595\n","Epoch 9: train_loss=0.092, validation_accuracy=0.9654\n","Epoch 10: train_loss=0.084, validation_accuracy=0.9661\n","Epoch 11: train_loss=0.081, validation_accuracy=0.9661\n","Epoch 12: train_loss=0.074, validation_accuracy=0.9667\n","Epoch 13: train_loss=0.069, validation_accuracy=0.9667\n","Epoch 14: train_loss=0.064, validation_accuracy=0.9660\n","Epoch 15: train_loss=0.062, validation_accuracy=0.9676\n","Epoch 16: train_loss=0.061, validation_accuracy=0.9672\n","Epoch 17: train_loss=0.054, validation_accuracy=0.9676\n","Epoch 18: train_loss=0.051, validation_accuracy=0.9686\n","Epoch 19: train_loss=0.050, validation_accuracy=0.9650\n","Epoch 20: train_loss=0.048, validation_accuracy=0.9677\n","\u001b[32m[I 2023-03-07 23:24:44,666]\u001b[0m Trial 399 finished with value: 0.9677 and parameters: {'n_hidden_layers': 5, 'hidden_dim[0]': 41, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 26, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 25, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 34, 'activation_func[3]': 'ELU', 'hidden_dim[4]': 34, 'activation_func[4]': 'ReLU', 'lr': 0.0075780556837911255, 'momentum': 0.7802404798935376}. Best is trial 261 with value: 0.97.\u001b[0m\n"]}],"source":["n_jobs = 4\n","\n","# python optuna_mnist_distributed_example.py を並列で n_jobs 回呼ぶ。\n","!seq $n_jobs | xargs -P0 -n1 python optuna_mnist_distributed_example.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["これで4つのworkerで25trialずつ、合計100trialが実行されます。もし計算資源に余裕があれば、1プロセスで100trial実行するよりも早く終わるでしょう。\n","\n","結果を見るのも、同じstudyを読み込むことでできます。"]},{"cell_type":"code","execution_count":27,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["最良の精度: 0.97\n","最良のハイパーパラメータ: {'n_hidden_layers': 5, 'hidden_dim[0]': 42, 'activation_func[0]': 'ELU', 'hidden_dim[1]': 41, 'activation_func[1]': 'ELU', 'hidden_dim[2]': 47, 'activation_func[2]': 'ReLU', 'hidden_dim[3]': 37, 'activation_func[3]': 'ReLU', 'hidden_dim[4]': 26, 'activation_func[4]': 'ReLU', 'lr': 0.0057429240762823085, 'momentum': 0.872636762299169}\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/tt/_c3nrr_56h14ctfrdh94spsh0000gn/T/ipykernel_23884/2556932345.py:2: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","  storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),\n"]}],"source":["distributed_study = optuna.load_study(\n","    storage=optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")),\n","    study_name=\"distributed_study\")\n","# optuna.load_studyは、指定したstudyが存在しなければエラーになる。\n","\n","print(f\"最良の精度: {distributed_study.best_value}\")\n","print(f\"最良のハイパーパラメータ: {distributed_study.best_params}\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optunaのこの`Storage`と呼ばれる枠組みは、非常に柔軟な分散最適化を可能にします。例えばこのファイルをNFS(ネットワークファイルシステム)上に置くことで、スパコン等の環境でもノードを超えた分散最適化が可能になります。また、メモリやファイルだけでなくRedis, あるいはMySQLやPostgreSQLなどのリレーショナルデータベース上にStudyの実体を置くこともできます。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"acZ6Z8kIcjD6"},"source":["## 7. 豊富な可視化機能を用いて最適化結果を分析する\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"rQPPRPUpJl9n"},"source":["高度なアルゴリズムの利用法、特に枝刈りの利用法について学び、最適化プロセスが改善されました。\n","また、必要があれば複数のワーカーで分散して並列処理をする事ができるようになりました。\n","最終的に達成された目的関数の評価値は**Study.best_value**, ハイパーパラメータの組は**Study.best_params**で取得できます。\n","最適化プロセスの改善や結果の分析は、これで十分でしょうか？\n","\n","**いいえ。そんなことはありません。**\n","\n","一度ハイパーパラメータ最適化を行うと、以下のような疑問が溢れてくることでしょう。\n","- トライアル数を決め打って最適化を行ったが、本当にこんなにたくさんのトライアルを実行する必要はあったのだろうか？\n","実はもっと早い段階で収束していたのではないだろうか？\n","逆にトライアル数は不十分だったりしないだろうか？\n","\n","- 自分の目的関数において、最も適切なsamplerとprunerの組み合わせは何なのだろうか？\n","今使ったsamplerとprunerが本当に最適なのだろうか？\n","\n","- 最適化の際に指定したハイパーパラメータの範囲は適切だろうか？\n","また、最終的に得たハイパーパラメータはどの程度信頼できるのだろうか？\n","\n","- 最適化したハイパーパラメータの中で、目的関数に最もよく効いているパラメータは何なのだろうか？\n","逆に、効いていないパラメータは最適化せずとも良かったのではないだろうか？\n","\n","Optunaは豊富な可視化機能を提供しており、ユーザはこれらの機能を利用して、\n","Optunaとインタラクティブに協同して、ハイパーパラメータ最適化のプロセスを改善していくことができます。\n","以下では、第3節(簡単な二層ニューラルネットワーク)で作った`study`を用いて、Optunaが提供する可視化機能の一部を紹介します。"]},{"cell_type":"markdown","metadata":{"id":"mE3vB64eODb6"},"source":["まずは、`optuna.visualization.plot_optimization_history` 関数を紹介します。\n","この関数の利用法はとてもシンプルで、最適化した`study`を関数に渡すだけです。\n","この関数は、与えられたstudyで行われた最適化の様子を、横軸をトライアル数、縦軸を目的関数値として表示します。\n","表示されるのは枝刈りされずに最後まで完了したトライアルだけです。"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":2230,"status":"ok","timestamp":1602580423190,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"8IcgXVIkO0_5","outputId":"608d8ba8-1718-409e-dac0-2b17b0f551f4"},"outputs":[{"ename":"NameError","evalue":"name 'study' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mセル58 を /Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m optuna\u001b[39m.\u001b[39mvisualization\u001b[39m.\u001b[39mplot_optimization_history(study)\n","\u001b[0;31mNameError\u001b[0m: name 'study' is not defined"]}],"source":["optuna.visualization.plot_optimization_history(study)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["図が見にくかったら図の右上のボタンからズームしてみてください。\n","\n","この図でもし早くから収束していてBest valueの線がそれ以上更新されてないようだと、実はこんなにtrialをたくさん回す必要がなかったということがわかります。逆に、まだまだ更新されるようでしたら、追加で`Study.optimize`を回すのがいいのかもしれません。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"VTQIH2xPRhvy"},"source":["また、今回の目的関数にどのsamplerが適しているのか調べるために、複数のsamplerに対して`study`を作り最適化を行ってみましょう。\n","\n","例えば、`QMCSampler`を使ってみます。`QMCSampler`は準モンテカルロ法(quasi-Monte Carlo method)と呼ばれる手法を用いて、「ランダムよりも一様な」数列を生成して満遍なく探索空間を試す、という手法です。グリッドサーチしたいけれど事前にどのくらい細かく分けるかは決めたくない、といった場合によく使える手法で、ランダムにとる`RandomSampler`よりも満遍なく試している分性能が高いことが多いです。\n","\n","果たしてOptunaのデフォルトである`TPESampler`はこのような単純な手法と比べて性能が高いのか、調べてみましょう。"]},{"cell_type":"code","execution_count":302,"metadata":{"id":"sYYGsxQISNhI"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: scipy in /opt/homebrew/lib/python3.10/site-packages (1.8.1)\n","Requirement already satisfied: numpy<1.25.0,>=1.17.3 in /opt/homebrew/lib/python3.10/site-packages (from scipy) (1.23.5)\n","\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/tt/_c3nrr_56h14ctfrdh94spsh0000gn/T/ipykernel_15883/2337401182.py:2: ExperimentalWarning:\n","\n","QMCSampler is experimental (supported from v3.0.0). The interface can change in the future.\n","\n","[I 2023-03-07 16:26:44,048] A new study created in memory with name: no-name-e0990621-caab-4520-b315-f4fb06911d15\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1: train_loss=0.452, validation_accuracy=0.1935\n","Epoch 2: train_loss=0.452, validation_accuracy=0.0958\n","Epoch 3: train_loss=0.452, validation_accuracy=0.0958\n","Epoch 4: train_loss=0.452, validation_accuracy=0.0959\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1032\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2095\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:45,585] Trial 0 finished with value: 0.1135 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.005273001939857696, 'momentum': 0.5804330797015227}. Best is trial 0 with value: 0.1135.\n","[W 2023-03-07 16:26:45,586] The parameter 'activation_func' in trial#1 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n","[W 2023-03-07 16:26:45,586] The parameter 'lr' in trial#1 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1291\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1438\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1465\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1402\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1597\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1815\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1840\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1970\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2047\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2069\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2062\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2082\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2083\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2085\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2085\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2088\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2091\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2095\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:46,741] Trial 1 finished with value: 0.2104 and parameters: {'hidden_dim': 10, 'activation_func': 'ReLU', 'lr': 8.875338607680504e-05, 'momentum': 0.5}. Best is trial 1 with value: 0.2104.\n","[W 2023-03-07 16:26:46,742] The parameter 'activation_func' in trial#2 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.2102\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2104\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3415\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4909\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5802\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6285\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6670\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6891\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7110\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7249\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7383\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7551\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7642\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7749\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7830\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7907\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8007\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8046\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8094\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8129\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8171\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:48,386] Trial 2 finished with value: 0.8213 and parameters: {'hidden_dim': 30, 'activation_func': 'Sigmoid', 'lr': 0.00031622776601683783, 'momentum': 0.75}. Best is trial 2 with value: 0.8213.\n","[W 2023-03-07 16:26:48,387] The parameter 'activation_func' in trial#3 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8213\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6187\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6812\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7239\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7559\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7767\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7963\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8114\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8232\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8305\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8385\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8445\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8488\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8538\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8581\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8614\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8654\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8684\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:49,939] Trial 3 finished with value: 0.8754 and parameters: {'hidden_dim': 40, 'activation_func': 'ReLU', 'lr': 5.6234132519034893e-05, 'momentum': 0.625}. Best is trial 3 with value: 0.8754.\n","[W 2023-03-07 16:26:49,940] The parameter 'activation_func' in trial#4 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8705\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8730\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8754\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:51,288] Trial 4 finished with value: 0.1135 and parameters: {'hidden_dim': 20, 'activation_func': 'ReLU', 'lr': 0.0017782794100389236, 'momentum': 0.875}. Best is trial 3 with value: 0.8754.\n","[W 2023-03-07 16:26:51,288] The parameter 'activation_func' in trial#5 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4878\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5715\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6260\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6524\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6697\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6986\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7310\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7593\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7723\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7851\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7924\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7966\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8206\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8575\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8694\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8771\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8843\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8949\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:52,640] Trial 5 finished with value: 0.9003 and parameters: {'hidden_dim': 25, 'activation_func': 'ReLU', 'lr': 0.00013335214321633237, 'momentum': 0.8125}. Best is trial 5 with value: 0.9003.\n","[W 2023-03-07 16:26:52,641] The parameter 'activation_func' in trial#6 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8950\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9003\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8304\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8718\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8924\n","Epoch 4: train_loss=0.452, validation_accuracy=0.9024\n","Epoch 5: train_loss=0.452, validation_accuracy=0.9022\n","Epoch 6: train_loss=0.452, validation_accuracy=0.9091\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9110\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9121\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9136\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9188\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9217\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9223\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9256\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9231\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9242\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9274\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9283\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9271\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9289\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:54,279] Trial 6 finished with value: 0.9304 and parameters: {'hidden_dim': 45, 'activation_func': 'Tanh', 'lr': 0.004216965034285825, 'momentum': 0.5625}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:26:54,279] The parameter 'activation_func' in trial#7 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9304\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6201\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7149\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7671\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8001\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8204\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8352\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8499\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8582\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8660\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8721\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8756\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8811\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8848\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8864\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8904\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8926\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8941\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8968\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8993\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:56,342] Trial 7 finished with value: 0.9 and parameters: {'hidden_dim': 35, 'activation_func': 'ELU', 'lr': 2.3713737056616547e-05, 'momentum': 0.9375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:26:56,343] The parameter 'activation_func' in trial#8 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9000\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3237\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3658\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3812\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3916\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4170\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4288\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4562\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5553\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5689\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5664\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5898\n","Epoch 12: train_loss=0.452, validation_accuracy=0.5954\n","Epoch 13: train_loss=0.452, validation_accuracy=0.5883\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6006\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6032\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6056\n","Epoch 17: train_loss=0.452, validation_accuracy=0.6056\n","Epoch 18: train_loss=0.452, validation_accuracy=0.6942\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7112\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:57,565] Trial 8 finished with value: 0.6805 and parameters: {'hidden_dim': 15, 'activation_func': 'ReLU', 'lr': 0.0007498942093324562, 'momentum': 0.6875}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:26:57,566] The parameter 'activation_func' in trial#9 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.6805\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4799\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6770\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7433\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7856\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8061\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8225\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8347\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8390\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8481\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8529\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8571\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8586\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8652\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8658\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8685\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8711\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8692\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8738\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:26:58,896] Trial 9 finished with value: 0.8753 and parameters: {'hidden_dim': 17, 'activation_func': 'Tanh', 'lr': 8.659643233600651e-05, 'momentum': 0.96875}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:26:58,897] The parameter 'activation_func' in trial#10 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8742\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8753\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2862\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2997\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3037\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3023\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3834\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4355\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4586\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5548\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5251\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5613\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5738\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6406\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6364\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5497\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6290\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6167\n","Epoch 17: train_loss=0.452, validation_accuracy=0.6315\n","Epoch 18: train_loss=0.452, validation_accuracy=0.6553\n","Epoch 19: train_loss=0.452, validation_accuracy=0.6627\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:00,342] Trial 10 finished with value: 0.6669 and parameters: {'hidden_dim': 38, 'activation_func': 'ReLU', 'lr': 0.0027384196342643626, 'momentum': 0.71875}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:00,343] The parameter 'activation_func' in trial#11 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.6669\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1356\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1641\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1961\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2198\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2413\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2607\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2814\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2998\n","Epoch 9: train_loss=0.452, validation_accuracy=0.3181\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3346\n","Epoch 11: train_loss=0.452, validation_accuracy=0.3492\n","Epoch 12: train_loss=0.452, validation_accuracy=0.3651\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3827\n","Epoch 14: train_loss=0.452, validation_accuracy=0.3998\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4168\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4314\n","Epoch 17: train_loss=0.452, validation_accuracy=0.4461\n","Epoch 18: train_loss=0.452, validation_accuracy=0.4596\n","Epoch 19: train_loss=0.452, validation_accuracy=0.4740\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:02,194] Trial 11 finished with value: 0.4889 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 1.5399265260594915e-05, 'momentum': 0.84375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:02,194] The parameter 'activation_func' in trial#12 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.4889\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6111\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7471\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8112\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8382\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8516\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8621\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8676\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8762\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8826\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8870\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8914\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8955\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8980\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9001\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9033\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9061\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9061\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:03,945] Trial 12 finished with value: 0.9106 and parameters: {'hidden_dim': 27, 'activation_func': 'ELU', 'lr': 0.00048696752516586293, 'momentum': 0.59375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:03,945] The parameter 'activation_func' in trial#13 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.9081\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9129\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9106\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1207\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1382\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1624\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1924\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2244\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2511\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2796\n","Epoch 8: train_loss=0.452, validation_accuracy=0.3042\n","Epoch 9: train_loss=0.452, validation_accuracy=0.3305\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3501\n","Epoch 11: train_loss=0.452, validation_accuracy=0.3662\n","Epoch 12: train_loss=0.452, validation_accuracy=0.3807\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3948\n","Epoch 14: train_loss=0.452, validation_accuracy=0.4100\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4213\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4358\n","Epoch 17: train_loss=0.452, validation_accuracy=0.4478\n","Epoch 18: train_loss=0.452, validation_accuracy=0.4585\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:05,412] Trial 13 finished with value: 0.4777 and parameters: {'hidden_dim': 22, 'activation_func': 'Sigmoid', 'lr': 3.651741272548376e-05, 'momentum': 0.65625}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:05,412] The parameter 'activation_func' in trial#14 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.4702\n","Epoch 20: train_loss=0.452, validation_accuracy=0.4777\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2864\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3512\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3572\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3499\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3536\n","Epoch 6: train_loss=0.452, validation_accuracy=0.3700\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5211\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5627\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6322\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6150\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6433\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6481\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3750\n","Epoch 14: train_loss=0.452, validation_accuracy=0.4320\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4425\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4693\n","Epoch 17: train_loss=0.452, validation_accuracy=0.5268\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5736\n","Epoch 19: train_loss=0.452, validation_accuracy=0.5775\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:07,175] Trial 14 finished with value: 0.5733 and parameters: {'hidden_dim': 43, 'activation_func': 'ELU', 'lr': 0.0011547819846894588, 'momentum': 0.90625}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:07,175] The parameter 'activation_func' in trial#15 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.5733\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1168\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1820\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2451\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3191\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4035\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4693\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5122\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5445\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5792\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6067\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6347\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6577\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6766\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6904\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7020\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7117\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7204\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:08,853] Trial 15 finished with value: 0.7443 and parameters: {'hidden_dim': 33, 'activation_func': 'Sigmoid', 'lr': 0.00020535250264571456, 'momentum': 0.53125}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:08,854] The parameter 'activation_func' in trial#16 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.7294\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7369\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7443\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6985\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7870\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8229\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8302\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8395\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8552\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8540\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8550\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8636\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8686\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8673\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8666\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8713\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8693\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8654\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8719\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:10,171] Trial 16 finished with value: 0.869 and parameters: {'hidden_dim': 12, 'activation_func': 'Sigmoid', 'lr': 0.0064938163157621165, 'momentum': 0.78125}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:10,172] The parameter 'activation_func' in trial#17 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.452, validation_accuracy=0.8691\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8755\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8711\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8690\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3546\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5349\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6035\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6309\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6541\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6800\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6970\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7075\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7240\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7320\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7458\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7543\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7624\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7675\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7806\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7871\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7819\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7928\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7974\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:11,701] Trial 17 finished with value: 0.7995 and parameters: {'hidden_dim': 13, 'activation_func': 'Tanh', 'lr': 0.0002548296747979348, 'momentum': 0.734375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:11,702] The parameter 'activation_func' in trial#18 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.7995\n","Epoch 1: train_loss=0.452, validation_accuracy=0.0982\n","Epoch 2: train_loss=0.452, validation_accuracy=0.0982\n","Epoch 3: train_loss=0.452, validation_accuracy=0.0958\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1010\n","Epoch 5: train_loss=0.452, validation_accuracy=0.0958\n","Epoch 6: train_loss=0.452, validation_accuracy=0.0982\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1010\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1009\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1032\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.0982\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:13,492] Trial 18 finished with value: 0.1135 and parameters: {'hidden_dim': 34, 'activation_func': 'ELU', 'lr': 0.008058421877614822, 'momentum': 0.984375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:13,492] The parameter 'activation_func' in trial#19 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2051\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2748\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3347\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3826\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4280\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4622\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4908\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5144\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5386\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5586\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5805\n","Epoch 12: train_loss=0.452, validation_accuracy=0.5976\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6115\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6276\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6390\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6513\n","Epoch 17: train_loss=0.452, validation_accuracy=0.6653\n","Epoch 18: train_loss=0.452, validation_accuracy=0.6784\n","Epoch 19: train_loss=0.452, validation_accuracy=0.6856\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:15,346] Trial 19 finished with value: 0.6937 and parameters: {'hidden_dim': 44, 'activation_func': 'Tanh', 'lr': 4.531583637600821e-05, 'momentum': 0.609375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:15,347] The parameter 'activation_func' in trial#20 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.6937\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3033\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3422\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3198\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4519\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4900\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5320\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4990\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5885\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5328\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4837\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5341\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6228\n","Epoch 13: train_loss=0.452, validation_accuracy=0.5620\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5772\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6531\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2562\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2553\n","Epoch 18: train_loss=0.452, validation_accuracy=0.3723\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:17,028] Trial 20 finished with value: 0.4638 and parameters: {'hidden_dim': 24, 'activation_func': 'ELU', 'lr': 0.0014330125702369636, 'momentum': 0.859375}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:17,028] The parameter 'activation_func' in trial#21 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.3987\n","Epoch 20: train_loss=0.452, validation_accuracy=0.4638\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2494\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3398\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4108\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4720\n","Epoch 5: train_loss=0.452, validation_accuracy=0.5142\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5503\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5796\n","Epoch 8: train_loss=0.452, validation_accuracy=0.6033\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6171\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6310\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6443\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6562\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6705\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6796\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6896\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6991\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7081\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7147\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7251\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:18,620] Trial 21 finished with value: 0.732 and parameters: {'hidden_dim': 29, 'activation_func': 'Tanh', 'lr': 1.9109529749704416e-05, 'momentum': 0.921875}. Best is trial 6 with value: 0.9304.\n","[W 2023-03-07 16:27:18,621] The parameter 'activation_func' in trial#22 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.7320\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7887\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8580\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8848\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8978\n","Epoch 5: train_loss=0.452, validation_accuracy=0.9047\n","Epoch 6: train_loss=0.452, validation_accuracy=0.9115\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9147\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9183\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9215\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9227\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9251\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9257\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9273\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9298\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9309\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9315\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9305\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9340\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:20,486] Trial 22 finished with value: 0.936 and parameters: {'hidden_dim': 49, 'activation_func': 'ReLU', 'lr': 0.0006042963902381332, 'momentum': 0.671875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:20,487] The parameter 'activation_func' in trial#23 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9348\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9360\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2085\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2566\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3114\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3780\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4372\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4938\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5552\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5996\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6307\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6541\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6735\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6879\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6990\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7097\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7220\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7290\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7362\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7425\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7481\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:22,469] Trial 23 finished with value: 0.7545 and parameters: {'hidden_dim': 39, 'activation_func': 'Sigmoid', 'lr': 0.00010746078283213182, 'momentum': 0.796875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:22,470] The parameter 'activation_func' in trial#24 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.7545\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2824\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2755\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2808\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2836\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2898\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2859\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2915\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2892\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2900\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2916\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2881\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2936\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3154\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2917\n","Epoch 15: train_loss=0.452, validation_accuracy=0.3018\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2783\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2123\n","Epoch 18: train_loss=0.452, validation_accuracy=0.3466\n","Epoch 19: train_loss=0.452, validation_accuracy=0.3210\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:23,842] Trial 24 finished with value: 0.3245 and parameters: {'hidden_dim': 18, 'activation_func': 'ELU', 'lr': 0.003398208328942561, 'momentum': 0.546875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:23,842] The parameter 'activation_func' in trial#25 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.3245\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1476\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1670\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1860\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2098\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2235\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2393\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2540\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2852\n","Epoch 9: train_loss=0.452, validation_accuracy=0.3201\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3471\n","Epoch 11: train_loss=0.452, validation_accuracy=0.3682\n","Epoch 12: train_loss=0.452, validation_accuracy=0.3957\n","Epoch 13: train_loss=0.452, validation_accuracy=0.4146\n","Epoch 14: train_loss=0.452, validation_accuracy=0.4371\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4578\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4713\n","Epoch 17: train_loss=0.452, validation_accuracy=0.4843\n","Epoch 18: train_loss=0.452, validation_accuracy=0.4933\n","Epoch 19: train_loss=0.452, validation_accuracy=0.5025\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:25,005] Trial 25 finished with value: 0.5095 and parameters: {'hidden_dim': 16, 'activation_func': 'ReLU', 'lr': 2.942727176209284e-05, 'momentum': 0.765625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:25,005] The parameter 'activation_func' in trial#26 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.5095\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4418\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5992\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6608\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6922\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7271\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7525\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7716\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7823\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7979\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8108\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8228\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8301\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8378\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8453\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8503\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8557\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8576\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8629\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8647\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:26,737] Trial 26 finished with value: 0.8672 and parameters: {'hidden_dim': 36, 'activation_func': 'Sigmoid', 'lr': 0.0009305720409296995, 'momentum': 0.515625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:26,738] The parameter 'activation_func' in trial#27 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8672\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5845\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7400\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7918\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8139\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8321\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8462\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8585\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8627\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8698\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8731\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8781\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8809\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8842\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8869\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8888\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8900\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8919\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:28,389] Trial 27 finished with value: 0.8959 and parameters: {'hidden_dim': 47, 'activation_func': 'Tanh', 'lr': 0.00016548170999431823, 'momentum': 0.890625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:28,389] The parameter 'activation_func' in trial#28 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8929\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8933\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8959\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4841\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3668\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2123\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2124\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2140\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2147\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2139\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2156\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2142\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2156\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2151\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2199\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2205\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2244\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2231\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2182\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:29,672] Trial 28 finished with value: 0.2157 and parameters: {'hidden_dim': 26, 'activation_func': 'ReLU', 'lr': 0.005232991146814949, 'momentum': 0.640625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:29,672] The parameter 'activation_func' in trial#29 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.452, validation_accuracy=0.2128\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2135\n","Epoch 19: train_loss=0.452, validation_accuracy=0.2149\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2157\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2748\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3485\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4190\n","Epoch 4: train_loss=0.452, validation_accuracy=0.5119\n","Epoch 5: train_loss=0.452, validation_accuracy=0.5876\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6327\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6742\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7326\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7666\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7900\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8057\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8152\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8215\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8299\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8378\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8435\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8502\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8552\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:31,519] Trial 29 finished with value: 0.8611 and parameters: {'hidden_dim': 21, 'activation_func': 'ELU', 'lr': 6.978305848598668e-05, 'momentum': 0.578125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:31,520] The parameter 'activation_func' in trial#30 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8588\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8611\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:33,546] Trial 30 finished with value: 0.1135 and parameters: {'hidden_dim': 42, 'activation_func': 'ELU', 'lr': 0.002206734069084591, 'momentum': 0.828125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:33,547] The parameter 'activation_func' in trial#31 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3966\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4179\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4382\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4577\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4802\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5028\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5299\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5576\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5882\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6173\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6461\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6695\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6907\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7035\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7176\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7288\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7372\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7470\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:35,470] Trial 31 finished with value: 0.7597 and parameters: {'hidden_dim': 31, 'activation_func': 'ELU', 'lr': 1.2409377607517204e-05, 'momentum': 0.703125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:35,471] The parameter 'activation_func' in trial#32 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.7527\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7597\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5691\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6867\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7573\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7916\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8079\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8213\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8302\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8398\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8374\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8516\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8463\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8528\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8521\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8439\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8609\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8597\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8571\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8602\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:36,834] Trial 32 finished with value: 0.8651 and parameters: {'hidden_dim': 11, 'activation_func': 'Tanh', 'lr': 0.0003924189758484538, 'momentum': 0.953125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:36,835] The parameter 'activation_func' in trial#33 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8654\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8651\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1096\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1593\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2311\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2588\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2752\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2835\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2886\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2909\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2924\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2928\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2934\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2947\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2953\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2971\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2962\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2970\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2972\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2981\n","Epoch 19: train_loss=0.452, validation_accuracy=0.2974\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:38,535] Trial 33 finished with value: 0.2977 and parameters: {'hidden_dim': 11, 'activation_func': 'ReLU', 'lr': 6.264335366568851e-05, 'momentum': 0.8515625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:38,535] The parameter 'activation_func' in trial#34 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.2977\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6011\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6889\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7646\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8276\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8187\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8270\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8558\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8673\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8689\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8768\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8812\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8770\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8823\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8809\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8775\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8798\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8755\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:40,156] Trial 34 finished with value: 0.8851 and parameters: {'hidden_dim': 32, 'activation_func': 'ELU', 'lr': 0.001980956778550339, 'momentum': 0.6015625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:40,157] The parameter 'activation_func' in trial#35 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8864\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8829\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8851\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2095\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2693\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3335\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4024\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4806\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5404\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5852\n","Epoch 8: train_loss=0.452, validation_accuracy=0.6219\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6489\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6752\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6945\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7091\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7216\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7306\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7405\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7491\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7546\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7639\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:42,053] Trial 35 finished with value: 0.7772 and parameters: {'hidden_dim': 42, 'activation_func': 'Sigmoid', 'lr': 1.1139738599948017e-05, 'momentum': 0.9765625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:42,054] The parameter 'activation_func' in trial#36 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.7694\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7772\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4500\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6202\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6736\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7079\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7330\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7501\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7765\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7892\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8035\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8142\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8224\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8314\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8359\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8370\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8444\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8479\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8509\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8553\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:43,664] Trial 36 finished with value: 0.8599 and parameters: {'hidden_dim': 22, 'activation_func': 'Tanh', 'lr': 0.0003522694651473102, 'momentum': 0.7265625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:43,665] The parameter 'activation_func' in trial#37 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8560\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8599\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5349\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5796\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5961\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6155\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6391\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6657\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6853\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7015\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7165\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7292\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7368\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7458\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7539\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7626\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7705\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7752\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7810\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:45,623] Trial 37 finished with value: 0.7977 and parameters: {'hidden_dim': 27, 'activation_func': 'ELU', 'lr': 2.6416483203860905e-05, 'momentum': 0.5390625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:45,624] The parameter 'activation_func' in trial#38 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.7882\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7930\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7977\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8055\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8733\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8932\n","Epoch 4: train_loss=0.452, validation_accuracy=0.9015\n","Epoch 5: train_loss=0.452, validation_accuracy=0.9077\n","Epoch 6: train_loss=0.452, validation_accuracy=0.9121\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9138\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9188\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9192\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9202\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9213\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9241\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9253\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9290\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9293\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9295\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9303\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9340\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:47,168] Trial 38 finished with value: 0.9344 and parameters: {'hidden_dim': 47, 'activation_func': 'ReLU', 'lr': 0.0008353625469578262, 'momentum': 0.7890625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:47,168] The parameter 'activation_func' in trial#39 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9341\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9344\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1414\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2089\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2967\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3741\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4441\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4925\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5283\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5537\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5756\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5983\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6163\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6354\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6534\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6669\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6793\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6905\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7001\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7084\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7176\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:48,914] Trial 39 finished with value: 0.7277 and parameters: {'hidden_dim': 37, 'activation_func': 'Sigmoid', 'lr': 0.0001485508017172774, 'momentum': 0.6640625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:48,915] The parameter 'activation_func' in trial#40 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.7277\n","Epoch 1: train_loss=0.452, validation_accuracy=0.0974\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1032\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 4: train_loss=0.452, validation_accuracy=0.0958\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1010\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:50,458] Trial 40 finished with value: 0.1135 and parameters: {'hidden_dim': 17, 'activation_func': 'ELU', 'lr': 0.004697588816706492, 'momentum': 0.9140625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:50,459] The parameter 'activation_func' in trial#41 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1072\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1149\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1226\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1291\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1353\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1429\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1474\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1541\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1610\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1674\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1763\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1834\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1904\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1968\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2037\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2101\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2173\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:52,123] Trial 41 finished with value: 0.2388 and parameters: {'hidden_dim': 19, 'activation_func': 'Sigmoid', 'lr': 1.715437896342878e-05, 'momentum': 0.6328125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:52,123] The parameter 'activation_func' in trial#42 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.2232\n","Epoch 19: train_loss=0.452, validation_accuracy=0.2305\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2388\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6380\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7482\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7915\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8218\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8407\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8538\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8637\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8718\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8775\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8804\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8841\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8892\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8901\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8914\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8933\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8953\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8973\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8978\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:53,837] Trial 42 finished with value: 0.8994 and parameters: {'hidden_dim': 40, 'activation_func': 'Sigmoid', 'lr': 0.0005424690937011326, 'momentum': 0.8828125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:53,837] The parameter 'activation_func' in trial#43 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8990\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8994\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1185\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1645\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2174\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2742\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3170\n","Epoch 6: train_loss=0.452, validation_accuracy=0.3558\n","Epoch 7: train_loss=0.452, validation_accuracy=0.3858\n","Epoch 8: train_loss=0.452, validation_accuracy=0.4171\n","Epoch 9: train_loss=0.452, validation_accuracy=0.4455\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4698\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4900\n","Epoch 12: train_loss=0.452, validation_accuracy=0.5111\n","Epoch 13: train_loss=0.452, validation_accuracy=0.5360\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5531\n","Epoch 15: train_loss=0.452, validation_accuracy=0.5740\n","Epoch 16: train_loss=0.452, validation_accuracy=0.5925\n","Epoch 17: train_loss=0.452, validation_accuracy=0.6098\n","Epoch 18: train_loss=0.452, validation_accuracy=0.6262\n","Epoch 19: train_loss=0.452, validation_accuracy=0.6375\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:55,692] Trial 43 finished with value: 0.6495 and parameters: {'hidden_dim': 50, 'activation_func': 'Sigmoid', 'lr': 9.646616199112003e-05, 'momentum': 0.5078125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:55,692] The parameter 'activation_func' in trial#44 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.6495\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8187\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8660\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8806\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8875\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8940\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8940\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9009\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9055\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9040\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9068\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9071\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9113\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9125\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9065\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9129\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9114\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9155\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9088\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9175\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:57,013] Trial 44 finished with value: 0.9139 and parameters: {'hidden_dim': 29, 'activation_func': 'Tanh', 'lr': 0.003050527890267026, 'momentum': 0.7578125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:57,013] The parameter 'activation_func' in trial#45 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9139\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5344\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6502\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7079\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7452\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7730\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7938\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8120\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8258\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8367\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8429\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8518\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8574\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8615\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8672\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8697\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8744\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8769\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:27:58,767] Trial 45 finished with value: 0.8832 and parameters: {'hidden_dim': 24, 'activation_func': 'Sigmoid', 'lr': 0.0002287573200318398, 'momentum': 0.9453125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:27:58,768] The parameter 'activation_func' in trial#46 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8815\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8824\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8832\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2768\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2739\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2863\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2875\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2937\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2906\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2959\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2996\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2161\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2128\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2165\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2127\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2129\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2140\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2161\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2883\n","Epoch 17: train_loss=0.452, validation_accuracy=0.3094\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2125\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:00,233] Trial 46 finished with value: 0.2102 and parameters: {'hidden_dim': 45, 'activation_func': 'ReLU', 'lr': 0.007233941627366748, 'momentum': 0.6953125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:00,234] The parameter 'activation_func' in trial#47 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.2064\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2102\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5698\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6640\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7234\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7691\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7913\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8052\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8176\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8291\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8347\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8411\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8467\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8519\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8566\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8595\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8634\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8665\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8701\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8709\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8745\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:02,353] Trial 47 finished with value: 0.8777 and parameters: {'hidden_dim': 34, 'activation_func': 'ELU', 'lr': 4.0679443210830444e-05, 'momentum': 0.8203125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:02,354] The parameter 'activation_func' in trial#48 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8777\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4581\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5994\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6690\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7185\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7469\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7641\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7722\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7818\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7842\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8016\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8085\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8145\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8221\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8257\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8284\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8321\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8362\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:03,925] Trial 48 finished with value: 0.8463 and parameters: {'hidden_dim': 14, 'activation_func': 'Sigmoid', 'lr': 0.0012863969449369746, 'momentum': 0.5703125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:03,926] The parameter 'activation_func' in trial#49 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8405\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8413\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8463\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2034\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2873\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2950\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3005\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3321\n","Epoch 6: train_loss=0.452, validation_accuracy=0.3584\n","Epoch 7: train_loss=0.452, validation_accuracy=0.3732\n","Epoch 8: train_loss=0.452, validation_accuracy=0.4615\n","Epoch 9: train_loss=0.452, validation_accuracy=0.4712\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4856\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4937\n","Epoch 12: train_loss=0.452, validation_accuracy=0.5015\n","Epoch 13: train_loss=0.452, validation_accuracy=0.5063\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5156\n","Epoch 15: train_loss=0.452, validation_accuracy=0.5214\n","Epoch 16: train_loss=0.452, validation_accuracy=0.5365\n","Epoch 17: train_loss=0.452, validation_accuracy=0.5527\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5766\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:05,496] Trial 49 finished with value: 0.6099 and parameters: {'hidden_dim': 13, 'activation_func': 'ELU', 'lr': 5.048065716667472e-05, 'momentum': 0.8984375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:05,496] The parameter 'activation_func' in trial#50 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.5976\n","Epoch 20: train_loss=0.452, validation_accuracy=0.6099\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6091\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7316\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7780\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8120\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8270\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8445\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8550\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8642\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8676\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8727\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8754\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8774\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8820\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8850\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8871\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8885\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8923\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:07,280] Trial 50 finished with value: 0.8965 and parameters: {'hidden_dim': 33, 'activation_func': 'Sigmoid', 'lr': 0.0015963385442879423, 'momentum': 0.6484375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:07,281] The parameter 'activation_func' in trial#51 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8943\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8959\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8965\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7073\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8278\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8554\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8757\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8827\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8925\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8953\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9001\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9056\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9105\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9106\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9144\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9157\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9195\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9205\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9220\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9240\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9253\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:08,778] Trial 51 finished with value: 0.9266 and parameters: {'hidden_dim': 43, 'activation_func': 'ReLU', 'lr': 0.0002838735964758755, 'momentum': 0.7734375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:08,779] The parameter 'activation_func' in trial#52 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9271\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9266\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8363\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8705\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8773\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8844\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8928\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8896\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8898\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8974\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9023\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8955\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9052\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9026\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9063\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9040\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8999\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9084\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:10,259] Trial 52 finished with value: 0.9088 and parameters: {'hidden_dim': 23, 'activation_func': 'Tanh', 'lr': 0.008976871324473142, 'momentum': 0.5234375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:10,260] The parameter 'activation_func' in trial#53 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.452, validation_accuracy=0.9093\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9091\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9130\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9088\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3531\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5168\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6556\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7348\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7873\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8168\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8369\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8470\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8573\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8636\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8708\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8749\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8774\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8807\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8865\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8863\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8899\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8927\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:12,162] Trial 53 finished with value: 0.8954 and parameters: {'hidden_dim': 28, 'activation_func': 'ELU', 'lr': 0.00011970850304957301, 'momentum': 0.7109375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:12,162] The parameter 'activation_func' in trial#54 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8931\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8954\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8685\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8811\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8855\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8908\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8891\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8959\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8966\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9039\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8957\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9078\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8989\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9024\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9031\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9074\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8965\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9044\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9019\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9053\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9018\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:13,679] Trial 54 finished with value: 0.9056 and parameters: {'hidden_dim': 49, 'activation_func': 'Tanh', 'lr': 0.00378551524925863, 'momentum': 0.9609375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:13,680] The parameter 'activation_func' in trial#55 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9056\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5216\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5826\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6120\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6323\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6533\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6716\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6921\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7093\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7217\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7320\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7440\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7524\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7613\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7667\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7776\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7858\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7897\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:15,045] Trial 55 finished with value: 0.8036 and parameters: {'hidden_dim': 38, 'activation_func': 'ReLU', 'lr': 2.128751661796373e-05, 'momentum': 0.5859375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:15,046] The parameter 'activation_func' in trial#56 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.7941\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7995\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8036\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6963\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7753\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8093\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8317\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8396\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8504\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8614\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8639\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8714\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8749\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8760\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8815\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8849\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8874\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8868\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8919\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8915\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8937\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8883\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:16,333] Trial 56 finished with value: 0.8957 and parameters: {'hidden_dim': 18, 'activation_func': 'Tanh', 'lr': 0.0006731703824144984, 'momentum': 0.8359375}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:16,334] The parameter 'activation_func' in trial#57 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8957\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3839\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5212\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6091\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6753\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7193\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7379\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7481\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7539\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7628\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7676\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7770\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7798\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7865\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7907\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7910\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7937\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7946\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7944\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7963\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:17,504] Trial 57 finished with value: 0.7965 and parameters: {'hidden_dim': 15, 'activation_func': 'ReLU', 'lr': 0.00018434229924091107, 'momentum': 0.6171875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:17,504] The parameter 'activation_func' in trial#58 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.7965\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2049\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2438\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2308\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2441\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2542\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2712\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2645\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2124\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2126\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2137\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2141\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2126\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2136\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2113\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2090\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2084\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2110\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:18,850] Trial 58 finished with value: 0.2139 and parameters: {'hidden_dim': 36, 'activation_func': 'ReLU', 'lr': 0.005829415347136074, 'momentum': 0.8671875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:18,850] The parameter 'activation_func' in trial#59 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.2121\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2139\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5712\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6599\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7158\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7508\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7774\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7992\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8128\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8240\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8304\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8364\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8425\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8474\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8505\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8541\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8583\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8608\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8642\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8678\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8701\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:21,002] Trial 59 finished with value: 0.8712 and parameters: {'hidden_dim': 46, 'activation_func': 'ELU', 'lr': 3.278121151393459e-05, 'momentum': 0.7421875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:21,003] The parameter 'activation_func' in trial#60 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8712\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7402\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8383\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8682\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8829\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8893\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8941\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8998\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8995\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8943\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8981\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8930\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9036\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9061\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8949\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9105\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9074\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9110\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:22,426] Trial 60 finished with value: 0.9083 and parameters: {'hidden_dim': 26, 'activation_func': 'Sigmoid', 'lr': 0.001036632928437698, 'momentum': 0.9921875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:22,426] The parameter 'activation_func' in trial#61 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.9103\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9075\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9083\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2664\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3171\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3449\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3613\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3731\n","Epoch 6: train_loss=0.452, validation_accuracy=0.3818\n","Epoch 7: train_loss=0.452, validation_accuracy=0.3939\n","Epoch 8: train_loss=0.452, validation_accuracy=0.4028\n","Epoch 9: train_loss=0.452, validation_accuracy=0.4136\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4270\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4451\n","Epoch 12: train_loss=0.452, validation_accuracy=0.4694\n","Epoch 13: train_loss=0.452, validation_accuracy=0.4903\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5084\n","Epoch 15: train_loss=0.452, validation_accuracy=0.5227\n","Epoch 16: train_loss=0.452, validation_accuracy=0.5358\n","Epoch 17: train_loss=0.452, validation_accuracy=0.5502\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5608\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:23,954] Trial 61 finished with value: 0.5794 and parameters: {'hidden_dim': 20, 'activation_func': 'ELU', 'lr': 1.3823722273578999e-05, 'momentum': 0.8046875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:23,955] The parameter 'activation_func' in trial#62 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.5713\n","Epoch 20: train_loss=0.452, validation_accuracy=0.5794\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5229\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6540\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7190\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7584\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7805\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8055\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8151\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8269\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8346\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8382\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8464\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8504\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8550\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8576\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8622\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8647\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8655\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8679\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8720\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:25,466] Trial 62 finished with value: 0.8732 and parameters: {'hidden_dim': 41, 'activation_func': 'Tanh', 'lr': 0.000437144481261109, 'momentum': 0.5546875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:25,467] The parameter 'activation_func' in trial#63 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8732\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2202\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3848\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4988\n","Epoch 4: train_loss=0.452, validation_accuracy=0.5889\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6549\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7007\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7331\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7533\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7677\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7770\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7874\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7957\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8030\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8085\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8124\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8176\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8220\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:26,974] Trial 63 finished with value: 0.8323 and parameters: {'hidden_dim': 31, 'activation_func': 'Sigmoid', 'lr': 7.77365030238776e-05, 'momentum': 0.9296875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:26,975] The parameter 'activation_func' in trial#64 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8243\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8281\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8323\n","Epoch 1: train_loss=0.452, validation_accuracy=0.0980\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1902\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1896\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1928\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1950\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1950\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2163\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2165\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2296\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2206\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2151\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2502\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2178\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2205\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1774\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2182\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2463\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2175\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:28,183] Trial 64 finished with value: 0.1882 and parameters: {'hidden_dim': 10, 'activation_func': 'ReLU', 'lr': 0.0024582440689201977, 'momentum': 0.6796875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:28,183] The parameter 'activation_func' in trial#65 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.2156\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1882\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2536\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4017\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4647\n","Epoch 4: train_loss=0.452, validation_accuracy=0.5307\n","Epoch 5: train_loss=0.452, validation_accuracy=0.5547\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5499\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5696\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5830\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6284\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6439\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6482\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6664\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6744\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6822\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6890\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6950\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7052\n","Epoch 18: train_loss=0.452, validation_accuracy=0.7112\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:29,364] Trial 65 finished with value: 0.7202 and parameters: {'hidden_dim': 10, 'activation_func': 'Sigmoid', 'lr': 0.00015678788438269704, 'momentum': 0.91015625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:29,365] The parameter 'activation_func' in trial#66 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.7177\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7202\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1009\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1009\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1009\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1011\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1013\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1934\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2041\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2105\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2912\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3065\n","Epoch 11: train_loss=0.452, validation_accuracy=0.2150\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2145\n","Epoch 13: train_loss=0.452, validation_accuracy=0.2039\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2099\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2137\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2071\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2091\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2080\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:30,596] Trial 66 finished with value: 0.2179 and parameters: {'hidden_dim': 31, 'activation_func': 'ReLU', 'lr': 0.00495806824168466, 'momentum': 0.66015625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:30,596] The parameter 'activation_func' in trial#67 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.2204\n","Epoch 20: train_loss=0.452, validation_accuracy=0.2179\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6730\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7203\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7454\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7659\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7809\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7949\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8059\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8132\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8172\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8234\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8279\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8343\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8407\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8436\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8487\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8529\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8563\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8594\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8629\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:32,649] Trial 67 finished with value: 0.8642 and parameters: {'hidden_dim': 41, 'activation_func': 'ELU', 'lr': 2.788126665413133e-05, 'momentum': 0.78515625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:32,650] The parameter 'activation_func' in trial#68 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8642\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2667\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2655\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5253\n","Epoch 4: train_loss=0.452, validation_accuracy=0.5965\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6252\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6907\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6955\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7004\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7262\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7669\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7820\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8004\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8141\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8257\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8411\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8430\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8486\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:34,068] Trial 68 finished with value: 0.856 and parameters: {'hidden_dim': 21, 'activation_func': 'ELU', 'lr': 0.0008816830667755708, 'momentum': 0.53515625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:34,068] The parameter 'activation_func' in trial#69 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8505\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8519\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8560\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2820\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3235\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3610\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3990\n","Epoch 5: train_loss=0.452, validation_accuracy=0.4358\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4684\n","Epoch 7: train_loss=0.452, validation_accuracy=0.5005\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5265\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5471\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5679\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5905\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6188\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6325\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6447\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6563\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6680\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:35,297] Trial 69 finished with value: 0.7056 and parameters: {'hidden_dim': 26, 'activation_func': 'ReLU', 'lr': 1.175743265920711e-05, 'momentum': 0.72265625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:35,298] The parameter 'activation_func' in trial#70 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.452, validation_accuracy=0.6787\n","Epoch 18: train_loss=0.452, validation_accuracy=0.6870\n","Epoch 19: train_loss=0.452, validation_accuracy=0.6960\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7056\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7094\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8185\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8601\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8780\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8897\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8946\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8991\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9027\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9080\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9096\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9118\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9150\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9170\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9190\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9188\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9194\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9207\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:37,425] Trial 70 finished with value: 0.9232 and parameters: {'hidden_dim': 46, 'activation_func': 'Sigmoid', 'lr': 0.0003718026663914474, 'momentum': 0.97265625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:37,426] The parameter 'activation_func' in trial#71 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9239\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9232\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1048\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1462\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1853\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2227\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2538\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2835\n","Epoch 7: train_loss=0.452, validation_accuracy=0.3127\n","Epoch 8: train_loss=0.452, validation_accuracy=0.3383\n","Epoch 9: train_loss=0.452, validation_accuracy=0.3653\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3927\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4216\n","Epoch 12: train_loss=0.452, validation_accuracy=0.4446\n","Epoch 13: train_loss=0.452, validation_accuracy=0.4601\n","Epoch 14: train_loss=0.452, validation_accuracy=0.4778\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4903\n","Epoch 16: train_loss=0.452, validation_accuracy=0.5045\n","Epoch 17: train_loss=0.452, validation_accuracy=0.5175\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5312\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:39,113] Trial 71 finished with value: 0.5532 and parameters: {'hidden_dim': 36, 'activation_func': 'Sigmoid', 'lr': 6.611690262414816e-05, 'momentum': 0.59765625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:39,113] The parameter 'activation_func' in trial#72 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.5412\n","Epoch 20: train_loss=0.452, validation_accuracy=0.5532\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1774\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1793\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2145\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2470\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2579\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2890\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2935\n","Epoch 8: train_loss=0.452, validation_accuracy=0.2909\n","Epoch 9: train_loss=0.452, validation_accuracy=0.2689\n","Epoch 10: train_loss=0.452, validation_accuracy=0.2828\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1948\n","Epoch 12: train_loss=0.452, validation_accuracy=0.2904\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3484\n","Epoch 14: train_loss=0.452, validation_accuracy=0.3060\n","Epoch 15: train_loss=0.452, validation_accuracy=0.3020\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2929\n","Epoch 17: train_loss=0.452, validation_accuracy=0.4240\n","Epoch 18: train_loss=0.452, validation_accuracy=0.3084\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:40,314] Trial 72 finished with value: 0.3179 and parameters: {'hidden_dim': 16, 'activation_func': 'ReLU', 'lr': 0.00209080004127872, 'momentum': 0.84765625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:40,315] The parameter 'activation_func' in trial#73 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.3194\n","Epoch 20: train_loss=0.452, validation_accuracy=0.3179\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1989\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2236\n","Epoch 3: train_loss=0.452, validation_accuracy=0.2500\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3052\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3291\n","Epoch 6: train_loss=0.452, validation_accuracy=0.3628\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4022\n","Epoch 8: train_loss=0.452, validation_accuracy=0.4364\n","Epoch 9: train_loss=0.452, validation_accuracy=0.4615\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4776\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4899\n","Epoch 12: train_loss=0.452, validation_accuracy=0.4984\n","Epoch 13: train_loss=0.452, validation_accuracy=0.5073\n","Epoch 14: train_loss=0.452, validation_accuracy=0.5125\n","Epoch 15: train_loss=0.452, validation_accuracy=0.5172\n","Epoch 16: train_loss=0.452, validation_accuracy=0.5233\n","Epoch 17: train_loss=0.452, validation_accuracy=0.5262\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5305\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:41,518] Trial 73 finished with value: 0.5343 and parameters: {'hidden_dim': 18, 'activation_func': 'ReLU', 'lr': 4.293510210083482e-05, 'momentum': 0.56640625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:41,518] The parameter 'activation_func' in trial#74 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.5319\n","Epoch 20: train_loss=0.452, validation_accuracy=0.5343\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4113\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6429\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7877\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8291\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8465\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8686\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8736\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8849\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8843\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8954\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8953\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8976\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9007\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8909\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8980\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9073\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9062\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9085\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9068\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:42,878] Trial 74 finished with value: 0.9105 and parameters: {'hidden_dim': 39, 'activation_func': 'ReLU', 'lr': 0.0013577271421051837, 'momentum': 0.81640625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:42,878] The parameter 'activation_func' in trial#75 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9105\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2483\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4541\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5662\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6225\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6604\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6897\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7106\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7249\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7377\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7471\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7556\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7635\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7702\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7780\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7846\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7913\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7974\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:44,729] Trial 75 finished with value: 0.8132 and parameters: {'hidden_dim': 49, 'activation_func': 'Sigmoid', 'lr': 0.00024144182212566391, 'momentum': 0.69140625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:44,729] The parameter 'activation_func' in trial#76 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8041\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8081\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8132\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1033\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1011\n","Epoch 5: train_loss=0.452, validation_accuracy=0.0981\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1136\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:46,433] Trial 76 finished with value: 0.1136 and parameters: {'hidden_dim': 28, 'activation_func': 'ELU', 'lr': 0.007635060803383351, 'momentum': 0.94140625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:46,434] The parameter 'activation_func' in trial#77 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 19: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1136\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4792\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5936\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6780\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7262\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7578\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7793\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8021\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8172\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8291\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8378\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8472\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8527\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8585\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8624\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8679\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8716\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8757\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8797\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:48,150] Trial 77 finished with value: 0.8852 and parameters: {'hidden_dim': 23, 'activation_func': 'ELU', 'lr': 0.00010181517217181818, 'momentum': 0.75390625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:48,151] The parameter 'activation_func' in trial#78 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8822\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8852\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6944\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7851\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8230\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8419\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8582\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8680\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8758\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8839\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8890\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8913\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8944\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8983\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8991\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9009\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9018\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9016\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9048\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9076\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9085\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:50,146] Trial 78 finished with value: 0.909 and parameters: {'hidden_dim': 44, 'activation_func': 'Sigmoid', 'lr': 0.0032196784442513815, 'momentum': 0.50390625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:50,147] The parameter 'activation_func' in trial#79 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9090\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3788\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4652\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5253\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6300\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6742\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7089\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7380\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7575\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7725\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7859\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7967\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8093\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8161\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8244\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8335\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8403\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8445\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8484\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:51,593] Trial 79 finished with value: 0.8576 and parameters: {'hidden_dim': 34, 'activation_func': 'ReLU', 'lr': 1.8105582430271218e-05, 'momentum': 0.87890625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:51,594] The parameter 'activation_func' in trial#80 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8535\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8576\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4152\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4958\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5677\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6478\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6932\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7288\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7663\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7750\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7769\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7971\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7999\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8102\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8158\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8223\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8247\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8298\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8329\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:52,847] Trial 80 finished with value: 0.846 and parameters: {'hidden_dim': 13, 'activation_func': 'Tanh', 'lr': 0.0005725487884358379, 'momentum': 0.62890625}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:52,847] The parameter 'activation_func' in trial#81 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8399\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8432\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8460\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2030\n","Epoch 2: train_loss=0.452, validation_accuracy=0.2907\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3221\n","Epoch 4: train_loss=0.452, validation_accuracy=0.3503\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3866\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4316\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4684\n","Epoch 8: train_loss=0.452, validation_accuracy=0.5013\n","Epoch 9: train_loss=0.452, validation_accuracy=0.5319\n","Epoch 10: train_loss=0.452, validation_accuracy=0.5584\n","Epoch 11: train_loss=0.452, validation_accuracy=0.5789\n","Epoch 12: train_loss=0.452, validation_accuracy=0.5989\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6155\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6284\n","Epoch 15: train_loss=0.452, validation_accuracy=0.6444\n","Epoch 16: train_loss=0.452, validation_accuracy=0.6664\n","Epoch 17: train_loss=0.452, validation_accuracy=0.6805\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:54,019] Trial 81 finished with value: 0.7228 and parameters: {'hidden_dim': 14, 'activation_func': 'ReLU', 'lr': 2.2467900918126424e-05, 'momentum': 0.83203125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:54,020] The parameter 'activation_func' in trial#82 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.6966\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7124\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7228\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5629\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7067\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8194\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8475\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8633\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8760\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8893\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8966\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9004\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9042\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9058\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9066\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9087\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9092\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9114\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9120\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9132\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9125\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:55,928] Trial 82 finished with value: 0.9152 and parameters: {'hidden_dim': 35, 'activation_func': 'ELU', 'lr': 0.0007104974114426786, 'momentum': 0.58203125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:55,929] The parameter 'activation_func' in trial#83 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9162\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9152\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7108\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8038\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8372\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8559\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8685\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8736\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8788\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8828\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8862\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8890\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8923\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8956\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8993\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8990\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9022\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9010\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9040\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9052\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:57,673] Trial 83 finished with value: 0.9078 and parameters: {'hidden_dim': 45, 'activation_func': 'Tanh', 'lr': 0.00012634629176544695, 'momentum': 0.95703125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:57,674] The parameter 'activation_func' in trial#84 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9068\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9078\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:28:59,122] Trial 84 finished with value: 0.1135 and parameters: {'hidden_dim': 25, 'activation_func': 'ELU', 'lr': 0.003995420558949889, 'momentum': 0.70703125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:28:59,123] The parameter 'activation_func' in trial#85 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1925\n","Epoch 2: train_loss=0.452, validation_accuracy=0.3065\n","Epoch 3: train_loss=0.452, validation_accuracy=0.3775\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4448\n","Epoch 5: train_loss=0.452, validation_accuracy=0.5090\n","Epoch 6: train_loss=0.452, validation_accuracy=0.5631\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6090\n","Epoch 8: train_loss=0.452, validation_accuracy=0.6480\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6760\n","Epoch 10: train_loss=0.452, validation_accuracy=0.7035\n","Epoch 11: train_loss=0.452, validation_accuracy=0.7254\n","Epoch 12: train_loss=0.452, validation_accuracy=0.7381\n","Epoch 13: train_loss=0.452, validation_accuracy=0.7533\n","Epoch 14: train_loss=0.452, validation_accuracy=0.7623\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7716\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7777\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7852\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:00,628] Trial 85 finished with value: 0.8032 and parameters: {'hidden_dim': 30, 'activation_func': 'Sigmoid', 'lr': 0.0002996142741004366, 'momentum': 0.51953125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:00,629] The parameter 'activation_func' in trial#86 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.7918\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7993\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8032\n","Epoch 1: train_loss=0.452, validation_accuracy=0.0980\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1009\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1010\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1010\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:02,365] Trial 86 finished with value: 0.1135 and parameters: {'hidden_dim': 50, 'activation_func': 'ELU', 'lr': 0.009474635256553761, 'momentum': 0.76953125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:02,365] The parameter 'activation_func' in trial#87 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6741\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7304\n","Epoch 3: train_loss=0.452, validation_accuracy=0.7648\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7844\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7999\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8247\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8331\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8396\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8446\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8505\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8560\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8594\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8637\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8658\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8686\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8704\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8737\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:04,340] Trial 87 finished with value: 0.8787 and parameters: {'hidden_dim': 40, 'activation_func': 'ELU', 'lr': 5.3279789458656456e-05, 'momentum': 0.64453125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:04,341] The parameter 'activation_func' in trial#88 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8763\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8787\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6965\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7852\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8318\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8487\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8609\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8708\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8750\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8796\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8787\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8845\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8840\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8896\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8919\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8927\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8983\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8953\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8956\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8972\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8985\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:05,733] Trial 88 finished with value: 0.8998 and parameters: {'hidden_dim': 19, 'activation_func': 'Sigmoid', 'lr': 0.0016848548794358386, 'momentum': 0.89453125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:05,734] The parameter 'activation_func' in trial#89 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.8998\n","Epoch 1: train_loss=0.452, validation_accuracy=0.3656\n","Epoch 2: train_loss=0.452, validation_accuracy=0.5301\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5819\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6070\n","Epoch 5: train_loss=0.452, validation_accuracy=0.6308\n","Epoch 6: train_loss=0.452, validation_accuracy=0.6409\n","Epoch 7: train_loss=0.452, validation_accuracy=0.6460\n","Epoch 8: train_loss=0.452, validation_accuracy=0.6517\n","Epoch 9: train_loss=0.452, validation_accuracy=0.6631\n","Epoch 10: train_loss=0.452, validation_accuracy=0.6688\n","Epoch 11: train_loss=0.452, validation_accuracy=0.6726\n","Epoch 12: train_loss=0.452, validation_accuracy=0.6786\n","Epoch 13: train_loss=0.452, validation_accuracy=0.6865\n","Epoch 14: train_loss=0.452, validation_accuracy=0.6974\n","Epoch 15: train_loss=0.452, validation_accuracy=0.7011\n","Epoch 16: train_loss=0.452, validation_accuracy=0.7113\n","Epoch 17: train_loss=0.452, validation_accuracy=0.7281\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:07,222] Trial 89 finished with value: 0.7753 and parameters: {'hidden_dim': 17, 'activation_func': 'ELU', 'lr': 8.204696109024983e-05, 'momentum': 0.67578125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:07,223] The parameter 'activation_func' in trial#90 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.7431\n","Epoch 19: train_loss=0.452, validation_accuracy=0.7620\n","Epoch 20: train_loss=0.452, validation_accuracy=0.7753\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4068\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4100\n","Epoch 3: train_loss=0.452, validation_accuracy=0.4419\n","Epoch 4: train_loss=0.452, validation_accuracy=0.4516\n","Epoch 5: train_loss=0.452, validation_accuracy=0.3739\n","Epoch 6: train_loss=0.452, validation_accuracy=0.4096\n","Epoch 7: train_loss=0.452, validation_accuracy=0.4321\n","Epoch 8: train_loss=0.452, validation_accuracy=0.3437\n","Epoch 9: train_loss=0.452, validation_accuracy=0.4012\n","Epoch 10: train_loss=0.452, validation_accuracy=0.4281\n","Epoch 11: train_loss=0.452, validation_accuracy=0.4431\n","Epoch 12: train_loss=0.452, validation_accuracy=0.4520\n","Epoch 13: train_loss=0.452, validation_accuracy=0.4226\n","Epoch 14: train_loss=0.452, validation_accuracy=0.4407\n","Epoch 15: train_loss=0.452, validation_accuracy=0.4263\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4428\n","Epoch 17: train_loss=0.452, validation_accuracy=0.4734\n","Epoch 18: train_loss=0.452, validation_accuracy=0.5093\n","Epoch 19: train_loss=0.452, validation_accuracy=0.5057\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:08,603] Trial 90 finished with value: 0.5281 and parameters: {'hidden_dim': 37, 'activation_func': 'ReLU', 'lr': 0.0025945527214040172, 'momentum': 0.92578125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:08,604] The parameter 'activation_func' in trial#91 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.5281\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1084\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1110\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1175\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1227\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1284\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1349\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1424\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1515\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1588\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1671\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1770\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1875\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1975\n","Epoch 14: train_loss=0.452, validation_accuracy=0.2085\n","Epoch 15: train_loss=0.452, validation_accuracy=0.2201\n","Epoch 16: train_loss=0.452, validation_accuracy=0.2292\n","Epoch 17: train_loss=0.452, validation_accuracy=0.2370\n","Epoch 18: train_loss=0.452, validation_accuracy=0.2456\n","Epoch 19: train_loss=0.452, validation_accuracy=0.2546\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:10,521] Trial 91 finished with value: 0.2646 and parameters: {'hidden_dim': 48, 'activation_func': 'Sigmoid', 'lr': 1.4590242156305593e-05, 'momentum': 0.55078125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:10,522] The parameter 'activation_func' in trial#92 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.2646\n","Epoch 1: train_loss=0.452, validation_accuracy=0.4013\n","Epoch 2: train_loss=0.452, validation_accuracy=0.6039\n","Epoch 3: train_loss=0.452, validation_accuracy=0.6644\n","Epoch 4: train_loss=0.452, validation_accuracy=0.7800\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7961\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8038\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8161\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8282\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8491\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8782\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8928\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8994\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8995\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9039\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9073\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9095\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9145\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9144\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9146\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:11,763] Trial 92 finished with value: 0.9161 and parameters: {'hidden_dim': 27, 'activation_func': 'ReLU', 'lr': 0.00046138396827332176, 'momentum': 0.80078125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:11,763] The parameter 'activation_func' in trial#93 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9161\n","Epoch 1: train_loss=0.452, validation_accuracy=0.2961\n","Epoch 2: train_loss=0.452, validation_accuracy=0.4696\n","Epoch 3: train_loss=0.452, validation_accuracy=0.5824\n","Epoch 4: train_loss=0.452, validation_accuracy=0.6708\n","Epoch 5: train_loss=0.452, validation_accuracy=0.7076\n","Epoch 6: train_loss=0.452, validation_accuracy=0.7398\n","Epoch 7: train_loss=0.452, validation_accuracy=0.7660\n","Epoch 8: train_loss=0.452, validation_accuracy=0.7777\n","Epoch 9: train_loss=0.452, validation_accuracy=0.7931\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8023\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8115\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8193\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8252\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8314\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8374\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8396\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8434\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:13,209] Trial 93 finished with value: 0.8545 and parameters: {'hidden_dim': 22, 'activation_func': 'Sigmoid', 'lr': 3.459891660869929e-05, 'momentum': 0.98828125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:13,210] The parameter 'activation_func' in trial#94 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.8473\n","Epoch 19: train_loss=0.452, validation_accuracy=0.8516\n","Epoch 20: train_loss=0.452, validation_accuracy=0.8545\n","Epoch 1: train_loss=0.452, validation_accuracy=0.5497\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8451\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8804\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8904\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8966\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8975\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9025\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9056\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9068\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9070\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9094\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9096\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9125\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9120\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9124\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9149\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9162\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9162\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:14,627] Trial 94 finished with value: 0.9193 and parameters: {'hidden_dim': 42, 'activation_func': 'ReLU', 'lr': 0.0010941138105771855, 'momentum': 0.73828125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:14,627] The parameter 'activation_func' in trial#95 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.9178\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9193\n","Epoch 1: train_loss=0.452, validation_accuracy=0.7133\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8003\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8323\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8494\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8632\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8767\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8849\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8923\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8996\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9041\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9052\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9083\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9086\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9127\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9149\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9182\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9194\n","Epoch 18: train_loss=0.452, validation_accuracy=0.9195\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9226\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:16,330] Trial 95 finished with value: 0.9227 and parameters: {'hidden_dim': 32, 'activation_func': 'ELU', 'lr': 0.00019456400615886337, 'momentum': 0.86328125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:16,330] The parameter 'activation_func' in trial#96 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 20: train_loss=0.452, validation_accuracy=0.9227\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1028\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 4: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 5: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 6: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 7: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 8: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 9: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 10: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 11: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 12: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 13: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 14: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 15: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 16: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 17: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 18: train_loss=0.452, validation_accuracy=0.1135\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:17,621] Trial 96 finished with value: 0.1135 and parameters: {'hidden_dim': 12, 'activation_func': 'ELU', 'lr': 0.0061526541014903765, 'momentum': 0.61328125}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:17,621] The parameter 'activation_func' in trial#97 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 20: train_loss=0.452, validation_accuracy=0.1135\n","Epoch 1: train_loss=0.452, validation_accuracy=0.1228\n","Epoch 2: train_loss=0.452, validation_accuracy=0.1265\n","Epoch 3: train_loss=0.452, validation_accuracy=0.1802\n","Epoch 4: train_loss=0.452, validation_accuracy=0.2118\n","Epoch 5: train_loss=0.452, validation_accuracy=0.2443\n","Epoch 6: train_loss=0.452, validation_accuracy=0.2722\n","Epoch 7: train_loss=0.452, validation_accuracy=0.2876\n","Epoch 8: train_loss=0.452, validation_accuracy=0.3057\n","Epoch 9: train_loss=0.452, validation_accuracy=0.3221\n","Epoch 10: train_loss=0.452, validation_accuracy=0.3397\n","Epoch 11: train_loss=0.452, validation_accuracy=0.3501\n","Epoch 12: train_loss=0.452, validation_accuracy=0.3617\n","Epoch 13: train_loss=0.452, validation_accuracy=0.3747\n","Epoch 14: train_loss=0.452, validation_accuracy=0.3869\n","Epoch 15: train_loss=0.452, validation_accuracy=0.3991\n","Epoch 16: train_loss=0.452, validation_accuracy=0.4484\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:18,918] Trial 97 finished with value: 0.5237 and parameters: {'hidden_dim': 11, 'activation_func': 'ReLU', 'lr': 2.502865431174609e-05, 'momentum': 0.69921875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:18,919] The parameter 'activation_func' in trial#98 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 17: train_loss=0.452, validation_accuracy=0.4794\n","Epoch 18: train_loss=0.452, validation_accuracy=0.4990\n","Epoch 19: train_loss=0.452, validation_accuracy=0.5095\n","Epoch 20: train_loss=0.452, validation_accuracy=0.5237\n","Epoch 1: train_loss=0.452, validation_accuracy=0.8119\n","Epoch 2: train_loss=0.452, validation_accuracy=0.8626\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8809\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8891\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8909\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8989\n","Epoch 7: train_loss=0.452, validation_accuracy=0.9064\n","Epoch 8: train_loss=0.452, validation_accuracy=0.9021\n","Epoch 9: train_loss=0.452, validation_accuracy=0.9069\n","Epoch 10: train_loss=0.452, validation_accuracy=0.9087\n","Epoch 11: train_loss=0.452, validation_accuracy=0.9057\n","Epoch 12: train_loss=0.452, validation_accuracy=0.9101\n","Epoch 13: train_loss=0.452, validation_accuracy=0.9116\n","Epoch 14: train_loss=0.452, validation_accuracy=0.9132\n","Epoch 15: train_loss=0.452, validation_accuracy=0.9122\n","Epoch 16: train_loss=0.452, validation_accuracy=0.9152\n","Epoch 17: train_loss=0.452, validation_accuracy=0.9128\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:20,339] Trial 98 finished with value: 0.9206 and parameters: {'hidden_dim': 32, 'activation_func': 'Tanh', 'lr': 0.0007914755439411164, 'momentum': 0.94921875}. Best is trial 22 with value: 0.936.\n","[W 2023-03-07 16:29:20,340] The parameter 'activation_func' in trial#99 is sampled independently by using `RandomSampler` instead of `QMCSampler` (optimization performance may be degraded). `QMCSampler` does not support dynamic search space or `CategoricalDistribution`. You can suppress this warning by setting `warn_independent_sampling` to `False` in the constructor of `QMCSampler`, if this independent sampling is intended behavior.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 18: train_loss=0.452, validation_accuracy=0.9163\n","Epoch 19: train_loss=0.452, validation_accuracy=0.9168\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9206\n","Epoch 1: train_loss=0.452, validation_accuracy=0.6940\n","Epoch 2: train_loss=0.452, validation_accuracy=0.7736\n","Epoch 3: train_loss=0.452, validation_accuracy=0.8058\n","Epoch 4: train_loss=0.452, validation_accuracy=0.8261\n","Epoch 5: train_loss=0.452, validation_accuracy=0.8373\n","Epoch 6: train_loss=0.452, validation_accuracy=0.8469\n","Epoch 7: train_loss=0.452, validation_accuracy=0.8538\n","Epoch 8: train_loss=0.452, validation_accuracy=0.8617\n","Epoch 9: train_loss=0.452, validation_accuracy=0.8667\n","Epoch 10: train_loss=0.452, validation_accuracy=0.8726\n","Epoch 11: train_loss=0.452, validation_accuracy=0.8765\n","Epoch 12: train_loss=0.452, validation_accuracy=0.8805\n","Epoch 13: train_loss=0.452, validation_accuracy=0.8851\n","Epoch 14: train_loss=0.452, validation_accuracy=0.8865\n","Epoch 15: train_loss=0.452, validation_accuracy=0.8901\n","Epoch 16: train_loss=0.452, validation_accuracy=0.8925\n","Epoch 17: train_loss=0.452, validation_accuracy=0.8948\n","Epoch 18: train_loss=0.452, validation_accuracy=0.8965\n"]},{"name":"stderr","output_type":"stream","text":["[I 2023-03-07 16:29:21,932] Trial 99 finished with value: 0.9002 and parameters: {'hidden_dim': 42, 'activation_func': 'ReLU', 'lr': 0.0001407464663339844, 'momentum': 0.57421875}. Best is trial 22 with value: 0.936.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 19: train_loss=0.452, validation_accuracy=0.8970\n","Epoch 20: train_loss=0.452, validation_accuracy=0.9002\n"]}],"source":["# QMCSamplerはscipyが必要です\n","!pip install scipy\n","study_qmc = optuna.create_study(sampler=optuna.samplers.QMCSampler(), direction=\"maximize\")\n","study_qmc.optimize(objective, n_trials=100)\n","\n","print(f\"最良の精度: {study_qmc.best_value}\")\n","print(f\"最良のハイパーパラメータ: {study_qmc.best_params}\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"cSl6aiEkTAjZ"},"source":["`TPESampler`での実行結果は第3節で実行してあるので、それと比較します。"]},{"cell_type":"code","execution_count":306,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1082,"status":"ok","timestamp":1602580507103,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"OSvfSrytTcP_","outputId":"857b0045-26a5-4107-9169-595fd6f47c61"},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"mode":"markers","name":"Objective Value (QMC)","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],"y":[0.1135,0.2104,0.8213,0.8754,0.1135,0.9003,0.9304,0.9,0.6805,0.8753,0.6669,0.4889,0.9106,0.4777,0.5733,0.7443,0.869,0.7995,0.1135,0.6937,0.4638,0.732,0.936,0.7545,0.3245,0.5095,0.8672,0.8959,0.2157,0.8611,0.1135,0.7597,0.8651,0.2977,0.8851,0.7772,0.8599,0.7977,0.9344,0.7277,0.1135,0.2388,0.8994,0.6495,0.9139,0.8832,0.2102,0.8777,0.8463,0.6099,0.8965,0.9266,0.9088,0.8954,0.9056,0.8036,0.8957,0.7965,0.2139,0.8712,0.9083,0.5794,0.8732,0.8323,0.1882,0.7202,0.2179,0.8642,0.856,0.7056,0.9232,0.5532,0.3179,0.5343,0.9105,0.8132,0.1136,0.8852,0.909,0.8576,0.846,0.7228,0.9152,0.9078,0.1135,0.8032,0.1135,0.8787,0.8998,0.7753,0.5281,0.2646,0.9161,0.8545,0.9193,0.9227,0.1135,0.5237,0.9206,0.9002]},{"name":"Best Value (QMC)","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],"y":[0.1135,0.2104,0.8213,0.8754,0.8754,0.9003,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936,0.936]},{"mode":"markers","name":"Objective Value (TPE)","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],"y":[0.9304,0.7724,0.1135,0.9148,0.9032,0.8244,0.7697,0.8552,0.1872,0.8675,0.8941,0.1135,0.773,0.1136,0.8591,0.7638,0.9015,0.9075,0.8912,0.3263,0.8345,0.9068,0.9078,0.8621,0.9094,0.9034,0.2008,0.1135,0.8897,0.8442,0.9195,0.8749,0.9469,0.9389,0.9372,0.9205,0.9357,0.9331,0.9188,0.9188,0.9392,0.9373,0.9389,0.9351,0.9429,0.946,0.9481,0.9395,0.902,0.8719,0.9541,0.9004,0.9464,0.9431,0.9206,0.9263,0.9416,0.9239,0.9328,0.8543,0.9283,0.9149,0.9377,0.9491,0.3756,0.9187,0.9416,0.9179,0.9339,0.9303,0.8985,0.9414,0.9289,0.9186,0.8802,0.9486,0.9107,0.9319,0.919,0.9379,0.8386,0.944,0.9492,0.94,0.9403,0.9264,0.9285,0.9358,0.9457,0.9427,0.8485,0.9412,0.9381,0.9381,0.2837,0.9376,0.9392,0.9405,0.9278,0.9124]},{"name":"Best Value (TPE)","type":"scatter","x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],"y":[0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9304,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9469,0.9481,0.9481,0.9481,0.9481,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541,0.9541]}],"layout":{"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Optimization History Plot"},"xaxis":{"title":{"text":"Trial"}},"yaxis":{"title":{"text":"Objective Value"}}}}},"metadata":{},"output_type":"display_data"}],"source":["import plotly\n","fig1 = optuna.visualization.plot_optimization_history(study_qmc)\n","fig2 = optuna.visualization.plot_optimization_history(study)\n","\n","fig1['data'][0]['name'] = 'Objective Value (QMC)'\n","fig1['data'][1]['name'] = 'Best Value (QMC)'\n","fig2['data'][0]['name'] = 'Objective Value (TPE)'\n","fig2['data'][1]['name'] = 'Best Value (TPE)'\n","fig = plotly.graph_objs.Figure(\n","    data=fig1['data'] + fig2['data'],\n","    layout=fig1['layout']\n",")\n","fig.show()"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"MleQK3Q7YRzP"},"source":["初めの10回程度の結果は、かなり運に左右されます。それ以降は、おそらく`TPESampler`の方が`QMCSampler`と比べて良い値をたくさんサンプルしており、より高い精度まで伸ばすことができているでしょう。\n","したがって、この目的関数に対しては`QMCSampler`よりも`TPESampler`の方が適していると判断できます。"]},{"cell_type":"markdown","metadata":{"id":"2hKeVIHMZEtM"},"source":["次に、`optuna.visualization.plot_contour`関数を紹介します。\n","この関数も、引数に`study`を与えるだけで動作します。\n","この関数は、全てのハイパーパラメータに対して、それらの任意の2個を縦軸横軸として目的関数値の等高線を表示します。（等高線を表示するハイパーパラメータの組を制限することもできます。詳細は[ドキュメント](https://optuna.readthedocs.io/en/stable/reference/visualization/generated/optuna.visualization.plot_contour.html#)を参照してください。）"]},{"cell_type":"code","execution_count":312,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":1631,"status":"ok","timestamp":1602580517721,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"sj_p2bYzceN_","outputId":"bbfa49ac-5876-4d69-ea34-f1765b88a8a1"},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"type":"scatter","xaxis":"x","yaxis":"y"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":true,"type":"contour","x":["ELU","ReLU","Sigmoid","Tanh"],"xaxis":"x5","y":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"yaxis":"y5","z":[[null,null,null,null],[0.2837,null,null,null],[null,0.1872,null,null],[0.1135,null,null,null],[0.2008,null,null,null],[null,null,null,0.8621],[0.7638,null,null,0.8442],[null,null,0.3263,0.9034],[null,0.1135,null,null],[null,null,null,0.9094],[null,null,null,0.9078],[null,null,0.8897,null],[0.1136,null,null,null],[null,null,null,0.9068],[null,null,0.8345,null],[0.8485,null,0.7697,null],[0.9188,null,0.9032,null],[null,0.1135,null,0.9124],[0.9188,null,null,null],[0.8941,0.9339,null,null],[null,null,0.8591,null],[0.9357,null,null,null],[0.9331,null,null,null],[0.9351,null,null,null],[0.9285,0.8802,0.8675,null],[0.9195,0.9283,null,0.919],[0.9381,0.3756,null,null],[0.9278,0.9263,0.8985,null],[0.9392,0.9379,null,null],[0.9405,0.9414,null,0.8552],[0.9376,0.9303,0.9107,null],[null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"xaxis":"x5","y":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"yaxis":"y5"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":["ELU","ReLU","Sigmoid","Tanh"],"xaxis":"x9","y":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"yaxis":"y9","z":[[null,null,null,null],[0.8912,null,null,null],[null,0.1872,null,null],[0.8244,null,null,null],[null,null,0.3263,null],[0.7638,null,null,null],[0.9304,null,null,null],[0.8941,null,null,null],[null,null,0.773,null],[null,null,null,0.8552],[null,0.9015,null,null],[null,null,0.8345,null],[0.9285,null,null,null],[null,0.9339,null,null],[0.9331,null,null,null],[0.9427,null,null,null],[0.9357,null,null,null],[0.9392,null,null,null],[0.94,null,null,null],[0.9188,null,null,null],[null,0.9303,null,null],[null,null,0.8591,null],[0.9405,null,null,null],[0.9358,null,null,null],[null,null,0.7697,null],[null,0.9416,null,null],[null,0.9416,null,null],[null,0.9491,null,null],[null,0.3756,null,null],[null,null,0.8985,null],[0.9492,null,null,null],[null,null,0.9107,null],[0.9403,null,null,null],[0.9372,null,null,null],[0.9381,null,null,null],[0.9205,null,null,null],[0.9389,null,null,null],[0.9457,null,null,null],[0.9392,null,null,null],[null,null,null,0.9124],[0.9389,null,null,null],[0.8485,null,null,null],[0.9188,null,null,null],[0.9469,null,null,null],[0.2837,null,null,null],[0.9373,null,null,null],[0.9351,null,null,null],[0.9289,null,null,null],[0.944,null,null,null],[0.9429,null,null,null],[0.9264,null,null,null],[null,null,null,0.919],[null,0.9149,null,null],[null,0.9414,null,null],[0.9381,null,null,null],[0.9486,null,null,null],[0.946,null,null,null],[null,0.9541,null,null],[null,0.9328,null,null],[null,0.9206,null,null],[null,0.9464,null,null],[null,0.9187,null,null],[null,0.9263,null,null],[0.9278,null,null,null],[null,0.9431,null,null],[null,null,null,0.9078],[null,0.9379,null,null],[null,null,null,0.9075],[null,null,0.8675,null],[0.9186,null,null,null],[null,0.9179,null,null],[0.9412,null,null,null],[null,null,null,0.9068],[0.9395,null,null,null],[0.902,null,null,null],[null,0.9377,null,null],[0.9319,null,null,null],[0.9481,null,null,null],[0.9376,null,null,null],[null,0.9004,null,null],[null,0.9239,null,null],[0.9195,null,null,null],[null,0.8802,null,null],[null,0.9283,null,null],[0.8386,null,null,null],[0.8749,null,null,null],[null,null,0.8897,null],[null,null,null,0.9094],[null,null,null,0.9034],[0.8719,null,null,null],[null,null,0.9032,null],[0.1135,null,null,null],[null,0.8543,null,null],[null,null,null,0.7724],[0.2008,null,null,null],[null,null,null,0.8442],[null,null,null,0.8621],[null,0.1135,null,null],[null,null,0.9148,null],[0.1136,null,null,null],[null,0.1135,null,null],[null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"xaxis":"x9","y":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"yaxis":"y9"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":["ELU","ReLU","Sigmoid","Tanh"],"xaxis":"x13","y":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"yaxis":"y13","z":[[null,null,null,null],[0.8244,null,null,null],[null,null,0.7697,null],[null,null,0.8675,null],[0.1136,null,null,null],[null,0.9015,null,null],[null,null,0.9032,null],[0.9351,null,null,null],[null,null,0.8897,null],[null,0.1135,null,null],[null,null,0.9148,null],[null,null,0.3263,null],[0.9188,null,null,null],[null,null,0.8591,null],[null,null,null,0.8552],[0.9358,null,null,null],[0.9188,null,null,null],[0.9357,null,null,null],[0.9331,null,null,null],[null,null,null,0.9068],[0.9392,null,null,null],[null,null,null,0.9075],[0.9285,null,null,null],[0.9392,null,null,null],[0.1135,null,null,null],[0.9469,null,null,null],[0.9389,null,null,null],[0.9372,null,null,null],[0.9205,null,null,null],[0.9373,null,null,null],[0.9381,null,null,null],[0.94,null,null,null],[0.9389,null,null,null],[0.9264,null,null,null],[null,null,0.8345,null],[0.944,null,null,null],[0.9429,null,null,null],[null,0.9414,null,null],[null,null,0.773,null],[0.9412,null,null,null],[null,null,null,0.9034],[null,0.9377,null,null],[null,0.8543,null,null],[0.2837,null,null,null],[null,0.8802,null,null],[0.9492,null,null,null],[null,0.9179,null,null],[0.9403,null,null,null],[null,null,null,0.9094],[null,null,null,0.9124],[0.8749,null,null,null],[0.9195,null,null,null],[0.2008,null,null,null],[null,null,null,0.919],[null,null,0.8985,null],[0.9427,null,null,null],[0.9405,null,null,null],[0.9486,null,null,null],[0.9457,null,null,null],[null,0.1872,null,null],[0.9319,null,null,null],[null,0.9339,null,null],[null,0.9283,null,null],[null,0.9416,null,null],[null,0.9464,null,null],[null,0.9206,null,null],[0.946,null,null,null],[null,0.9431,null,null],[0.7638,null,null,null],[null,0.9541,null,null],[0.9381,null,null,null],[0.9481,null,null,null],[null,0.9004,null,null],[null,0.9303,null,null],[null,0.9491,null,null],[null,0.9187,null,null],[null,0.9379,null,null],[0.8719,null,null,null],[0.8912,null,null,null],[0.9376,null,null,null],[null,null,0.9107,null],[null,0.9239,null,null],[null,0.9149,null,null],[null,null,null,0.9078],[0.8485,null,null,null],[0.9304,null,null,null],[null,null,null,0.8621],[0.9289,null,null,null],[0.8386,null,null,null],[0.9395,null,null,null],[null,0.9416,null,null],[0.902,null,null,null],[null,0.9263,null,null],[0.9278,null,null,null],[null,0.9328,null,null],[0.9186,null,null,null],[null,null,null,0.8442],[0.8941,null,null,null],[null,null,null,0.7724],[null,0.1135,null,null],[null,0.3756,null,null],[null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"xaxis":"x13","y":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"yaxis":"y13"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"xaxis":"x2","y":["ELU","ReLU","Sigmoid","Tanh"],"yaxis":"y2","z":[[null,0.2837,null,0.1135,0.2008,null,0.7638,null,null,null,null,null,0.1136,null,null,0.8485,0.9188,null,0.9188,0.8941,null,0.9357,0.9331,0.9351,0.9285,0.9195,0.9381,0.9278,0.9392,0.9405,0.9376,null],[null,null,0.1872,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,0.1135,null,0.9339,null,null,null,null,0.8802,0.9283,0.3756,0.9263,0.9379,0.9414,0.9303,null],[null,null,null,null,null,null,null,0.3263,null,null,null,0.8897,null,null,0.8345,0.7697,0.9032,null,null,null,0.8591,null,null,null,0.8675,null,null,0.8985,null,null,0.9107,null],[null,null,null,null,null,0.8621,0.8442,0.9034,null,0.9094,0.9078,null,null,0.9068,null,null,null,0.9124,null,null,null,null,null,null,null,0.919,null,null,null,0.8552,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"xaxis":"x2","y":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"yaxis":"y2"},{"type":"scatter","xaxis":"x6","yaxis":"y6"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"xaxis":"x10","y":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"yaxis":"y10","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8912,null,null,null,null,null,null],[null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8244,null],[null,null,null,null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9304,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8941,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8552,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.94,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9303,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9405,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9358,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9491,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9492,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9107,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9403,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9372,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9205,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9457,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null],[null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9373,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9351,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.944,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9429,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9149,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9414,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9486,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.946,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9541,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9328,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9464,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9187,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9263,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9278,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9431,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9379,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8675,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9186,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9179,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9412,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9395,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.902,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9377,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9319,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9481,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9376,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9004,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9239,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9195,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9283,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8386,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8749,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.8897,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8719,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9032,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null],[null,null,null,null,null,null,0.7724,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,0.2008,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.8442,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,0.8621,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.9148,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.1136,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"xaxis":"x10","y":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"yaxis":"y10"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"xaxis":"x14","y":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"yaxis":"y14","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8244,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8675,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.1136,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9032,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9351,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.8897,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.9148,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8552,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9358,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null],[null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9372,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9205,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9373,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.94,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.944,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9429,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9414,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9412,null,null],[null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9377,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null],[null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9492,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9179,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9403,null],[null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8749,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9195,null,null,null,null,null,null],[null,null,null,null,0.2008,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9405,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9486,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9457,null,null,null],[null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9319,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9283,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9464,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.946,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9431,null,null,null,null,null],[null,null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9541,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9481,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9004,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9303,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9491,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9187,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9379,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8719,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8912,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9376,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9107,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9239,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9149,null,null],[null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9304,null,null],[null,null,null,null,null,0.8621,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8386,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9395,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.902,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9263,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9278,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9328,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9186,null,null,null],[null,null,null,null,null,null,0.8442,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8941,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.7724,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"xaxis":"x14","y":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"yaxis":"y14"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"xaxis":"x3","y":["ELU","ReLU","Sigmoid","Tanh"],"yaxis":"y3","z":[[null,0.8912,null,0.8244,null,0.7638,0.9304,0.8941,null,null,null,null,0.9285,null,0.9331,0.9427,0.9357,0.9392,0.94,0.9188,null,null,0.9405,0.9358,null,null,null,null,null,null,0.9492,null,0.9403,0.9372,0.9381,0.9205,0.9389,0.9457,0.9392,null,0.9389,0.8485,0.9188,0.9469,0.2837,0.9373,0.9351,0.9289,0.944,0.9429,0.9264,null,null,null,0.9381,0.9486,0.946,null,null,null,null,null,null,0.9278,null,null,null,null,null,0.9186,null,0.9412,null,0.9395,0.902,null,0.9319,0.9481,0.9376,null,null,0.9195,null,null,0.8386,0.8749,null,null,null,0.8719,null,0.1135,null,null,0.2008,null,null,null,null,0.1136,null,null],[null,null,0.1872,null,null,null,null,null,null,null,0.9015,null,null,0.9339,null,null,null,null,null,null,0.9303,null,null,null,null,0.9416,0.9416,0.9491,0.3756,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9149,0.9414,null,null,null,0.9541,0.9328,0.9206,0.9464,0.9187,0.9263,null,0.9431,null,0.9379,null,null,null,0.9179,null,null,null,null,0.9377,null,null,null,0.9004,0.9239,null,0.8802,0.9283,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,0.1135,null,null,0.1135,null],[null,null,null,null,0.3263,null,null,null,0.773,null,null,0.8345,null,null,null,null,null,null,null,null,null,0.8591,null,null,0.7697,null,null,null,null,0.8985,null,0.9107,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8675,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8897,null,null,null,0.9032,null,null,null,null,null,null,null,0.9148,null,null,null],[null,null,null,null,null,null,null,null,null,0.8552,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,0.9075,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9094,0.9034,null,null,null,null,0.7724,null,0.8442,0.8621,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"xaxis":"x3","y":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"yaxis":"y3"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"xaxis":"x7","y":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"yaxis":"y7","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2008,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8621,null,null,null,null,null],[null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7724,null,0.8442,null,null,null,null,null,null],[null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8897,null,null,null,null,null,null,null,null,null,null,null,0.9148,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1136,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9075,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9032,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.8941,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9372,null,0.9205,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,0.9392,null,null,null,null,null,null,0.9373,0.9351,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8675,null,0.9179,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,0.8912,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9239,0.9195,null,0.9283,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,null,null,null,0.9431,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,0.9381,null,null,null,null,null,0.9464,null,0.9263,0.9278,null,null,null,null,null,null,null,null,null,null,null,null,0.9319,null,null,null,null,null,null,null,null,0.8749,null,null,null,0.8719,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,0.9392,null,null,null,null,null,null,null,0.9416,null,null,null,null,null,null,null,null,null,null,null,0.9457,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.946,null,0.9328,null,null,null,null,null,null,null,0.9379,null,null,0.9186,null,null,null,0.9395,null,0.9377,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.9304,null,null,0.8552,null,null,null,null,null,null,null,null,0.94,null,null,null,0.9405,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.944,0.9429,null,null,0.9149,0.9414,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9412,null,null,0.902,null,null,0.9481,null,null,null,null,null,null,0.8386,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.8244,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9303,null,null,0.9358,null,null,0.9416,0.9491,null,null,0.9492,0.9107,0.9403,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9486,null,0.9541,null,null,null,0.9187,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9376,0.9004,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"xaxis":"x7","y":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"yaxis":"y7"},{"type":"scatter","xaxis":"x11","yaxis":"y11"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"xaxis":"x15","y":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"yaxis":"y15","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.8244,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8675,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1136,null,null],[null,null,null,null,null,null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9032,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9351,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8897,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9148,null,null,null],[null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.8552,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9358,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9372,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9205,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9373,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.94,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.944,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9429,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9414,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9412,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9377,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9492,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9179,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9403,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8749,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9195,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2008,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9405,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9486,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9457,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9319,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9283,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9464,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.946,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9431,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9541,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9481,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9004,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9303,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9491,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9187,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9379,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8719,null,null,null,null,null,null,null,null,null,null,null,null],[null,0.8912,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9376,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9107,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9239,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9149,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.9304,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8621,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8386,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9395,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.902,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9278,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9328,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9186,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8442,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.8941,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7724,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"xaxis":"x15","y":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"yaxis":"y15"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"xaxis":"x4","y":["ELU","ReLU","Sigmoid","Tanh"],"yaxis":"y4","z":[[null,0.8244,null,null,0.1136,null,null,0.9351,null,null,null,null,0.9188,null,null,0.9358,0.9188,0.9357,0.9331,null,0.9392,null,0.9285,0.9392,0.1135,0.9469,0.9389,0.9372,0.9205,0.9373,0.9381,0.94,0.9389,0.9264,null,0.944,0.9429,null,null,0.9412,null,null,null,0.2837,null,0.9492,null,0.9403,null,null,0.8749,0.9195,0.2008,null,null,0.9427,0.9405,0.9486,0.9457,null,0.9319,null,null,null,null,null,0.946,null,0.7638,null,0.9381,0.9481,null,null,null,null,null,0.8719,0.8912,0.9376,null,null,null,null,0.8485,0.9304,null,0.9289,0.8386,0.9395,null,0.902,null,0.9278,null,0.9186,null,0.8941,null,null,null,null],[null,null,null,null,null,0.9015,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9414,null,null,null,0.9377,0.8543,null,0.8802,null,0.9179,null,null,null,null,null,null,null,null,null,null,null,null,0.1872,null,0.9339,0.9283,0.9416,0.9464,0.9206,null,0.9431,null,0.9541,null,null,0.9004,0.9303,0.9491,0.9187,0.9379,null,null,null,null,0.9239,0.9149,null,null,null,null,null,null,null,0.9416,null,0.9263,null,0.9328,null,null,null,null,0.1135,0.3756,null],[null,null,0.7697,0.8675,null,null,0.9032,null,0.8897,null,0.9148,0.3263,null,0.8591,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9107,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8552,null,null,null,null,0.9068,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,0.9094,0.9124,null,null,null,0.919,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,null,0.8621,null,null,null,null,null,null,null,null,null,0.8442,null,0.7724,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"xaxis":"x4","y":["ELU","Tanh","ELU","Sigmoid","Sigmoid","ELU","Sigmoid","Tanh","ReLU","Sigmoid","ELU","ReLU","Sigmoid","ELU","Sigmoid","ELU","ReLU","Tanh","ELU","Sigmoid","Sigmoid","Tanh","Tanh","Tanh","Tanh","Tanh","ELU","ReLU","Sigmoid","Tanh","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","ReLU","Sigmoid","ReLU","ELU","ELU","ReLU","ELU","Sigmoid","ELU","Tanh","ReLU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","ELU","Tanh"],"yaxis":"y4"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"xaxis":"x8","y":[8,10,11,12,15,16,18,21,22,23,24,25,27,28,31,32,34,36,38,39,40,41,42,43,44,45,46,47,48,49,50,52],"yaxis":"y8","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2008,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8621,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8442,null,0.7724,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.8897,null,0.9148,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,0.1136,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9068,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.9032,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8941,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,0.9389,0.9372,0.9205,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.9351,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,0.9373,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.8675,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,0.9179,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9195,null,0.919,null,null,null,null,null,null,null,null,0.9283,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8912,null,null,0.9239,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,0.9431,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8749,null,null,null,0.8985,null,null,null,null,null,0.9319,null,null,null,0.9464,null,null,null,null,null,0.9381,null,null,null,null,null,null,0.8719,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9263,0.9278,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9377,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,null,0.9457,null,null,null,null,null,null,null,0.946,null,null,null,null,null,null,null,null,null,0.9379,null,null,null,null,null,null,null,null,null,null,null,null,0.9395,0.9416,null,null,null,0.9328,0.9186,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8552,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.94,null,null,null,0.944,0.9429,0.9414,null,0.9412,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9405,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9481,null,null,null,null,null,null,null,null,null,null,0.9149,null,null,0.9304,null,null,0.8386,null,null,0.902,null,null,null,null,null,null,null,null,null,null],[null,0.8244,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9358,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9492,null,0.9403,null,null,null,null,null,null,null,null,null,0.9486,null,null,null,null,null,0.9416,null,null,null,null,null,0.9541,null,null,0.9004,0.9303,0.9491,0.9187,null,null,null,0.9376,0.9107,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"xaxis":"x8","y":[49,18,12,25,34,50,32,49,11,44,39,22,25,27,40,18,36,28,45,21,31,28,24,16,23,21,15,36,25,18,45,47,42,41,41,41,41,42,38,34,43,43,43,43,49,48,49,48,49,47,50,50,47,46,46,47,50,45,48,46,45,49,48,50,46,50,48,44,39,50,47,49,46,48,44,50,50,47,45,48,49,49,50,49,50,47,44,50,48,48,32,49,46,47,10,50,48,49,47,36],"yaxis":"y8"},{"colorbar":{"title":{"text":"Objective Value"}},"colorscale":[[0,"rgb(247,251,255)"],[0.125,"rgb(222,235,247)"],[0.25,"rgb(198,219,239)"],[0.375,"rgb(158,202,225)"],[0.5,"rgb(107,174,214)"],[0.625,"rgb(66,146,198)"],[0.75,"rgb(33,113,181)"],[0.875,"rgb(8,81,156)"],[1,"rgb(8,48,107)"]],"connectgaps":true,"contours":{"coloring":"heatmap"},"hoverinfo":"none","line":{"smoothing":1.3},"reversescale":false,"showscale":false,"type":"contour","x":[0.47559144470991804,0.5005385697160749,0.5387286798544435,0.6510568849505591,0.7049165190698226,0.756317649332428,0.7581120909584393,0.7809074361492837,0.7893748464337371,0.7970743720786617,0.8022766782983275,0.8226795663321819,0.8239629920897446,0.8310872157157525,0.8315282835814655,0.8401845756873458,0.851828862373031,0.8530190459386299,0.8539386003711584,0.8580515725167611,0.8627649394668739,0.8636338370426936,0.863719227625149,0.8694796826071978,0.8708489206763508,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8776620510456014,0.8802046197937091,0.8860727767283736,0.8864823162057998,0.8873422019330954,0.8884770493772618,0.8909374775137995,0.891024158382202,0.8950936157119771,0.8962614332979085,0.8977455145826501,0.8982848711917526,0.898452143758298,0.9010742982207106,0.905195703535726,0.9069357443249196,0.9080858102341667,0.9081250025551683,0.9081910731591085,0.9091905295534644,0.9107474994957117,0.9140665956682978,0.9150647082110005,0.9156884557450946,0.9158679208066273,0.9177535054101553,0.9200451350113962,0.9205734814727813,0.9210168554365417,0.921892818898288,0.924715121629897,0.9252808510047659,0.9264170473796257,0.926420926003745,0.9270131354133357,0.9274563419697653,0.931185600008614,0.9326692137853243,0.9330563475553577,0.9339059581853395,0.9345346946262646,0.9358357113696035,0.9375988110632599,0.9382285987040141,0.938858543157199,0.9388954501791448,0.939086950313488,0.9422759915605663,0.9437418617777731,0.9454112568071839,0.945607800123267,0.9492664005699963,0.9520861597170444,0.9538935899940181,0.955102072883425,0.9561541234984088,0.9571372771710684,0.9581974108083505,0.9586877824045527,0.9662098292839705,0.9669031434387362,0.9678772013501159,0.9695643705703106,0.9744074514158978,0.9804369522987495,0.9819888638326002,0.9841706036369542,0.98618453971126,0.9920158424903519,0.9950140401886343,0.9973750305017562,0.9994810698392119,1.0244281948453688],"xaxis":"x12","y":[0.00000859856608088788,0.000012017863286285035,0.0000123662030949225,0.0000160635765686492,0.000027049839882391724,0.00002821576195060964,0.00003517789037571699,0.00004747806550519493,0.0000611544167511967,0.00009543271771322577,0.00009848563019177695,0.00013859606644361005,0.0001476211269745807,0.00016725566437030757,0.00017690253026316947,0.0001824134107169585,0.000195878653096875,0.00020259612195534034,0.00021319963708972702,0.0002175993526810036,0.00022610207185085442,0.00023955521819323688,0.00024249733196017841,0.00024874746028635776,0.000251493651950654,0.0002552906998428572,0.0002596871001839682,0.0002679901089121067,0.0002730735783708396,0.00028851848931655985,0.0002972793951997851,0.00029757464616977946,0.0003033727416457135,0.00030462288049526134,0.0003083813550508463,0.0003317141530906696,0.00033721379706959034,0.00033780359830239056,0.0003422478331600862,0.0003448348611029693,0.0003470069949264327,0.00035124120378332677,0.0003555688912015689,0.00036487994816916707,0.00036681873038293776,0.00037422948565420756,0.00038991678025800857,0.0003906709877249635,0.0003993482137190134,0.0004000023041130761,0.0004066832878411739,0.0004317912976388686,0.000442916172926192,0.00044305284435782263,0.00044571742248681917,0.0004514254294626113,0.0004727939741343193,0.00047331694643087865,0.00047777913090968306,0.0004868549393009577,0.0004946919478076694,0.0005025927105779137,0.0005062812933589137,0.0005172288065026961,0.0005199226306989645,0.0005339844996437578,0.0005448958123154112,0.0005581255651674452,0.0005715890755892744,0.0005853661235562488,0.0005963797065702815,0.0006063545040080582,0.0006220306677279959,0.0006359934241799896,0.0006592274335493457,0.0006906427871757981,0.0007089708823281438,0.0007238158654621592,0.0007418617645890998,0.0007646352770251174,0.0007827538577217244,0.000863408906693863,0.0008692295125485819,0.0008839676919543571,0.000948237246734749,0.0010583923299957577,0.001069669920631024,0.001074574242984173,0.0012832699500411019,0.0014692834702324231,0.001716740964361503,0.0017444025331396088,0.0018655261720574101,0.002269321496976276,0.0025891636772256187,0.0028907518461860396,0.0043092202862666466,0.004673938533595844,0.0066522794045366,0.009085242417269494,0.009724152912488692,0.013591049853878916],"yaxis":"y12","z":[[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8912,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1872,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,0.8244,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,0.3263,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7638,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9304,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8941,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.773,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8552,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,0.9015,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8345,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9285,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9339,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9331,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9427,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9357,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.94,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9303,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,0.8591,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9405,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9358,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,0.7697,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9416,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9491,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.3756,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8985,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9492,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9107,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9403,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9372,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9205,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9457,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9392,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9124,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9389,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8485,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9188,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9469,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2837,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9373,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,0.9351,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9289,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.944,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9429,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9264,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.919,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9149,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9414,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9381,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9486,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.946,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9541,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9328,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9206,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9464,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9187,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9263,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9278,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9431,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9078,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9379,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9075,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,0.8675,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9186,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9179,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9412,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9068,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9395,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.902,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9377,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9319,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9481,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9376,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9004,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9239,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9195,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8802,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9283,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8386,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8749,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,0.8897,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9094,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.9034,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8719,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,0.9032,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8543,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.7724,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.2008,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8442,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.8621,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,0.1135,null,null],[null,null,null,null,null,null,null,null,null,null,0.9148,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,0.1136,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,0.1135,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null],[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null]]},{"marker":{"color":"black","line":{"color":"Grey","width":2}},"mode":"markers","showlegend":false,"type":"scatter","x":[0.9571372771710684,0.9950140401886343,0.8708489206763508,0.8022766782983275,0.7581120909584393,0.5005385697160749,0.5387286798544435,0.8315282835814655,0.924715121629897,0.6510568849505591,0.9920158424903519,0.7970743720786617,0.8962614332979085,0.7049165190698226,0.8310872157157525,0.9339059581853395,0.756317649332428,0.8636338370426936,0.9454112568071839,0.8226795663321819,0.8884770493772618,0.8580515725167611,0.955102072883425,0.9581974108083505,0.9091905295534644,0.8982848711917526,0.9156884557450946,0.9973750305017562,0.7893748464337371,0.98618453971126,0.9150647082110005,0.9140665956682978,0.87345468804648,0.8737602166143212,0.8751145206971184,0.8760007825734699,0.8530190459386299,0.8539386003711584,0.851828862373031,0.8239629920897446,0.8627649394668739,0.8776620510456014,0.8864823162057998,0.7809074361492837,0.891024158382202,0.9326692137853243,0.9375988110632599,0.9669031434387362,0.9695643705703106,0.9437418617777731,0.9345346946262646,0.9382285987040141,0.9274563419697653,0.9330563475553577,0.931185600008614,0.9744074514158978,0.9270131354133357,0.9520861597170444,0.9819888638326002,0.9010742982207106,0.926420926003745,0.9538935899940181,0.898452143758298,0.9388954501791448,0.9994810698392119,0.939086950313488,0.9678772013501159,0.9081250025551683,0.9264170473796257,0.938858543157199,0.9177535054101553,0.8950936157119771,0.9586877824045527,0.9841706036369542,0.9069357443249196,0.9210168554365417,0.9492664005699963,0.9252808510047659,0.9158679208066273,0.9422759915605663,0.9662098292839705,0.8909374775137995,0.9080858102341667,0.8860727767283736,0.9081910731591085,0.8873422019330954,0.863719227625149,0.8401845756873458,0.921892818898288,0.9200451350113962,0.9561541234984088,0.8977455145826501,0.8802046197937091,0.9358357113696035,0.905195703535726,0.945607800123267,0.8694796826071978,0.9205734814727813,0.9804369522987495,0.9107474994957117],"xaxis":"x12","y":[0.00003517789037571699,0.002269321496976276,0.0017444025331396088,0.0066522794045366,0.001716740964361503,0.0000160635765686492,0.000251493651950654,0.00009543271771322577,0.0000123662030949225,0.0005715890755892744,0.00004747806550519493,0.009724152912488692,0.0000611544167511967,0.009085242417269494,0.00023955521819323688,0.00002821576195060964,0.00009848563019177695,0.0005581255651674452,0.000012017863286285035,0.000027049839882391724,0.00013859606644361005,0.0006220306677279959,0.0005339844996437578,0.0043092202862666466,0.001074574242984173,0.0012832699500411019,0.0025891636772256187,0.004673938533595844,0.001069669920631024,0.0028907518461860396,0.000863408906693863,0.0010583923299957577,0.00036487994816916707,0.0003470069949264327,0.00030462288049526134,0.0003317141530906696,0.000195878653096875,0.00017690253026316947,0.0003555688912015689,0.0002175993526810036,0.0003422478331600862,0.00037422948565420756,0.00033721379706959034,0.00038991678025800857,0.0004000023041130761,0.0004727939741343193,0.0007238158654621592,0.0006359934241799896,0.0006592274335493457,0.0014692834702324231,0.00047331694643087865,0.0007646352770251174,0.0004946919478076694,0.0005199226306989645,0.0004868549393009577,0.0005062812933589137,0.0002596871001839682,0.0007827538577217244,0.00047777913090968306,0.0018655261720574101,0.0008839676919543571,0.000442916172926192,0.0006906427871757981,0.0002679901089121067,0.0002730735783708396,0.0005025927105779137,0.0002552906998428572,0.0005963797065702815,0.00016725566437030757,0.00022610207185085442,0.00028851848931655985,0.00044305284435782263,0.0003906709877249635,0.0005853661235562488,0.0008692295125485819,0.0004514254294626113,0.00029757464616977946,0.0007089708823281438,0.0004317912976388686,0.0005448958123154112,0.000948237246734749,0.0003993482137190134,0.0002972793951997851,0.00021319963708972702,0.0003033727416457135,0.0004066832878411739,0.0001476211269745807,0.00024874746028635776,0.00033780359830239056,0.0001824134107169585,0.00035124120378332677,0.0006063545040080582,0.0003083813550508463,0.00044571742248681917,0.00036681873038293776,0.0007418617645890998,0.00020259612195534034,0.00024249733196017841,0.0005172288065026961,0.0003448348611029693],"yaxis":"y12"},{"type":"scatter","xaxis":"x16","yaxis":"y16"}],"layout":{"autosize":false,"height":800,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Contour Plot"},"width":800,"xaxis":{"anchor":"y","domain":[0,0.2125],"matches":"x13","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"xaxis10":{"anchor":"y10","domain":[0.2625,0.475],"matches":"x14","range":[8,52],"showticklabels":false},"xaxis11":{"anchor":"y11","domain":[0.525,0.7375],"matches":"x15","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"xaxis12":{"anchor":"y12","domain":[0.7875,1],"matches":"x16","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"xaxis13":{"anchor":"y13","domain":[0,0.2125],"range":[-0.15000000000000002,3.15],"title":{"text":"activation_func"},"type":"category"},"xaxis14":{"anchor":"y14","domain":[0.2625,0.475],"range":[8,52],"title":{"text":"hidden_dim"}},"xaxis15":{"anchor":"y15","domain":[0.525,0.7375],"range":[-5.065573966789006,-1.866746994471628],"title":{"text":"lr"},"type":"log"},"xaxis16":{"anchor":"y16","domain":[0.7875,1],"range":[0.47559144470991804,1.0244281948453688],"title":{"text":"momentum"}},"xaxis2":{"anchor":"y2","domain":[0.2625,0.475],"matches":"x14","range":[8,52],"showticklabels":false},"xaxis3":{"anchor":"y3","domain":[0.525,0.7375],"matches":"x15","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"xaxis4":{"anchor":"y4","domain":[0.7875,1],"matches":"x16","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"xaxis5":{"anchor":"y5","domain":[0,0.2125],"matches":"x13","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"xaxis6":{"anchor":"y6","domain":[0.2625,0.475],"matches":"x14","range":[8,52],"showticklabels":false},"xaxis7":{"anchor":"y7","domain":[0.525,0.7375],"matches":"x15","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"xaxis8":{"anchor":"y8","domain":[0.7875,1],"matches":"x16","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"xaxis9":{"anchor":"y9","domain":[0,0.2125],"matches":"x13","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"yaxis":{"anchor":"x","domain":[0.80625,1],"range":[-0.15000000000000002,3.15],"title":{"text":"activation_func"},"type":"category"},"yaxis10":{"anchor":"x10","domain":[0.26875,0.4625],"matches":"y9","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"yaxis11":{"anchor":"x11","domain":[0.26875,0.4625],"matches":"y9","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"yaxis12":{"anchor":"x12","domain":[0.26875,0.4625],"matches":"y9","range":[-5.065573966789006,-1.866746994471628],"showticklabels":false,"type":"log"},"yaxis13":{"anchor":"x13","domain":[0,0.19375],"range":[0.47559144470991804,1.0244281948453688],"title":{"text":"momentum"}},"yaxis14":{"anchor":"x14","domain":[0,0.19375],"matches":"y13","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"yaxis15":{"anchor":"x15","domain":[0,0.19375],"matches":"y13","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"yaxis16":{"anchor":"x16","domain":[0,0.19375],"matches":"y13","range":[0.47559144470991804,1.0244281948453688],"showticklabels":false},"yaxis2":{"anchor":"x2","domain":[0.80625,1],"matches":"y","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"yaxis3":{"anchor":"x3","domain":[0.80625,1],"matches":"y","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"yaxis4":{"anchor":"x4","domain":[0.80625,1],"matches":"y","range":[-0.15000000000000002,3.15],"showticklabels":false,"type":"category"},"yaxis5":{"anchor":"x5","domain":[0.5375,0.73125],"range":[8,52],"title":{"text":"hidden_dim"}},"yaxis6":{"anchor":"x6","domain":[0.5375,0.73125],"matches":"y5","range":[8,52],"showticklabels":false},"yaxis7":{"anchor":"x7","domain":[0.5375,0.73125],"matches":"y5","range":[8,52],"showticklabels":false},"yaxis8":{"anchor":"x8","domain":[0.5375,0.73125],"matches":"y5","range":[8,52],"showticklabels":false},"yaxis9":{"anchor":"x9","domain":[0.26875,0.4625],"range":[-5.065573966789006,-1.866746994471628],"title":{"text":"lr"},"type":"log"}}}},"metadata":{},"output_type":"display_data"}],"source":["fig = optuna.visualization.plot_contour(study)\n","fig.update_layout(autosize=False, width=800, height=800) # 図が小さいのでサイズを調整"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"XQIcyRcSfgRI"},"source":["出力された等高線を見ると、`hidden_dim`は大きい方がよくて、`lr`は0.001以上だと非常に悪い結果になっていそう、ということが読み取れると思います。次に最適化するときは、例えば`lr`の探索範囲の上限を`1e-2`ではなく`1e-3`にしたり、`hidden_dim`の探索範囲の上限をより大きくしたりするとより早く良い解にたどり着くかもしれません。"]},{"cell_type":"markdown","metadata":{"id":"i23WOLZYl2Zj"},"source":["最後に、`optuna.visualization.plot_param_importances`関数を紹介します。\n","この関数も最適化結果のstudyを渡すだけで利用することができます。\n","この関数は、最適化したハイパーパラメータに対して、目的関数の値に与えた影響の度合い（重要度）を計算して出力します。\n","\n","上で計算した`study_new`をもとに、パラメータの重要度を計算してみましょう。"]},{"cell_type":"code","execution_count":313,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"elapsed":2570,"status":"ok","timestamp":1602580562198,"user":{"displayName":"Hideaki Imamura","photoUrl":"","userId":"04696776684975772520"},"user_tz":-540},"id":"iSrWvfJpmc6o","outputId":"784b244e-2b3d-4ce5-87fc-1e7dddb229fa"},"outputs":[{"data":{"application/vnd.plotly.v1+json":{"config":{"plotlyServerURL":"https://plot.ly"},"data":[{"cliponaxis":false,"hovertemplate":["momentum (FloatDistribution): 0.03489313877290548<extra></extra>","activation_func (CategoricalDistribution): 0.14156991820093442<extra></extra>","hidden_dim (IntDistribution): 0.3542504191913008<extra></extra>","lr (FloatDistribution): 0.46928652383485936<extra></extra>"],"marker":{"color":"rgb(66,146,198)"},"orientation":"h","text":["0.03","0.14","0.35","0.47"],"textposition":"outside","type":"bar","x":[0.03489313877290548,0.14156991820093442,0.3542504191913008,0.46928652383485936],"y":["momentum","activation_func","hidden_dim","lr"]}],"layout":{"showlegend":false,"template":{"data":{"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"choropleth":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"choropleth"}],"contour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"contour"}],"contourcarpet":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"contourcarpet"}],"heatmap":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmap"}],"heatmapgl":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"heatmapgl"}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"histogram2d":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2d"}],"histogram2dcontour":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"histogram2dcontour"}],"mesh3d":[{"colorbar":{"outlinewidth":0,"ticks":""},"type":"mesh3d"}],"parcoords":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"parcoords"}],"pie":[{"automargin":true,"type":"pie"}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"scatter3d":[{"line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatter3d"}],"scattercarpet":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattercarpet"}],"scattergeo":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergeo"}],"scattergl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattergl"}],"scattermapbox":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scattermapbox"}],"scatterpolar":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolar"}],"scatterpolargl":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterpolargl"}],"scatterternary":[{"marker":{"colorbar":{"outlinewidth":0,"ticks":""}},"type":"scatterternary"}],"surface":[{"colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"type":"surface"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}]},"layout":{"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"autotypenumbers":"strict","coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]],"sequential":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]],"sequentialminus":[[0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1,"#f0f921"]]},"colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"geo":{"bgcolor":"white","lakecolor":"white","landcolor":"#E5ECF6","showlakes":true,"showland":true,"subunitcolor":"white"},"hoverlabel":{"align":"left"},"hovermode":"closest","mapbox":{"style":"light"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","gridwidth":2,"linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white"}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"ternary":{"aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"bgcolor":"#E5ECF6","caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"title":{"x":0.05},"xaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2},"yaxis":{"automargin":true,"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","zerolinewidth":2}}},"title":{"text":"Hyperparameter Importances"},"xaxis":{"title":{"text":"Importance for Objective Value"}},"yaxis":{"title":{"text":"Hyperparameter"}}}}},"metadata":{},"output_type":"display_data"}],"source":["optuna.visualization.plot_param_importances(study)"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"223KvKfAmoLL"},"source":["今回の目的関数に対しては、`lr`と`hidden_dim`が最も重要であり、`momentum`の寄与はほとんどないことがわかります。次に最適化するときは、例えば`momentum = 0.9`などと決め打ってやって、変数の数を減らすと早く最適化できるかもしれません。"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# 8. Optuna Dashboard\n","\n","実は、7節で行った可視化を全て自動で行い、Webインターフェイスで表示してくれるOptuna dashboardという便利なものがあります。この節ではOptuna dashboardの使い方を説明します。\n","\n","まず、次のようにOptuna dashboardをインストールします。"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: optuna-dashboard in /opt/homebrew/lib/python3.10/site-packages (0.8.1)\n","Collecting optuna-fast-fanova\n","  Downloading optuna-fast-fanova-0.0.4.tar.gz (30 kB)\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n","\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n","\u001b[?25hCollecting gunicorn\n","  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n","Requirement already satisfied: bottle in /opt/homebrew/lib/python3.10/site-packages (from optuna-dashboard) (0.12.25)\n","Requirement already satisfied: packaging in /opt/homebrew/lib/python3.10/site-packages (from optuna-dashboard) (23.0)\n","Requirement already satisfied: optuna>=2.4.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna-dashboard) (3.1.0.dev0)\n","Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (from optuna-dashboard) (1.1.2)\n","Requirement already satisfied: numpy in /opt/homebrew/lib/python3.10/site-packages (from optuna-fast-fanova) (1.23.5)\n","Requirement already satisfied: setuptools>=3.0 in /opt/homebrew/lib/python3.10/site-packages (from gunicorn) (67.2.0)\n","Requirement already satisfied: scipy>=1.7.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (1.8.1)\n","Requirement already satisfied: PyYAML in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (6.0)\n","Requirement already satisfied: colorlog in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (6.7.0)\n","Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (4.64.0)\n","Requirement already satisfied: alembic>=1.5.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (1.8.1)\n","Requirement already satisfied: cmaes>=0.9.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (0.9.1)\n","Requirement already satisfied: sqlalchemy>=1.3.0 in /opt/homebrew/lib/python3.10/site-packages (from optuna>=2.4.0->optuna-dashboard) (2.0.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->optuna-dashboard) (3.1.0)\n","Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn->optuna-dashboard) (1.1.0)\n","Requirement already satisfied: Mako in /opt/homebrew/lib/python3.10/site-packages (from alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (1.2.1)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/lib/python3.10/site-packages (from sqlalchemy>=1.3.0->optuna>=2.4.0->optuna-dashboard) (4.3.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/homebrew/lib/python3.10/site-packages (from Mako->alembic>=1.5.0->optuna>=2.4.0->optuna-dashboard) (2.1.1)\n","Building wheels for collected packages: optuna-fast-fanova\n","  Building wheel for optuna-fast-fanova (pyproject.toml) ... \u001b[?25lerror\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for optuna-fast-fanova \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m \u001b[31m[122 lines of output]\u001b[0m\n","  \u001b[31m   \u001b[0m /opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/setuptools/config/pyprojecttoml.py:108: _BetaConfiguration: Support for `[tool.setuptools]` in `pyproject.toml` is still *beta*.\n","  \u001b[31m   \u001b[0m   warnings.warn(msg, _BetaConfiguration)\n","  \u001b[31m   \u001b[0m running bdist_wheel\n","  \u001b[31m   \u001b[0m running build\n","  \u001b[31m   \u001b[0m running build_py\n","  \u001b[31m   \u001b[0m creating build\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-310\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m copying optuna_fast_fanova/_version.py -> build/lib.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m copying optuna_fast_fanova/__init__.py -> build/lib.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m copying optuna_fast_fanova/_evaluator.py -> build/lib.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-310/venv\n","  \u001b[31m   \u001b[0m creating build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2xetex.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2latex.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/readelf.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2odt_prepstyles.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2html4.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2html5.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2xml.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2odt.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2pseudoxml.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2s5.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2html.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rst2man.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m copying venv/bin/rstpep2html.py -> build/lib.macosx-12-arm64-cpython-310/venv/bin\n","  \u001b[31m   \u001b[0m running egg_info\n","  \u001b[31m   \u001b[0m writing optuna_fast_fanova.egg-info/PKG-INFO\n","  \u001b[31m   \u001b[0m writing dependency_links to optuna_fast_fanova.egg-info/dependency_links.txt\n","  \u001b[31m   \u001b[0m writing requirements to optuna_fast_fanova.egg-info/requires.txt\n","  \u001b[31m   \u001b[0m writing top-level names to optuna_fast_fanova.egg-info/top_level.txt\n","  \u001b[31m   \u001b[0m listing git files failed - pretending there aren't any\n","  \u001b[31m   \u001b[0m reading manifest file 'optuna_fast_fanova.egg-info/SOURCES.txt'\n","  \u001b[31m   \u001b[0m reading manifest template 'MANIFEST.in'\n","  \u001b[31m   \u001b[0m warning: no files found matching '*.pyx'\n","  \u001b[31m   \u001b[0m warning: no previously-included files found matching 'tools/*'\n","  \u001b[31m   \u001b[0m warning: no previously-included files found matching 'tests/*'\n","  \u001b[31m   \u001b[0m warning: no previously-included files found matching '.github/*'\n","  \u001b[31m   \u001b[0m adding license file 'LICENSE'\n","  \u001b[31m   \u001b[0m writing manifest file 'optuna_fast_fanova.egg-info/SOURCES.txt'\n","  \u001b[31m   \u001b[0m copying optuna_fast_fanova/_fanova.pyx -> build/lib.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m running build_ext\n","  \u001b[31m   \u001b[0m cythoning optuna_fast_fanova/_fanova.pyx to optuna_fast_fanova/_fanova.c\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m Error compiling Cython file:\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m ...\n","  \u001b[31m   \u001b[0m                 active_features[i] = True\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m         while active_nodes_index >= 0:\n","  \u001b[31m   \u001b[0m             node_index = active_nodes[active_nodes_index]\n","  \u001b[31m   \u001b[0m             node = self._tree.nodes + node_index\n","  \u001b[31m   \u001b[0m             search_spaces = active_search_spaces[active_nodes_index]\n","  \u001b[31m   \u001b[0m            ^\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.pyx:148:12: Assignment of Python object not allowed without gil\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m Error compiling Cython file:\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m ...\n","  \u001b[31m   \u001b[0m             if active_features[i] and subtree_active_feature[i]:\n","  \u001b[31m   \u001b[0m                 return True\n","  \u001b[31m   \u001b[0m         return False\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m     @cython.boundscheck(False)\n","  \u001b[31m   \u001b[0m     cdef (double, double) _get_marginalized_statistics(\n","  \u001b[31m   \u001b[0m         ^\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.pyx:122:9: Function declared nogil has Python locals or temporaries\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m Error compiling Cython file:\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m ...\n","  \u001b[31m   \u001b[0m                 active_features[i] = True\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m         while active_nodes_index >= 0:\n","  \u001b[31m   \u001b[0m             node_index = active_nodes[active_nodes_index]\n","  \u001b[31m   \u001b[0m             node = self._tree.nodes + node_index\n","  \u001b[31m   \u001b[0m             search_spaces = active_search_spaces[active_nodes_index]\n","  \u001b[31m   \u001b[0m                                                ^\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.pyx:148:48: Converting to Python object not allowed without gil\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m Error compiling Cython file:\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m ...\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m                 # If subtree starting from node splits on an active feature, push both child nodes.\n","  \u001b[31m   \u001b[0m                 if self._is_subtree_active(node_index, active_features) == 1:\n","  \u001b[31m   \u001b[0m                     active_nodes_index += 1\n","  \u001b[31m   \u001b[0m                     active_nodes[active_nodes_index] = node.left_child\n","  \u001b[31m   \u001b[0m                     active_search_spaces[active_nodes_index] = search_spaces\n","  \u001b[31m   \u001b[0m                                                               ^\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.pyx:169:63: Coercion from Python not allowed without the GIL\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m Error compiling Cython file:\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m ...\n","  \u001b[31m   \u001b[0m                     active_nodes[active_nodes_index] = node.left_child\n","  \u001b[31m   \u001b[0m                     active_search_spaces[active_nodes_index] = search_spaces\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m                     active_nodes_index += 1\n","  \u001b[31m   \u001b[0m                     active_nodes[active_nodes_index] = node.right_child\n","  \u001b[31m   \u001b[0m                     active_search_spaces[active_nodes_index] = search_spaces\n","  \u001b[31m   \u001b[0m                                                               ^\n","  \u001b[31m   \u001b[0m ------------------------------------------------------------\n","  \u001b[31m   \u001b[0m \n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.pyx:173:63: Coercion from Python not allowed without the GIL\n","  \u001b[31m   \u001b[0m building 'optuna_fast_fanova._fanova' extension\n","  \u001b[31m   \u001b[0m creating build/temp.macosx-12-arm64-cpython-310\n","  \u001b[31m   \u001b[0m creating build/temp.macosx-12-arm64-cpython-310/optuna_fast_fanova\n","  \u001b[31m   \u001b[0m clang -Wno-unused-result -Wsign-compare -Wunreachable-code -fno-common -dynamic -DNDEBUG -g -fwrapv -O3 -Wall -isysroot /Library/Developer/CommandLineTools/SDKs/MacOSX12.sdk -I/opt/homebrew/Cellar/python@3.10/3.10.10_1/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/numpy/core/include -I/opt/homebrew/opt/python@3.10/Frameworks/Python.framework/Versions/3.10/include/python3.10 -c optuna_fast_fanova/_fanova.c -o build/temp.macosx-12-arm64-cpython-310/optuna_fast_fanova/_fanova.o\n","  \u001b[31m   \u001b[0m optuna_fast_fanova/_fanova.c:1:2: error: Do not use this file, it is the result of a failed Cython compilation.\n","  \u001b[31m   \u001b[0m #error Do not use this file, it is the result of a failed Cython compilation.\n","  \u001b[31m   \u001b[0m  ^\n","  \u001b[31m   \u001b[0m 1 error generated.\n","  \u001b[31m   \u001b[0m error: command '/usr/bin/clang' failed with exit code 1\n","  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","\u001b[?25h\u001b[31m  ERROR: Failed building wheel for optuna-fast-fanova\u001b[0m\u001b[31m\n","\u001b[0mFailed to build optuna-fast-fanova\n","\u001b[31mERROR: Could not build wheels for optuna-fast-fanova, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -ubernetes-models-pfn (/opt/homebrew/lib/python3.10/site-packages)\u001b[0m\u001b[33m\n","\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install optuna-dashboard\n","!pip install optuna-fast-fanova gunicorn # Optuna dashboardの表示の高速化に役立つが、なくても構わない"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Optuna dashboardで表示するためには、Studyが何らかのStorageに永続化されている必要があります。今回は第6節で作った`./mnist_study.optuna`をそのまま使います。\n","\n","次のようなコードを実行することで、Optuna dashboardのサーバーを立ち上げることができます。\n","```python\n","import optuna_dashboard, optuna\n","optuna_dashboard.run_server(optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"./mnist_study.optuna\")))\n","```\n","しかしこれをそのままJupyter notebook内でやってしまうと、notebookをブロックしてしまってサーバーを落とすまで他に何もできなくなるので、Jupyter notebookでは次のようにします。"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["<string>:3: ExperimentalWarning: JournalStorage is experimental (supported from v3.1.0). The interface can change in the future.\n","Bottle v0.12.25 server starting up (using WSGIRefServer())...\n","Listening on http://localhost:8080/\n","Hit Ctrl-C to quit.\n","\n"]},{"ename":"ModuleNotFoundError","evalue":"No module named 'google.colab'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mセル88 を /Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y200sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m time\u001b[39m.\u001b[39msleep(\u001b[39m3\u001b[39m) \u001b[39m# サーバーが立ち上がるのを待つ。\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y200sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# Google Colab only\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y200sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m output\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yunzhuowang/optuna-hands-on/ja/Optuna_MNIST.ipynb#Y200sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m output\u001b[39m.\u001b[39mserve_kernel_port_as_window(port, path\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"]}],"source":["path = \"./mnist_study.optuna\"\n","port = 8080\n","\n","import subprocess\n","try:\n","    # 既にoptuna_dashboard_processが立ち上がっている場合、portが占有されているので先に落とす。\n","    optuna_dashboard_process.kill()\n","except NameError:\n","    pass\n","\n","optuna_dashboard_process = subprocess.Popen([\"python\", \"-c\", f\"\"\"\n","import optuna_dashboard, optuna\n","optuna_dashboard.run_server(optuna.storages.JournalStorage(optuna.storages.JournalFileStorage(\"{path}\")), port={port})\n","\"\"\"])\n","\n","import time\n","time.sleep(3) # サーバーが立ち上がるのを待つ。\n","\n","try:\n","    from google.colab import output\n","    output.serve_kernel_port_as_window(port, path='')\n","except ModuleNotFoundError:\n","    # Google Colabではない環境では何もしない\n","    pass"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["最も下に表示されたリンクをクリックしてください。Study名の一覧が表示され、先ほど設定した`distributed_study`を選択すると、様々な可視化を見ることができます。\n","\n","さらに、このOptuna dashboardの画面は一定時間ごとに自動更新されます。試しに"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!python optuna_mnist_distributed_example.py"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["をもう一度呼んで、optuna dashboardがどう変化するか見てみてください。"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"NROoj1y4T8C9"},"source":["## おわりに\n","\n","以上でOptunaのチュートリアルは終わりです。\n","\n","今回はPyTorchを使った簡単なニューラルネットワークでMNISTを学習することを題材として、Optunaの基本的な使い方から少し高度な機能までざっと紹介しました。\n","\n","今回は紹介できなかった優れたアルゴリズムや便利な可視化機能がまだまだ沢山あるので、ぜひ[ドキュメント](https://optuna.readthedocs.io/en/stable/index.html)を読んでみてくださいね。\n","Optunaが気に入った方は、ぜひ[GitHubページ](https://github.com/optuna/optuna)でスターを押してください！\n","\n","それでは、よいハイパラ最適化ライフを！"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"01_Optuna_Quick_Start_ja.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"},"vscode":{"interpreter":{"hash":"6ecdebf77f2ee3a47348d003f751c63e810ca996c1c68d1179f338200fa83b34"}}},"nbformat":4,"nbformat_minor":0}
